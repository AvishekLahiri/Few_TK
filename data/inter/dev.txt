The	O
rapid	O
development	O
of	O
high	Miscellaneous-term
-	Miscellaneous-term
throughput	Miscellaneous-term
technologies	O
has	O
enabled	O
the	O
generation	O
of	O
data	O
from	O
biological	O
or	O
disease	O
processes	O
that	O
span	O
multiple	O
layers	O
,	O
like	O
genomic	Miscellaneous-term
proteomic	Miscellaneous-term
or	O
metabolomic	Miscellaneous-term
data	O
,	O
and	O
further	O
pertain	O
to	O
multiple	O
sources	O
,	O
like	O
disease	O
subtypes	O
or	O
experimental	O
conditions	O
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
general	Miscellaneous-term
statistical	Miscellaneous-term
framework	Miscellaneous-term
based	O
on	O
Gaussian	O
graphical	O
models	O
for	O
horizontal	O
(	O
i	O
.	O
e	O
.	O

across	O
different	O
layers	O
containing	O
data	O
on	O
molecular	O
compartments	O
)	O
integration	O
of	O
information	O
in	O
such	O
datasets	Miscellaneous-term
.	O

We	O
use	O
a	O
combination	O
of	O
neighborhood	O
selection	O
and	O
group	O
-	O
penalized	O
regression	O
to	O
obtain	O
sparse	AI/ML/DL-term
estimates	AI/ML/DL-term
of	O
all	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

Following	O
this	O
,	O
we	O
develop	O
a	O
debiasing	Miscellaneous-term
technique	Miscellaneous-term
and	O
asymptotic	O
distributions	O
of	O
inter	Miscellaneous-term
-	Miscellaneous-term
layer	Miscellaneous-term
directed	Miscellaneous-term
edge	Miscellaneous-term
weights	Miscellaneous-term
that	O
utilize	O
already	O
computed	O
neighborhood	AI/ML/DL-term
selection	AI/ML/DL-term
coefficients	AI/ML/DL-term
for	O
nodes	O
in	O
the	O
upper	O
layer	O
.	O

Following	O
this	O
,	O
we	O
develop	O
a	O
debiasing	Miscellaneous-term
technique	Miscellaneous-term
and	O
asymptotic	O
distributions	O
of	O
inter	Miscellaneous-term
-	Miscellaneous-term
layer	Miscellaneous-term
directed	Miscellaneous-term
edge	Miscellaneous-term
weights	Miscellaneous-term
that	O
utilize	O
already	O
computed	O
neighborhood	AI/ML/DL-term
selection	AI/ML/DL-term
coefficients	AI/ML/DL-term
for	O
nodes	O
in	O
the	O
upper	O
layer	O
.	O

Subsequently	O
,	O
we	O
establish	O
global	O
and	O
simultaneous	O
testing	O
procedures	O
for	O
these	O
edge	Miscellaneous-term
weights	Miscellaneous-term
.	O

Performance	O
of	O
the	O
proposed	O
methodology	O
is	O
evaluated	O
on	O
synthetic	Miscellaneous-term
and	O
real	Miscellaneous-term
data	Miscellaneous-term
.	O

Although	O
various	O
distributed	O
machine	O
learning	O
schemes	O
have	O
been	O
proposed	O
recently	O
for	O
purely	O
linear	O
models	O
and	O
fully	O
nonparametric	O
models	O
little	O
attention	O
has	O
been	O
paid	O
to	O
distributed	AI/ML/DL-term
optimization	AI/ML/DL-term
for	O
semi	O
-	O
parametric	O
models	O
with	O
multiple	O
structures	O
(	O
e	O
.	O
g	O
.	O
sparsity	AI/ML/DL-term
linearity	AI/ML/DL-term
and	O
nonlinearity	AI/ML/DL-term
.	O

With	O
the	O
proposed	O
method	O
,	O
we	O
theoretically	O
prove	O
that	O
our	O
global	O
parametric	O
estimator	O
can	O
achieve	O
the	O
optimal	AI/ML/DL-term
parametric	AI/ML/DL-term
rate	AI/ML/DL-term
in	O
our	O
semi	O
-	O
parametric	O
model	O
given	O
an	O
appropriate	O
partition	O
on	O
the	O
total	O
data	O
.	O

Specifically	O
,	O
the	O
choice	O
of	O
data	O
partition	O
relies	O
on	O
the	O
underlying	O
smoothness	O
of	O
the	O
nonparametric	AI/ML/DL-term
component	AI/ML/DL-term
and	O
it	O
is	O
adaptive	O
to	O
the	O
sparsity	AI/ML/DL-term
parameter	AI/ML/DL-term
.	O

Finally	O
,	O
some	O
simulated	O
experiments	O
are	O
carried	O
out	O
to	O
illustrate	O
the	O
empirical	O
performances	O
of	O
our	O
debiased	O
technique	O
under	O
the	O
distributed	AI/ML/DL-term
setting	AI/ML/DL-term
.	O

In	O
increasingly	O
many	O
settings	O
,	O
data	Miscellaneous-term
sets	Miscellaneous-term
consist	O
of	O
multiple	O
samples	O
from	O
a	O
population	AI/ML/DL-term
of	AI/ML/DL-term
networks	AI/ML/DL-term
with	O
vertices	O
aligned	O
across	O
networks	O
;	O
for	O
example	O
,	O
brain	O
connectivity	O
networks	O
in	O
neuroscience	O
.	O

In	O
increasingly	O
many	O
settings	O
,	O
data	Miscellaneous-term
sets	Miscellaneous-term
consist	O
of	O
multiple	O
samples	O
from	O
a	O
population	AI/ML/DL-term
of	AI/ML/DL-term
networks	AI/ML/DL-term
with	O
vertices	O
aligned	O
across	O
networks	O
;	O
for	O
example	O
,	O
brain	O
connectivity	O
networks	O
in	O
neuroscience	O
.	O

Our	O
approach	O
exploits	O
the	O
shared	O
mean	O
structure	O
to	O
denoise	AI/ML/DL-term
edge	O
-	O
level	O
measurements	O
of	O
the	O
observed	O
networks	O
and	O
estimate	O
the	O
underlying	O
population	O
-	O
level	O
parameters	O
.	O

We	O
also	O
explore	O
the	O
extent	O
to	O
which	O
edge	O
-	O
level	O
errors	O
influence	O
estimation	O
and	O
downstream	O
inference	AI/ML/DL-term
.	O

We	O
propose	O
algorithms	Miscellaneous-term
for	O
approximate	O
filtering	O
and	O
smoothing	O
in	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
Factorial	O
hidden	O
Markov	O
models	O
.	O

We	O
propose	O
algorithms	Miscellaneous-term
for	O
approximate	O
filtering	O
and	O
smoothing	O
in	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
Factorial	O
hidden	O
Markov	O
models	O
.	O

A	O
key	O
step	O
in	O
the	O
analysis	O
is	O
to	O
quantify	O
the	O
error	O
introduced	O
by	O
localizing	O
the	O
likelihood	O
function	O
in	O
a	O
Bayes	AI/ML/DL-term
'	AI/ML/DL-term
rule	AI/ML/DL-term
update	AI/ML/DL-term
.	O

We	O
demonstrate	O
the	O
new	O
algorithms	Miscellaneous-term
on	O
synthetic	O
examples	O
and	O
a	O
London	O
Underground	O
passenger	O
flow	O
problem	O
where	O
the	O
factor	O
graph	O
is	O
effectively	O
given	O
by	O
the	O
train	O
network	O
.	O

We	O
consider	O
the	O
classic	O
supervised	O
learning	O
problem	O
where	O
a	O
continuous	O
non	O
-	O
negative	O
random	O
label	O
$	O
Y	O
$	O
(	O
e	O
.	O
g	O
.	O
a	O
random	O
duration	O
)	O
is	O
to	O
be	O
predicted	O
based	O
upon	O
observing	O
a	O
random	AI/ML/DL-term
vector	AI/ML/DL-term
$	O
X	O
$	O
valued	O
in	O
$\	O
mathbb	O
{	O
R	O
}^	O
d	O
$	O
with	O
$	O
d	O
\	O
geq	O
1	O
$	O
by	O
means	O
of	O
a	O
regression	O
rule	O
with	O
minimum	O
least	O
square	O
error	O
.	O

In	O
various	O
applications	O
,	O
ranging	O
from	O
industrial	O
quality	O
control	O
to	O
public	O
health	O
through	O
credit	O
risk	O
analysis	O
for	O
instance	O
,	O
training	AI/ML/DL-term
observations	AI/ML/DL-term
can	O
be	O
right	O
censored	O
,	O
meaning	O
that	O
,	O
rather	O
than	O
on	O
independent	O
copies	O
of	O
$(	O
X	O
,	O
Y	O
)$,	O
statistical	O
learning	O
relies	O
on	O
a	O
collection	O
of	O
$	O
n	O
\	O
geq	O
1	O
$	O
independent	O
realizations	O
of	O
the	O
triplet	Miscellaneous-term
$(	O
X	O
,	O
\;	O
\	O
min	O
\{	O
Y	O
,\;	O
C	O
\},\;	O
\	O
delta	O
)$,	O
where	O
$	O
C	O
$	O
is	O
a	O
nonnegative	O
random	O
variable	O
with	O
unknown	O
distribution	O
modelling	O
censoring	O
and	O
$\	O
delta	O
=\	O
mathbb	O
{	O
I	O
}\{	O
Y	O
\	O
leq	O
C	O
\}$	O
indicates	O
whether	O
the	O
duration	O
is	O
right	O
censored	O
or	O
not	O
.	O

In	O
various	O
applications	O
,	O
ranging	O
from	O
industrial	O
quality	O
control	O
to	O
public	O
health	O
through	O
credit	O
risk	O
analysis	O
for	O
instance	O
,	O
training	AI/ML/DL-term
observations	AI/ML/DL-term
can	O
be	O
right	O
censored	O
,	O
meaning	O
that	O
,	O
rather	O
than	O
on	O
independent	O
copies	O
of	O
$(	O
X	O
,	O
Y	O
)$,	O
statistical	O
learning	O
relies	O
on	O
a	O
collection	O
of	O
$	O
n	O
\	O
geq	O
1	O
$	O
independent	O
realizations	O
of	O
the	O
triplet	Miscellaneous-term
$(	O
X	O
,	O
\;	O
\	O
min	O
\{	O
Y	O
,\;	O
C	O
\},\;	O
\	O
delta	O
)$,	O
where	O
$	O
C	O
$	O
is	O
a	O
nonnegative	O
random	O
variable	O
with	O
unknown	O
distribution	O
modelling	O
censoring	O
and	O
$\	O
delta	O
=\	O
mathbb	O
{	O
I	O
}\{	O
Y	O
\	O
leq	O
C	O
\}$	O
indicates	O
whether	O
the	O
duration	O
is	O
right	O
censored	O
or	O
not	O
.	O

It	O
is	O
established	O
,	O
under	O
mild	O
conditions	O
,	O
that	O
the	O
learning	AI/ML/DL-term
rate	AI/ML/DL-term
of	O
minimizers	O
of	O
this	O
biased	AI/ML/DL-term
/	AI/ML/DL-term
weighted	AI/ML/DL-term
empirical	AI/ML/DL-term
risk	AI/ML/DL-term
functional	AI/ML/DL-term
is	O
of	O
order	O
$	O
O_	O
{\	O
mathbb	O
{	O
P	O
}}(\	O
sqrt	O
{\	O
log	O
(	O
n	O
)/	O
n	O
})$	O
when	O
ignoring	O
model	AI/ML/DL-term
bias	AI/ML/DL-term
issues	O
inherent	O
to	O
plug	O
-	O
in	O
estimation	O
,	O
as	O
can	O
be	O
attained	O
in	O
absence	O
of	O
censoring	O
.	O

The	O
first	O
is	O
how	O
to	O
directly	O
design	O
a	O
neural	O
network	O
with	O
inherent	AI/ML/DL-term
interpretability	AI/ML/DL-term
rather	O
than	O
giving	O
post	O
-	O
hoc	O
explanations	O
of	O
a	O
black	Miscellaneous-term
-	Miscellaneous-term
box	Miscellaneous-term
model	Miscellaneous-term
.	O

The	O
first	O
is	O
how	O
to	O
directly	O
design	O
a	O
neural	O
network	O
with	O
inherent	AI/ML/DL-term
interpretability	AI/ML/DL-term
rather	O
than	O
giving	O
post	O
-	O
hoc	O
explanations	O
of	O
a	O
black	Miscellaneous-term
-	Miscellaneous-term
box	Miscellaneous-term
model	Miscellaneous-term
.	O

To	O
address	O
these	O
two	O
challenges	O
,	O
we	O
design	O
a	O
novel	O
neural	O
network	O
which	O
is	O
a	O
differentiable	O
reformulation	O
of	O
the	O
vanilla	O
$	O
k	O
$-	O
means	O
called	O
inTerpretable	AI/ML/DL-technique
nEuraL	AI/ML/DL-technique
cLustering	AI/ML/DL-technique
(	AI/ML/DL-technique
TELL	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

First	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
most	O
existing	O
XAI	O
works	O
focus	O
on	O
supervised	AI/ML/DL-term
learning	AI/ML/DL-term
paradigms	O
.	O

This	O
work	O
is	O
one	O
of	O
the	O
few	O
XAI	O
studies	O
on	O
unsupervised	AI/ML/DL-term
learning	AI/ML/DL-term
in	O
particular	O
,	O
data	O
clustering	O
.	O

Second	O
,	O
TELL	AI/ML/DL-technique
is	O
an	O
interpretable	O
,	O
or	O
the	O
so	O
-	O
called	O
intrinsically	O
explainable	O
and	O
transparent	O
model	O
.	O

In	O
contrast	O
,	O
most	O
existing	O
XAI	O
studies	O
resort	O
to	O
various	O
means	O
for	O
understanding	O
a	O
black	Miscellaneous-term
-	Miscellaneous-term
box	Miscellaneous-term
model	Miscellaneous-term
with	O
post	O
-	O
hoc	O
explanations	O
.	O

Third	O
,	O
from	O
the	O
view	O
of	O
data	O
clustering	O
TELL	AI/ML/DL-technique
possesses	O
many	O
properties	O
highly	O
desired	O
by	O
$	O
k	O
$-	O
means	O
including	O
but	O
not	O
limited	O
to	O
online	O
clustering	O
plug	O
-	O
and	O
-	O
play	O
module	O
parallel	O
computing	O
and	O
provable	O
convergence	O
.	O

Extensive	O
experiments	O
show	O
that	O
our	O
method	O
achieves	O
superior	O
performance	O
comparing	O
with	O
14	O
clustering	O
approaches	O
on	O
three	O
challenging	O
data	Miscellaneous-term
sets	Miscellaneous-term
.	O

However	O
,	O
existing	O
implementations	O
of	O
MLN	O
models	O
are	O
limited	O
to	O
small	O
datasets	Miscellaneous-term
due	O
to	O
the	O
non	O
-	O
conjugacy	O
of	O
the	O
multinomial	O
and	O
logistic	O
-	O
normal	O
distributions	O
.	O

Motivated	O
by	O
the	O
need	O
to	O
develop	O
efficient	O
inference	AI/ML/DL-term
for	O
Bayesian	O
MLN	O
models	O
we	O
develop	O
two	O
key	O
ideas	O
.	O

First	O
,	O
we	O
develop	O
the	O
class	O
of	O
Marginally	AI/ML/DL-technique
Latent	AI/ML/DL-technique
Matrix	AI/ML/DL-technique
-	AI/ML/DL-technique
T	AI/ML/DL-technique
Process	AI/ML/DL-technique
(	AI/ML/DL-technique
Marginally	AI/ML/DL-technique
LTP	AI/ML/DL-technique
)	AI/ML/DL-technique
models	AI/ML/DL-technique
.	O

We	O
demonstrate	O
that	O
many	O
popular	O
MLN	O
models	O
including	O
those	O
with	O
latent	AI/ML/DL-term
linear	AI/ML/DL-term
non	AI/ML/DL-term
-	AI/ML/DL-term
linear	AI/ML/DL-term
and	O
dynamic	AI/ML/DL-term
linear	AI/ML/DL-term
structure	AI/ML/DL-term
are	O
special	O
cases	O
of	O
this	O
class	O
.	O

Second	O
,	O
we	O
develop	O
an	O
efficient	O
inference	AI/ML/DL-term
scheme	O
for	O
Marginally	AI/ML/DL-technique
LTP	AI/ML/DL-technique
models	AI/ML/DL-technique
with	O
specific	O
accelerations	O
for	O
the	O
MLN	O
subclass	O
.	O

Second	O
,	O
we	O
develop	O
an	O
efficient	O
inference	AI/ML/DL-term
scheme	O
for	O
Marginally	AI/ML/DL-technique
LTP	AI/ML/DL-technique
models	AI/ML/DL-technique
with	O
specific	O
accelerations	O
for	O
the	O
MLN	O
subclass	O
.	O

Through	O
application	O
to	O
MLN	O
models	O
we	O
demonstrate	O
that	O
our	O
inference	AI/ML/DL-term
scheme	O
are	O
both	O
highly	O
accurate	O
and	O
often	O
4	O
-	O
5	O
orders	O
of	O
magnitude	O
faster	O
than	O
MCMC	O
.	O

The	O
neural	O
networks	O
are	O
usually	O
trained	O
by	O
tuning	O
the	O
weights	O
to	O
directly	O
minimise	O
a	O
given	O
loss	AI/ML/DL-term
function	AI/ML/DL-term
.	O

It	O
is	O
argued	O
that	O
using	O
targets	O
for	O
training	O
addresses	O
the	O
problem	O
of	O
exploding	O
gradients	O
by	O
a	O
process	O
which	O
we	O
call	O
cascade	AI/ML/DL-technique
untangling	AI/ML/DL-technique
and	O
makes	O
the	O
loss	AI/ML/DL-term
-	AI/ML/DL-term
function	AI/ML/DL-term
surface	AI/ML/DL-term
training	AI/ML/DL-term
to	O
traverse	O
,	O
and	O
so	O
leads	O
to	O
easier	O
,	O
faster	O
training	O
,	O
and	O
also	O
potentially	O
better	O
generalisation	O
,	O
of	O
the	O
neural	O
network	O
.	O

It	O
is	O
argued	O
that	O
using	O
targets	O
for	O
training	O
addresses	O
the	O
problem	O
of	O
exploding	O
gradients	O
by	O
a	O
process	O
which	O
we	O
call	O
cascade	AI/ML/DL-technique
untangling	AI/ML/DL-technique
and	O
makes	O
the	O
loss	AI/ML/DL-term
-	AI/ML/DL-term
function	AI/ML/DL-term
surface	AI/ML/DL-term
training	AI/ML/DL-term
to	O
traverse	O
,	O
and	O
so	O
leads	O
to	O
easier	O
,	O
faster	O
training	O
,	O
and	O
also	O
potentially	O
better	O
generalisation	O
,	O
of	O
the	O
neural	O
network	O
.	O

It	O
also	O
allows	O
for	O
easier	O
learning	O
of	O
deeper	O
and	O
recurrent	AI/ML/DL-term
network	AI/ML/DL-term
structures	AI/ML/DL-term
.	O

When	O
data	O
is	O
plentiful	O
,	O
the	O
test	AI/ML/DL-term
loss	AI/ML/DL-term
achieved	O
by	O
well	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
neural	O
networks	O
scales	O
as	O
a	O
power	O
-	O
law	O
$	O
L	O
\	O
propto	O
N	O
^{-\	O
alpha	O
}$	O
in	O
the	O
number	O
of	O
network	AI/ML/DL-term
parameters	AI/ML/DL-term
$	O
N	O
$.	O

The	O
scaling	O
law	O
can	O
be	O
explained	O
if	O
neural	O
models	O
are	O
effectively	O
just	O
performing	O
regression	O
on	O
a	O
data	AI/ML/DL-term
manifold	AI/ML/DL-term
of	O
intrinsic	O
dimension	O
$	O
d	O
$.	O

This	O
simple	O
theory	O
predicts	O
that	O
the	O
scaling	AI/ML/DL-term
exponents	AI/ML/DL-term
$\	O
alpha	O
\	O
approx	O
4	O
/	O
d	O
$	O
for	O
cross	O
-	O
entropy	O
and	O
mean	O
-	O
squared	O
error	O
losses	O
.	O

We	O
confirm	O
the	O
theory	O
by	O
independently	O
measuring	O
the	O
intrinsic	O
dimension	O
and	O
the	O
scaling	O
exponents	O
in	O
a	O
teacher	AI/ML/DL-term
/	AI/ML/DL-term
student	AI/ML/DL-term
framework	AI/ML/DL-term
where	O
we	O
can	O
study	O
a	O
variety	O
of	O
$	O
d	O
$	O
and	O
$\	O
alpha	O
$	O
by	O
dialing	O
the	O
properties	O
of	O
random	O
teacher	O
networks	O
.	O

This	O
work	O
studies	O
finite	AI/ML/DL-term
-	AI/ML/DL-term
sample	AI/ML/DL-term
properties	AI/ML/DL-term
of	O
the	O
risk	O
of	O
the	O
minimum	O
-	O
norm	O
interpolating	O
predictor	O
in	O
high	O
-	O
dimensional	O
regression	O
models	O
.	O

If	O
the	O
effective	O
rank	O
of	O
the	O
covariance	O
matrix	O
$\	O
Sigma	O
$	O
of	O
the	O
$	O
p	O
$	O
regression	AI/ML/DL-term
features	AI/ML/DL-term
is	O
much	O
larger	O
than	O
the	O
sample	AI/ML/DL-term
size	AI/ML/DL-term
$	O
n	O
$,	O
we	O
show	O
that	O
the	O
min	O
-	O
norm	O
interpolating	O
predictor	O
is	O
not	O
desirable	O
,	O
as	O
its	O
risk	O
approaches	O
the	O
risk	O
of	O
trivially	O
predicting	O
the	O
response	O
by	O
0	O
.	O

However	O
,	O
our	O
detailed	O
finite	O
-	O
sample	O
analysis	O
reveals	O
,	O
surprisingly	O
,	O
that	O
this	O
behavior	O
is	O
not	O
present	O
when	O
the	O
regression	AI/ML/DL-term
response	AI/ML/DL-term
and	O
the	O
features	AI/ML/DL-term
are	O
jointly	O
low	O
-	O
dimensional	O
following	O
a	O
widely	O
used	O
factor	O
regression	O
model	O
.	O

Within	O
this	O
popular	O
model	O
class	O
,	O
and	O
when	O
the	O
effective	O
rank	O
of	O
$\	O
Sigma	O
$	O
is	O
smaller	O
than	O
$	O
n	O
$,	O
while	O
still	O
allowing	O
for	O
$	O
p	O
\	O
gg	O
n	O
$,	O
both	O
the	O
bias	AI/ML/DL-term
and	O
the	O
variance	AI/ML/DL-term
terms	O
of	O
the	O
excess	O
risk	O
can	O
be	O
controlled	O
,	O
and	O
the	O
risk	O
of	O
the	O
minimum	O
-	O
norm	O
interpolating	O
predictor	O
approaches	O
optimal	O
benchmarks	O
.	O

Moreover	O
,	O
through	O
a	O
detailed	O
analysis	O
of	O
the	O
bias	AI/ML/DL-term
term	O
,	O
we	O
exhibit	O
model	O
classes	O
under	O
which	O
our	O
upper	O
bound	O
upper	O
bound	O
s	O
risk	O
approaches	O
zero	O
,	O
while	O
the	O
corresponding	O
upper	O
bound	O
in	O
the	O
recent	O
work	O
arXiv	O
:	O
1906	O
.	O
11300	O
diverges	O
.	O

Furthermore	O
,	O
we	O
show	O
that	O
the	O
minimum	O
-	O
norm	O
interpolating	O
predictor	O
analyzed	O
under	O
the	O
factor	O
regression	O
model	O
despite	O
being	O
model	AI/ML/DL-term
-	AI/ML/DL-term
agnostic	AI/ML/DL-term
and	O
devoid	O
of	O
tuning	O
parameters	O
,	O
can	O
have	O
similar	O
risk	O
to	O
predictors	O
based	O
on	O
principal	O
components	O
regression	O
and	O
ridge	O
regression	O
and	O
can	O
improve	O
over	O
LASSO	O
based	O
predictors	O
in	O
the	O
high	O
-	O
dimensional	O
regime	O
.	O

We	O
then	O
find	O
optimal	O
policies	O
for	O
the	O
approximate	O
model	O
and	O
we	O
rigorously	O
establish	O
near	O
optimality	O
of	O
the	O
constructed	O
finite	O
window	O
control	O
policies	O
in	O
POMDPs	O
under	O
mild	O
non	O
-	O
linear	O
filter	O
stability	O
conditions	O
and	O
the	O
assumption	O
that	O
the	O
measurement	O
and	O
action	O
sets	O
are	O
finite	O
(	O
and	O
the	O
state	AI/ML/DL-term
space	AI/ML/DL-term
is	O
real	O
vector	O
valued	O
).	O

We	O
propose	O
a	O
theoretical	Miscellaneous-term
framework	Miscellaneous-term
for	O
approximate	O
planning	O
and	O
learning	O
in	O
partially	O
observed	O
systems	O
.	O

Our	O
framework	O
is	O
based	O
on	O
the	O
fundamental	O
notion	O
of	O
information	AI/ML/DL-term
state	AI/ML/DL-term
.	O

We	O
provide	O
two	O
definitions	O
of	O
information	AI/ML/DL-term
state	AI/ML/DL-term
--	O
i	O
)	O
a	O
function	O
of	O
history	O
which	O
is	O
sufficient	O
to	O
compute	O
the	O
expected	O
reward	O
and	O
predict	O
its	O
next	O
value	O
;	O
ii	O
)	O
a	O
function	O
of	O
the	O
history	O
which	O
can	O
be	O
recursively	O
updated	O
and	O
is	O
sufficient	O
to	O
compute	O
the	O
expected	O
reward	O
and	O
predict	O
the	O
next	O
observation	O
.	O

An	O
information	AI/ML/DL-term
state	AI/ML/DL-term
always	O
leads	O
to	O
a	O
dynamic	O
programming	O
decomposition	O
.	O

Our	O
key	O
result	O
is	O
to	O
show	O
that	O
if	O
a	O
function	O
of	O
the	O
history	O
(	O
called	O
AIS	O
approximately	O
satisfies	O
the	O
properties	O
of	O
the	O
information	AI/ML/DL-term
state	AI/ML/DL-term
then	O
there	O
is	O
a	O
corresponding	O
approximate	O
dynamic	O
program	O
.	O

We	O
present	O
AIS	AI/ML/DL-technique
based	AI/ML/DL-technique
multi	AI/ML/DL-technique
-	AI/ML/DL-technique
time	AI/ML/DL-technique
scale	AI/ML/DL-technique
policy	AI/ML/DL-technique
gradient	AI/ML/DL-technique
algorithms	AI/ML/DL-technique
and	O
detailed	O
numerical	Miscellaneous-term
experiments	Miscellaneous-term
with	O
low	O
,	O
moderate	O
and	O
high	O
dimensional	O
environments	O
.	O

We	O
present	O
AIS	AI/ML/DL-technique
based	AI/ML/DL-technique
multi	AI/ML/DL-technique
-	AI/ML/DL-technique
time	AI/ML/DL-technique
scale	AI/ML/DL-technique
policy	AI/ML/DL-technique
gradient	AI/ML/DL-technique
algorithms	AI/ML/DL-technique
and	O
detailed	O
numerical	Miscellaneous-term
experiments	Miscellaneous-term
with	O
low	O
,	O
moderate	O
and	O
high	O
dimensional	O
environments	O
.	O

Sparse	O
principal	O
component	O
analysis	O
(	O
PCA	O
)	O
is	O
a	O
popular	O
dimensionality	O
reduction	O
technique	O
for	O
obtaining	O
principal	AI/ML/DL-term
components	AI/ML/DL-term
which	O
are	O
linear	O
combinations	O
of	O
a	O
small	O
subset	O
of	O
the	O
original	O
features	O
.	O

Existing	O
approaches	O
cannot	O
supply	O
certifiably	O
optimal	AI/ML/DL-term
principal	AI/ML/DL-term
components	AI/ML/DL-term
with	O
more	O
than	O
$	O
p	O
=	O
100s	O
$	O
of	O
variables	O
.	O

Using	O
real	O
-	O
world	O
financial	O
and	O
medical	O
data	O
sets	O
,	O
we	O
illustrate	O
our	O
approach	O
'	O
s	O
ability	O
to	O
derive	O
interpretable	AI/ML/DL-term
principal	AI/ML/DL-term
components	AI/ML/DL-term
tractably	O
at	O
scale	O
.	O

We	O
further	O
propose	O
a	O
generalization	O
of	O
these	O
classifiers	O
based	O
on	O
the	O
idea	O
of	O
grouping	O
of	O
variables	Miscellaneous-term
.	O

Numerical	Miscellaneous-term
experiments	Miscellaneous-term
with	O
a	O
variety	O
of	O
simulated	O
examples	O
as	O
well	O
as	O
an	O
extensive	O
analysis	O
of	O
benchmark	O
data	O
sets	O
from	O
three	O
different	O
databases	O
exhibit	O
advantages	O
of	O
the	O
proposed	O
methods	O
.	O

We	O
propose	O
a	O
novel	O
method	O
for	O
training	O
deep	O
neural	O
networks	O
that	O
are	O
capable	O
of	O
interpolation	O
that	O
is	O
,	O
driving	O
the	O
empirical	AI/ML/DL-term
loss	AI/ML/DL-term
to	O
zero	O
.	O

At	O
each	O
iteration	Miscellaneous-term
our	O
method	O
constructs	O
a	O
stochastic	O
approximation	O
of	O
the	O
learning	AI/ML/DL-term
objective	AI/ML/DL-term
.	O

At	O
each	O
iteration	Miscellaneous-term
our	O
method	O
constructs	O
a	O
stochastic	O
approximation	O
of	O
the	O
learning	AI/ML/DL-term
objective	AI/ML/DL-term
.	O

Our	O
bundle	O
contains	O
a	O
constant	O
function	O
that	O
lower	O
bounds	O
the	O
empirical	AI/ML/DL-term
loss	AI/ML/DL-term
.	O

This	O
enables	O
us	O
to	O
compute	O
an	O
automatic	O
adaptive	AI/ML/DL-term
learning	AI/ML/DL-term
rate	AI/ML/DL-term
thereby	O
providing	O
an	O
accurate	O
solution	O
.	O

The	O
use	O
of	O
these	O
additional	O
approximations	O
makes	O
our	O
method	O
significantly	O
more	O
robust	O
to	O
its	O
hyperparameters	AI/ML/DL-term
.	O

Based	O
on	O
its	O
desirable	O
empirical	O
properties	O
,	O
we	O
term	O
our	O
method	O
Bundle	AI/ML/DL-technique
Optimisation	AI/ML/DL-technique
for	AI/ML/DL-technique
Robust	AI/ML/DL-technique
and	AI/ML/DL-technique
Accurate	AI/ML/DL-technique
Training	AI/ML/DL-technique
(	AI/ML/DL-technique
BORAT	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

In	O
order	O
to	O
operationalise	O
BORAT	AI/ML/DL-technique
we	O
design	O
a	O
novel	O
algorithm	Miscellaneous-term
for	O
optimising	O
the	O
bundle	O
approximation	O
efficiently	O
at	O
each	O
iteration	O
.	O

In	O
order	O
to	O
operationalise	O
BORAT	AI/ML/DL-technique
we	O
design	O
a	O
novel	O
algorithm	Miscellaneous-term
for	O
optimising	O
the	O
bundle	O
approximation	O
efficiently	O
at	O
each	O
iteration	O
.	O

We	O
establish	O
the	O
theoretical	O
convergence	O
of	O
BORAT	AI/ML/DL-technique
in	O
both	O
convex	O
and	O
non	O
-	O
convex	O
settings	O
.	O

Using	O
standard	O
publicly	O
available	O
data	Miscellaneous-term
sets	Miscellaneous-term
we	O
provide	O
a	O
thorough	O
comparison	O
of	O
BORAT	AI/ML/DL-technique
to	O
other	O
single	O
hyperparameter	O
optimisation	O
algorithms	O
.	O

Using	O
standard	O
publicly	O
available	O
data	Miscellaneous-term
sets	Miscellaneous-term
we	O
provide	O
a	O
thorough	O
comparison	O
of	O
BORAT	AI/ML/DL-technique
to	O
other	O
single	O
hyperparameter	O
optimisation	O
algorithms	O
.	O

Our	O
experiments	O
demonstrate	O
BORAT	AI/ML/DL-technique
matches	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
generalisation	O
performance	O
for	O
these	O
methods	O
and	O
is	O
the	O
most	O
robust	O
.	O

Our	O
experiments	O
demonstrate	O
BORAT	AI/ML/DL-technique
matches	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
generalisation	O
performance	O
for	O
these	O
methods	O
and	O
is	O
the	O
most	O
robust	O
.	O

In	O
this	O
work	O
,	O
we	O
present	O
a	O
class	O
of	O
tuning	AI/ML/DL-technique
-	AI/ML/DL-technique
free	AI/ML/DL-technique
PnP	AI/ML/DL-technique
proximal	AI/ML/DL-technique
algorithms	AI/ML/DL-technique
that	O
can	O
determine	O
parameters	O
such	O
as	O
denoising	AI/ML/DL-term
strength	AI/ML/DL-term
termination	O
time	O
,	O
and	O
other	O
optimization	AI/ML/DL-term
-	AI/ML/DL-term
specific	AI/ML/DL-term
parameters	AI/ML/DL-term
automatically	O
.	O

In	O
this	O
work	O
,	O
we	O
present	O
a	O
class	O
of	O
tuning	AI/ML/DL-technique
-	AI/ML/DL-technique
free	AI/ML/DL-technique
PnP	AI/ML/DL-technique
proximal	AI/ML/DL-technique
algorithms	AI/ML/DL-technique
that	O
can	O
determine	O
parameters	O
such	O
as	O
denoising	AI/ML/DL-term
strength	AI/ML/DL-term
termination	O
time	O
,	O
and	O
other	O
optimization	AI/ML/DL-term
-	AI/ML/DL-term
specific	AI/ML/DL-term
parameters	AI/ML/DL-term
automatically	O
.	O

We	O
demonstrate	O
,	O
through	O
rigorous	O
numerical	O
and	O
visual	O
experiments	O
,	O
that	O
the	O
learned	O
policy	O
can	O
customize	O
parameters	AI/ML/DL-term
to	O
different	O
settings	O
,	O
and	O
is	O
often	O
more	O
efficient	O
and	O
effective	O
than	O
existing	O
handcrafted	O
criteria	O
.	O

Moreover	O
,	O
we	O
discuss	O
several	O
practical	O
considerations	O
of	O
PnP	O
denoisers	O
which	O
together	O
with	O
our	O
learned	O
policy	O
yield	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
.	O

High	Miscellaneous-term
resolution	Miscellaneous-term
geospatial	Miscellaneous-term
data	Miscellaneous-term
are	O
challenging	O
because	O
standard	O
geostatistical	O
models	O
based	O
on	O
Gaussian	O
processes	O
are	O
known	O
to	O
not	O
scale	O
to	O
large	O
data	O
sizes	O
.	O

Our	O
Bayesian	AI/ML/DL-technique
multivariate	AI/ML/DL-technique
regression	AI/ML/DL-technique
models	AI/ML/DL-technique
based	O
on	O
spatial	O
multivariate	O
trees	O
(	O
SpamTrees	O
)	O
achieve	O
scalability	Miscellaneous-term
via	O
conditional	O
independence	O
assumptions	O
on	O
latent	O
random	O
effects	O
following	O
a	O
treed	O
directed	O
acyclic	O
graph	O
.	O

Our	O
Bayesian	AI/ML/DL-technique
multivariate	AI/ML/DL-technique
regression	AI/ML/DL-technique
models	AI/ML/DL-technique
based	O
on	O
spatial	O
multivariate	O
trees	O
(	O
SpamTrees	O
)	O
achieve	O
scalability	Miscellaneous-term
via	O
conditional	O
independence	O
assumptions	O
on	O
latent	O
random	O
effects	O
following	O
a	O
treed	O
directed	O
acyclic	O
graph	O
.	O

Information	O
-	O
theoretic	O
arguments	O
and	O
considerations	O
on	O
computational	Miscellaneous-term
efficiency	Miscellaneous-term
guide	O
the	O
construction	O
of	O
the	O
tree	O
and	O
the	O
related	O
efficient	O
sampling	O
algorithms	O
in	O
imbalanced	O
multivariate	O
settings	O
.	O

In	O
addition	O
to	O
simulated	O
data	O
examples	O
,	O
we	O
illustrate	O
SpamTrees	O
using	O
a	O
large	O
climate	O
data	O
set	O
which	O
combines	O
satellite	O
data	O
with	O
land	O
-	O
based	O
station	O
data	O
.	O
Software	Miscellaneous-term
.	O

Software	O
and	O
source	Miscellaneous-term
code	Miscellaneous-term
are	O
available	O
on	O
CRAN	O
at	O
https	O
://	O
CRAN	O
.	O
R	O
-	O
project	O
.	O
org	O
/	O
package	O
=	O
spamtree	O
.	O

This	O
paper	O
proposes	O
a	O
novel	O
multiscale	O
representation	O
system	O
for	O
graph	O
data	O
,	O
called	O
decimated	AI/ML/DL-technique
framelets	AI/ML/DL-technique
which	O
form	O
a	O
localized	O
tight	O
frame	O
on	O
the	O
graph	O
.	O

The	O
decimated	AI/ML/DL-technique
framelet	AI/ML/DL-technique
system	AI/ML/DL-technique
allows	O
storage	O
of	O
the	O
graph	O
data	O
representation	O
on	O
a	O
coarse	O
-	O
grained	O
chain	O
and	O
processes	O
the	O
graph	O
data	O
at	O
multi	O
scales	O
where	O
at	O
each	O
scale	O
,	O
the	O
data	O
is	O
stored	O
on	O
a	O
subgraph	O
.	O

Based	O
on	O
this	O
,	O
we	O
establish	O
decimated	AI/ML/DL-technique
G	AI/ML/DL-technique
-	AI/ML/DL-technique
framelet	AI/ML/DL-technique
transforms	AI/ML/DL-technique
for	O
the	O
decomposition	O
and	O
reconstruction	O
of	O
the	O
graph	O
data	O
at	O
multi	O
resolutions	O
via	O
a	O
constructive	O
data	O
-	O
driven	O
filter	O
bank	O
.	O

From	O
this	O
,	O
we	O
give	O
a	O
fast	O
algorithm	O
for	O
the	O
decimated	AI/ML/DL-technique
G	AI/ML/DL-technique
-	AI/ML/DL-technique
framelet	AI/ML/DL-technique
transforms	AI/ML/DL-technique
or	O
FGT	AI/ML/DL-technique
that	O
has	O
linear	O
computational	O
complexity	O
O	O
(	O
N	O
)	O
for	O
a	O
graph	O
of	O
size	O
N	O
.	O

The	O
effectiveness	O
for	O
constructing	O
the	O
decimated	AI/ML/DL-technique
framelet	AI/ML/DL-technique
system	AI/ML/DL-technique
and	O
the	O
FGT	AI/ML/DL-technique
is	O
demonstrated	O
by	O
a	O
simulated	O
example	O
of	O
random	O
graphs	O
and	O
real	O
-	O
world	O
applications	O
,	O
including	O
multiresolution	O
analysis	O
for	O
traffic	O
network	O
and	O
representation	O
learning	O
of	O
graph	O
neural	O
networks	O
for	O
graph	O
classification	O
tasks	O
.	O

We	O
propose	O
a	O
new	O
tool	O
for	O
visualizing	O
complex	O
,	O
and	O
potentially	O
large	O
and	O
high	Miscellaneous-term
-	Miscellaneous-term
dimensional	Miscellaneous-term
,	Miscellaneous-term
data	Miscellaneous-term
sets	Miscellaneous-term
called	O
Centroid	AI/ML/DL-technique
-	AI/ML/DL-technique
Encoder	AI/ML/DL-technique
(	AI/ML/DL-technique
CE	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

We	O
propose	O
a	O
new	O
tool	O
for	O
visualizing	O
complex	O
,	O
and	O
potentially	O
large	O
and	O
high	Miscellaneous-term
-	Miscellaneous-term
dimensional	Miscellaneous-term
,	Miscellaneous-term
data	Miscellaneous-term
sets	Miscellaneous-term
called	O
Centroid	AI/ML/DL-technique
-	AI/ML/DL-technique
Encoder	AI/ML/DL-technique
(	AI/ML/DL-technique
CE	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

The	O
architecture	O
of	O
the	O
Centroid	AI/ML/DL-technique
-	AI/ML/DL-technique
Encoder	AI/ML/DL-technique
is	O
similar	O
to	O
the	O
autoencoder	O
neural	O
network	O
but	O
it	O
has	O
a	O
modified	O
target	O
,	O
i	O
.	O
e	O
.,	O
the	O
class	AI/ML/DL-term
centroid	AI/ML/DL-term
in	O
the	O
ambient	O
space	O
.	O
CE	AI/ML/DL-technique
.	O

The	O
architecture	O
of	O
the	O
Centroid	AI/ML/DL-technique
-	AI/ML/DL-technique
Encoder	AI/ML/DL-technique
is	O
similar	O
to	O
the	O
autoencoder	O
neural	O
network	O
but	O
it	O
has	O
a	O
modified	O
target	O
,	O
i	O
.	O
e	O
.,	O
the	O
class	AI/ML/DL-term
centroid	AI/ML/DL-term
in	O
the	O
ambient	O
space	O
.	O
CE	AI/ML/DL-technique
.	O

As	O
such	O
,	O
CE	O
incorporates	O
label	O
information	O
and	O
performs	O
a	O
supervised	O
data	O
visualization	O
CE	AI/ML/DL-technique
.	O

The	O
training	O
of	O
CE	O
is	O
done	O
in	O
the	O
usual	O
way	O
with	O
a	O
training	AI/ML/DL-term
set	AI/ML/DL-term
whose	O
parameters	O
are	O
tuned	O
using	O
a	O
validation	AI/ML/DL-term
set	AI/ML/DL-term
.	O

The	O
evaluation	O
of	O
the	O
resulting	O
CE	Miscellaneous-term
visualization	Miscellaneous-term
is	O
performed	O
on	O
a	O
sequestered	O
test	O
set	O
where	O
the	O
generalization	O
of	O
the	O
model	O
is	O
assessed	O
both	O
visually	O
and	O
quantitatively	O
.	O

We	O
present	O
a	O
detailed	O
comparative	O
analysis	O
of	O
the	O
method	O
using	O
a	O
wide	O
variety	O
of	O
data	O
sets	O
and	O
techniques	O
,	O
both	O
supervised	AI/ML/DL-term
and	O
unsupervised	AI/ML/DL-term
including	O
NCA	O
non	O
-	O
linear	O
NCA	O
t	O
-	O
distributed	O
NCA	O
t	O
-	O
distributed	O
MCML	O
supervised	O
UMAP	O
supervised	O
PCA	O
Colored	O
Maximum	O
Variance	O
Unfolding	O
supervised	O
Isomap	O
Parametric	O
Embedding	O
supervised	O
Neighbor	O
Retrieval	O
Visualizer	O
and	O
Multiple	O
Relational	O
Embedding	O
.	O

The	O
variational	AI/ML/DL-term
parameters	AI/ML/DL-term
of	O
truncated	O
posteriors	O
are	O
sets	O
of	O
latent	O
states	O
.	O

By	O
interpreting	O
these	O
states	O
as	O
genomes	O
of	O
individuals	O
and	O
by	O
using	O
the	O
variational	AI/ML/DL-term
lower	AI/ML/DL-term
bound	AI/ML/DL-term
to	O
define	O
a	O
fitness	O
,	O
we	O
can	O
apply	O
evolutionary	O
algorithms	O
to	O
realize	O
the	O
variational	AI/ML/DL-term
loop	AI/ML/DL-term
.	O

Furthermore	O
,	O
the	O
variational	AI/ML/DL-term
loop	AI/ML/DL-term
is	O
generally	O
applicable	O
(“	O
black	O
box	O
”)	O
with	O
no	O
analytical	O
derivations	O
required	O
.	O

To	O
demonstrate	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
novel	O
variational	O
approach	O
,	O
we	O
use	O
the	O
standard	O
competitive	O
benchmarks	Miscellaneous-term
of	O
image	O
denoising	O
and	O
inpainting	O
benchmarks	Miscellaneous-term
.	O

In	O
the	O
category	O
of	O
“	O
zero	O
-	O
shot	O
”	O
learning	O
(	O
when	O
only	O
the	O
corrupted	O
image	O
is	O
used	O
for	O
training	AI/ML/DL-term
,	O
we	O
observed	O
the	O
evolutionary	O
variational	O
algorithm	O
to	O
significantly	O
improve	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
in	O
many	O
benchmark	O
settings	O
.	O

In	O
the	O
category	O
of	O
“	O
zero	O
-	O
shot	O
”	O
learning	O
(	O
when	O
only	O
the	O
corrupted	O
image	O
is	O
used	O
for	O
training	AI/ML/DL-term
,	O
we	O
observed	O
the	O
evolutionary	O
variational	O
algorithm	O
to	O
significantly	O
improve	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
in	O
many	O
benchmark	O
settings	O
.	O

For	O
one	O
well	O
-	O
known	O
inpainting	O
benchmark	O
,	O
we	O
also	O
observed	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
across	O
all	O
categories	O
of	O
algorithms	Miscellaneous-term
although	O
we	O
only	O
train	O
on	O
the	O
corrupted	O
image	O
.	O

We	O
apply	O
methods	O
from	O
randomized	O
numerical	O
linear	O
algebra	O
(	O
RandNLA	O
)	O
to	O
develop	O
improved	O
algorithms	Miscellaneous-term
for	O
the	O
analysis	O
of	O
large	O
-	O
scale	O
time	O
series	O
data	O
.	O

We	O
first	O
develop	O
a	O
new	O
fast	O
algorithm	Miscellaneous-term
to	O
estimate	O
the	O
leverage	O
scores	O
of	O
an	O
autoregressive	O
(	O
AR	O
)	O
model	O
in	O
big	O
data	O
regimes	O
.	O

These	O
theoretical	O
results	O
are	O
subsequently	O
exploited	O
to	O
develop	O
an	O
efficient	O
algorithm	Miscellaneous-term
called	O
LSAR	AI/ML/DL-technique
for	O
fitting	O
an	O
appropriate	O
AR	O
model	O
to	O
big	O
time	O
series	O
data	O
.	O

These	O
theoretical	O
results	O
are	O
subsequently	O
exploited	O
to	O
develop	O
an	O
efficient	O
algorithm	Miscellaneous-term
called	O
LSAR	AI/ML/DL-technique
for	O
fitting	O
an	O
appropriate	O
AR	O
model	O
to	O
big	O
time	O
series	O
data	O
.	O

Our	O
proposed	O
algorithm	Miscellaneous-term
is	O
guaranteed	O
,	O
with	O
high	O
probability	O
to	O
find	O
the	O
maximum	O
likelihood	O
estimates	O
of	O
the	O
parameters	O
of	O
the	O
underlying	O
true	O
AR	O
model	O
and	O
has	O
a	O
worst	O
case	O
running	O
time	O
that	O
significantly	O
improves	O
those	O
of	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
alternatives	O
in	O
big	O
data	O
regimes	O
.	O

Existing	O
robust	O
RAs	O
usually	O
resort	O
to	O
an	O
augmentation	AI/ML/DL-term
of	O
the	O
ranking	O
model	O
to	O
account	O
for	O
additional	O
noises	O
,	O
where	O
the	O
collected	O
preferences	O
can	O
be	O
treated	O
as	O
a	O
noisy	O
perturbation	O
of	O
idealized	O
preferences	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
CoarsenRank	AI/ML/DL-technique
which	O
possesses	O
robustness	O
against	O
model	O
misspecification	O
.	O

Specifically	O
,	O
the	O
properties	O
of	O
our	O
CoarsenRank	AI/ML/DL-technique
CoarsenRank	AI/ML/DL-technique
CoarsenRank	AI/ML/DL-technique
s	O
:	O
(	O
1	O
)	O
CoarsenRank	O
is	O
designed	O
for	O
mild	O
model	O
misspecification	O
,	O
which	O
assumes	O
there	O
exist	O
the	O
ideal	O
preferences	O
(	O
consistent	O
with	O
model	O
assumption	O
)	O
that	O
locate	O
in	O
a	O
neighborhood	O
of	O
the	O
actual	O
preferences	O
.	O

(	O
2	O
)	O
CoarsenRank	O
then	O
performs	O
regular	O
RAs	O
over	O
a	O
neighborhood	O
of	O
the	O
preferences	O
instead	O
of	O
the	O
original	O
data	Miscellaneous-term
set	Miscellaneous-term
CoarsenRank	AI/ML/DL-technique
.	O

(	O
2	O
)	O
CoarsenRank	O
then	O
performs	O
regular	O
RAs	O
over	O
a	O
neighborhood	O
of	O
the	O
preferences	O
instead	O
of	O
the	O
original	O
data	Miscellaneous-term
set	Miscellaneous-term
CoarsenRank	AI/ML/DL-technique
.	O

Further	O
,	O
we	O
put	O
an	O
exponential	O
prior	O
on	O
the	O
unknown	O
size	O
of	O
the	O
neighborhood	O
and	O
derive	O
a	O
much	O
-	O
simplified	O
posterior	O
formula	O
for	O
CoarsenRank	AI/ML/DL-technique
CoarsenRank	AI/ML/DL-technique
ular	O
divergence	O
measures	O
.	O

In	O
the	O
end	O
,	O
we	O
apply	O
CoarsenRank	AI/ML/DL-technique
on	O
four	O
real	O
-	O
world	O
data	O
sets	O
.	O

Experiments	O
show	O
that	O
CoarsenRank	AI/ML/DL-technique
is	O
fast	O
and	O
robust	O
,	O
achieving	O
consistent	O
improvements	O
over	O
baseline	O
methods	O
.	O

We	O
present	O
a	O
uniform	O
analysis	O
of	O
biased	O
stochastic	O
gradient	O
methods	O
for	O
minimizing	O
convex	AI/ML/DL-term
strongly	AI/ML/DL-term
convex	AI/ML/DL-term
and	O
non	AI/ML/DL-term
-	AI/ML/DL-term
convex	AI/ML/DL-term
composite	Miscellaneous-term
objectives	Miscellaneous-term
bias	AI/ML/DL-term
identify	O
settings	O
where	O
bias	O
is	O
useful	O
in	O
stochastic	O
gradient	O
estimation	O
.	O

We	O
present	O
a	O
uniform	O
analysis	O
of	O
biased	O
stochastic	O
gradient	O
methods	O
for	O
minimizing	O
convex	AI/ML/DL-term
strongly	AI/ML/DL-term
convex	AI/ML/DL-term
and	O
non	AI/ML/DL-term
-	AI/ML/DL-term
convex	AI/ML/DL-term
composite	Miscellaneous-term
objectives	Miscellaneous-term
bias	AI/ML/DL-term
identify	O
settings	O
where	O
bias	O
is	O
useful	O
in	O
stochastic	O
gradient	O
estimation	O
.	O

The	O
framework	O
we	O
present	O
allows	O
us	O
to	O
extend	O
proximal	O
support	O
to	O
biased	AI/ML/DL-term
algorithms	AI/ML/DL-term
including	O
SAG	O
and	O
SARAH	O
for	O
the	O
first	O
time	O
in	O
the	O
convex	O
setting	O
.	O

We	O
also	O
use	O
our	O
framework	O
to	O
develop	O
a	O
new	O
algorithm	O
,	O
Stochastic	AI/ML/DL-technique
Average	AI/ML/DL-technique
Recursive	AI/ML/DL-technique
GradiEnt	AI/ML/DL-technique
(	AI/ML/DL-technique
SARGE	AI/ML/DL-technique
)	AI/ML/DL-technique
that	O
achieves	O
the	O
oracle	Miscellaneous-term
complexity	Miscellaneous-term
lower	O
-	O
bound	O
for	O
non	O
-	O
convex	O
finite	AI/ML/DL-term
-	AI/ML/DL-term
sum	AI/ML/DL-term
objectives	AI/ML/DL-term
and	O
requires	O
strictly	O
fewer	O
calls	O
to	O
a	O
stochastic	AI/ML/DL-term
gradient	AI/ML/DL-term
oracle	AI/ML/DL-term
per	O
iteration	O
than	O
SVRG	O
and	O
SARAH	O
.	O

We	O
also	O
use	O
our	O
framework	O
to	O
develop	O
a	O
new	O
algorithm	O
,	O
Stochastic	AI/ML/DL-technique
Average	AI/ML/DL-technique
Recursive	AI/ML/DL-technique
GradiEnt	AI/ML/DL-technique
(	AI/ML/DL-technique
SARGE	AI/ML/DL-technique
)	AI/ML/DL-technique
that	O
achieves	O
the	O
oracle	Miscellaneous-term
complexity	Miscellaneous-term
lower	O
-	O
bound	O
for	O
non	O
-	O
convex	O
finite	AI/ML/DL-term
-	AI/ML/DL-term
sum	AI/ML/DL-term
objectives	AI/ML/DL-term
and	O
requires	O
strictly	O
fewer	O
calls	O
to	O
a	O
stochastic	AI/ML/DL-term
gradient	AI/ML/DL-term
oracle	AI/ML/DL-term
per	O
iteration	O
than	O
SVRG	O
and	O
SARAH	O
.	O

We	O
also	O
use	O
our	O
framework	O
to	O
develop	O
a	O
new	O
algorithm	O
,	O
Stochastic	AI/ML/DL-technique
Average	AI/ML/DL-technique
Recursive	AI/ML/DL-technique
GradiEnt	AI/ML/DL-technique
(	AI/ML/DL-technique
SARGE	AI/ML/DL-technique
)	AI/ML/DL-technique
that	O
achieves	O
the	O
oracle	Miscellaneous-term
complexity	Miscellaneous-term
lower	O
-	O
bound	O
for	O
non	O
-	O
convex	O
finite	AI/ML/DL-term
-	AI/ML/DL-term
sum	AI/ML/DL-term
objectives	AI/ML/DL-term
and	O
requires	O
strictly	O
fewer	O
calls	O
to	O
a	O
stochastic	AI/ML/DL-term
gradient	AI/ML/DL-term
oracle	AI/ML/DL-term
per	O
iteration	O
than	O
SVRG	O
and	O
SARAH	O
.	O

Performing	O
exact	O
Bayesian	O
inference	O
for	O
complex	AI/ML/DL-term
models	AI/ML/DL-term
is	O
computationally	Miscellaneous-term
intractable	Miscellaneous-term
.	O

Performing	O
exact	O
Bayesian	O
inference	O
for	O
complex	AI/ML/DL-term
models	AI/ML/DL-term
is	O
computationally	Miscellaneous-term
intractable	Miscellaneous-term
.	O

Markov	O
chain	O
Monte	O
Carlo	O
(	O
MCMC	O
)	O
algorithms	O
can	O
provide	O
reliable	O
approximations	O
of	O
the	O
posterior	O
distribution	O
but	O
are	O
expensive	O
for	O
large	O
data	Miscellaneous-term
sets	Miscellaneous-term
and	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
models	AI/ML/DL-term
.	O

Markov	O
chain	O
Monte	O
Carlo	O
(	O
MCMC	O
)	O
algorithms	O
can	O
provide	O
reliable	O
approximations	O
of	O
the	O
posterior	O
distribution	O
but	O
are	O
expensive	O
for	O
large	O
data	Miscellaneous-term
sets	Miscellaneous-term
and	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
models	AI/ML/DL-term
.	O

These	O
methods	O
appear	O
to	O
provide	O
empirically	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
but	O
their	O
theoretical	O
behavior	O
in	O
high	O
dimension	O
is	O
currently	O
unknown	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
detailed	O
theoretical	O
study	O
of	O
one	O
of	O
these	O
algorithms	Miscellaneous-term
known	O
as	O
the	O
split	O
Gibbs	O
sampler	O
.	O

Decision	O
tree	O
learning	O
is	O
a	O
widely	O
used	O
approach	O
in	O
machine	O
learning	O
favoured	O
in	O
applications	O
that	O
require	O
concise	Miscellaneous-term
and	O
interpretable	AI/ML/DL-term
models	AI/ML/DL-term
Heuristic	Miscellaneous-term
methods	Miscellaneous-term
.	O

Decision	O
tree	O
learning	O
is	O
a	O
widely	O
used	O
approach	O
in	O
machine	O
learning	O
favoured	O
in	O
applications	O
that	O
require	O
concise	Miscellaneous-term
and	O
interpretable	AI/ML/DL-term
models	AI/ML/DL-term
Heuristic	Miscellaneous-term
methods	Miscellaneous-term
.	O

In	O
recent	O
years	O
,	O
this	O
motivated	O
the	O
development	O
of	O
optimal	O
classification	O
tree	O
algorithms	O
that	O
globally	O
optimise	O
the	O
decision	O
tree	O
in	O
contrast	O
to	O
heuristic	Miscellaneous-term
methods	Miscellaneous-term
that	O
perform	O
a	O
sequence	O
of	O
locally	O
optimal	O
decisions	O
.	O

We	O
follow	O
this	O
line	O
of	O
work	O
and	O
provide	O
a	O
novel	Miscellaneous-term
algorithm	Miscellaneous-term
for	O
learning	O
optimal	O
classification	O
trees	O
based	O
on	O
dynamic	O
programming	O
algorithm	Miscellaneous-term
.	O

Whereas	O
algorithms	O
for	O
optimal	O
classification	O
trees	O
have	O
traditionally	O
been	O
plagued	O
by	O
high	O
runtimes	O
and	O
limited	O
scalability	O
we	O
show	O
in	O
a	O
detailed	O
experimental	O
study	O
that	O
our	O
approach	O
uses	O
only	O
a	O
fraction	O
of	O
the	O
time	O
required	O
by	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
and	O
can	O
handle	O
datasets	Miscellaneous-term
with	O
tens	O
of	O
thousands	O
of	O
instances	O
,	O
providing	O
several	O
orders	O
of	O
magnitude	O
improvements	O
and	O
notably	O
contributing	O
towards	O
the	O
practical	O
use	O
of	O
optimal	O
decision	O
trees	O
.	O

Many	O
current	O
applications	O
in	O
data	O
science	O
need	O
rich	AI/ML/DL-term
model	AI/ML/DL-term
classes	AI/ML/DL-term
to	O
adequately	O
represent	O
the	O
statistics	O
rich	AI/ML/DL-term
model	AI/ML/DL-term
classes	AI/ML/DL-term
the	O
observations	O
.	O

But	O
this	O
viewpoint	O
has	O
the	O
practical	O
drawback	O
that	O
estimator	O
performance	O
is	O
a	O
function	O
of	O
the	O
unknown	O
model	O
within	O
the	O
model	AI/ML/DL-term
class	AI/ML/DL-term
estimator	O
ing	O
estimated	O
.	O

Even	O
if	O
an	O
estimator	O
is	O
consistent	O
how	O
well	O
it	O
is	O
doing	O
at	O
any	O
given	O
time	O
may	O
not	O
be	O
clear	O
,	O
no	O
matter	O
what	O
the	O
sample	Miscellaneous-term
size	Miscellaneous-term
of	O
the	O
observations	O
.	O

In	O
these	O
cases	O
,	O
a	O
line	O
of	O
analysis	O
favors	O
sample	AI/ML/DL-term
dependent	AI/ML/DL-term
guarantees	AI/ML/DL-term
.	O

We	O
explore	O
this	O
framework	O
by	O
studying	O
rich	AI/ML/DL-term
model	AI/ML/DL-term
classes	AI/ML/DL-term
that	O
may	O
only	O
admit	O
pointwise	O
consistency	O
guarantees	O
,	O
yet	O
enough	O
information	O
about	O
the	O
unknown	O
model	O
driving	O
the	O
observations	O
needed	O
to	O
gauge	O
estimator	O
accuracy	O
can	O
be	O
inferred	O
from	O
the	O
sample	O
at	O
hand	O
.	O

In	O
this	O
paper	O
we	O
obtain	O
a	O
novel	O
characterization	O
of	O
lossless	O
compression	O
problems	O
over	O
a	O
countable	O
alphabet	O
in	O
the	O
data	AI/ML/DL-term
-	AI/ML/DL-term
derived	AI/ML/DL-term
framework	AI/ML/DL-term
in	O
terms	O
of	O
what	O
we	O
term	O
deceptive	O
distributions	O
.	O

We	O
also	O
show	O
that	O
the	O
ability	O
to	O
estimate	O
the	O
redundancy	O
of	O
compressing	O
memoryless	Miscellaneous-term
sources	Miscellaneous-term
is	O
equivalent	O
to	O
learning	O
the	O
underlying	O
single	O
-	O
letter	O
marginal	O
in	O
a	O
data	O
-	O
derived	O
fashion	O
.	O

We	O
expect	O
that	O
the	O
methodology	O
underlying	O
such	O
characterizations	O
in	O
a	O
data	AI/ML/DL-term
-	AI/ML/DL-term
derived	AI/ML/DL-term
estimation	AI/ML/DL-term
framework	AI/ML/DL-term
will	O
be	O
broadly	O
applicable	O
to	O
a	O
wide	O
range	O
of	O
estimation	O
problems	O
enabling	O
a	O
more	O
systematic	O
approach	O
to	O
data	Miscellaneous-term
-	Miscellaneous-term
derived	Miscellaneous-term
guarantees	Miscellaneous-term
.	O

We	O
expect	O
that	O
the	O
methodology	O
underlying	O
such	O
characterizations	O
in	O
a	O
data	AI/ML/DL-term
-	AI/ML/DL-term
derived	AI/ML/DL-term
estimation	AI/ML/DL-term
framework	AI/ML/DL-term
will	O
be	O
broadly	O
applicable	O
to	O
a	O
wide	O
range	O
of	O
estimation	O
problems	O
enabling	O
a	O
more	O
systematic	O
approach	O
to	O
data	Miscellaneous-term
-	Miscellaneous-term
derived	Miscellaneous-term
guarantees	Miscellaneous-term
.	O

In	O
this	O
article	O
,	O
we	O
dwell	O
into	O
the	O
class	O
of	O
so	O
-	O
called	O
ill	O
-	O
posed	O
Linear	O
Inverse	O
Problems	O
(	O
LIP	O
)	O
which	O
simply	O
refer	O
to	O
the	O
task	O
of	O
recovering	O
the	O
entire	O
signal	O
from	O
its	O
relatively	O
few	O
random	O
linear	AI/ML/DL-term
measurements	AI/ML/DL-term
.	O

We	O
propose	O
a	O
slightly	O
generalized	O
version	O
of	O
the	O
error	O
constrained	O
linear	O
inverse	O
problem	O
and	O
obtain	O
a	O
novel	O
and	O
equivalent	O
convex	O
-	O
concave	O
min	O
-	O
max	O
reformulation	O
by	O
providing	O
an	O
exposition	O
to	O
its	O
convex	O
geometry	O
Saddle	AI/ML/DL-term
points	AI/ML/DL-term
.	O

Applying	O
simple	O
saddle	AI/ML/DL-term
point	AI/ML/DL-term
seeking	O
ascend	O
-	O
descent	O
type	O
algorithms	O
to	O
solve	O
the	O
min	O
-	O
max	O
problems	O
provides	O
novel	O
and	O
simple	O
algorithms	O
to	O
find	O
a	O
solution	O
to	O
the	O
LIP	O
.	O

In	O
this	O
paper	O
,	O
we	O
develop	O
a	O
new	O
theoretical	Miscellaneous-term
framework	Miscellaneous-term
to	O
provide	O
such	O
convergence	O
guarantee	O
for	O
two	O
types	O
of	O
objective	AI/ML/DL-term
functions	AI/ML/DL-term
that	O
are	O
of	O
interest	O
in	O
practice	O
:	O
(	O
a	O
)	O
resampling	O
case	O
(	O
e	O
.	O
g	O
.,	O
reinforcement	O
learning	O
,	O
where	O
loss	AI/ML/DL-term
functions	AI/ML/DL-term
take	O
the	O
form	O
in	O
expectation	O
and	O
new	O
data	O
are	O
sampled	O
as	O
the	O
algorithm	O
runs	O
;	O
and	O
(	O
b	O
)	O
finite	O
-	O
sum	O
case	O
(	O
e	O
.	O
g	O
.,	O
supervised	AI/ML/DL-term
learning	AI/ML/DL-term
loss	AI/ML/DL-term
functions	AI/ML/DL-term
nctions	O
take	O
the	O
finite	O
-	O
sum	O
form	O
with	O
given	O
samples	O
.	O

In	O
this	O
paper	O
,	O
we	O
develop	O
a	O
new	O
theoretical	Miscellaneous-term
framework	Miscellaneous-term
to	O
provide	O
such	O
convergence	O
guarantee	O
for	O
two	O
types	O
of	O
objective	AI/ML/DL-term
functions	AI/ML/DL-term
that	O
are	O
of	O
interest	O
in	O
practice	O
:	O
(	O
a	O
)	O
resampling	O
case	O
(	O
e	O
.	O
g	O
.,	O
reinforcement	O
learning	O
,	O
where	O
loss	AI/ML/DL-term
functions	AI/ML/DL-term
take	O
the	O
form	O
in	O
expectation	O
and	O
new	O
data	O
are	O
sampled	O
as	O
the	O
algorithm	O
runs	O
;	O
and	O
(	O
b	O
)	O
finite	O
-	O
sum	O
case	O
(	O
e	O
.	O
g	O
.,	O
supervised	AI/ML/DL-term
learning	AI/ML/DL-term
loss	AI/ML/DL-term
functions	AI/ML/DL-term
nctions	O
take	O
the	O
finite	O
-	O
sum	O
form	O
with	O
given	O
samples	O
.	O

For	O
both	O
cases	O
,	O
we	O
characterize	O
the	O
convergence	AI/ML/DL-term
rate	AI/ML/DL-term
and	O
the	O
computational	O
complexity	O
to	O
attain	O
an	O
$\	O
epsilon	O
$-	O
accurate	O
solution	O
for	O
multi	O
-	O
step	O
MAML	O
in	O
the	O
general	O
nonconvex	O
setting	O
.	O

Multinomial	O
probit	O
models	O
are	O
routinely	O
-	O
implemented	O
representations	O
for	O
learning	O
how	O
the	O
class	AI/ML/DL-term
probabilities	AI/ML/DL-term
of	O
categorical	O
response	O
data	O
change	O
with	O
$	O
p	O
$	O
observed	O
predictors	O
.	O

Such	O
an	O
issue	O
has	O
motivated	O
increasing	O
efforts	O
toward	O
the	O
development	O
of	O
effective	O
Markov	O
chain	O
Monte	O
Carlo	O
methods	O
,	O
but	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
solutions	O
still	O
face	O
severe	O
computational	Miscellaneous-term
bottlenecks	Miscellaneous-term
especially	O
in	O
high	O
dimensions	O
.	O

Leveraging	O
this	O
result	O
and	O
the	O
SUN	O
properties	O
,	O
we	O
improve	O
upon	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
solutions	O
for	O
posterior	O
inference	O
and	O
classification	O
both	O
in	O
terms	O
of	O
closed	O
-	O
form	O
results	O
for	O
several	O
functionals	O
of	O
interest	O
,	O
and	O
also	O
by	O
developing	O
novel	O
computational	O
methods	O
relying	O
either	O
on	O
independent	O
and	O
identically	O
distributed	O
samples	O
from	O
the	O
exact	O
posterior	O
or	O
on	O
scalable	O
and	O
accurate	O
variational	O
approximations	O
based	O
on	O
blocked	O
partially	O
-	O
factorized	O
representations	O
.	O

We	O
introduce	O
a	O
procedure	O
for	O
conditional	O
density	O
estimation	O
under	O
logarithmic	AI/ML/DL-term
loss	AI/ML/DL-term
which	O
we	O
call	O
SMP	AI/ML/DL-technique
(	AI/ML/DL-technique
Sample	AI/ML/DL-technique
Minmax	AI/ML/DL-technique
Predictor	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

We	O
introduce	O
a	O
procedure	O
for	O
conditional	O
density	O
estimation	O
under	O
logarithmic	AI/ML/DL-term
loss	AI/ML/DL-term
which	O
we	O
call	O
SMP	AI/ML/DL-technique
(	AI/ML/DL-technique
Sample	AI/ML/DL-technique
Minmax	AI/ML/DL-technique
Predictor	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

On	O
standard	O
examples	O
,	O
this	O
bound	O
scales	O
as	O
$	O
d	O
/	O
n	O
$	O
with	O
$	O
d	O
$	O
the	O
model	AI/ML/DL-term
dimension	AI/ML/DL-term
and	O
$	O
n	O
$	O
the	O
sample	AI/ML/DL-term
size	AI/ML/DL-term
and	O
critically	O
remains	O
valid	O
under	O
model	O
misspecification	O
.	O

Being	O
an	O
improper	O
(	O
out	O
-	O
of	O
-	O
model	O
)	O
procedure	O
,	O
SMP	AI/ML/DL-technique
improves	O
over	O
within	O
-	O
model	O
estimators	O
such	O
as	O
the	O
maximum	O
likelihood	O
estimator	O
whose	O
excess	O
risk	O
degrades	O
under	O
misspecification	O
.	O

For	O
the	O
Gaussian	O
linear	O
model	O
,	O
the	O
predictions	O
and	O
risk	O
bound	O
of	O
SMP	AI/ML/DL-technique
are	O
governed	O
by	O
leverage	O
scores	O
of	O
covariates	O
nearly	O
matching	O
the	O
optimal	O
risk	O
in	O
the	O
well	O
-	O
specified	O
case	O
without	O
conditions	O
on	O
the	O
noise	O
variance	O
or	O
approximation	O
error	O
of	O
the	O
linear	O
model	O
.	O
logistic	O
regression	O
SMP	AI/ML/DL-technique
.	O

Motivated	O
by	O
practical	O
settings	O
,	O
we	O
study	O
a	O
class	O
of	O
nonlinear	O
dynamical	O
systems	O
whose	O
state	AI/ML/DL-term
transitions	AI/ML/DL-term
depend	O
linearly	O
on	O
a	O
known	O
feature	AI/ML/DL-term
embedding	AI/ML/DL-term
of	O
state	O
-	O
action	O
pairs	O
.	O

To	O
estimate	O
such	O
systems	O
in	O
finite	O
time	O
identification	O
methods	O
must	O
explore	O
all	O
directions	O
in	O
feature	AI/ML/DL-term
space	AI/ML/DL-term
active	O
learning	O
.	O

One	O
key	O
technical	O
challenge	O
for	O
directly	O
applying	O
maximum	O
likelihood	O
estimation	O
(	O
MLE	O
)	O
to	O
censored	O
data	O
is	O
that	O
evaluating	O
the	O
objective	AI/ML/DL-term
function	AI/ML/DL-term
and	O
its	O
gradients	AI/ML/DL-term
with	O
respect	O
to	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
requires	O
the	O
calculation	O
of	O
integrals	O
.	O

Following	O
this	O
connection	O
,	O
we	O
model	O
the	O
distribution	O
of	O
event	O
time	O
through	O
an	O
ordinary	O
differential	O
equation	O
and	O
utilize	O
efficient	O
ODE	O
solvers	O
and	O
adjoint	O
sensitivity	O
analysis	O
to	O
numerically	O
evaluate	O
the	O
likelihood	O
and	O
the	O
gradients	AI/ML/DL-term
.	O

Using	O
this	O
approach	O
,	O
we	O
are	O
able	O
to	O
1	O
)	O
provide	O
a	O
broad	O
family	O
of	O
continuous	O
-	O
time	O
survival	O
distributions	O
without	O
strong	O
structural	O
assumptions	O
,	O
2	O
)	O
obtain	O
powerful	O
feature	AI/ML/DL-term
representations	AI/ML/DL-term
using	O
neural	O
networks	O
and	O
3	O
)	O
allow	O
efficient	O
estimation	O
of	O
the	O
model	O
in	O
large	O
-	O
scale	O
applications	O
using	O
stochastic	AI/ML/DL-term
gradient	AI/ML/DL-term
descent	AI/ML/DL-term
.	O

Through	O
both	O
simulation	O
studies	O
and	O
real	O
-	O
world	O
data	O
examples	O
,	O
we	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
in	O
comparison	O
to	O
existing	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
deep	O
learning	O
survival	O
analysis	O
models	O
.	O

The	O
implementation	O
of	O
the	O
proposed	O
SODEN	AI/ML/DL-technique
approach	O
has	O
been	O
made	O
publicly	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
jiaqima	O
/	O
SODEN	O
.	O
Convergence	O
saddle	O
point	O
.	O

It	O
remains	O
an	O
intriguing	O
research	O
challenge	O
how	O
local	AI/ML/DL-term
optimal	AI/ML/DL-term
points	AI/ML/DL-term
are	O
defined	O
and	O
which	O
algorithm	Miscellaneous-term
can	O
converge	O
to	O
such	O
points	O
.	O

It	O
remains	O
an	O
intriguing	O
research	O
challenge	O
how	O
local	AI/ML/DL-term
optimal	AI/ML/DL-term
points	AI/ML/DL-term
are	O
defined	O
and	O
which	O
algorithm	Miscellaneous-term
can	O
converge	O
to	O
such	O
points	O
.	O

An	O
interesting	O
concept	O
is	O
known	O
as	O
the	O
local	AI/ML/DL-term
minimax	AI/ML/DL-term
point	AI/ML/DL-term
which	O
strongly	O
correlates	O
with	O
the	O
widely	O
-	O
known	O
gradient	O
descent	O
ascent	O
algorithm	O
.	O

This	O
paper	O
aims	O
to	O
provide	O
a	O
comprehensive	O
analysis	O
of	O
local	AI/ML/DL-term
minimax	AI/ML/DL-term
points	AI/ML/DL-term
such	O
as	O
their	O
relation	O
with	O
other	O
solution	O
concepts	O
and	O
their	O
optimality	O
conditions	O
.	O
local	AI/ML/DL-term
saddle	AI/ML/DL-term
points	AI/ML/DL-term
.	O

We	O
find	O
that	O
local	O
saddle	O
points	O
can	O
be	O
regarded	O
as	O
a	O
special	O
type	O
of	O
local	AI/ML/DL-term
minimax	AI/ML/DL-term
points	AI/ML/DL-term
local	AI/ML/DL-term
minimax	AI/ML/DL-term
points	AI/ML/DL-term
al	O
minimax	O
points	O
,	O
under	O
mild	O
continuity	O
assumptions	O
.	O
non	O
-	O
convex	O
)	O
quadratic	O
games	O
.	O

In	O
(	O
non	O
-	O
convex	O
)	O
quadratic	O
games	O
,	O
we	O
show	O
that	O
local	AI/ML/DL-term
minimax	AI/ML/DL-term
points	AI/ML/DL-term
are	O
(	O
in	O
some	O
sense	O
)	O
equivalent	O
to	O
global	AI/ML/DL-term
minimax	AI/ML/DL-term
points	AI/ML/DL-term
.	O

Finally	O
,	O
we	O
study	O
the	O
stability	O
of	O
gradient	O
algorithms	O
near	O
local	AI/ML/DL-term
minimax	AI/ML/DL-term
points	AI/ML/DL-term
gradient	O
algorithms	O
.	O

Although	O
gradient	O
algorithms	O
can	O
converge	O
to	O
l	O
ocal	AI/ML/DL-term
/	AI/ML/DL-term
global	AI/ML/DL-term
minimax	AI/ML/DL-term
points	AI/ML/DL-term
in	O
the	O
non	O
-	O
degenerate	O
case	O
,	O
they	O
would	O
often	O
fail	O
in	O
general	O
cases	O
.	O

This	O
implies	O
the	O
necessity	O
of	O
either	O
novel	Miscellaneous-term
algorithms	Miscellaneous-term
or	O
concepts	O
beyond	O
saddle	AI/ML/DL-term
points	AI/ML/DL-term
and	O
minimax	AI/ML/DL-term
points	AI/ML/DL-term
in	O
non	O
-	O
convex	O
smooth	O
games	O
.	O

This	O
implies	O
the	O
necessity	O
of	O
either	O
novel	Miscellaneous-term
algorithms	Miscellaneous-term
or	O
concepts	O
beyond	O
saddle	AI/ML/DL-term
points	AI/ML/DL-term
and	O
minimax	AI/ML/DL-term
points	AI/ML/DL-term
in	O
non	O
-	O
convex	O
smooth	O
games	O
.	O

Specifically	O
,	O
we	O
propose	O
a	O
new	O
accelerated	AI/ML/DL-technique
zeroth	AI/ML/DL-technique
-	AI/ML/DL-technique
order	AI/ML/DL-technique
momentum	AI/ML/DL-technique
(	AI/ML/DL-technique
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
ZOM	AI/ML/DL-technique
)	AI/ML/DL-technique
method	O
for	O
black	O
-	O
box	O
mini	O
-	O
optimization	O
where	O
only	O
function	O
values	O
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
ZOM	AI/ML/DL-technique
btained	O
.	O

Moreover	O
,	O
we	O
prove	O
that	O
our	O
Acc	O
-	O
ZOM	O
method	O
achieves	O
a	O
lower	O
query	O
complexity	O
of	O
$\	O
tilde	O
{	O
O	O
}(	O
d	O
^{	O
3	O
/	O
4	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
for	O
finding	O
an	O
$\	O
epsilon	O
$-	O
stationary	AI/ML/DL-term
point	AI/ML/DL-term
which	O
improves	O
the	O
best	O
known	O
result	O
by	O
a	O
factor	O
of	O
$	O
O	O
(	O
d	O
^{	O
1	O
/	O
4	O
})$	O
where	O
$	O
d	O
$	O
denotes	O
the	O
variable	O
dimension	O
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
ZOM	AI/ML/DL-technique
.	O

Moreover	O
,	O
we	O
prove	O
that	O
our	O
Acc	O
-	O
ZOM	O
method	O
achieves	O
a	O
lower	O
query	O
complexity	O
of	O
$\	O
tilde	O
{	O
O	O
}(	O
d	O
^{	O
3	O
/	O
4	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
for	O
finding	O
an	O
$\	O
epsilon	O
$-	O
stationary	AI/ML/DL-term
point	AI/ML/DL-term
which	O
improves	O
the	O
best	O
known	O
result	O
by	O
a	O
factor	O
of	O
$	O
O	O
(	O
d	O
^{	O
1	O
/	O
4	O
})$	O
where	O
$	O
d	O
$	O
denotes	O
the	O
variable	O
dimension	O
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
ZOM	AI/ML/DL-technique
.	O

Meanwhile	O
,	O
we	O
propose	O
an	O
accelerated	AI/ML/DL-technique
zeroth	AI/ML/DL-technique
-	AI/ML/DL-technique
order	AI/ML/DL-technique
momentum	AI/ML/DL-technique
descent	AI/ML/DL-technique
ascent	AI/ML/DL-technique
(	AI/ML/DL-technique
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
ZOMDA	AI/ML/DL-technique
)	AI/ML/DL-technique
method	O
for	O
black	O
-	O
box	O
minimax	O
optimization	O
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
ZOMDA	AI/ML/DL-technique
y	O
function	O
values	O
can	O
be	O
obtained	O
.	O

Our	O
Acc	O
-	O
ZOMDA	O
obtains	O
a	O
low	O
query	O
complexity	O
of	O
$\	O
tilde	O
{	O
O	O
}((	O
d_1	O
+	O
d_2	O
)^{	O
3	O
/	O
4	O
}\	O
kappa_y	O
^{	O
4	O
.	O
5	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
without	O
requiring	O
large	O
batches	O
for	O
finding	O
an	O
$\	O
epsilon	O
$-	O
stationary	AI/ML/DL-term
point	AI/ML/DL-term
where	O
$	O
d_1	O
$	O
and	O
$	O
d_2	O
$	O
denote	O
variable	O
dimensions	O
and	O
$\	O
kappa_y	O
$	O
is	O
condition	O
number	O
.	O

Moreover	O
,	O
we	O
propose	O
an	O
accelerated	AI/ML/DL-technique
first	AI/ML/DL-technique
-	AI/ML/DL-technique
order	AI/ML/DL-technique
momentum	AI/ML/DL-technique
descent	AI/ML/DL-technique
ascent	AI/ML/DL-technique
(	AI/ML/DL-technique
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
MDA	AI/ML/DL-technique
)	AI/ML/DL-technique
method	O
for	O
minimax	O
optimization	O
whose	O
explicit	O
gradients	AI/ML/DL-term
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
MDA	AI/ML/DL-technique
ssible	O
.	O

Moreover	O
,	O
we	O
propose	O
an	O
accelerated	AI/ML/DL-technique
first	AI/ML/DL-technique
-	AI/ML/DL-technique
order	AI/ML/DL-technique
momentum	AI/ML/DL-technique
descent	AI/ML/DL-technique
ascent	AI/ML/DL-technique
(	AI/ML/DL-technique
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
MDA	AI/ML/DL-technique
)	AI/ML/DL-technique
method	O
for	O
minimax	O
optimization	O
whose	O
explicit	O
gradients	AI/ML/DL-term
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
MDA	AI/ML/DL-technique
ssible	O
.	O

Our	O
Acc	O
-	O
MDA	O
achieves	O
a	O
low	O
gradient	AI/ML/DL-term
complexity	AI/ML/DL-term
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
MDA	AI/ML/DL-technique
de	O
{	O
O	O
}(\	O
kappa_y	O
^{	O
4	O
.	O
5	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
without	O
requiring	O
large	O
batches	O
for	O
finding	O
an	O
$\	O
epsilon	O
$-	O
stationary	O
point	O
.	O

Our	O
Acc	O
-	O
MDA	O
achieves	O
a	O
low	O
gradient	AI/ML/DL-term
complexity	AI/ML/DL-term
Acc	AI/ML/DL-technique
-	AI/ML/DL-technique
MDA	AI/ML/DL-technique
de	O
{	O
O	O
}(\	O
kappa_y	O
^{	O
4	O
.	O
5	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
without	O
requiring	O
large	O
batches	O
for	O
finding	O
an	O
$\	O
epsilon	O
$-	O
stationary	O
point	O
.	O

In	O
particular	O
,	O
our	O
Acc	O
-	O
MDA	O
can	O
obtain	O
a	O
lower	O
gradient	AI/ML/DL-term
complexity	AI/ML/DL-term
of	O
$\	O
tilde	O
{	O
O	O
}(\	O
kappa_y	O
^{	O
2	O
.	O
5	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
with	O
a	O
batch	O
size	O
$	O
O	O
(\	O
kappa_y	O
^	O
4	O
)$,	O
which	O
improves	O
the	O
best	O
known	O
result	O
by	O
a	O
factor	O
of	O
$	O
O	O
(\	O
kappa_y	O
^{	O
1	O
/	O
2	O
})$.	O

Extensive	O
experimental	O
results	O
on	O
black	O
-	O
box	O
adversarial	O
attack	O
to	O
deep	O
neural	O
networks	O
and	O
poisoning	O
attack	O
to	O
logistic	O
regression	O
demonstrate	O
efficiency	O
of	O
our	O
algorithms	Miscellaneous-term
.	O

By	O
carefully	O
choosing	O
the	O
tangent	O
point	O
we	O
are	O
able	O
to	O
derive	O
fast	O
empirical	Miscellaneous-term
methods	Miscellaneous-term
exploiting	O
a	O
constrained	O
B	O
-	O
spline	O
approximation	O
.	O

In	O
Approximate	O
Bayesian	O
Computation	O
(	O
ABC	O
)	O
a	O
popular	O
LFI	O
method	O
,	O
summary	O
statistics	O
are	O
used	O
to	O
reduce	O
data	AI/ML/DL-term
dimensionality	AI/ML/DL-term
ABC	O
algorithms	Miscellaneous-term
.	O

In	O
Approximate	O
Bayesian	O
Computation	O
(	O
ABC	O
)	O
a	O
popular	O
LFI	O
method	O
,	O
summary	O
statistics	O
are	O
used	O
to	O
reduce	O
data	AI/ML/DL-term
dimensionality	AI/ML/DL-term
ABC	O
algorithms	Miscellaneous-term
.	O

In	O
this	O
work	O
,	O
we	O
introduce	O
a	O
new	O
way	O
to	O
learn	O
ABC	O
statistics	O
:	O
we	O
first	O
generate	O
parameter	AI/ML/DL-term
-	AI/ML/DL-term
simulation	AI/ML/DL-term
pairs	AI/ML/DL-term
from	O
the	O
model	O
independently	O
on	O
the	O
observation	O
;	O
then	O
,	O
we	O
use	O
Score	O
Matching	O
to	O
train	O
a	O
neural	O
conditional	O
exponential	O
family	O
to	O
approximate	O
the	O
likelihood	O
.	O

The	O
exponential	O
family	O
is	O
the	O
largest	O
class	O
of	O
distributions	O
with	O
fixed	O
-	O
size	O
sufficient	O
statistics	O
;	O
thus	O
,	O
we	O
use	O
them	O
in	O
ABC	O
which	O
is	O
intuitively	O
appealing	O
and	O
has	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
.	O

We	O
develop	O
a	O
rigorous	O
and	O
general	O
framework	O
for	O
constructing	O
information	AI/ML/DL-term
-	AI/ML/DL-term
theoretic	AI/ML/DL-term
divergences	AI/ML/DL-term
divergences	O
both	O
$	O
f	O
$-	O
divergences	O
and	O
integral	O
probability	O
metrics	O
(	O
IPMs	O
)	O
such	O
as	O
the	O
$	O
1	O
$-	O
Wasserstein	O
distance	O
.	O

Using	O
statistical	O
learning	O
as	O
an	O
example	O
,	O
we	O
demonstrate	O
their	O
advantage	O
in	O
training	AI/ML/DL-term
generative	O
adversarial	O
networks	O
(	O
GANs	O
)	O
for	O
heavy	O
-	O
tailed	O
,	O
not	O
-	O
absolutely	O
continuous	O
sample	O
distributions	O
.	O

We	O
consider	O
a	O
problem	O
of	O
manifold	O
estimation	O
from	O
noisy	AI/ML/DL-term
observations	AI/ML/DL-term
manifold	O
learning	O
.	O

In	O
our	O
theoretical	O
study	O
,	O
we	O
establish	O
tight	O
lower	O
and	O
upper	O
bounds	O
proving	O
asymptotic	O
optimality	O
of	O
the	O
method	O
for	O
manifold	O
estimation	O
under	O
the	O
Hausdorff	AI/ML/DL-term
loss	AI/ML/DL-term
provided	O
that	O
the	O
noise	O
degrades	O
to	O
zero	O
fast	O
enough	O
.	O

We	O
introduce	O
a	O
novel	O
approach	O
to	O
estimation	O
problems	O
in	O
settings	O
with	O
missing	Miscellaneous-term
data	Miscellaneous-term
.	O

Our	O
proposal	O
--	O
the	O
Correlation	AI/ML/DL-technique
-	AI/ML/DL-technique
Assisted	AI/ML/DL-technique
Missing	AI/ML/DL-technique
data	AI/ML/DL-technique
(	AI/ML/DL-technique
CAM	AI/ML/DL-technique
)	AI/ML/DL-technique
estimator	AI/ML/DL-technique
--	O
works	O
by	O
exploiting	O
the	O
relationship	O
between	O
the	O
observations	O
with	O
missing	O
features	O
and	O
those	O
without	O
missing	O
features	O
in	O
order	O
to	O
obtain	O
improved	O
prediction	O
accuracy	O
.	O

In	O
particular	O
,	O
our	O
theoretical	O
results	O
elucidate	O
general	O
conditions	O
under	O
which	O
the	O
proposed	O
CAM	AI/ML/DL-technique
estimator	AI/ML/DL-technique
has	O
lower	O
mean	O
squared	O
error	O
than	O
the	O
widely	O
used	O
complete	O
-	O
case	O
approach	O
in	O
a	O
range	O
of	O
estimation	O
problems	O
.	O

We	O
showcase	O
in	O
detail	O
how	O
the	O
CAM	AI/ML/DL-technique
estimator	AI/ML/DL-technique
can	O
be	O
applied	O
to	O
$	O
U	O
$-	O
Statistics	O
to	O
obtain	O
an	O
unbiased	O
,	O
asymptotically	O
Gaussian	O
estimator	O
that	O
has	O
lower	O
variance	O
than	O
the	O
complete	O
-	O
case	O
$	O
U	O
$-	O
Statistic	O
.	O

Further	O
,	O
in	O
nonparametric	O
density	O
estimation	O
and	O
regression	O
problems	O
,	O
we	O
construct	O
our	O
CAM	AI/ML/DL-technique
estimator	AI/ML/DL-technique
using	O
kernel	AI/ML/DL-term
functions	AI/ML/DL-term
and	O
show	O
it	O
has	O
lower	O
asymptotic	O
mean	O
squared	O
error	O
than	O
the	O
corresponding	O
complete	O
-	O
case	O
kernel	O
estimator	O
.	O

Further	O
,	O
in	O
nonparametric	O
density	O
estimation	O
and	O
regression	O
problems	O
,	O
we	O
construct	O
our	O
CAM	AI/ML/DL-technique
estimator	AI/ML/DL-technique
using	O
kernel	AI/ML/DL-term
functions	AI/ML/DL-term
and	O
show	O
it	O
has	O
lower	O
asymptotic	O
mean	O
squared	O
error	O
than	O
the	O
corresponding	O
complete	O
-	O
case	O
kernel	O
estimator	O
.	O

We	O
perform	O
a	O
systematic	O
study	O
of	O
the	O
approximation	O
properties	O
and	O
optimization	O
dynamics	O
of	O
recurrent	O
neural	O
networks	O
(	O
RNNs	O
)	O
when	O
applied	O
to	O
learn	O
input	O
-	O
output	O
relationships	O
in	O
temporal	AI/ML/DL-term
data	AI/ML/DL-term
.	O

In	O
particular	O
,	O
we	O
show	O
that	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
can	O
be	O
effectively	O
approximated	O
by	O
RNNs	O
if	O
and	O
only	O
if	O
the	O
former	O
possesses	O
sufficient	O
memory	O
decay	O
.	O

On	O
the	O
optimization	O
front	O
,	O
we	O
perform	O
detailed	O
analysis	O
of	O
the	O
optimization	AI/ML/DL-term
dynamics	AI/ML/DL-term
including	O
a	O
precise	O
understanding	O
of	O
the	O
difficulty	O
that	O
may	O
arise	O
in	O
learning	O
relationships	O
with	O
long	Miscellaneous-term
-	Miscellaneous-term
term	Miscellaneous-term
memory	Miscellaneous-term
.	O

On	O
the	O
optimization	O
front	O
,	O
we	O
perform	O
detailed	O
analysis	O
of	O
the	O
optimization	AI/ML/DL-term
dynamics	AI/ML/DL-term
including	O
a	O
precise	O
understanding	O
of	O
the	O
difficulty	O
that	O
may	O
arise	O
in	O
learning	O
relationships	O
with	O
long	Miscellaneous-term
-	Miscellaneous-term
term	Miscellaneous-term
memory	Miscellaneous-term
.	O

These	O
results	O
form	O
a	O
relatively	O
complete	O
picture	O
of	O
the	O
interaction	O
of	O
memory	O
and	O
recurrent	O
structures	O
in	O
the	O
linear	AI/ML/DL-term
dynamical	AI/ML/DL-term
setting	AI/ML/DL-term
.	O
Game	O
-	O
theoretic	O
attribution	O
techniques	O
.	O

Game	O
-	O
theoretic	O
attribution	O
techniques	O
based	O
on	O
Shapley	O
values	O
are	O
used	O
to	O
interpret	O
black	O
-	O
box	O
machine	O
learning	O
models	O
but	O
their	O
exact	O
calculation	O
is	O
generally	O
NP	Miscellaneous-term
-	Miscellaneous-term
hard	Miscellaneous-term
Shapley	O
values	O
oximation	O
methods	O
for	O
non	O
-	O
trivial	O
models	O
.	O

Second	O
,	O
we	O
exploit	O
connections	O
between	O
the	O
hypersphere	O
$\	O
mathbb	O
{	O
S	O
}^{	O
d	O
-	O
2	O
}$	O
and	O
permutations	O
to	O
create	O
practical	O
algorithms	Miscellaneous-term
for	O
generating	O
permutation	O
samples	O
with	O
good	O
properties	O
.	O

Open	O
category	O
detection	O
is	O
the	O
problem	O
of	O
detecting	O
“	O
alien	O
"	O
test	O
instances	O
that	O
belong	O
to	O
categories	O
or	O
classes	O
that	O
were	O
not	O
present	O
in	O
the	O
training	AI/ML/DL-term
data	AI/ML/DL-term
.	O

In	O
many	O
applications	O
,	O
reliably	O
detecting	O
such	O
aliens	O
is	O
central	O
to	O
ensuring	O
the	O
safety	O
and	O
accuracy	O
of	O
test	O
set	O
predictions	O
.	O
algorithms	Miscellaneous-term
.	O

Unfortunately	O
,	O
there	O
are	O
no	O
algorithms	Miscellaneous-term
that	O
provide	O
theoretical	O
guarantees	O
on	O
their	O
ability	O
to	O
detect	O
aliens	O
under	O
general	O
assumptions	O
.	O

Thus	O
,	O
there	O
are	O
significant	O
theoretical	O
and	O
empirical	Miscellaneous-term
gaps	Miscellaneous-term
in	O
our	O
understanding	O
of	O
open	O
category	O
detection	O
.	O

In	O
our	O
setting	O
,	O
we	O
are	O
provided	O
with	O
a	O
“	AI/ML/DL-term
clean	AI/ML/DL-term
"	AI/ML/DL-term
training	AI/ML/DL-term
set	AI/ML/DL-term
that	O
contains	O
only	O
the	O
target	O
categories	O
of	O
interest	O
and	O
an	O
unlabeled	AI/ML/DL-term
“	AI/ML/DL-term
contaminated	AI/ML/DL-term
”	AI/ML/DL-term
training	AI/ML/DL-term
set	AI/ML/DL-term
that	O
contains	O
a	O
fraction	O
$\	O
alpha	O
$	O
of	O
alien	O
examples	O
.	O

Under	O
the	O
assumption	O
that	O
we	O
know	O
an	O
upper	O
bound	O
on	O
$\	O
alpha	O
$,	O
we	O
develop	O
an	O
algorithm	Miscellaneous-term
that	O
gives	O
PAC	AI/ML/DL-term
-	AI/ML/DL-term
style	AI/ML/DL-term
guarantees	AI/ML/DL-term
on	O
the	O
alien	AI/ML/DL-term
detection	AI/ML/DL-term
rate	AI/ML/DL-term
while	O
aiming	O
to	O
minimize	O
false	O
alarms	O
.	O

Under	O
the	O
assumption	O
that	O
we	O
know	O
an	O
upper	O
bound	O
on	O
$\	O
alpha	O
$,	O
we	O
develop	O
an	O
algorithm	Miscellaneous-term
that	O
gives	O
PAC	AI/ML/DL-term
-	AI/ML/DL-term
style	AI/ML/DL-term
guarantees	AI/ML/DL-term
on	O
the	O
alien	AI/ML/DL-term
detection	AI/ML/DL-term
rate	AI/ML/DL-term
while	O
aiming	O
to	O
minimize	O
false	O
alarms	O
.	O

Given	O
an	O
overall	O
budget	O
on	O
the	O
amount	O
of	O
training	AI/ML/DL-term
data	AI/ML/DL-term
we	O
also	O
derive	O
the	O
optimal	O
allocation	O
of	O
samples	O
between	O
the	O
mixture	O
and	O
the	O
clean	Miscellaneous-term
data	Miscellaneous-term
sets	Miscellaneous-term
.	O

Given	O
an	O
overall	O
budget	O
on	O
the	O
amount	O
of	O
training	AI/ML/DL-term
data	AI/ML/DL-term
we	O
also	O
derive	O
the	O
optimal	O
allocation	O
of	O
samples	O
between	O
the	O
mixture	O
and	O
the	O
clean	Miscellaneous-term
data	Miscellaneous-term
sets	Miscellaneous-term
.	O

Experiments	O
on	O
synthetic	O
and	O
standard	O
benchmark	O
datasets	O
evaluate	O
the	O
regimes	O
in	O
which	O
the	O
algorithm	Miscellaneous-term
can	O
be	O
effective	O
and	O
provide	O
a	O
baseline	Miscellaneous-term
for	O
further	O
advancements	O
.	O

In	O
addition	O
,	O
for	O
the	O
situation	O
when	O
an	O
upper	O
bound	O
for	O
$\	O
alpha	O
$	O
is	O
not	O
available	O
,	O
we	O
employ	O
nine	O
different	O
anomaly	O
proportion	O
estimators	O
and	O
run	O
experiments	O
on	O
both	O
synthetic	O
and	O
standard	Miscellaneous-term
benchmark	Miscellaneous-term
data	Miscellaneous-term
sets	Miscellaneous-term
to	O
compare	O
their	O
performance	O
.	O
optimal	O
transport	O
problem	O
.	O

Transition	O
couplings	O
are	O
a	O
constrained	O
family	O
of	O
transport	AI/ML/DL-term
plans	AI/ML/DL-term
that	O
capture	O
the	O
dynamics	O
of	O
Markov	O
chains	O
.	O

We	O
establish	O
a	O
connection	O
between	O
the	O
OTC	O
problem	O
and	O
Markov	O
decision	O
processes	O
OTC	O
show	O
that	O
solutions	O
of	O
the	O
OTC	O
problem	O
can	O
be	O
obtained	O
via	O
an	O
adaptation	O
of	O
policy	O
iteration	O
.	O
state	AI/ML/DL-term
spaces	AI/ML/DL-term
.	O

For	O
settings	O
with	O
large	O
state	O
spaces	O
,	O
we	O
develop	O
a	O
fast	O
approximate	O
algorithm	O
based	O
on	O
an	O
entropy	AI/ML/DL-term
-	AI/ML/DL-term
regularized	AI/ML/DL-term
version	AI/ML/DL-term
of	O
the	O
OTC	O
problem	O
,	O
and	O
provide	O
bounds	O
on	O
its	O
per	Miscellaneous-term
-	Miscellaneous-term
iteration	Miscellaneous-term
complexity	Miscellaneous-term
.	O

For	O
settings	O
with	O
large	O
state	O
spaces	O
,	O
we	O
develop	O
a	O
fast	O
approximate	O
algorithm	O
based	O
on	O
an	O
entropy	AI/ML/DL-term
-	AI/ML/DL-term
regularized	AI/ML/DL-term
version	AI/ML/DL-term
of	O
the	O
OTC	O
problem	O
,	O
and	O
provide	O
bounds	O
on	O
its	O
per	Miscellaneous-term
-	Miscellaneous-term
iteration	Miscellaneous-term
complexity	Miscellaneous-term
.	O

We	O
establish	O
a	O
stability	O
result	O
for	O
both	O
the	O
regularized	Miscellaneous-term
and	O
unregularized	Miscellaneous-term
algorithms	Miscellaneous-term
from	O
which	O
a	O
statistical	O
consistency	O
result	O
follows	O
as	O
a	O
corollary	O
.	O

We	O
validate	O
our	O
theoretical	O
results	O
empirically	O
through	O
a	O
simulation	O
study	O
,	O
demonstrating	O
that	O
the	O
approximate	Miscellaneous-term
algorithm	Miscellaneous-term
exhibits	O
faster	O
overall	O
runtime	Miscellaneous-term
with	O
low	O
error	O
.	O

Finally	O
,	O
we	O
extend	O
the	O
setting	O
and	O
application	O
of	O
our	O
methods	O
to	O
hidden	O
Markov	O
models	O
and	O
illustrate	O
the	O
potential	O
use	O
of	O
the	O
proposed	O
algorithms	Miscellaneous-term
in	O
practice	O
with	O
an	O
application	O
to	O
computer	O
-	O
generated	O
music	O
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
the	O
concentration	AI/ML/DL-term
property	AI/ML/DL-term
of	O
stochastic	O
gradient	O
descent	O
(	O
SGD	O
)	O
solutions	O
.	O
concentration	O
analyses	O
.	O

In	O
existing	O
concentration	O
analyses	O
,	O
researchers	O
impose	O
restrictive	O
requirements	O
on	O
the	O
gradient	AI/ML/DL-term
noise	AI/ML/DL-term
such	O
as	O
boundedness	O
or	O
sub	O
-	O
Gaussianity	O
.	O

Specifically	O
,	O
we	O
prove	O
that	O
,	O
after	O
$	O
T	O
$	O
steps	O
of	O
SGD	O
the	O
ASGD	O
estimate	O
achieves	O
an	O
$	O
O	O
(\	O
sqrt	O
{\	O
log	O
(	O
1	O
/\	O
delta	O
)/	O
T	O
}	O
+	O
(\	O
delta	O
T	O
^{	O
q	O
-	O
1	O
})^{-	O
1	O
/	O
q	O
})$	O
error	O
rate	O
with	O
probability	O
at	O
least	O
$	O
1	O
-\	O
delta	O
$,	O
where	O
$	O
q	O
>	O
2	O
$	O
controls	O
the	O
tail	O
of	O
the	O
gradient	AI/ML/DL-term
noise	AI/ML/DL-term
.	O

Our	O
concentration	O
analysis	O
indicates	O
that	O
,	O
in	O
the	O
case	O
of	O
heavy	O
-	O
tailed	O
noises	O
,	O
the	O
polynomial	Miscellaneous-term
dependence	Miscellaneous-term
on	O
the	O
failure	O
probability	O
$\	O
delta	O
$	O
is	O
generally	O
unavoidable	O
for	O
the	O
error	O
rate	O
of	O
SGD	O
.	O
cascaded	O
diffusion	O
models	O
.	O

We	O
show	O
that	O
cascaded	O
diffusion	O
models	O
are	O
capable	O
of	O
generating	O
high	Computer/vision-term
fidelity	Computer/vision-term
images	Computer/vision-term
on	O
the	O
class	O
-	O
conditional	O
ImageNet	O
generation	O
benchmark	O
without	O
any	O
assistance	O
from	O
auxiliary	O
image	O
classifiers	O
cascaded	O
diffusion	O
model	O
.	O

Our	O
experiments	O
show	O
that	O
conditioning	O
augmentation	O
prevents	O
compounding	O
error	O
during	O
sampling	O
in	O
a	O
cascaded	O
model	O
,	O
helping	O
us	O
to	O
train	O
cascading	O
pipelines	O
achieving	O
FID	O
scores	O
of	O
1	O
.	O
48	O
at	O
64x64	O
3	O
.	O
52	O
at	O
128x128	O
and	O
4	O
.	O
88	O
at	O
256x256	O
resolutions	O
,	O
outperforming	O
BigGAN	O
-	O
deep	O
and	O
classification	O
accuracy	O
scores	O
of	O
63	O
.	O
02	O
%	O
(	O
top	O
-	O
1	O
)	O
and	O
84	O
.	O
06	O
%	O
(	O
top	O
-	O
5	O
)	O
at	O
256x256	O
outperforming	O
VQ	O
-	O
VAE	O
-	O
2	O
.	O
parameters	Miscellaneous-term
.	O

Finding	O
parameters	O
in	O
a	O
deep	O
neural	O
network	O
(	O
NN	O
)	O
that	O
fit	O
training	AI/ML/DL-term
data	AI/ML/DL-term
is	O
a	O
nonconvex	O
optimization	O
problem	O
but	O
a	O
basic	O
first	O
-	O
order	O
optimization	O
method	O
(	O
gradient	O
descent	O
finds	O
a	O
global	O
optimizer	O
with	O
perfect	O
fit	O
(	O
zero	O
-	O
loss	AI/ML/DL-term
in	O
many	O
practical	O
situations	O
.	O

We	O
examine	O
this	O
phenomenon	O
for	O
the	O
case	O
of	O
Residual	O
Neural	O
Networks	O
(	O
ResNet	O
)	O
with	O
smooth	O
activation	O
functions	O
in	O
a	O
limiting	O
regime	O
in	O
which	O
both	O
the	O
number	O
of	O
layers	AI/ML/DL-term
(	O
depth	O
)	O
and	O
the	O
number	O
of	O
weights	AI/ML/DL-term
in	O
each	O
layer	O
(	O
width	O
)	O
go	O
to	O
infinity	O
.	O

First	O
,	O
we	O
use	O
a	O
mean	O
-	O
field	O
-	O
limit	O
argument	O
to	O
prove	O
that	O
the	O
gradient	O
descent	O
for	O
parameter	O
training	O
becomes	O
a	O
gradient	AI/ML/DL-term
flow	AI/ML/DL-term
for	O
a	O
probability	O
distribution	O
that	O
is	O
characterized	O
by	O
a	O
partial	O
differential	O
equation	O
(	O
PDE	O
)	O
in	O
the	O
large	AI/ML/DL-term
-	AI/ML/DL-term
NN	AI/ML/DL-term
limit	AI/ML/DL-term
.	O

Next	O
,	O
we	O
show	O
that	O
under	O
certain	O
assumptions	O
,	O
the	O
solution	O
to	O
the	O
PDE	O
converges	O
in	O
the	O
training	O
time	O
to	O
a	O
zero	O
-	O
loss	AI/ML/DL-term
solution	O
.	O

Together	O
,	O
these	O
results	O
suggest	O
that	O
the	O
training	O
of	O
the	O
ResNet	O
gives	O
a	O
near	O
-	O
zero	O
loss	AI/ML/DL-term
ResNet	O
ResNet	O
is	O
large	O
enough	O
.	O

The	O
innovation	O
at	O
a	O
time	O
is	O
statistically	AI/ML/DL-term
independent	AI/ML/DL-term
of	O
the	O
history	O
of	O
the	O
time	O
series	O
.	O

This	O
paper	O
presents	O
a	O
deep	O
learning	O
approach	O
,	O
referred	O
to	O
as	O
Innovations	AI/ML/DL-technique
Autoencoder	AI/ML/DL-technique
(	AI/ML/DL-technique
IAE	AI/ML/DL-technique
)	AI/ML/DL-technique
that	O
extracts	O
innovations	O
sequences	O
using	O
a	O
causal	O
convolutional	O
neural	O
network	O
IAE	AI/ML/DL-technique
.	O

With	O
few	O
exceptions	O
,	O
neural	O
networks	O
have	O
been	O
relying	O
on	O
backpropagation	AI/ML/DL-term
and	O
gradient	O
descent	O
as	O
the	O
inference	O
engine	O
in	O
order	O
to	O
learn	O
the	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
because	O
closed	O
-	O
form	O
Bayesian	O
inference	O
neural	O
networks	O
rks	O
has	O
been	O
considered	O
to	O
be	O
intractable	O
.	O

In	O
this	O
paper	O
,	O
we	O
show	O
how	O
we	O
can	O
leverage	O
the	O
tractable	O
approximate	O
Gaussian	O
inference	O
'	O
s	O
(	O
TAGI	O
)	O
capabilities	O
to	O
infer	O
hidden	O
states	O
,	O
rather	O
than	O
only	O
using	O
it	O
for	O
inferring	O
the	O
network	O
'	O
s	O
parameters	AI/ML/DL-term
.	O

One	O
novel	O
aspect	O
is	O
that	O
it	O
allows	O
inferring	O
hidden	AI/ML/DL-term
states	AI/ML/DL-term
through	O
the	O
imposition	O
of	O
constraints	O
designed	O
to	O
achieve	O
specific	O
objectives	O
,	O
as	O
illustrated	O
through	O
three	O
examples	O
:	O
(	O
1	O
)	O
the	O
generation	O
of	O
adversarial	AI/ML/DL-term
-	AI/ML/DL-term
attack	AI/ML/DL-term
examples	AI/ML/DL-term
(	O
2	O
)	O
the	O
usage	O
of	O
a	O
neural	O
network	O
as	O
a	O
black	O
-	O
box	O
optimization	O
method	O
,	O
and	O
(	O
3	O
)	O
the	O
application	O
of	O
inference	AI/ML/DL-term
on	O
continuous	O
-	O
action	O
reinforcement	O
learning	O
.	O

In	O
these	O
three	O
examples	O
,	O
the	O
constrains	O
are	O
in	O
(	O
1	O
),	O
a	O
target	AI/ML/DL-term
label	AI/ML/DL-term
chosen	O
to	O
fool	O
a	O
neural	O
network	O
network	AI/ML/DL-term
(	O
2	O
and	O
3	O
)	O
the	O
derivative	O
of	O
the	O
network	O
with	O
respect	O
to	O
its	O
input	O
that	O
is	O
set	O
to	O
zero	O
in	O
order	O
to	O
infer	O
the	O
optimal	Miscellaneous-term
input	Miscellaneous-term
values	Miscellaneous-term
that	O
are	O
either	O
maximizing	O
or	O
minimizing	O
it	O
.	O

In	O
these	O
three	O
examples	O
,	O
the	O
constrains	O
are	O
in	O
(	O
1	O
),	O
a	O
target	AI/ML/DL-term
label	AI/ML/DL-term
chosen	O
to	O
fool	O
a	O
neural	O
network	O
network	AI/ML/DL-term
(	O
2	O
and	O
3	O
)	O
the	O
derivative	O
of	O
the	O
network	O
with	O
respect	O
to	O
its	O
input	O
that	O
is	O
set	O
to	O
zero	O
in	O
order	O
to	O
infer	O
the	O
optimal	Miscellaneous-term
input	Miscellaneous-term
values	Miscellaneous-term
that	O
are	O
either	O
maximizing	O
or	O
minimizing	O
it	O
.	O

These	O
applications	O
showcase	O
how	O
tasks	O
that	O
were	O
previously	O
reserved	O
to	O
gradient	O
-	O
based	O
optimization	O
approaches	O
can	O
now	O
be	O
approached	O
with	O
analytically	AI/ML/DL-term
tractable	AI/ML/DL-term
inference	AI/ML/DL-term
.	O
scikit	O
-	O
multimodallearn	O
Python	O
library	O
.	O

scikit	O
-	O
multimodallearn	O
is	O
a	O
Python	O
library	O
for	O
multimodal	O
supervised	O
learning	O
licensed	O
under	O
Free	Miscellaneous-term
BSD	Miscellaneous-term
and	O
compatible	O
with	O
the	O
well	O
-	O
known	O
scikit	O
-	O
learn	O
toolbox	O
(	O
Fabian	O
Pedregosa	O
,	O
2011	O
).	O

This	O
paper	O
details	O
the	O
content	O
of	O
the	O
library	O
,	O
including	O
a	O
specific	O
multimodal	AI/ML/DL-term
data	AI/ML/DL-term
formatting	O
and	O
classification	O
and	O
regression	O
algorithms	Miscellaneous-term
.	O

This	O
paper	O
details	O
the	O
content	O
of	O
the	O
library	O
,	O
including	O
a	O
specific	O
multimodal	AI/ML/DL-term
data	AI/ML/DL-term
formatting	O
and	O
classification	O
and	O
regression	O
algorithms	Miscellaneous-term
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
conditional	O
density	O
estimator	O
based	O
on	O
gradient	O
boosting	O
and	O
Lindsey	O
'	O
s	O
method	O
(	O
LinCDE	AI/ML/DL-technique
LinCDE	AI/ML/DL-technique
.	O

LinCDE	O
admits	O
flexible	O
modeling	O
of	O
the	O
density	O
family	O
and	O
can	O
capture	O
distributional	O
characteristics	O
like	O
modality	O
LinCDE	AI/ML/DL-technique
pe	O
.	O

In	O
particular	O
,	O
when	O
suitably	O
parametrized	O
,	O
LinCDE	O
will	O
produce	O
smooth	O
and	O
non	O
-	O
negative	O
density	O
estimates	O
.	O
boosted	O
regression	O
trees	O
LinCDE	AI/ML/DL-technique
.	O

Furthermore	O
,	O
like	O
boosted	O
regression	O
trees	O
,	O
LinCDE	O
does	O
automatic	O
feature	O
selection	O
LinCDE	AI/ML/DL-technique
'	AI/ML/DL-technique
s	AI/ML/DL-technique
.	O

DoubleML	O
is	O
an	O
open	O
-	O
source	O
Python	O
library	O
implementing	O
the	O
double	AI/ML/DL-term
machine	AI/ML/DL-term
learning	AI/ML/DL-term
framework	AI/ML/DL-term
of	O
Chernozhukov	O
et	O
al	O
.	O

It	O
contains	O
functionalities	O
for	O
valid	O
statistical	O
inference	O
on	O
causal	O
parameters	AI/ML/DL-term
parameters	AI/ML/DL-term
timation	O
of	O
nuisance	O
parameters	O
is	O
based	O
on	O
machine	O
learning	O
methods	O
.	O
DoubleML	O
.	O

The	O
object	O
-	O
oriented	O
implementation	O
of	O
DoubleML	O
provides	O
a	O
high	O
flexibility	O
in	O
terms	O
of	O
model	O
specifications	O
and	O
makes	O
it	O
easily	O
extendable	O
.	O
MIT	Miscellaneous-term
license	Miscellaneous-term
.	O

Source	O
code	O
,	O
documentation	O
and	O
an	O
extensive	O
user	O
guide	O
can	O
be	O
found	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
DoubleML	O
/	O
doubleml	O
-	O
for	O
-	O
py	O
and	O
https	O
://	O
docs	O
.	O
doubleml	O
.	O
org	O
.	O
hyperparameters	AI/ML/DL-term
.	O

Algorithm	O
parameters	O
,	O
in	O
particular	O
hyperparameters	O
of	O
machine	O
learning	O
algorithms	Miscellaneous-term
can	O
substantially	O
impact	O
their	O
performance	O
.	O

To	O
support	O
users	O
in	O
determining	O
well	O
-	O
performing	O
hyperparameter	AI/ML/DL-term
configurations	AI/ML/DL-term
for	O
their	O
algorithms	Miscellaneous-term
datasets	Miscellaneous-term
and	O
applications	O
at	O
hand	O
,	O
SMAC3	O
offers	O
a	O
robust	Miscellaneous-term
and	O
flexible	Miscellaneous-term
framework	Miscellaneous-term
for	O
Bayesian	O
Optimization	O
which	O
can	O
improve	O
performance	O
within	O
a	O
few	O
evaluations	O
.	O

To	O
support	O
users	O
in	O
determining	O
well	O
-	O
performing	O
hyperparameter	AI/ML/DL-term
configurations	AI/ML/DL-term
for	O
their	O
algorithms	Miscellaneous-term
datasets	Miscellaneous-term
and	O
applications	O
at	O
hand	O
,	O
SMAC3	O
offers	O
a	O
robust	Miscellaneous-term
and	O
flexible	Miscellaneous-term
framework	Miscellaneous-term
for	O
Bayesian	O
Optimization	O
which	O
can	O
improve	O
performance	O
within	O
a	O
few	O
evaluations	O
.	O

It	O
offers	O
several	O
facades	O
and	O
pre	O
-	O
sets	O
for	O
typical	O
use	O
cases	O
,	O
such	O
as	O
optimizing	O
hyperparameters	AI/ML/DL-term
solving	O
low	O
dimensional	O
continuous	O
(	O
artificial	O
)	O
global	O
optimization	O
problems	O
and	O
configuring	O
algorithms	Miscellaneous-term
to	O
perform	O
well	O
across	O
multiple	O
problem	O
instances	O
.	O
SMAC3	O
.	O

It	O
offers	O
several	O
facades	O
and	O
pre	O
-	O
sets	O
for	O
typical	O
use	O
cases	O
,	O
such	O
as	O
optimizing	O
hyperparameters	AI/ML/DL-term
solving	O
low	O
dimensional	O
continuous	O
(	O
artificial	O
)	O
global	O
optimization	O
problems	O
and	O
configuring	O
algorithms	Miscellaneous-term
to	O
perform	O
well	O
across	O
multiple	O
problem	O
instances	O
.	O
SMAC3	O
.	O

The	O
SMAC3	O
package	O
is	O
available	O
under	O
a	O
permissive	O
BSD	Miscellaneous-term
-	Miscellaneous-term
license	Miscellaneous-term
at	O
https	O
://	O
github	O
.	O
com	O
/	O
automl	O
/	O
SMAC3	O
.	O
Bayesian	AI/ML/DL-technique
pseudo	AI/ML/DL-technique
posterior	AI/ML/DL-technique
mechanism	AI/ML/DL-technique
.	O

The	O
SMAC3	O
package	O
is	O
available	O
under	O
a	O
permissive	O
BSD	Miscellaneous-term
-	Miscellaneous-term
license	Miscellaneous-term
at	O
https	O
://	O
github	O
.	O
com	O
/	O
automl	O
/	O
SMAC3	O
.	O
Bayesian	AI/ML/DL-technique
pseudo	AI/ML/DL-technique
posterior	AI/ML/DL-technique
mechanism	AI/ML/DL-technique
.	O

We	O
propose	O
a	O
Bayesian	O
pseudo	O
posterior	O
mechanism	O
to	O
generate	O
record	O
-	O
level	O
synthetic	Miscellaneous-term
databases	Miscellaneous-term
equipped	O
with	O
an	O
$(\	O
epsilon	O
,\	O
pi	O
)-$	O
probabilistic	O
differential	O
privacy	O
(	O
pDP	O
)	O
guarantee	O
,	O
where	O
$\	O
pi	O
$	O
denotes	O
the	O
probability	O
database	Miscellaneous-term
pseudo	AI/ML/DL-term
posterior	AI/ML/DL-term
mechanism	AI/ML/DL-term
\	O
epsilon	O
$.	O

We	O
propose	O
a	O
Bayesian	O
pseudo	O
posterior	O
mechanism	O
to	O
generate	O
record	O
-	O
level	O
synthetic	Miscellaneous-term
databases	Miscellaneous-term
equipped	O
with	O
an	O
$(\	O
epsilon	O
,\	O
pi	O
)-$	O
probabilistic	O
differential	O
privacy	O
(	O
pDP	O
)	O
guarantee	O
,	O
where	O
$\	O
pi	O
$	O
denotes	O
the	O
probability	O
database	Miscellaneous-term
pseudo	AI/ML/DL-term
posterior	AI/ML/DL-term
mechanism	AI/ML/DL-term
\	O
epsilon	O
$.	O

The	O
pseudo	O
posterior	O
mechanism	O
employs	O
a	O
data	O
record	O
-	O
indexed	O
,	O
risk	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
weight	AI/ML/DL-term
vector	AI/ML/DL-term
with	O
weight	O
values	O
$\	O
in	O
[	O
0	O
,	O
1	O
]$	O
that	O
surgically	O
downweight	O
the	O
likelihood	O
contributions	O
for	O
high	O
-	O
risk	O
records	O
for	O
model	AI/ML/DL-term
estimation	AI/ML/DL-term
and	O
the	O
generation	O
of	O
record	Miscellaneous-term
-	Miscellaneous-term
level	Miscellaneous-term
synthetic	Miscellaneous-term
data	Miscellaneous-term
for	O
public	O
release	O
.	O
pseudo	AI/ML/DL-technique
posterior	AI/ML/DL-technique
synthesizer	AI/ML/DL-technique
.	O

The	O
pseudo	O
posterior	O
mechanism	O
employs	O
a	O
data	O
record	O
-	O
indexed	O
,	O
risk	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
weight	AI/ML/DL-term
vector	AI/ML/DL-term
with	O
weight	O
values	O
$\	O
in	O
[	O
0	O
,	O
1	O
]$	O
that	O
surgically	O
downweight	O
the	O
likelihood	O
contributions	O
for	O
high	O
-	O
risk	O
records	O
for	O
model	AI/ML/DL-term
estimation	AI/ML/DL-term
and	O
the	O
generation	O
of	O
record	Miscellaneous-term
-	Miscellaneous-term
level	Miscellaneous-term
synthetic	Miscellaneous-term
data	Miscellaneous-term
for	O
public	O
release	O
.	O
pseudo	AI/ML/DL-technique
posterior	AI/ML/DL-technique
synthesizer	AI/ML/DL-technique
.	O

The	O
pseudo	O
posterior	O
mechanism	O
employs	O
a	O
data	O
record	O
-	O
indexed	O
,	O
risk	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
weight	AI/ML/DL-term
vector	AI/ML/DL-term
with	O
weight	O
values	O
$\	O
in	O
[	O
0	O
,	O
1	O
]$	O
that	O
surgically	O
downweight	O
the	O
likelihood	O
contributions	O
for	O
high	O
-	O
risk	O
records	O
for	O
model	AI/ML/DL-term
estimation	AI/ML/DL-term
and	O
the	O
generation	O
of	O
record	Miscellaneous-term
-	Miscellaneous-term
level	Miscellaneous-term
synthetic	Miscellaneous-term
data	Miscellaneous-term
for	O
public	O
release	O
.	O
pseudo	AI/ML/DL-technique
posterior	AI/ML/DL-technique
synthesizer	AI/ML/DL-technique
.	O

The	O
pseudo	O
posterior	O
synthesizer	O
constructs	O
a	O
weight	O
for	O
each	O
datum	Miscellaneous-term
record	Miscellaneous-term
by	O
using	O
the	O
Lipschitz	O
bound	O
for	O
that	O
record	O
under	O
a	O
log	O
-	O
pseudo	O
likelihood	O
utility	O
function	O
that	O
generalizes	O
the	O
exponential	O
mechanism	O
(	O
EM	O
)	O
likelihood	O
struct	O
a	O
formally	O
private	O
data	O
generating	O
mechanism	O
.	O

By	O
selecting	O
weights	O
to	O
remove	O
likelihood	O
contributions	O
with	O
non	O
-	O
finite	O
log	O
-	O
likelihood	O
values	O
we	O
guarantee	O
a	O
finite	O
local	O
privacy	O
guarantee	O
for	O
our	O
pseudo	AI/ML/DL-term
posterior	AI/ML/DL-term
mechanism	AI/ML/DL-term
at	O
every	O
sample	O
size	O
.	O

Our	O
results	O
may	O
be	O
applied	O
to	O
any	O
synthesizing	O
model	O
envisioned	O
by	O
the	O
data	O
disseminator	O
in	O
a	O
computationally	O
tractable	O
way	O
that	O
only	O
involves	O
estimation	O
of	O
a	O
pseudo	O
posterior	O
distribution	O
for	O
parameters	AI/ML/DL-term
$\	O
theta	O
$,	O
unlike	O
recent	O
approaches	O
that	O
use	O
naturally	O
-	O
bounded	O
utility	O
functions	O
implemented	O
through	O
the	O
EM	O
.	O

We	O
specify	O
conditions	O
that	O
guarantee	O
the	O
asymptotic	O
contraction	O
asymptotic	O
$	O
0	O
$	O
over	O
the	O
space	O
of	O
databases	O
,	O
such	O
that	O
the	O
form	O
of	O
the	O
guarantee	O
provided	O
by	O
our	O
method	O
is	O
asymptotic	O
.	O
pseudo	AI/ML/DL-term
posterior	AI/ML/DL-term
mechanism	AI/ML/DL-term
.	O

We	O
illustrate	O
our	O
pseudo	O
posterior	O
mechanism	O
on	O
the	O
sensitive	O
family	Miscellaneous-term
income	Miscellaneous-term
variable	Miscellaneous-term
from	O
the	O
Consumer	O
Expenditure	O
Surveys	O
database	O
published	O
by	O
the	O
U	O
.	O
S	O
.	O
U	O
.	O
S	O
.	O
Bureau	O
of	O
Labor	O
Statistics	O
.	O

We	O
show	O
that	O
utility	O
is	O
better	O
preserved	O
in	O
the	O
synthetic	Miscellaneous-term
data	Miscellaneous-term
for	O
our	O
pseudo	AI/ML/DL-term
posterior	AI/ML/DL-term
mechanism	AI/ML/DL-term
as	O
compared	O
to	O
the	O
EM	O
both	O
estimated	O
using	O
the	O
same	O
non	O
-	O
private	O
synthesizer	O
,	O
due	O
to	O
our	O
use	O
of	O
targeted	O
downweighting	O
.	O
solo	O
-	O
learn	O
.	O

We	O
show	O
that	O
utility	O
is	O
better	O
preserved	O
in	O
the	O
synthetic	Miscellaneous-term
data	Miscellaneous-term
for	O
our	O
pseudo	AI/ML/DL-term
posterior	AI/ML/DL-term
mechanism	AI/ML/DL-term
as	O
compared	O
to	O
the	O
EM	O
both	O
estimated	O
using	O
the	O
same	O
non	O
-	O
private	O
synthesizer	O
,	O
due	O
to	O
our	O
use	O
of	O
targeted	O
downweighting	O
.	O
solo	O
-	O
learn	O
.	O

This	O
paper	O
presents	O
solo	O
-	O
learn	O
,	O
a	O
library	O
of	O
self	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
methods	O
for	O
visual	O
representation	O
learning	O
Pytorch	O
.	O

Implemented	O
in	O
Python	O
,	O
using	O
Pytorch	O
and	O
Pytorch	O
lightning	O
the	O
library	O
fits	O
both	O
research	O
and	O
industry	O
needs	O
by	O
featuring	O
distributed	AI/ML/DL-term
training	AI/ML/DL-term
pipelines	O
with	O
mixed	Miscellaneous-term
-	Miscellaneous-term
precision	Miscellaneous-term
faster	O
data	O
loading	O
via	O
Nvidia	O
DALI	O
,	O
online	O
linear	O
evaluation	O
for	O
better	O
prototyping	O
,	O
and	O
many	O
additional	O
training	O
tricks	O
.	O
easy	O
-	O
to	O
-	O
use	O
library	O
.	O

Implemented	O
in	O
Python	O
,	O
using	O
Pytorch	O
and	O
Pytorch	O
lightning	O
the	O
library	O
fits	O
both	O
research	O
and	O
industry	O
needs	O
by	O
featuring	O
distributed	AI/ML/DL-term
training	AI/ML/DL-term
pipelines	O
with	O
mixed	Miscellaneous-term
-	Miscellaneous-term
precision	Miscellaneous-term
faster	O
data	O
loading	O
via	O
Nvidia	O
DALI	O
,	O
online	O
linear	O
evaluation	O
for	O
better	O
prototyping	O
,	O
and	O
many	O
additional	O
training	O
tricks	O
.	O
easy	O
-	O
to	O
-	O
use	O
library	O
.	O

Our	O
goal	O
is	O
to	O
provide	O
an	O
easy	O
-	O
to	O
-	O
use	O
library	O
comprising	O
a	O
large	O
amount	O
of	O
Self	O
-	O
supervised	O
Learning	O
(	O
SSL	O
)	O
methods	O
,	O
that	O
can	O
be	O
easily	O
extended	O
and	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuned	AI/ML/DL-term
by	O
the	O
community	O
.	O
solo	O
-	O
learn	O
.	O

solo	O
-	O
learn	O
opens	O
up	O
avenues	O
for	O
exploiting	O
large	O
-	O
budget	O
SSL	O
SSL	O
tions	O
on	O
inexpensive	O
smaller	O
infrastructures	O
and	O
seeks	O
to	O
democratize	O
SSL	O
by	O
making	O
it	O
accessible	O
to	O
all	O
.	O
source	Miscellaneous-term
code	Miscellaneous-term
.	O

Our	O
impossibility	O
theorem	O
could	O
be	O
interpreted	O
as	O
a	O
certain	O
uncertainty	O
principle	O
in	O
fairness	O
:	O
if	O
the	O
base	O
rates	O
differ	O
among	O
groups	O
,	O
then	O
any	O
fair	O
classifier	O
satisfying	O
statistical	O
parity	O
has	O
to	O
incur	O
a	O
large	O
error	O
on	O
at	O
least	O
one	O
of	O
the	O
groups	O
.	O
lower	AI/ML/DL-term
bound	AI/ML/DL-term
.	O

To	O
show	O
that	O
our	O
lower	O
bound	O
is	O
tight	O
,	O
assuming	O
oracle	O
access	O
to	O
Bayes	O
(	O
potentially	O
unfair	O
)	O
classifiers	O
we	O
also	O
construct	O
an	O
algorithm	Miscellaneous-term
that	O
returns	O
a	O
randomized	O
classifier	O
which	O
is	O
both	O
optimal	O
(	O
in	O
terms	O
of	O
accuracy	O
and	O
fair	O
.	O

On	O
the	O
upside	O
,	O
we	O
prove	O
that	O
if	O
the	O
group	O
-	O
wise	O
Bayes	O
optimal	O
classifiers	O
are	O
close	O
,	O
then	O
learning	O
fair	AI/ML/DL-term
representations	AI/ML/DL-term
leads	O
to	O
an	O
alternative	O
notion	O
of	O
fairness	O
,	O
known	O
as	O
the	O
accuracy	O
parity	O
which	O
states	O
that	O
the	O
error	O
rates	O
are	O
close	O
between	O
groups	O
.	O

Latent	O
Dirichlet	O
Allocation	O
is	O
a	O
popular	O
machine	O
-	O
learning	O
technique	O
that	O
identifies	O
latent	AI/ML/DL-term
structures	AI/ML/DL-term
in	O
a	O
corpus	O
of	O
documents	O
.	O

This	O
paper	O
addresses	O
the	O
ongoing	O
concern	O
that	O
formal	O
procedures	O
for	O
determining	O
the	O
optimal	O
LDA	O
configuration	O
do	O
not	O
exist	O
by	O
introducing	O
a	O
set	O
of	O
parametric	AI/ML/DL-term
tests	AI/ML/DL-term
that	O
rely	O
on	O
the	O
assumed	O
multinomial	O
distribution	O
specification	O
underlying	O
the	O
original	O
LDA	O
model	O
.	O

Our	O
methodology	O
defines	O
a	O
set	O
of	O
rigorous	O
statistical	O
procedures	O
that	O
identify	O
and	O
evaluate	O
the	O
optimal	O
topic	O
model	O
U	NLP-dataset
.	NLP-dataset
S	NLP-dataset
.	NLP-dataset
Presidential	NLP-dataset
Inaugural	NLP-dataset
Address	NLP-dataset
Corpus	NLP-dataset
.	O

Presidential	O
Inaugural	O
Address	O
Corpus	O
is	O
used	O
as	O
a	O
case	O
study	O
to	O
show	O
the	O
numerical	O
results	O
.	O
corpus	Miscellaneous-term
.	O

We	O
find	O
that	O
92	O
topics	O
best	O
describe	O
the	O
corpus	O
.	O
simulation	Miscellaneous-term
study	Miscellaneous-term
.	O

We	O
further	O
validate	O
the	O
method	O
through	O
a	O
simulation	O
study	O
confirming	O
the	O
superiority	O
of	O
our	O
approach	O
compared	O
to	O
other	O
standard	O
heuristic	Miscellaneous-term
metrics	Miscellaneous-term
like	O
the	O
perplexity	O
index	O
.	O
causal	O
classification	O
.	O

Rather	O
than	O
disregarding	O
this	O
as	O
naive	O
behavior	O
,	O
we	O
present	O
a	O
theoretical	Miscellaneous-term
analysis	Miscellaneous-term
comparing	O
treatment	O
effect	O
estimation	O
and	O
outcome	O
prediction	O
when	O
addressing	O
causal	O
classification	O
.	O

We	O
focus	O
on	O
the	O
key	O
question	O
:	O
"	O
When	O
(	O
if	O
ever	O
)	O
is	O
simple	O
outcome	O
prediction	O
preferable	O
to	O
treatment	O
effect	O
estimation	O
for	O
causal	O
classification	O
"	O
The	O
analysis	O
reveals	O
a	O
causal	AI/ML/DL-term
bias	AI/ML/DL-term
--	AI/ML/DL-term
variance	AI/ML/DL-term
tradeoff	AI/ML/DL-term
treatment	O
effect	O
estimation	O
.	O

First	O
,	O
when	O
the	O
treatment	O
effect	O
estimation	O
depends	O
on	O
two	O
outcome	O
predictions	O
larger	O
sampling	O
variance	O
may	O
lead	O
to	O
more	O
errors	O
than	O
the	O
(	O
biased	AI/ML/DL-term
outcome	O
prediction	O
approach	O
.	O
signal	AI/ML/DL-term
-	AI/ML/DL-term
to	AI/ML/DL-term
-	AI/ML/DL-term
noise	AI/ML/DL-term
ratio	AI/ML/DL-term
.	O

Second	O
,	O
a	O
stronger	O
signal	O
-	O
to	O
-	O
noise	O
ratio	O
in	O
outcome	O
prediction	O
implies	O
that	O
the	O
bias	AI/ML/DL-term
can	O
help	O
with	O
intervention	O
decisions	O
when	O
outcomes	O
are	O
informative	O
of	O
effects	O
.	O

The	O
theoretical	O
results	O
,	O
as	O
well	O
as	O
simulations	O
,	O
illustrate	O
settings	O
where	O
outcome	O
prediction	O
should	O
actually	O
be	O
better	O
,	O
including	O
cases	O
where	O
(	O
1	O
)	O
the	O
bias	AI/ML/DL-term
may	O
be	O
partially	O
corrected	O
by	O
choosing	O
a	O
different	O
threshold	Miscellaneous-term
(	O
2	O
)	O
outcomes	O
and	O
treatment	O
effects	O
are	O
correlated	O
,	O
and	O
(	O
3	O
)	O
data	O
to	O
estimate	O
counterfactuals	Miscellaneous-term
are	O
limited	O
.	O

The	O
theoretical	O
results	O
,	O
as	O
well	O
as	O
simulations	O
,	O
illustrate	O
settings	O
where	O
outcome	O
prediction	O
should	O
actually	O
be	O
better	O
,	O
including	O
cases	O
where	O
(	O
1	O
)	O
the	O
bias	AI/ML/DL-term
may	O
be	O
partially	O
corrected	O
by	O
choosing	O
a	O
different	O
threshold	Miscellaneous-term
(	O
2	O
)	O
outcomes	O
and	O
treatment	O
effects	O
are	O
correlated	O
,	O
and	O
(	O
3	O
)	O
data	O
to	O
estimate	O
counterfactuals	Miscellaneous-term
are	O
limited	O
.	O

It	O
is	O
common	O
to	O
encounter	O
large	O
-	O
scale	O
monotone	O
inclusion	O
problems	O
where	O
the	O
objective	O
has	O
a	O
finite	AI/ML/DL-term
sum	AI/ML/DL-term
structure	AI/ML/DL-term
.	O

We	O
further	O
consider	O
Catalyst	O
acceleration	O
and	O
asynchronous	O
implementation	O
to	O
reduce	O
the	O
algorithmic	Miscellaneous-term
complexity	Miscellaneous-term
and	O
computation	Miscellaneous-term
time	Miscellaneous-term
.	O

In	O
this	O
paper	O
we	O
introduce	O
a	O
novel	O
model	O
for	O
Gaussian	O
process	O
(	O
GP	O
)	O
regression	O
in	O
the	O
fully	AI/ML/DL-term
Bayesian	AI/ML/DL-term
setting	AI/ML/DL-term
sparsification	O
localization	O
.	O

Motivated	O
by	O
the	O
ideas	O
of	O
sparsification	O
,	O
localization	O
and	O
Bayesian	O
additive	O
modeling	O
our	O
model	O
is	O
built	O
around	O
a	O
recursive	O
partitioning	O
(	O
RP	O
)	O
scheme	O
.	O
RP	AI/ML/DL-term
partition	AI/ML/DL-term
sparse	O
GP	O
(	O
SGP	O
)	O
regression	O
model	O
.	O

A	O
Bayesian	O
additive	O
framework	O
then	O
combines	O
multiple	O
layers	O
of	O
partitioned	O
SGPs	O
capturing	O
both	O
global	Miscellaneous-term
trends	Miscellaneous-term
and	O
local	Miscellaneous-term
refinements	Miscellaneous-term
with	O
efficient	O
computations	O
.	O

The	O
model	O
addresses	O
both	O
the	O
problem	O
of	O
efficiency	O
in	O
fitting	O
a	O
full	O
Gaussian	O
process	O
regression	O
model	O
and	O
the	O
problem	O
of	O
prediction	O
performance	O
associated	O
with	O
a	O
single	O
SGP	O
pseudo	Miscellaneous-term
-	Miscellaneous-term
input	Miscellaneous-term
selection	Miscellaneous-term
.	O

The	O
crucial	O
trade	O
-	O
off	O
becomes	O
choosing	O
between	O
many	O
simpler	O
local	Miscellaneous-term
model	Miscellaneous-term
components	Miscellaneous-term
or	O
fewer	O
complex	O
global	Miscellaneous-term
model	Miscellaneous-term
components	Miscellaneous-term
which	O
the	O
practitioner	O
can	O
sensibly	O
tune	O
.	O

We	O
compare	O
our	O
model	O
against	O
popular	O
alternatives	O
on	O
simulated	O
and	O
real	O
datasets	Miscellaneous-term
and	O
find	O
the	O
performance	O
is	O
competitive	O
,	O
while	O
the	O
fully	O
Bayesian	O
procedure	O
enables	O
the	O
quantification	O
of	O
model	O
uncertainties	O
.	O
Statistical	O
learning	O
.	O

We	O
demonstrate	O
the	O
practical	O
usability	O
of	O
the	O
AIM	O
algorithm	O
by	O
prototype	O
implementations	O
for	O
parameter	O
learning	O
from	O
continuous	O
Gaussian	O
data	O
and	O
from	O
discrete	AI/ML/DL-term
Bayesian	AI/ML/DL-term
network	AI/ML/DL-term
data	AI/ML/DL-term
.	O

We	O
propose	O
a	O
method	O
for	O
simultaneous	O
estimation	O
and	O
variable	O
selection	O
of	O
an	O
additive	O
quantile	O
regression	O
model	O
that	O
can	O
be	O
used	O
with	O
high	AI/ML/DL-term
dimensional	AI/ML/DL-term
data	AI/ML/DL-term
Quantile	O
regression	O
.	O

Quantile	O
regression	O
is	O
an	O
appealing	O
method	O
for	O
analyzing	O
high	AI/ML/DL-term
dimensional	AI/ML/DL-term
data	AI/ML/DL-term
because	O
it	O
can	O
correctly	O
model	O
heteroscedastic	O
relationships	O
is	O
robust	O
to	O
outliers	AI/ML/DL-term
in	O
the	O
response	O
,	O
sparsity	AI/ML/DL-term
levels	AI/ML/DL-term
can	O
change	O
with	O
quantiles	O
,	O
and	O
it	O
provides	O
a	O
thorough	O
analysis	O
of	O
the	O
conditional	O
distribution	O
of	O
the	O
response	O
.	O
additive	O
nonlinear	O
model	O
.	O

An	O
additive	O
nonlinear	O
model	O
can	O
capture	O
more	O
complex	O
relationships	O
,	O
while	O
avoiding	O
the	O
curse	O
of	O
dimensionality	AI/ML/DL-term
additive	O
nonlinear	O
model	O
B	O
-	O
splines	O
.	O

In	O
addition	O
,	O
we	O
propose	O
a	O
coordinate	O
descent	O
algorithm	O
that	O
reduces	O
the	O
computational	Miscellaneous-term
cost	Miscellaneous-term
compared	O
to	O
the	O
linear	O
programming	O
approach	O
typically	O
used	O
for	O
solving	O
quantile	O
regression	O
problems	O
.	O

The	O
performance	O
of	O
the	O
method	O
is	O
tested	O
using	O
Monte	O
Carlo	O
simulations	O
an	O
analysis	O
of	O
fat	O
content	O
of	O
meat	O
conditional	O
on	O
a	O
100	Miscellaneous-term
channel	Miscellaneous-term
spectrum	Miscellaneous-term
of	O
absorbances	O
and	O
predicting	O
TRIM32	Miscellaneous-term
expression	Miscellaneous-term
using	O
gene	O
expression	O
data	O
from	O
the	O
eyes	O
of	O
rats	O
.	O
Stochastic	O
zeroth	O
-	O
order	O
optimization	O
algorithms	O
.	O

Stochastic	O
zeroth	O
-	O
order	O
optimization	O
algorithms	O
have	O
been	O
predominantly	O
analyzed	O
under	O
the	O
assumption	O
that	O
the	O
objective	AI/ML/DL-term
function	AI/ML/DL-term
being	O
optimized	O
is	O
time	AI/ML/DL-term
-	AI/ML/DL-term
invariant	AI/ML/DL-term
dynamic	O
matrix	O
sensing	O
completion	O
.	O

For	O
the	O
case	O
of	O
first	O
-	O
order	O
optimal	O
solution	O
based	O
regret	O
measures	O
,	O
we	O
provide	O
regret	O
bounds	O
in	O
both	O
the	O
low	O
-	O
and	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
settings	AI/ML/DL-term
second	O
-	O
order	O
optimal	O
solution	O
.	O

Our	O
nonstationary	O
regret	O
bounds	O
in	O
terms	O
of	O
second	O
-	O
order	O
optimal	O
solutions	O
have	O
interesting	O
consequences	O
for	O
avoiding	O
saddle	O
points	O
in	O
the	O
nonstationary	O
setting	O
.	O
complexity	Miscellaneous-term
.	O

This	O
negative	O
result	O
implies	O
that	O
some	O
combinatorial	O
algorithms	O
,	O
e	O
.	O
g	O
.,	O
network	O
simplex	O
method	O
,	O
are	O
not	O
suitable	O
for	O
approximating	O
the	O
MOT	O
problem	O
,	O
while	O
the	O
worst	Miscellaneous-term
-	Miscellaneous-term
case	Miscellaneous-term
complexity	Miscellaneous-term
bound	Miscellaneous-term
for	O
the	O
deterministic	O
interior	O
-	O
point	O
algorithm	O
remains	O
a	O
quantity	O
of	O
$\	O
tilde	O
{\	O
mathcal	O
{	O
O	O
}}(	O
n	O
^{	O
3m	O
})$.	O
deterministic	Miscellaneous-term
algorithms	Miscellaneous-term
.	O

We	O
then	O
propose	O
two	O
simple	O
and	O
deterministic	O
algorithms	O
for	O
approximating	O
the	O
MOT	O
algorithm	Miscellaneous-term
.	O

The	O
first	O
algorithm	O
,	O
which	O
we	O
refer	O
to	O
as	O
multimarginal	AI/ML/DL-technique
Sinkhorn	AI/ML/DL-technique
algorithm	AI/ML/DL-technique
is	O
a	O
provably	O
efficient	O
multimarginal	AI/ML/DL-term
generalization	AI/ML/DL-term
Sinkhorn	O
algorithm	O
orithm	O
.	O
complexity	Miscellaneous-term
bound	Miscellaneous-term
.	O

The	O
first	O
algorithm	O
,	O
which	O
we	O
refer	O
to	O
as	O
multimarginal	AI/ML/DL-technique
Sinkhorn	AI/ML/DL-technique
algorithm	AI/ML/DL-technique
is	O
a	O
provably	O
efficient	O
multimarginal	AI/ML/DL-term
generalization	AI/ML/DL-term
Sinkhorn	O
algorithm	O
orithm	O
.	O
complexity	Miscellaneous-term
bound	Miscellaneous-term
.	O

The	O
first	O
algorithm	O
,	O
which	O
we	O
refer	O
to	O
as	O
multimarginal	AI/ML/DL-technique
Sinkhorn	AI/ML/DL-technique
algorithm	AI/ML/DL-technique
is	O
a	O
provably	O
efficient	O
multimarginal	AI/ML/DL-term
generalization	AI/ML/DL-term
Sinkhorn	O
algorithm	O
orithm	O
.	O
complexity	Miscellaneous-term
bound	Miscellaneous-term
.	O

We	O
show	O
that	O
it	O
achieves	O
a	O
complexity	O
bound	O
of	O
$\	O
tilde	O
{\	O
mathcal	O
{	O
O	O
}}(	O
m	O
^	O
3n	O
^	O
m	O
\	O
varepsilon	O
^{-	O
2	O
})$	O
for	O
a	O
tolerance	O
$\	O
varepsilon	O
\	O
in	O
(	O
0	O
,	O
1	O
)$.	O
near	Miscellaneous-term
-	Miscellaneous-term
linear	Miscellaneous-term
time	Miscellaneous-term
complexity	Miscellaneous-term
bound	Miscellaneous-term
.	O

This	O
provides	O
a	O
first	O
near	O
-	O
linear	O
time	O
complexity	O
bound	O
guarantee	O
for	O
approximating	O
the	O
MOT	O
complexity	Miscellaneous-term
bound	Miscellaneous-term
es	O
the	O
best	O
known	O
complexity	O
bound	O
for	O
the	O
Sinkhorn	O
algorithm	O
algorithm	Miscellaneous-term
ssical	O
OT	O
setting	O
when	O
$	O
m	O
=	O
2	O
$.	O

The	O
second	O
algorithm	O
,	O
which	O
we	O
refer	O
to	O
as	O
accelerated	AI/ML/DL-technique
multimarginal	AI/ML/DL-technique
Sinkhorn	AI/ML/DL-technique
algorithm	AI/ML/DL-technique
achieves	O
the	O
acceleration	O
by	O
incorporating	O
an	O
estimate	O
sequence	O
and	O
the	O
complexity	Miscellaneous-term
bound	Miscellaneous-term
algorithm	Miscellaneous-term
{\	O
mathcal	O
{	O
O	O
}}(	O
m	O
^	O
3n	O
^{	O
m	O
+	O
1	O
/	O
3	O
}\	O
varepsilon	O
^{-	O
4	O
/	O
3	O
})$.	O

The	O
second	O
algorithm	O
,	O
which	O
we	O
refer	O
to	O
as	O
accelerated	AI/ML/DL-technique
multimarginal	AI/ML/DL-technique
Sinkhorn	AI/ML/DL-technique
algorithm	AI/ML/DL-technique
achieves	O
the	O
acceleration	O
by	O
incorporating	O
an	O
estimate	O
sequence	O
and	O
the	O
complexity	Miscellaneous-term
bound	Miscellaneous-term
algorithm	Miscellaneous-term
{\	O
mathcal	O
{	O
O	O
}}(	O
m	O
^	O
3n	O
^{	O
m	O
+	O
1	O
/	O
3	O
}\	O
varepsilon	O
^{-	O
4	O
/	O
3	O
})$.	O

This	O
bound	O
is	O
better	O
than	O
that	O
of	O
the	O
first	O
algorithm	O
in	O
terms	O
of	O
$	O
1	O
/\	O
varepsilon	O
$,	O
and	O
accelerated	O
alternating	O
minimization	O
algorithm	O
(	O
Tupitsa	O
et	O
al	O
.,	O
2020	O
)	O
in	O
terms	O
of	O
$	O
n	O
$.	O
algorithms	Miscellaneous-term
LP	O
.	O

Preliminary	O
results	O
on	O
synthetic	O
data	O
and	O
real	O
images	O
demonstrate	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
our	O
algorithms	Miscellaneous-term
.	O
multivariate	O
square	O
-	O
root	O
lasso	O
.	O

Unlike	O
existing	O
methods	O
that	O
require	O
explicit	O
estimates	O
of	O
the	O
error	AI/ML/DL-term
precision	AI/ML/DL-term
(	AI/ML/DL-term
inverse	AI/ML/DL-term
covariance	AI/ML/DL-term
)	AI/ML/DL-term
matrix	AI/ML/DL-term
the	O
multivariate	O
square	O
-	O
root	O
lasso	O
implicitly	O
accounts	O
for	O
error	O
dependence	O
and	O
is	O
the	O
solution	O
to	O
a	O
convex	O
optimization	O
problem	O
.	O

In	O
addition	O
,	O
we	O
propose	O
a	O
variation	O
of	O
the	O
alternating	O
direction	O
method	O
of	O
multipliers	O
algorithm	O
to	O
compute	O
the	O
estimator	O
and	O
discuss	O
an	O
accelerated	O
first	O
order	O
algorithm	O
that	O
can	O
be	O
applied	O
in	O
certain	O
cases	O
.	O
simulation	Miscellaneous-term
studies	Miscellaneous-term
.	O

In	O
both	O
simulation	O
studies	O
and	O
a	O
genomic	O
data	O
application	O
,	O
we	O
show	O
that	O
the	O
multivariate	O
square	O
-	O
root	O
lasso	O
can	O
outperform	O
more	O
computationally	O
intensive	O
methods	O
that	O
require	O
explicit	O
estimation	O
of	O
the	O
error	AI/ML/DL-term
precision	AI/ML/DL-term
matrix	AI/ML/DL-term
.	O
deep	O
neural	O
networks	O
.	O

The	O
practical	O
success	O
of	O
excessively	O
large	O
networks	O
underscores	O
the	O
need	O
for	O
better	O
theoretical	O
analyses	O
and	O
justifications	O
.	O
layer	AI/ML/DL-term
-	AI/ML/DL-term
wise	AI/ML/DL-term
functional	AI/ML/DL-term
structure	AI/ML/DL-term
.	O

To	O
do	O
so	O
,	O
we	O
study	O
empirically	O
the	O
layers	O
'	O
robustness	O
to	O
post	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
re	O
-	O
initialization	O
and	O
re	O
-	O
randomization	O
of	O
the	O
parameters	AI/ML/DL-term
.	O

We	O
provide	O
experimental	O
results	O
which	O
give	O
evidence	O
for	O
the	O
heterogeneity	Miscellaneous-term
of	O
layers	O
.	O
deep	O
neural	O
networks	O
.	O

Our	O
study	O
provides	O
further	O
evidence	O
that	O
mere	O
parameter	O
counting	O
or	O
norm	O
calculations	O
are	O
too	O
coarse	O
in	O
studying	O
generalization	O
of	O
deep	O
models	O
and	O
"	O
flatness	O
"	O
and	O
robustness	O
analysis	O
of	O
trained	O
models	O
need	O
to	O
be	O
examined	O
while	O
taking	O
into	O
account	O
the	O
respective	O
network	AI/ML/DL-term
architectures	AI/ML/DL-term
.	O

Encoding	O
the	O
scale	O
information	O
explicitly	O
into	O
the	O
representation	O
learned	O
by	O
a	O
convolutional	O
neural	O
network	O
(	O
CNN	O
)	O
is	O
beneficial	O
for	O
many	O
computer	O
vision	O
tasks	O
especially	O
when	O
dealing	O
with	O
multiscale	O
inputs	O
.	O
scaling	AI/ML/DL-term
-	AI/ML/DL-term
translation	AI/ML/DL-term
-	AI/ML/DL-term
equivariant	AI/ML/DL-term
.	O

We	O
study	O
,	O
in	O
this	O
paper	O
,	O
a	O
scaling	O
-	O
translation	O
-	O
equivariant	O
($\	O
mathcal	O
{	O
ST	O
}$-	O
equivariant	O
)	O
CNN	O
with	O
joint	O
convolutions	O
across	O
the	O
space	O
and	O
the	O
scaling	O
group	O
,	O
which	O
is	O
shown	O
to	O
be	O
both	O
sufficient	O
and	O
necessary	O
to	O
achieve	O
equivariance	O
for	O
the	O
regular	AI/ML/DL-term
representation	AI/ML/DL-term
of	O
the	O
scaling	O
-	O
translation	O
group	O
$\	O
mathcal	O
{	O
ST	O
}$.	O
model	Miscellaneous-term
complexity	Miscellaneous-term
.	O

We	O
study	O
,	O
in	O
this	O
paper	O
,	O
a	O
scaling	O
-	O
translation	O
-	O
equivariant	O
($\	O
mathcal	O
{	O
ST	O
}$-	O
equivariant	O
)	O
CNN	O
with	O
joint	O
convolutions	O
across	O
the	O
space	O
and	O
the	O
scaling	O
group	O
,	O
which	O
is	O
shown	O
to	O
be	O
both	O
sufficient	O
and	O
necessary	O
to	O
achieve	O
equivariance	O
for	O
the	O
regular	AI/ML/DL-term
representation	AI/ML/DL-term
of	O
the	O
scaling	O
-	O
translation	O
group	O
$\	O
mathcal	O
{	O
ST	O
}$.	O
model	Miscellaneous-term
complexity	Miscellaneous-term
.	O

A	O
further	O
benefit	O
of	O
the	O
truncated	O
filter	O
expansion	O
is	O
the	O
improved	O
deformation	O
robustness	O
of	O
the	O
equivariant	AI/ML/DL-term
representation	AI/ML/DL-term
a	O
property	O
which	O
is	O
theoretically	O
analyzed	O
and	O
empirically	O
verified	O
.	O

Numerical	O
experiments	O
demonstrate	O
that	O
the	O
proposed	O
scaling	AI/ML/DL-technique
-	AI/ML/DL-technique
translation	AI/ML/DL-technique
-	AI/ML/DL-technique
equivariant	AI/ML/DL-technique
network	AI/ML/DL-technique
with	AI/ML/DL-technique
decomposed	AI/ML/DL-technique
convolutional	AI/ML/DL-technique
filters	AI/ML/DL-technique
(	AI/ML/DL-technique
ScDCFNet	AI/ML/DL-technique
)	AI/ML/DL-technique
achieves	O
significantly	O
improved	O
performance	O
in	O
multiscale	O
image	O
classification	O
and	O
better	O
interpretability	O
than	O
regular	O
CNNs	O
at	O
a	O
reduced	O
model	O
size	O
.	O
distributed	O
subgradient	O
methods	O
.	O

While	O
it	O
might	O
be	O
hoped	O
that	O
distributed	O
network	O
of	O
$	O
n	O
$	O
nodes	O
that	O
can	O
compute	O
$	O
n	O
$	O
times	O
more	O
subgradients	AI/ML/DL-term
in	O
parallel	O
compared	O
to	O
a	O
single	O
node	O
might	O
,	O
as	O
a	O
result	O
,	O
be	O
$	O
n	O
$	O
times	O
faster	O
,	O
existing	O
bounds	O
for	O
distributed	AI/ML/DL-term
optimization	AI/ML/DL-term
methods	O
are	O
often	O
consistent	O
with	O
a	O
slowdown	O
rather	O
than	O
speedup	O
compared	O
to	O
a	O
single	O
node	O
.	O
distributed	O
subgradient	O
method	O
.	O

We	O
show	O
that	O
a	O
distributed	O
subgradient	O
method	O
has	O
this	O
“	O
linear	O
speedup	O
”	O
property	O
when	O
using	O
a	O
class	O
of	O
square	AI/ML/DL-term
-	AI/ML/DL-term
summable	AI/ML/DL-term
-	AI/ML/DL-term
but	AI/ML/DL-term
-	AI/ML/DL-term
not	AI/ML/DL-term
-	AI/ML/DL-term
summable	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
sizes	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
sizes	AI/ML/DL-term
de	O
$	O
1	O
/	O
t	O
^{\	O
beta	O
}$	O
when	O
$\	O
beta	O
\	O
in	O
(	O
1	O
/	O
2	O
,	O
1	O
)$;	O
for	O
such	O
step	O
-	O
sizes	O
,	O
we	O
show	O
that	O
after	O
a	O
transient	O
period	O
whose	O
size	O
depends	O
on	O
the	O
spectral	Data/Mining/Information/Retrieval-term
gap	Data/Mining/Information/Retrieval-term
of	O
the	O
network	O
,	O
the	O
method	O
achieves	O
a	O
performance	O
guarantee	O
that	O
does	O
not	O
depend	O
on	O
the	O
network	O
or	O
the	O
number	O
of	O
nodes	O
.	O

We	O
show	O
that	O
a	O
distributed	O
subgradient	O
method	O
has	O
this	O
“	O
linear	O
speedup	O
”	O
property	O
when	O
using	O
a	O
class	O
of	O
square	AI/ML/DL-term
-	AI/ML/DL-term
summable	AI/ML/DL-term
-	AI/ML/DL-term
but	AI/ML/DL-term
-	AI/ML/DL-term
not	AI/ML/DL-term
-	AI/ML/DL-term
summable	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
sizes	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
sizes	AI/ML/DL-term
de	O
$	O
1	O
/	O
t	O
^{\	O
beta	O
}$	O
when	O
$\	O
beta	O
\	O
in	O
(	O
1	O
/	O
2	O
,	O
1	O
)$;	O
for	O
such	O
step	O
-	O
sizes	O
,	O
we	O
show	O
that	O
after	O
a	O
transient	O
period	O
whose	O
size	O
depends	O
on	O
the	O
spectral	Data/Mining/Information/Retrieval-term
gap	Data/Mining/Information/Retrieval-term
of	O
the	O
network	O
,	O
the	O
method	O
achieves	O
a	O
performance	O
guarantee	O
that	O
does	O
not	O
depend	O
on	O
the	O
network	O
or	O
the	O
number	O
of	O
nodes	O
.	O

We	O
also	O
show	O
that	O
the	O
same	O
method	O
can	O
fail	O
to	O
have	O
this	O
“	O
asymptotic	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
independence	Data/Mining/Information/Retrieval-term
property	O
under	O
the	O
optimally	AI/ML/DL-term
decaying	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
size	AI/ML/DL-term
$	O
1	O
/\	O
sqrt	O
{	O
t	O
}$	O
and	O
,	O
as	O
a	O
consequence	O
,	O
can	O
fail	O
to	O
provide	O
a	O
linear	AI/ML/DL-term
speedup	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
size	AI/ML/DL-term
o	O
a	O
single	O
node	O
with	O
$	O
1	O
/\	O
sqrt	O
{	O
t	O
}$	O
step	O
-	O
size	O
.	O
estimation	O
.	O

We	O
also	O
show	O
that	O
the	O
same	O
method	O
can	O
fail	O
to	O
have	O
this	O
“	O
asymptotic	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
independence	Data/Mining/Information/Retrieval-term
property	O
under	O
the	O
optimally	AI/ML/DL-term
decaying	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
size	AI/ML/DL-term
$	O
1	O
/\	O
sqrt	O
{	O
t	O
}$	O
and	O
,	O
as	O
a	O
consequence	O
,	O
can	O
fail	O
to	O
provide	O
a	O
linear	AI/ML/DL-term
speedup	AI/ML/DL-term
step	AI/ML/DL-term
-	AI/ML/DL-term
size	AI/ML/DL-term
o	O
a	O
single	O
node	O
with	O
$	O
1	O
/\	O
sqrt	O
{	O
t	O
}$	O
step	O
-	O
size	O
.	O
estimation	O
.	O

The	O
framework	O
defines	O
a	O
large	O
class	O
of	O
penalized	O
regression	O
estimators	O
encompassing	O
many	O
existing	O
methods	O
.	O
computational	Miscellaneous-term
algorithm	Miscellaneous-term
.	O

An	O
efficient	O
computational	O
algorithm	O
for	O
this	O
class	O
is	O
presented	O
that	O
easily	O
scales	O
to	O
thousands	O
of	O
observations	O
and	O
features	O
.	O
minimax	AI/ML/DL-term
optimal	AI/ML/DL-term
convergence	AI/ML/DL-term
bounds	AI/ML/DL-term
.	O

We	O
prove	O
minimax	O
optimal	O
convergence	O
bounds	O
for	O
this	O
class	O
under	O
a	O
weak	AI/ML/DL-term
compatibility	AI/ML/DL-term
condition	AI/ML/DL-term
rate	O
of	O
convergence	O
.	O

In	O
addition	O
,	O
we	O
characterize	O
the	O
rate	O
of	O
convergence	O
when	O
this	O
compatibility	O
condition	O
is	O
not	O
met	O
.	O
optimal	AI/ML/DL-term
penalty	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

Finally	O
,	O
we	O
also	O
show	O
that	O
the	O
optimal	O
penalty	O
parameters	O
for	O
structure	O
and	O
sparsity	AI/ML/DL-term
penalties	AI/ML/DL-term
in	O
our	O
framework	O
are	O
linked	O
,	O
allowing	O
cross	O
-	O
validation	O
to	O
be	O
conducted	O
over	O
only	O
a	O
single	AI/ML/DL-term
tuning	AI/ML/DL-term
parameter	AI/ML/DL-term
.	O

We	O
propose	O
a	O
multiple	O
-	O
splitting	O
projection	O
test	O
(	O
MPT	O
)	O
for	O
one	AI/ML/DL-term
-	AI/ML/DL-term
sample	AI/ML/DL-term
mean	AI/ML/DL-term
vectors	AI/ML/DL-term
in	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
settings	AI/ML/DL-term
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
samples	AI/ML/DL-term
.	O

The	O
idea	O
of	O
projection	O
test	O
is	O
to	O
project	O
high	O
-	O
dimensional	O
samples	O
to	O
a	O
1	O
-	O
dimensional	O
space	O
using	O
an	O
optimal	AI/ML/DL-term
projection	AI/ML/DL-term
optimal	AI/ML/DL-term
projection	AI/ML/DL-term
traditional	O
tests	O
can	O
be	O
carried	O
out	O
with	O
projected	O
samples	O
.	O

To	O
retain	O
type	O
I	O
error	O
rate	O
,	O
we	O
adopt	O
a	O
data	AI/ML/DL-term
-	AI/ML/DL-term
splitting	AI/ML/DL-term
strategy	O
when	O
constructing	O
test	O
statistics	O
.	O

Numerical	O
studies	O
show	O
that	O
the	O
proposed	O
test	O
well	O
retains	O
the	O
type	AI/ML/DL-term
I	AI/ML/DL-term
error	AI/ML/DL-term
rate	AI/ML/DL-term
and	O
is	O
more	O
powerful	O
than	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
tests	O
.	O
Batch	O
normalization	O
(	O
BN	O
)	O
.	O

Numerical	O
studies	O
show	O
that	O
the	O
proposed	O
test	O
well	O
retains	O
the	O
type	AI/ML/DL-term
I	AI/ML/DL-term
error	AI/ML/DL-term
rate	AI/ML/DL-term
and	O
is	O
more	O
powerful	O
than	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
tests	O
.	O
Batch	O
normalization	O
(	O
BN	O
)	O
.	O

Batch	O
normalization	O
(	O
BN	O
)	O
is	O
a	O
popular	O
and	O
ubiquitous	O
method	O
in	O
deep	O
learning	O
that	O
has	O
been	O
shown	O
to	O
decrease	O
training	AI/ML/DL-term
time	O
and	O
improve	O
generalization	O
performance	O
of	O
neural	O
networks	O
BN	O
.	O

Despite	O
its	O
success	O
,	O
BN	O
is	O
not	O
theoretically	O
well	O
understood	O
.	O
mini	AI/ML/DL-term
-	AI/ML/DL-term
batch	AI/ML/DL-term
sizes	AI/ML/DL-term
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
method	O
called	O
Batch	AI/ML/DL-technique
Normalization	AI/ML/DL-technique
Preconditioning	AI/ML/DL-technique
(	AI/ML/DL-technique
BNP	AI/ML/DL-technique
)	AI/ML/DL-technique
normalization	O
.	O

Instead	O
of	O
applying	O
normalization	O
explicitly	O
through	O
a	O
batch	AI/ML/DL-term
normalization	AI/ML/DL-term
layer	AI/ML/DL-term
as	O
is	O
done	O
in	O
BN	O
BNP	AI/ML/DL-technique
applies	O
normalization	O
by	O
conditioning	O
the	O
parameter	AI/ML/DL-term
gradients	AI/ML/DL-term
directly	O
during	O
training	AI/ML/DL-term
Hessian	O
matrix	O
loss	AI/ML/DL-term
function	AI/ML/DL-term
.	O

Instead	O
of	O
applying	O
normalization	O
explicitly	O
through	O
a	O
batch	AI/ML/DL-term
normalization	AI/ML/DL-term
layer	AI/ML/DL-term
as	O
is	O
done	O
in	O
BN	O
BNP	AI/ML/DL-technique
applies	O
normalization	O
by	O
conditioning	O
the	O
parameter	AI/ML/DL-term
gradients	AI/ML/DL-term
directly	O
during	O
training	AI/ML/DL-term
Hessian	O
matrix	O
loss	AI/ML/DL-term
function	AI/ML/DL-term
.	O

This	O
is	O
designed	O
to	O
improve	O
the	O
Hessian	O
matrix	O
of	O
the	O
loss	O
function	O
and	O
hence	O
convergence	O
during	O
training	AI/ML/DL-term
BNP	AI/ML/DL-technique
mini	AI/ML/DL-term
-	AI/ML/DL-term
batch	AI/ML/DL-term
size	AI/ML/DL-term
.	O

This	O
is	O
designed	O
to	O
improve	O
the	O
Hessian	O
matrix	O
of	O
the	O
loss	O
function	O
and	O
hence	O
convergence	O
during	O
training	AI/ML/DL-term
BNP	AI/ML/DL-technique
mini	AI/ML/DL-term
-	AI/ML/DL-term
batch	AI/ML/DL-term
size	AI/ML/DL-term
.	O

For	O
a	O
theoretical	O
foundation	O
,	O
we	O
also	O
present	O
a	O
novel	O
Hessian	O
condition	O
number	O
based	O
convergence	O
theory	O
for	O
a	O
locally	O
convex	O
but	O
not	O
strong	O
-	O
convex	O
loss	O
,	O
which	O
is	O
applicable	O
to	O
networks	O
with	O
a	O
scale	O
-	O
invariant	O
property	O
.	O
nonparametric	AI/ML/DL-term
two	Miscellaneous-term
-	Miscellaneous-term
sample	Miscellaneous-term
test	Miscellaneous-term
procedure	Miscellaneous-term
.	O

For	O
a	O
theoretical	O
foundation	O
,	O
we	O
also	O
present	O
a	O
novel	O
Hessian	O
condition	O
number	O
based	O
convergence	O
theory	O
for	O
a	O
locally	O
convex	O
but	O
not	O
strong	O
-	O
convex	O
loss	O
,	O
which	O
is	O
applicable	O
to	O
networks	O
with	O
a	O
scale	O
-	O
invariant	O
property	O
.	O
nonparametric	AI/ML/DL-term
two	Miscellaneous-term
-	Miscellaneous-term
sample	Miscellaneous-term
test	Miscellaneous-term
procedure	Miscellaneous-term
.	O

The	O
Bayesian	O
treatment	O
of	O
neural	O
networks	O
dictates	O
that	O
a	O
prior	O
distribution	O
is	O
specified	O
over	O
their	O
weight	O
and	O
bias	AI/ML/DL-term
parameters	AI/ML/DL-term
neural	O
networks	O
.	O

This	O
poses	O
a	O
challenge	O
because	O
modern	O
neural	O
networks	O
are	O
characterized	O
by	O
a	O
large	O
number	O
of	O
parameters	AI/ML/DL-term
and	O
the	O
choice	O
of	O
these	O
priors	O
has	O
an	O
uncontrolled	O
effect	O
on	O
the	O
induced	O
functional	O
prior	O
parameters	AI/ML/DL-term
he	O
distribution	O
of	O
the	O
functions	O
obtained	O
by	O
sampling	O
the	O
parameters	O
from	O
their	O
prior	O
distribution	O
Bayesian	O
deep	O
learning	O
.	O

Our	O
proposal	O
is	O
to	O
reason	O
in	O
terms	O
of	O
functional	O
priors	O
,	O
which	O
are	O
easier	O
to	O
elicit	O
,	O
and	O
to	O
“	O
tune	O
”	O
the	O
priors	O
of	O
neural	AI/ML/DL-term
network	AI/ML/DL-term
parameters	AI/ML/DL-term
in	O
a	O
way	O
that	O
they	O
reflect	O
such	O
functional	O
priors	O
.	O
Gaussian	O
processes	O
.	O

We	O
provide	O
vast	O
experimental	O
evidence	O
that	O
coupling	O
these	O
priors	O
with	O
scalable	O
Markov	O
chain	O
Monte	O
Carlo	O
sampling	O
offers	O
systematically	O
large	O
performance	O
improvements	O
over	O
alternative	O
choices	O
of	O
priors	O
and	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
approximate	O
Bayesian	O
deep	O
learning	O
approaches	O
.	O

Posterior	O
collapse	O
is	O
a	O
common	O
failure	O
mode	O
of	O
density	O
models	O
trained	O
as	O
variational	O
autoencoders	O
wherein	O
they	O
model	O
the	O
data	O
without	O
relying	O
on	O
their	O
latent	AI/ML/DL-term
variables	AI/ML/DL-term
rendering	O
these	O
variables	O
useless	O
.	O
posterior	O
collapse	O
.	O

First	O
,	O
the	O
underspecification	O
of	O
the	O
model	O
,	O
which	O
in	O
an	O
extreme	O
but	O
common	O
case	O
allows	O
posterior	O
collapse	O
to	O
be	O
the	O
theoretical	AI/ML/DL-term
optimium	AI/ML/DL-term
variational	AI/ML/DL-term
lower	AI/ML/DL-term
bound	AI/ML/DL-term
.	O

We	O
weave	O
these	O
two	O
strands	O
of	O
research	O
together	O
,	O
specifically	O
the	O
tighter	O
bounds	O
of	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
sample	AI/ML/DL-term
Monte	AI/ML/DL-term
-	AI/ML/DL-term
Carlo	AI/ML/DL-term
objectives	AI/ML/DL-term
and	O
constraints	O
on	O
the	O
mutual	O
information	O
between	O
the	O
observable	O
and	O
the	O
latent	AI/ML/DL-term
variables	AI/ML/DL-term
.	O

The	O
main	O
obstacle	O
is	O
that	O
the	O
usual	O
method	O
of	O
estimating	O
the	O
mutual	O
information	O
as	O
the	O
average	O
Kullback	O
-	O
Leibler	O
divergence	O
between	O
the	O
easily	O
available	O
variational	AI/ML/DL-term
posterior	AI/ML/DL-term
q	O
(	O
z	O
|	O
x	O
)	O
and	O
the	O
prior	O
does	O
not	O
work	O
with	O
Monte	O
-	O
Carlo	O
objectives	O
posterior	O
eir	O
q	O
(	O
z	O
|	O
x	O
)	O
is	O
not	O
a	O
direct	O
approximation	O
to	O
the	O
model	O
'	O
s	O
true	O
posterior	O
p	O
(	O
z	O
|	O
x	O
).	O
estimators	O
Kullback	O
-	O
Leibler	O
divergence	O
.	O

Graph	O
stationarity	O
implies	O
that	O
the	O
mapping	O
between	O
the	O
covariance	O
of	O
the	O
signals	O
and	O
the	O
sparse	AI/ML/DL-term
matrix	AI/ML/DL-term
representing	O
the	O
underlying	O
graph	O
is	O
given	O
by	O
a	O
matrix	O
polynomial	O
.	O

A	O
prominent	O
example	O
is	O
that	O
of	O
Markov	O
random	O
fields	O
,	O
where	O
the	O
inverse	O
of	O
the	O
covariance	O
yields	O
the	O
sparse	O
matrix	O
of	O
interest	O
.	O
stationary	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
signals	Data/Mining/Information/Retrieval-term
.	O

Numerical	O
experiments	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
with	O
perfect	O
covariance	O
information	O
as	O
well	O
as	O
its	O
robustness	O
in	O
the	O
noisy	O
regime	O
.	O
GLRklUCB	AI/ML/DL-technique
algorithm	Miscellaneous-term
.	O

Numerical	O
experiments	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
with	O
perfect	O
covariance	O
information	O
as	O
well	O
as	O
its	O
robustness	O
in	O
the	O
noisy	O
regime	O
.	O
GLRklUCB	AI/ML/DL-technique
algorithm	Miscellaneous-term
.	O

We	O
introduce	O
GLRklUCB	O
,	O
a	O
novel	O
algorithm	Miscellaneous-term
for	O
the	O
piecewise	O
iid	O
non	O
-	O
stationary	O
bandit	O
problem	O
with	O
bounded	O
rewards	O
.	O
bandit	O
algorithm	O
klUCB	O
.	O

This	O
algorithm	O
combines	O
an	O
efficient	O
bandit	O
algorithm	O
,	O
klUCB	O
,	O
with	O
an	O
efficient	O
,	O
parameter	AI/ML/DL-term
-	AI/ML/DL-term
free	AI/ML/DL-term
change	AI/ML/DL-term
-	AI/ML/DL-term
point	AI/ML/DL-term
detector	AI/ML/DL-term
the	O
Bernoulli	O
Generalized	O
Likelihood	O
Ratio	O
Test	O
for	O
which	O
we	O
provide	O
new	O
theoretical	O
guarantees	O
of	O
independent	O
interest	O
.	O
non	O
-	O
stationary	O
bandit	O
algorithms	O
.	O

Unlike	O
previous	O
non	O
-	O
stationary	O
bandit	O
algorithms	O
using	O
a	O
change	O
-	O
point	O
detector	O
,	O
GLRklUCB	AI/ML/DL-technique
does	O
not	O
need	O
to	O
be	O
calibrated	O
based	O
on	O
prior	O
knowledge	O
on	O
the	O
arms	O
'	O
means	O
.	O

In	O
contrast	O
with	O
recently	O
proposed	O
algorithms	O
that	O
are	O
agnostic	O
to	O
$\	O
Upsilon_T	O
$,	O
we	O
perform	O
a	O
numerical	O
study	O
showing	O
that	O
GLRklUCB	AI/ML/DL-technique
is	O
also	O
very	O
efficient	O
in	O
practice	O
,	O
beyond	O
easy	O
instances	O
.	O

Specifically	O
,	O
we	O
propose	O
and	O
analyze	O
a	O
class	O
of	O
adaptive	O
dual	O
averaging	O
schemes	O
in	O
which	O
agents	O
only	O
need	O
to	O
accumulate	O
gradient	AI/ML/DL-term
feedback	AI/ML/DL-term
received	O
from	O
the	O
whole	O
system	O
,	O
without	O
requiring	O
any	O
between	O
-	O
agent	O
coordination	O
.	O
single	AI/ML/DL-term
-	AI/ML/DL-term
agent	AI/ML/DL-term
.	O

In	O
the	O
single	O
-	O
agent	O
case	O
,	O
the	O
adaptivity	O
of	O
the	O
proposed	O
method	O
allows	O
us	O
to	O
extend	O
a	O
range	O
of	O
existing	O
results	O
to	O
problems	O
with	O
potentially	O
unbounded	O
delays	O
between	O
playing	O
an	O
action	O
and	O
receiving	O
the	O
corresponding	O
feedback	O
.	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
agent	AI/ML/DL-term
.	O

Finally	O
,	O
we	O
also	O
analyze	O
an	O
“	O
optimistic	O
”	O
variant	O
of	O
the	O
proposed	O
algorithm	O
which	O
is	O
capable	O
of	O
exploiting	O
the	O
predictability	O
of	O
problems	O
with	O
a	O
slower	O
variation	O
and	O
leads	O
to	O
improved	O
regret	O
bounds	O
.	O
multimodal	AI/ML/DL-term
Bayesian	AI/ML/DL-term
posterior	AI/ML/DL-term
distributions	AI/ML/DL-term
.	O

The	O
result	O
from	O
stacking	O
efficiently	O
samples	O
from	O
multimodal	AI/ML/DL-term
posterior	AI/ML/DL-term
distribution	AI/ML/DL-term
minimizes	O
cross	O
validation	O
prediction	O
error	O
,	O
and	O
represents	O
the	O
posterior	O
uncertainty	O
better	O
than	O
variational	O
inference	O
,	O
but	O
it	O
is	O
not	O
necessarily	O
equivalent	O
,	O
even	O
asymptotically	O
,	O
to	O
fully	O
Bayesian	O
inference	O
.	O

Bayesian	O
hierarchical	O
models	O
are	O
powerful	O
tools	O
for	O
learning	O
common	O
latent	AI/ML/DL-term
features	AI/ML/DL-term
across	O
multiple	O
data	O
sources	O
.	O
Hierarchical	O
Dirichlet	O
Process	O
(	O
HDP	O
)	O
.	O

The	O
Hierarchical	O
Dirichlet	O
Process	O
(	O
HDP	O
)	O
is	O
invoked	O
when	O
the	O
number	O
of	O
latent	AI/ML/DL-term
components	AI/ML/DL-term
is	O
a	O
priori	O
unknown	O
.	O

The	O
effect	O
varies	O
according	O
to	O
the	O
smoothness	O
level	O
of	O
the	O
true	O
data	AI/ML/DL-term
distributions	AI/ML/DL-term
Gaussian	O
mixtures	O
.	O

There	O
is	O
an	O
increased	O
emphasis	O
on	O
fairness	O
in	O
machine	O
learning	O
and	O
AI	O
;	O
one	O
representative	O
notion	O
of	O
fairness	O
is	O
that	O
no	O
single	O
group	O
should	O
be	O
over	O
-	O
represented	O
among	O
the	O
cluster	AI/ML/DL-term
-	AI/ML/DL-term
centers	AI/ML/DL-term
clustering	O
.	O

This	O
,	O
and	O
much	O
more	O
general	O
clustering	O
problems	O
,	O
can	O
be	O
formulated	O
with	O
“	O
knapsack	AI/ML/DL-term
and	O
“	O
partition	AI/ML/DL-term
constraints	O
.	O
randomized	O
algorithms	O
.	O

We	O
develop	O
new	O
randomized	O
algorithms	O
targeting	O
such	O
problems	O
,	O
and	O
study	O
two	O
in	O
particular	O
:	O
multi	O
-	O
knapsack	O
median	O
and	O
multi	O
-	O
knapsack	O
center	O
rounding	O
algorithms	O
approximation	AI/ML/DL-term
.	O

One	O
key	O
technical	O
tool	O
,	O
which	O
may	O
be	O
of	O
independent	O
interest	O
,	O
is	O
a	O
new	O
tail	O
bound	O
analogous	O
to	O
Feige	O
(	O
2006	O
)	O
for	O
sums	O
of	O
random	AI/ML/DL-term
variables	AI/ML/DL-term
with	O
unbounded	O
variances	O
.	O

In	O
such	O
a	O
problem	O
,	O
not	O
only	O
can	O
the	O
number	O
of	O
functions	O
measured	O
per	O
sample	O
be	O
large	O
,	O
but	O
each	O
function	O
is	O
itself	O
an	O
infinite	O
dimensional	O
object	O
,	O
making	O
estimation	O
of	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
challenging	O
.	O

This	O
is	O
further	O
complicated	O
by	O
the	O
fact	O
that	O
curves	O
are	O
usually	O
observed	O
only	O
at	O
discrete	O
time	O
points	O
.	O
functional	Data/Mining/Information/Retrieval-term
differential	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
.	O

This	O
is	O
particularly	O
beneficial	O
in	O
settings	O
where	O
the	O
individual	O
graphs	O
are	O
dense	O
but	O
the	O
differential	O
graph	O
is	O
sparse	O
.	O
FuDGE	O
functional	Data/Mining/Information/Retrieval-term
differential	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
.	O

We	O
show	O
that	O
FuDGE	O
consistently	O
estimates	O
the	O
functional	O
differential	O
graph	O
even	O
in	O
a	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
setting	AI/ML/DL-term
for	O
both	O
fully	O
observed	O
and	O
discretely	O
observed	O
function	O
paths	O
.	O

We	O
illustrate	O
the	O
finite	O
sample	O
properties	O
of	O
our	O
method	O
through	O
simulation	O
studies	O
.	O
Joint	AI/ML/DL-technique
Functional	AI/ML/DL-technique
Graphical	AI/ML/DL-technique
Lasso	AI/ML/DL-technique
.	O

To	O
overcome	O
such	O
difficulties	O
,	O
recent	O
efforts	O
have	O
been	O
devoted	O
to	O
developing	O
supervised	O
algorithms	O
to	O
accurately	O
predict	O
phenotypes	O
based	O
on	O
relatively	O
small	O
training	Miscellaneous-term
datasets	Miscellaneous-term
with	O
gold	O
-	O
standard	O
labels	O
extracted	O
via	O
chart	O
review	O
.	O

However	O
,	O
supervised	O
methods	O
typically	O
require	O
a	O
sizable	O
training	O
set	O
to	O
yield	O
generalizable	O
algorithms	O
,	O
especially	O
when	O
the	O
number	O
of	O
candidate	O
features	O
is	O
large	O
.	O
semi	AI/ML/DL-technique
-	AI/ML/DL-technique
supervised	AI/ML/DL-technique
(	AI/ML/DL-technique
SS	AI/ML/DL-technique
)	AI/ML/DL-technique
EHR	AI/ML/DL-technique
phenotyping	AI/ML/DL-technique
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
semi	O
-	O
supervised	O
(	O
SS	O
)	O
EHR	O
phenotyping	O
method	O
that	O
borrows	O
information	O
from	O
both	O
a	O
small	O
,	O
labeled	O
dataset	Miscellaneous-term
(	O
where	O
both	O
the	O
label	O
Y	O
and	O
the	O
feature	O
set	O
X	O
are	O
observed	O
)	O
and	O
a	O
much	O
larger	O
,	O
weakly	AI/ML/DL-term
-	AI/ML/DL-term
labeled	AI/ML/DL-term
dataset	Miscellaneous-term
in	O
which	O
the	O
feature	O
set	O
X	O
is	O
accompanied	O
only	O
by	O
a	O
surrogate	O
label	O
S	O
that	O
is	O
available	O
to	O
all	O
patients	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
semi	O
-	O
supervised	O
(	O
SS	O
)	O
EHR	O
phenotyping	O
method	O
that	O
borrows	O
information	O
from	O
both	O
a	O
small	O
,	O
labeled	O
dataset	Miscellaneous-term
(	O
where	O
both	O
the	O
label	O
Y	O
and	O
the	O
feature	O
set	O
X	O
are	O
observed	O
)	O
and	O
a	O
much	O
larger	O
,	O
weakly	AI/ML/DL-term
-	AI/ML/DL-term
labeled	AI/ML/DL-term
dataset	Miscellaneous-term
in	O
which	O
the	O
feature	O
set	O
X	O
is	O
accompanied	O
only	O
by	O
a	O
surrogate	O
label	O
S	O
that	O
is	O
available	O
to	O
all	O
patients	O
.	O

Under	O
a	O
working	O
prior	O
assumption	O
that	O
S	O
is	O
related	O
to	O
X	O
only	O
through	O
Y	O
and	O
allowing	O
it	O
to	O
hold	O
approximately	O
,	O
we	O
propose	O
a	O
prior	AI/ML/DL-technique
adaptive	AI/ML/DL-technique
semi	AI/ML/DL-technique
-	AI/ML/DL-technique
supervised	AI/ML/DL-technique
(	AI/ML/DL-technique
PASS	AI/ML/DL-technique
)	AI/ML/DL-technique
estimator	AI/ML/DL-technique
that	O
incorporates	O
the	O
prior	O
knowledge	O
by	O
shrinking	O
the	O
estimator	O
towards	O
a	O
direction	O
derived	O
under	O
the	O
prior	O
.	O

Based	O
on	O
the	O
equivalence	O
,	O
we	O
propose	O
an	O
index	O
to	O
measure	O
the	O
conditional	O
dependence	O
by	O
quantifying	O
the	O
mutual	O
dependence	O
among	O
the	O
transformed	AI/ML/DL-term
variables	AI/ML/DL-term
.	O

Thus	O
,	O
it	O
has	O
nontrivial	O
power	O
under	O
the	O
alternative	O
hypothesis	O
.	O
outliers	AI/ML/DL-term
.	O

(	O
c	O
)	O
It	O
is	O
robust	O
to	O
outliers	O
and	O
heavy	O
-	O
tailed	O
data	O
since	O
it	O
is	O
invariant	O
to	O
conditional	O
strictly	O
monotone	AI/ML/DL-term
transformations	AI/ML/DL-term
.	O

(	O
d	O
)	O
It	O
has	O
low	O
computational	O
cost	O
since	O
it	O
incorporates	O
a	O
simple	O
closed	O
-	O
form	O
expression	O
and	O
can	O
be	O
implemented	O
in	O
quadratic	Miscellaneous-term
time	Miscellaneous-term
.	O

(	O
e	O
)	O
It	O
is	O
insensitive	O
to	O
tuning	O
parameters	O
involved	O
in	O
the	O
calculation	O
of	O
the	O
proposed	O
index	O
.	O
multivariate	AI/ML/DL-term
random	AI/ML/DL-term
vectors	AI/ML/DL-term
.	O

Roseland	O
is	O
theoretically	O
justified	O
under	O
the	O
manifold	O
model	O
,	O
and	O
its	O
computational	Miscellaneous-term
complexity	Miscellaneous-term
is	O
comparable	O
with	O
commonly	O
applied	O
subsampling	O
scheme	O
such	O
as	O
the	O
Nystr	O
\"	O
om	O
extension	O
.	O

To	O
demonstrate	O
the	O
potential	O
of	O
Roseland	O
,	O
we	O
apply	O
it	O
to	O
{	O
three	O
}	O
datasets	O
and	O
compare	O
it	O
with	O
several	O
other	O
existing	O
algorithms	Miscellaneous-term
Roseland	O
spectral	O
clustering	O
MNIST	O
.	O

In	O
conclusion	O
,	O
Roseland	O
is	O
scalable	O
and	O
robust	O
,	O
and	O
it	O
has	O
a	O
potential	O
for	O
analyzing	O
large	O
datasets	Miscellaneous-term
.	O

In	O
particular	O
,	O
we	O
show	O
that	O
CD	O
-	O
split	O
converges	O
asymptotically	O
to	O
the	O
oracle	O
highest	O
predictive	O
density	O
set	O
and	O
satisfies	O
local	O
and	O
asymptotic	AI/ML/DL-term
conditional	AI/ML/DL-term
validity	AI/ML/DL-term
CD	O
-	O
split	O
.	O

We	O
also	O
present	O
simulations	O
that	O
show	O
how	O
to	O
tune	O
CD	O
-	O
split	O
.	O
HPD	AI/ML/DL-technique
-	AI/ML/DL-technique
split	AI/ML/DL-technique
CD	O
-	O
split	O
.	O

Finally	O
,	O
we	O
introduce	O
HPD	O
-	O
split	O
,	O
a	O
variation	O
of	O
CD	O
-	O
split	O
CD	O
-	O
split	O
HPD	AI/ML/DL-technique
-	AI/ML/DL-technique
split	AI/ML/DL-technique
tuning	O
,	O
and	O
show	O
that	O
it	O
shares	O
the	O
same	O
theoretical	O
guarantees	O
as	O
CD	O
-	O
split	O
.	O

In	O
this	O
paper	O
,	O
we	O
first	O
generalize	O
the	O
ambiguity	O
decomposition	O
theory	O
from	O
regression	O
ensemble	O
to	O
ranking	O
ensemble	O
which	O
proves	O
the	O
effectiveness	O
of	O
ranking	O
ensemble	O
with	O
consideration	O
of	O
list	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
wise	Data/Mining/Information/Retrieval-term
ranking	Data/Mining/Information/Retrieval-term
information	O
.	O

According	O
to	O
the	O
generalized	O
theory	O
,	O
we	O
propose	O
an	O
explicit	O
diversity	O
measure	O
for	O
ranking	O
ensemble	O
which	O
can	O
be	O
used	O
to	O
enhance	O
the	O
diversity	O
of	O
ensemble	O
and	O
improve	O
the	O
performance	O
of	O
ensemble	O
model	O
query	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
dependent	Data/Mining/Information/Retrieval-term
.	O

Furthermore	O
,	O
we	O
adopt	O
an	O
adaptive	O
learning	O
scheme	O
to	O
learn	O
query	O
-	O
dependent	O
ensemble	AI/ML/DL-term
weights	AI/ML/DL-term
which	O
can	O
fit	O
into	O
the	O
generalized	O
theory	O
and	O
help	O
to	O
further	O
improve	O
the	O
performance	O
of	O
ensemble	O
model	O
recommendation	O
information	O
retrieval	O
.	O

Extensive	O
experiments	O
on	O
recommendation	O
and	O
information	O
retrieval	O
tasks	O
demonstrate	O
the	O
effectiveness	O
and	O
theoretical	O
advantages	O
of	O
the	O
proposed	O
method	O
compared	O
with	O
several	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
.	O
graph	O
representation	O
learning	O
(	O
GRL	O
)	O
GRL	O
.	O

GRL	O
methods	O
have	O
generally	O
fallen	O
into	O
three	O
main	O
categories	O
,	O
based	O
on	O
the	O
availability	O
of	O
labeled	O
data	O
.	O
network	Data/Mining/Information/Retrieval-term
embedding	Data/Mining/Information/Retrieval-term
unsupervised	AI/ML/DL-term
representations	AI/ML/DL-term
.	O

GRL	O
methods	O
have	O
generally	O
fallen	O
into	O
three	O
main	O
categories	O
,	O
based	O
on	O
the	O
availability	O
of	O
labeled	O
data	O
.	O
network	Data/Mining/Information/Retrieval-term
embedding	Data/Mining/Information/Retrieval-term
unsupervised	AI/ML/DL-term
representations	AI/ML/DL-term
.	O

However	O
,	O
despite	O
the	O
popularity	O
of	O
these	O
areas	O
there	O
has	O
been	O
surprisingly	O
little	O
work	O
on	O
unifying	O
the	O
three	O
paradigms	O
.	O
network	Data/Mining/Information/Retrieval-term
embedding	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
regularization	Data/Mining/Information/Retrieval-term
.	O

We	O
propose	O
a	O
comprehensive	O
taxonomy	O
of	O
GRL	O
methods	O
,	O
aiming	O
to	O
unify	O
several	O
disparate	O
bodies	O
of	O
work	O
.	O
GraphEDM	O
algorithms	Miscellaneous-term
.	O

(	O
2020	O
)	O
using	O
the	O
full	O
Hessian	O
information	O
.	O
algorithm	Miscellaneous-term
.	O

Experimental	O
results	O
on	O
the	O
regularized	O
logistic	O
regression	O
problems	O
demonstrate	O
a	O
clear	O
effect	O
of	O
acceleration	O
on	O
several	O
real	O
data	Miscellaneous-term
sets	Miscellaneous-term
.	O
supervised	O
learning	O
algorithm	O
.	O

The	O
hypothesis	O
of	O
the	O
learner	O
is	O
taken	O
from	O
some	O
fixed	O
class	O
of	O
functions	O
(	O
e	O
.	O
g	O
.,	O
linear	O
classifiers	O
neural	O
networks	O
etc	O
.).	O
algorithm	Miscellaneous-term
.	O

Although	O
both	O
approximation	O
and	O
learnability	O
are	O
important	O
for	O
the	O
success	O
of	O
the	O
algorithm	O
,	O
they	O
are	O
typically	O
studied	O
separately	O
.	O
hardness	AI/ML/DL-term
property	AI/ML/DL-term
.	O

In	O
this	O
work	O
,	O
we	O
show	O
a	O
single	O
hardness	O
property	O
that	O
implies	O
both	O
hardness	O
of	O
approximation	O
using	O
linear	AI/ML/DL-term
classes	AI/ML/DL-term
and	O
shallow	O
networks	O
and	O
hardness	O
of	O
learning	O
using	O
correlation	O
queries	O
and	O
gradient	AI/ML/DL-term
-	AI/ML/DL-term
descent	AI/ML/DL-term
.	O

This	O
allows	O
us	O
to	O
obtain	O
new	O
results	O
on	O
hardness	O
of	O
approximation	O
and	O
learnability	O
of	O
parity	AI/ML/DL-term
functions	AI/ML/DL-term
DNF	AI/ML/DL-term
formulas	AI/ML/DL-term
and	O
$	O
AC	O
^	O
0	O
$	O
circuits	O
.	O
Gaussian	O
processes	O
probabilistic	O
kernel	O
learning	O
.	O

Nevertheless	O
,	O
the	O
learning	O
phase	O
of	O
Gaussian	O
process	O
regression	O
requires	O
massive	O
computations	O
which	O
are	O
not	O
realistic	O
for	O
large	O
datasets	Miscellaneous-term
Gauss	O
-	O
Legendre	O
quadrature	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
a	O
Gauss	O
-	O
Legendre	O
quadrature	O
based	O
approach	O
for	O
scaling	O
up	O
Gaussian	O
process	O
regression	O
via	O
a	O
low	O
rank	O
approximation	O
of	O
the	O
kernel	AI/ML/DL-term
matrix	AI/ML/DL-term
low	O
rank	O
approximation	O
.	O

We	O
utilize	O
the	O
structure	O
of	O
the	O
low	O
rank	O
approximation	O
to	O
achieve	O
effective	O
hyperparameter	O
learning	O
training	AI/ML/DL-term
and	O
prediction	O
.	O
random	O
Fourier	O
features	O
.	O

Our	O
method	O
is	O
very	O
much	O
inspired	O
by	O
the	O
well	O
-	O
known	O
random	O
Fourier	O
features	O
approach	O
,	O
which	O
also	O
builds	O
low	O
-	O
rank	O
approximations	O
via	O
numerical	O
integration	O
.	O
kernel	AI/ML/DL-term
.	O

Furthermore	O
,	O
the	O
structure	O
of	O
the	O
low	O
-	O
rank	O
approximation	O
that	O
our	O
method	O
builds	O
is	O
subtly	O
different	O
from	O
the	O
one	O
generated	O
by	O
random	O
Fourier	O
features	O
,	O
and	O
this	O
enables	O
much	O
more	O
efficient	O
hyperparameter	O
learning	O
datasets	Miscellaneous-term
.	O

Different	O
penalization	O
strategies	O
are	O
considered	O
and	O
compared	O
in	O
a	O
theoretical	O
analysis	O
and	O
an	O
extensive	O
Monte	O
Carlo	O
simulation	O
study	O
.	O
hard	AI/ML/DL-technique
-	AI/ML/DL-technique
threshold	AI/ML/DL-technique
K	AI/ML/DL-technique
-	AI/ML/DL-technique
means	AI/ML/DL-technique
(	AI/ML/DL-technique
HTK	AI/ML/DL-technique
-	AI/ML/DL-technique
means	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

Based	O
on	O
the	O
results	O
,	O
we	O
propose	O
a	O
new	O
method	O
called	O
hard	O
-	O
threshold	O
K	O
-	O
means	O
(	O
HTK	AI/ML/DL-technique
-	AI/ML/DL-technique
means	AI/ML/DL-technique
,	O
which	O
uses	O
an	O
ℓ0	O
penalty	O
to	O
induce	O
sparsity	O
.	O
sparse	O
clustering	O
.	O

A	O
procedure	O
is	O
introduced	O
,	O
based	O
on	O
nonparametric	O
empirical	O
Bayes	O
ideas	O
,	O
that	O
controls	O
the	O
False	AI/ML/DL-term
Discovery	AI/ML/DL-term
Rate	AI/ML/DL-term
(	AI/ML/DL-term
FDR	AI/ML/DL-term
)	AI/ML/DL-term
at	O
a	O
user	O
-	O
specified	O
level	O
.	O

We	O
provide	O
the	O
existence	O
of	O
such	O
estimators	O
,	O
with	O
convergence	O
at	O
the	O
optimal	O
minimax	O
rate	O
,	O
for	O
the	O
case	O
of	O
a	O
HMM	O
with	O
$	O
J	O
\	O
ge	O
2	O
$	O
states	O
,	O
which	O
is	O
of	O
independent	O
interest	O
.	O
Neighbor	Data/Mining/Information/Retrieval-term
embeddings	Data/Mining/Information/Retrieval-term
.	O

Neighbor	O
embeddings	O
are	O
a	O
family	O
of	O
methods	O
for	O
visualizing	O
complex	O
high	O
-	O
dimensional	O
data	O
sets	O
using	O
kNN	O
graphs	O
low	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
embedding	AI/ML/DL-term
algorithms	Miscellaneous-term
.	O

Neighbor	O
embeddings	O
are	O
a	O
family	O
of	O
methods	O
for	O
visualizing	O
complex	O
high	O
-	O
dimensional	O
data	O
sets	O
using	O
kNN	O
graphs	O
low	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
embedding	AI/ML/DL-term
algorithms	Miscellaneous-term
.	O

To	O
find	O
the	O
low	O
-	O
dimensional	O
embedding	O
,	O
these	O
algorithms	Miscellaneous-term
combine	O
an	O
attractive	O
force	O
between	O
neighboring	O
pairs	O
of	O
points	O
with	O
a	O
repulsive	O
force	O
between	O
all	O
points	O
.	O
t	O
-	O
SNE	O
.	O

Likewise	O
,	O
ForceAtlas2	O
,	O
commonly	O
used	O
for	O
visualizing	O
developmental	O
single	O
-	O
cell	O
transcriptomic	O
data	O
,	O
yields	O
embeddings	AI/ML/DL-term
corresponding	O
to	O
t	O
-	O
SNE	O
with	O
the	O
attraction	O
increased	O
even	O
more	O
.	O
Laplacian	AI/ML/DL-term
eigenmaps	AI/ML/DL-term
.	O

The	O
size	O
of	O
the	O
output	O
space	O
for	O
these	O
problems	O
can	O
range	O
from	O
millions	O
to	O
billions	O
,	O
and	O
can	O
even	O
be	O
infinite	O
in	O
some	O
applications	O
.	O
training	AI/ML/DL-term
data	AI/ML/DL-term
output	AI/ML/DL-term
space	AI/ML/DL-term
.	O

Fortunately	O
,	O
items	O
in	O
the	O
output	O
space	O
are	O
often	O
correlated	O
thereby	O
presenting	O
an	O
opportunity	O
to	O
alleviate	O
the	O
data	AI/ML/DL-term
sparsity	AI/ML/DL-term
issue	O
.	O
Prediction	AI/ML/DL-technique
for	AI/ML/DL-technique
Enormous	AI/ML/DL-technique
and	AI/ML/DL-technique
Correlated	AI/ML/DL-technique
Output	AI/ML/DL-technique
Spaces	AI/ML/DL-technique
(	AI/ML/DL-technique
PECOS	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

Fortunately	O
,	O
items	O
in	O
the	O
output	O
space	O
are	O
often	O
correlated	O
thereby	O
presenting	O
an	O
opportunity	O
to	O
alleviate	O
the	O
data	AI/ML/DL-term
sparsity	AI/ML/DL-term
issue	O
.	O
Prediction	AI/ML/DL-technique
for	AI/ML/DL-technique
Enormous	AI/ML/DL-technique
and	AI/ML/DL-technique
Correlated	AI/ML/DL-technique
Output	AI/ML/DL-technique
Spaces	AI/ML/DL-technique
(	AI/ML/DL-technique
PECOS	AI/ML/DL-technique
)	AI/ML/DL-technique
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
the	O
Prediction	O
for	O
Enormous	O
and	O
Correlated	O
Output	O
Spaces	O
(	O
PECOS	O
)	O
framework	O
,	O
a	O
versatile	O
and	O
modular	O
machine	O
learning	O
framework	O
for	O
solving	O
prediction	O
problems	O
for	O
very	O
large	O
output	O
spaces	O
,	O
and	O
apply	O
it	O
to	O
the	O
eXtreme	O
Multilabel	O
Ranking	O
(	O
XMR	O
)	O
PECOS	AI/ML/DL-technique
PECOS	AI/ML/DL-technique
en	O
an	O
input	O
instance	O
,	O
find	O
and	O
rank	O
the	O
most	O
relevant	O
items	O
from	O
an	O
enormous	O
but	O
fixed	O
and	O
finite	O
output	O
space	O
.	O

We	O
propose	O
a	O
three	O
phase	O
framework	O
for	O
PECOS	O
:	O
(	O
i	O
)	O
in	O
the	O
first	O
phase	O
,	O
PECOS	O
organizes	O
the	O
output	O
space	O
using	O
a	O
semantic	O
indexing	O
PECOS	AI/ML/DL-technique
,	O
(	O
ii	O
)	O
in	O
the	O
second	O
phase	O
,	O
PECOS	O
uses	O
the	O
indexing	O
to	O
narrow	O
down	O
the	O
output	O
space	O
by	O
orders	O
of	O
magnitude	O
using	O
a	O
machine	O
learned	O
matching	O
PECOS	AI/ML/DL-technique
PECOS	AI/ML/DL-technique
(	O
iii	O
)	O
in	O
the	O
third	O
phase	O
,	O
PECOS	O
ranks	O
the	O
matched	O
items	O
using	O
a	O
final	O
ranking	O
scheme	O
.	O

When	O
applied	O
to	O
eXtreme	O
Multilabel	O
Ranking	O
where	O
the	O
input	O
instances	O
are	O
in	O
textual	O
form	O
,	O
we	O
find	O
that	O
the	O
recursive	O
Transformer	O
matcher	O
gives	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
accuracy	O
results	O
,	O
at	O
the	O
cost	O
of	O
two	O
orders	O
of	O
magnitude	O
increased	O
training	O
time	O
compared	O
to	O
the	O
recursive	O
linear	O
matcher	O
dataset	Miscellaneous-term
.	O

We	O
also	O
develop	O
very	O
fast	O
inference	O
procedures	O
which	O
allow	O
us	O
to	O
perform	O
XMR	O
predictions	O
in	O
real	O
time	O
;	O
for	O
example	O
,	O
inference	O
takes	O
less	O
than	O
1	O
millisecond	O
per	O
input	O
on	O
the	O
dataset	Miscellaneous-term
with	O
2	O
.	O
8	O
million	O
labels	O
.	O
PECOS	O
https	O
://	O
libpecos	O
.	O
org	O
information	O
technology	O
.	O

The	O
PECOS	O
software	O
is	O
available	O
at	O
https	O
://	O
libpecos	O
.	O
org	O
.	O
datasets	Miscellaneous-term
.	O

This	O
paper	O
applies	O
this	O
strategy	O
to	O
develop	O
a	O
distributed	O
learning	O
procedure	O
of	O
finite	O
Gaussian	O
mixtures	O
reduction	O
majorization	O
-	O
minimization	O
algorithm	Miscellaneous-term
.	O

Experiments	O
based	O
on	O
simulated	O
and	O
real	O
-	O
world	O
datasets	O
show	O
that	O
the	O
proposed	O
estimator	O
has	O
comparable	O
statistical	O
dataset	Miscellaneous-term
nce	O
with	O
the	O
global	O
estimator	O
based	O
on	O
the	O
full	O
dataset	O
,	O
if	O
the	O
latter	O
is	O
feasible	O
.	O

Regularized	O
kernel	O
-	O
based	O
methods	O
such	O
as	O
support	O
vector	O
machines	O
(	O
SVMs	O
)	O
typically	O
depend	O
on	O
the	O
underlying	O
probability	O
measure	O
$\	O
mathrm	O
{	O
P	O
}$	O
(	O
respectively	O
an	O
empirical	O
measure	O
$\	O
mathrm	O
{	O
D	O
}	O
_n	O
$	O
in	O
applications	O
)	O
as	O
well	O
as	O
on	O
the	O
regularization	AI/ML/DL-term
parameter	AI/ML/DL-term
kernel	AI/ML/DL-term
a	O
$	O
and	O
the	O
kernel	O
$	O
k	O
$.	O
statistical	Miscellaneous-term
robustness	Miscellaneous-term
.	O

Regularized	O
kernel	O
-	O
based	O
methods	O
such	O
as	O
support	O
vector	O
machines	O
(	O
SVMs	O
)	O
typically	O
depend	O
on	O
the	O
underlying	O
probability	O
measure	O
$\	O
mathrm	O
{	O
P	O
}$	O
(	O
respectively	O
an	O
empirical	O
measure	O
$\	O
mathrm	O
{	O
D	O
}	O
_n	O
$	O
in	O
applications	O
)	O
as	O
well	O
as	O
on	O
the	O
regularization	AI/ML/DL-term
parameter	AI/ML/DL-term
kernel	AI/ML/DL-term
a	O
$	O
and	O
the	O
kernel	O
$	O
k	O
$.	O
statistical	Miscellaneous-term
robustness	Miscellaneous-term
.	O

In	O
order	O
to	O
also	O
make	O
them	O
applicable	O
to	O
big	O
data	O
,	O
where	O
regular	O
SVMs	O
suffer	O
from	O
their	O
super	O
-	O
linear	O
computational	O
requirements	O
,	O
we	O
show	O
how	O
our	O
results	O
can	O
be	O
transferred	O
to	O
the	O
context	O
of	O
localized	O
learning	O
regionalization	AI/ML/DL-term
.	O

RAG	O
has	O
only	O
been	O
trained	O
and	O
explored	O
with	O
a	O
Wikipedia	Miscellaneous-term
-	Miscellaneous-term
based	Miscellaneous-term
external	NLP-term
knowledge	NLP-term
base	NLP-term
and	O
is	O
not	O
optimized	O
for	O
use	O
in	O
other	O
specialized	O
domains	O
such	O
as	O
healthcare	O
and	O
news	O
.	O

RAG	O
has	O
only	O
been	O
trained	O
and	O
explored	O
with	O
a	O
Wikipedia	Miscellaneous-term
-	Miscellaneous-term
based	Miscellaneous-term
external	NLP-term
knowledge	NLP-term
base	NLP-term
and	O
is	O
not	O
optimized	O
for	O
use	O
in	O
other	O
specialized	O
domains	O
such	O
as	O
healthcare	O
and	O
news	O
.	O

In	O
this	O
paper	O
,	O
we	O
evaluate	O
the	O
impact	O
of	O
joint	AI/ML/DL-term
training	AI/ML/DL-term
of	O
the	O
retriever	O
and	O
generator	O
components	O
of	O
RAG	O
for	O
the	O
task	O
of	O
domain	O
adaptation	O
in	O
ODQA	O
.	O

We	O
propose	O
RAG	O
-	O
end2end	O
RAG	O
extension	O
to	O
RAG	O
that	O
can	O
adapt	O
to	O
a	O
domain	NLP-term
-	NLP-term
specific	NLP-term
knowledge	NLP-term
base	NLP-term
by	O
updating	O
all	O
components	O
of	O
the	O
external	NLP-term
knowledge	NLP-term
base	NLP-term
during	O
training	AI/ML/DL-term
.	O

We	O
propose	O
RAG	O
-	O
end2end	O
RAG	O
extension	O
to	O
RAG	O
that	O
can	O
adapt	O
to	O
a	O
domain	NLP-term
-	NLP-term
specific	NLP-term
knowledge	NLP-term
base	NLP-term
by	O
updating	O
all	O
components	O
of	O
the	O
external	NLP-term
knowledge	NLP-term
base	NLP-term
during	O
training	AI/ML/DL-term
.	O

In	O
addition	O
,	O
we	O
introduce	O
an	O
auxiliary	O
training	O
signal	O
to	O
inject	O
more	O
domain	NLP-term
-	NLP-term
specific	NLP-term
knowledge	NLP-term
.	O

This	O
auxiliary	O
signal	O
forces	O
RAG	O
-	O
end2end	O
to	O
reconstruct	O
a	O
given	O
sentence	O
by	O
accessing	O
the	O
relevant	O
information	O
from	O
the	O
external	NLP-term
knowledge	NLP-term
base	NLP-term
.	NLP-term
.	O

Our	O
novel	O
contribution	O
is	O
that	O
,	O
unlike	O
RAG	O
RAG	O
-	O
end2end	O
does	O
joint	AI/ML/DL-term
training	AI/ML/DL-term
of	O
the	O
retriever	O
and	O
generator	O
for	O
the	O
end	O
QA	O
task	O
and	O
domain	O
adaptation	O
.	O

Many	O
studies	O
have	O
shown	O
that	O
transformers	O
are	O
able	O
to	O
predict	O
subject	O
-	O
verb	O
agreement	O
demonstrating	O
their	O
ability	O
to	O
uncover	O
an	O
abstract	O
representation	O
of	O
the	O
sentence	NLP-term
in	O
an	O
unsupervised	AI/ML/DL-term
way	AI/ML/DL-term
.	O

Many	O
studies	O
have	O
shown	O
that	O
transformers	O
are	O
able	O
to	O
predict	O
subject	O
-	O
verb	O
agreement	O
demonstrating	O
their	O
ability	O
to	O
uncover	O
an	O
abstract	O
representation	O
of	O
the	O
sentence	NLP-term
in	O
an	O
unsupervised	AI/ML/DL-term
way	AI/ML/DL-term
.	O

(	O
2021	O
)	O
found	O
that	O
transformers	O
were	O
also	O
able	O
to	O
predict	O
the	O
object	O
-	O
past	O
participle	O
agreement	O
in	O
French	Miscellaneous-term
the	O
modeling	O
of	O
which	O
in	O
formal	O
grammar	O
is	O
fundamentally	O
different	O
from	O
that	O
of	O
subject	O
-	O
verb	O
agreement	O
and	O
relies	O
on	O
a	O
movement	O
and	O
an	O
anaphora	Miscellaneous-term
resolution	Miscellaneous-term
transformers	O
erstand	O
transformers	O
’	O
internal	O
working	O
,	O
we	O
propose	O
to	O
contrast	O
how	O
they	O
handle	O
these	O
two	O
kinds	O
of	O
agreement	O
.	O

Using	O
probing	O
and	O
counterfactual	O
analysis	O
methods	O
,	O
our	O
experiments	O
on	O
French	O
agreements	O
show	O
that	O
(	O
i	O
)	O
the	O
agreement	O
task	O
suffers	O
from	O
several	O
confounders	O
that	O
partially	O
question	O
the	O
conclusions	O
drawn	O
so	O
far	O
and	O
(	O
ii	O
)	O
transformers	O
handle	O
subject	O
-	O
verb	O
and	O
object	O
-	O
past	O
participle	O
agreements	O
in	O
a	O
way	O
that	O
is	O
consistent	O
with	O
their	O
modeling	O
in	O
theoretical	Miscellaneous-term
linguistics	Miscellaneous-term
.	O

Every	O
legal	O
case	O
sets	O
a	O
precedent	Miscellaneous-term
by	O
developing	O
the	O
law	O
in	O
one	O
of	O
the	O
following	O
two	O
ways	O
.	O

It	O
either	O
expands	O
its	O
scope	O
,	O
in	O
which	O
case	O
it	O
sets	O
positive	Miscellaneous-term
precedent	Miscellaneous-term
or	O
it	O
narrows	O
it	O
,	O
in	O
which	O
case	O
it	O
sets	O
negative	Miscellaneous-term
precedent	Miscellaneous-term
.	O

Legal	O
outcome	O
prediction	O
the	O
prediction	O
of	O
positive	Miscellaneous-term
outcome	Miscellaneous-term
is	O
an	O
increasingly	O
popular	O
task	O
in	O
AI	O
.	O

In	O
contrast	O
,	O
we	O
turn	O
our	O
focus	O
to	O
negative	Miscellaneous-term
outcomes	Miscellaneous-term
here	O
,	O
and	O
introduce	O
a	O
new	O
task	O
of	O
negative	O
outcome	O
prediction	O
.	O

We	O
discover	O
an	O
asymmetry	O
in	O
existing	O
models	O
’	O
ability	O
to	O
predict	O
positive	Miscellaneous-term
and	O
negative	Miscellaneous-term
outcomes	Miscellaneous-term
.	Miscellaneous-term
.	O

Where	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
outcome	O
prediction	O
model	O
we	O
used	O
predicts	O
positive	Miscellaneous-term
outcomes	Miscellaneous-term
at	O
75	O
.	O
06	O
F1	O
it	O
predicts	O
negative	Miscellaneous-term
outcomes	Miscellaneous-term
at	O
only	O
10	O
.	O
09	O
F1	O
worse	O
than	O
a	O
random	AI/ML/DL-term
baseline	AI/ML/DL-term
.	O

Where	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
outcome	O
prediction	O
model	O
we	O
used	O
predicts	O
positive	Miscellaneous-term
outcomes	Miscellaneous-term
at	O
75	O
.	O
06	O
F1	O
it	O
predicts	O
negative	Miscellaneous-term
outcomes	Miscellaneous-term
at	O
only	O
10	O
.	O
09	O
F1	O
worse	O
than	O
a	O
random	AI/ML/DL-term
baseline	AI/ML/DL-term
.	O

To	O
address	O
this	O
performance	O
gap	O
,	O
we	O
develop	O
two	O
new	O
models	O
inspired	O
by	O
the	O
dynamics	Miscellaneous-term
of	Miscellaneous-term
a	Miscellaneous-term
court	Miscellaneous-term
process	Miscellaneous-term
.	O

Despite	O
this	O
improvement	O
,	O
shifting	O
focus	O
to	O
negative	Miscellaneous-term
outcomes	Miscellaneous-term
reveals	O
that	O
there	O
is	O
still	O
much	O
room	O
for	O
improvement	O
for	O
outcome	O
prediction	O
models	O
https	O
://	O
github	O
.	O
com	O
/	O
valvoda	O
/	O
Negative	O
-	O
Precedent	O
-	O
in	O
-	O
Legal	O
-	O
Outcome	O
-	O
Prediction	O
.	O

We	O
consider	O
how	O
to	O
effectively	O
leverage	O
minimal	AI/ML/DL-term
annotated	AI/ML/DL-term
examples	AI/ML/DL-term
in	O
new	O
languages	O
for	O
few	O
-	O
shot	O
cross	O
-	O
lingual	O
semantic	O
parsing	O
.	O

Our	O
algorithm	O
uses	O
high	NLP-term
-	NLP-term
resource	NLP-term
languages	NLP-term
to	O
train	O
the	O
parser	O
and	O
simultaneously	O
optimizes	O
for	O
cross	O
-	O
lingual	O
generalization	O
to	O
lower	NLP-term
-	NLP-term
resource	NLP-term
languages	NLP-term
.	O

Results	O
across	O
six	O
languages	O
on	O
ATIS	NLP-dataset
demonstrate	O
that	O
our	O
combination	O
of	O
generalization	O
steps	O
yields	O
accurate	O
semantic	O
parsers	O
sampling	O
≤	O
10	O
\\%	O
of	O
source	O
training	O
data	O
in	O
each	O
new	O
language	O
.	O

Our	O
approach	O
also	O
trains	O
a	O
competitive	AI/ML/DL-term
model	AI/ML/DL-term
on	O
Spider	NLP-dataset
using	O
English	O
with	O
generalization	O
to	O
Chinese	O
similarly	O
sampling	O
≤	O
10	O
\\%	O
of	O
training	O
data	O
.	O
1	O
.	O

Our	O
approach	O
also	O
trains	O
a	O
competitive	AI/ML/DL-term
model	AI/ML/DL-term
on	O
Spider	NLP-dataset
using	O
English	O
with	O
generalization	O
to	O
Chinese	O
similarly	O
sampling	O
≤	O
10	O
\\%	O
of	O
training	O
data	O
.	O
1	O
.	O

The	O
dialogue	NLP-term
state	NLP-term
consists	O
of	O
the	O
domain	O
-	O
slot	O
-	O
value	O
triples	O
which	O
are	O
regarded	O
as	O
the	O
user	O
’	O
s	O
constraints	O
to	O
search	O
the	O
domain	O
-	O
related	O
databases	O
.	O

The	O
first	O
phase	O
is	O
to	O
pretrain	O
on	O
large	NLP-term
-	NLP-term
scale	NLP-term
contextual	NLP-term
text	NLP-term
data	NLP-term
where	O
the	O
structured	O
information	O
of	O
the	O
text	O
is	O
extracted	O
by	O
the	O
information	O
extracting	O
tool	O
.	O

To	O
bridge	O
the	O
gap	O
between	O
the	O
pretraining	AI/ML/DL-term
method	O
and	O
downstream	O
tasks	O
,	O
we	O
design	O
two	O
pretraining	O
tasks	O
:	O
ontology	O
-	O
like	O
triple	O
recovery	O
and	O
next	O
-	O
text	O
generation	O
which	O
simulates	O
the	O
DST	O
and	O
RG	O
respectively	O
.	O

The	O
experimental	O
results	O
show	O
that	O
our	O
proposed	O
method	O
achieves	O
an	O
exciting	O
boost	O
and	O
obtains	O
competitive	O
performance	O
even	O
without	O
any	O
TOD	NLP-dataset
data	NLP-dataset
on	O
CamRest676	NLP-dataset
and	O
MultiWOZ	NLP-dataset
benchmarks	O
.	O

We	O
present	O
a	O
novel	O
architecture	AI/ML/DL-term
that	O
learns	O
to	O
use	O
the	O
pronunciations	O
of	O
neighboring	O
names	O
in	O
order	O
to	O
guess	O
the	O
pronunciation	O
of	O
a	O
given	O
target	O
feature	O
.	O

A	O
version	O
of	O
the	O
code	Miscellaneous-term
has	O
been	O
open	O
-	O
sourced	O
.	O
1	O
.	O

Today	O
’	O
s	O
probabilistic	O
language	O
generators	O
fall	O
short	O
when	O
it	O
comes	O
to	O
producing	O
coherent	NLP-term
and	NLP-term
fluent	NLP-term
text	NLP-term
despite	O
the	O
fact	O
that	O
the	O
underlying	O
models	O
perform	O
well	O
under	O
standard	AI/ML/DL-term
metrics	AI/ML/DL-term
(	O
e	O
.	O
g	O
.,	O
perplexity	O
.	O

Today	O
’	O
s	O
probabilistic	O
language	O
generators	O
fall	O
short	O
when	O
it	O
comes	O
to	O
producing	O
coherent	NLP-term
and	NLP-term
fluent	NLP-term
text	NLP-term
despite	O
the	O
fact	O
that	O
the	O
underlying	O
models	O
perform	O
well	O
under	O
standard	AI/ML/DL-term
metrics	AI/ML/DL-term
(	O
e	O
.	O
g	O
.,	O
perplexity	O
.	O

In	O
this	O
work	O
,	O
we	O
posit	O
that	O
the	O
abstraction	O
of	O
natural	O
language	O
generation	O
as	O
a	O
discrete	O
stochastic	O
process	O
which	O
allows	O
for	O
an	O
information	O
-	O
theoretic	O
analysis	O
can	O
provide	O
new	O
insights	O
into	O
the	O
behavior	O
of	O
probabilistic	O
language	O
generators	O
for	O
example	O
,	O
why	O
high	NLP-term
-	NLP-term
probability	NLP-term
texts	NLP-term
can	O
be	O
dull	Miscellaneous-term
or	O
repetitive	Miscellaneous-term
.	O

In	O
this	O
work	O
,	O
we	O
posit	O
that	O
the	O
abstraction	O
of	O
natural	O
language	O
generation	O
as	O
a	O
discrete	O
stochastic	O
process	O
which	O
allows	O
for	O
an	O
information	O
-	O
theoretic	O
analysis	O
can	O
provide	O
new	O
insights	O
into	O
the	O
behavior	O
of	O
probabilistic	O
language	O
generators	O
for	O
example	O
,	O
why	O
high	NLP-term
-	NLP-term
probability	NLP-term
texts	NLP-term
can	O
be	O
dull	Miscellaneous-term
or	O
repetitive	Miscellaneous-term
.	O

Humans	O
use	O
language	O
as	O
a	O
means	O
of	O
communicating	O
information	O
,	O
aiming	O
to	O
do	O
so	O
in	O
a	O
simultaneously	O
efficient	O
and	O
error	O
-	O
minimizing	O
manner	O
;	O
in	O
fact	O
,	O
psycholinguistics	Miscellaneous-term
research	Miscellaneous-term
suggests	O
humans	O
choose	O
each	O
word	O
in	O
a	O
string	O
with	O
this	O
subconscious	O
goal	O
in	O
mind	O
.	O

We	O
formally	O
define	O
the	O
set	O
of	O
strings	O
that	O
meet	O
this	O
criterion	O
:	O
Those	O
for	O
which	O
each	O
word	O
has	O
an	O
information	O
content	O
close	O
to	O
the	O
expected	NLP-term
information	NLP-term
content	NLP-term
namely	O
,	O
the	O
conditional	O
entropy	O
of	O
our	O
model	O
.	O

Nevertheless	O
,	O
its	O
potential	O
is	O
not	O
fully	O
realized	O
,	O
as	O
current	O
multilingual	NLP-term
ToD	NLP-term
datasets	NLP-term
both	O
for	O
modular	O
and	O
end	O
-	O
to	O
-	O
end	O
modeling	O
suffer	O
from	O
severe	Miscellaneous-term
limitations	Miscellaneous-term
.	O

Nevertheless	O
,	O
its	O
potential	O
is	O
not	O
fully	O
realized	O
,	O
as	O
current	O
multilingual	NLP-term
ToD	NLP-term
datasets	NLP-term
both	O
for	O
modular	O
and	O
end	O
-	O
to	O
-	O
end	O
modeling	O
suffer	O
from	O
severe	Miscellaneous-term
limitations	Miscellaneous-term
.	O

2	O
)	O
Translation	O
-	O
based	O
ToD	NLP-term
datasets	NLP-term
might	O
lack	O
naturalness	Miscellaneous-term
and	O
cultural	Miscellaneous-term
specificity	Miscellaneous-term
in	O
the	O
target	O
language	O
.	O

2	O
)	O
Translation	O
-	O
based	O
ToD	NLP-term
datasets	NLP-term
might	O
lack	O
naturalness	Miscellaneous-term
and	O
cultural	Miscellaneous-term
specificity	Miscellaneous-term
in	O
the	O
target	O
language	O
.	O

Through	O
this	O
process	O
we	O
annotate	O
a	O
new	O
large	O
-	O
scale	O
dataset	O
for	O
evaluation	O
of	O
multilingual	NLP-term
and	O
cross	NLP-term
-	NLP-term
lingual	NLP-term
ToD	O
systems	O
.	O

Our	O
Cross	NLP-dataset
-	NLP-dataset
lingual	NLP-dataset
Outline	NLP-dataset
-	NLP-dataset
based	NLP-dataset
Dialogue	NLP-dataset
dataset	NLP-dataset
(	NLP-dataset
cod	NLP-dataset
)	NLP-dataset
enables	O
natural	O
language	O
understanding	O
dialogue	O
state	O
tracking	O
and	O
end	O
-	O
to	O
-	O
end	O
dialogue	O
evaluation	O
in	O
4	O
diverse	O
languages	O
:	O
Arabic	O
,	O
Indonesian	O
,	O
Russian	O
,	O
and	O
Kiswahili	O
.	O

Qualitative	O
and	O
quantitative	O
analyses	O
of	O
cod	NLP-dataset
versus	O
an	O
equivalent	O
translation	NLP-term
-	NLP-term
based	NLP-term
dataset	NLP-term
demonstrate	O
improvements	O
in	O
data	O
quality	O
,	O
unlocked	O
by	O
the	O
outline	O
-	O
based	O
approach	O
.	O

Qualitative	O
and	O
quantitative	O
analyses	O
of	O
cod	NLP-dataset
versus	O
an	O
equivalent	O
translation	NLP-term
-	NLP-term
based	NLP-term
dataset	NLP-term
demonstrate	O
improvements	O
in	O
data	O
quality	O
,	O
unlocked	O
by	O
the	O
outline	O
-	O
based	O
approach	O
.	O

Finally	O
,	O
we	O
benchmark	O
a	O
series	O
of	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
systems	O
for	O
cross	O
-	O
lingual	O
ToD	O
setting	O
reference	O
scores	O
for	O
future	O
work	O
and	O
demonstrating	O
that	O
cod	NLP-dataset
prevents	O
over	O
-	O
inflated	O
performance	O
,	O
typically	O
met	O
with	O
prior	O
translation	O
-	O
based	O
ToD	O
datasets	O
.	O

Finally	O
,	O
we	O
benchmark	O
a	O
series	O
of	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
systems	O
for	O
cross	O
-	O
lingual	O
ToD	O
setting	O
reference	O
scores	O
for	O
future	O
work	O
and	O
demonstrating	O
that	O
cod	NLP-dataset
prevents	O
over	O
-	O
inflated	O
performance	O
,	O
typically	O
met	O
with	O
prior	O
translation	O
-	O
based	O
ToD	O
datasets	O
.	O

While	O
it	O
is	O
known	O
that	O
different	O
emotions	O
can	O
vary	O
in	O
intensity	O
within	O
a	O
song	O
,	O
annotated	Miscellaneous-term
data	Miscellaneous-term
for	O
this	O
setup	O
is	O
scarce	O
and	O
difficult	O
to	O
obtain	O
.	O

We	O
frame	O
each	O
song	O
as	O
a	O
time	O
series	O
and	O
employ	O
a	O
State	AI/ML/DL-technique
Space	AI/ML/DL-technique
Model	AI/ML/DL-technique
(	AI/ML/DL-technique
SSM	AI/ML/DL-technique
),	AI/ML/DL-technique
combining	O
a	O
sentence	O
-	O
level	O
emotion	O
predictor	O
with	O
an	O
Expectation	O
-	O
Maximization	O
(	O
EM	O
)	O
procedure	O
to	O
generate	O
the	O
full	O
emotion	O
dynamics	O
.	O

Our	O
experiments	O
show	O
that	O
applying	O
our	O
method	O
consistently	O
improves	O
the	O
performance	O
of	O
sentence	NLP-term
-	NLP-term
level	NLP-term
baselines	NLP-term
without	O
requiring	O
any	O
annotated	O
songs	O
,	O
making	O
it	O
ideal	O
for	O
limited	O
training	O
data	O
scenarios	O
.	O

We	O
investigate	O
how	O
neural	AI/ML/DL-technique
language	AI/ML/DL-technique
models	AI/ML/DL-technique
acquire	O
individual	O
words	O
during	O
training	AI/ML/DL-term
extracting	O
learning	O
curves	O
and	O
ages	O
of	O
acquisition	O
for	O
over	O
600	O
words	O
on	O
the	O
MacArthur	NLP-dataset
-	NLP-dataset
Bates	NLP-dataset
Communicative	NLP-dataset
Development	NLP-dataset
Inventory	NLP-dataset
(	O
Fenson	O
et	O
al	O
.,	O
2007	O
).	O

We	O
investigate	O
how	O
neural	AI/ML/DL-technique
language	AI/ML/DL-technique
models	AI/ML/DL-technique
acquire	O
individual	O
words	O
during	O
training	AI/ML/DL-term
extracting	O
learning	O
curves	O
and	O
ages	O
of	O
acquisition	O
for	O
over	O
600	O
words	O
on	O
the	O
MacArthur	NLP-dataset
-	NLP-dataset
Bates	NLP-dataset
Communicative	NLP-dataset
Development	NLP-dataset
Inventory	NLP-dataset
(	O
Fenson	O
et	O
al	O
.,	O
2007	O
).	O

We	O
investigate	O
how	O
neural	AI/ML/DL-technique
language	AI/ML/DL-technique
models	AI/ML/DL-technique
acquire	O
individual	O
words	O
during	O
training	AI/ML/DL-term
extracting	O
learning	O
curves	O
and	O
ages	O
of	O
acquisition	O
for	O
over	O
600	O
words	O
on	O
the	O
MacArthur	NLP-dataset
-	NLP-dataset
Bates	NLP-dataset
Communicative	NLP-dataset
Development	NLP-dataset
Inventory	NLP-dataset
(	O
Fenson	O
et	O
al	O
.,	O
2007	O
).	O

We	O
find	O
that	O
the	O
effects	O
of	O
concreteness	O
,	O
word	NLP-term
length	NLP-term
and	O
lexical	NLP-term
class	NLP-term
are	O
pointedly	O
different	O
in	O
children	O
and	O
language	O
models	O
reinforcing	O
the	O
importance	O
of	O
interaction	O
and	O
sensorimotor	O
experience	O
in	O
child	O
language	O
acquisition	O
.	O

Language	O
models	O
rely	O
far	O
more	O
on	O
word	NLP-term
frequency	NLP-term
than	O
children	O
,	O
but	O
,	O
like	O
children	O
,	O
they	O
exhibit	O
slower	O
learning	O
of	O
words	O
in	O
longer	O
utterances	O
.	O

Models	O
predict	O
based	O
on	O
unigram	NLP-term
token	NLP-term
frequencies	NLP-term
early	O
in	O
training	AI/ML/DL-term
before	O
transitioning	O
loosely	O
to	O
bigram	NLP-term
probabilities	NLP-term
eventually	O
converging	O
on	O
more	O
nuanced	O
predictions	O
.	O

Models	O
predict	O
based	O
on	O
unigram	NLP-term
token	NLP-term
frequencies	NLP-term
early	O
in	O
training	AI/ML/DL-term
before	O
transitioning	O
loosely	O
to	O
bigram	NLP-term
probabilities	NLP-term
eventually	O
converging	O
on	O
more	O
nuanced	O
predictions	O
.	O

We	O
present	O
an	O
event	O
structure	O
classification	O
empirically	O
derived	O
from	O
inferential	NLP-term
properties	NLP-term
annotated	O
on	O
sentence	NLP-term
-	NLP-term
and	O
document	NLP-term
-	NLP-term
level	NLP-term
Universal	O
Decompositional	O
Semantics	O
(	O
UDS	O
)	O
graphs	O
.	O

We	O
induce	O
this	O
classification	O
jointly	O
with	O
semantic	NLP-term
role	NLP-term
entity	NLP-term
and	O
event	NLP-term
-	NLP-term
event	NLP-term
relation	NLP-term
classifications	O
using	O
a	O
document	O
-	O
level	O
generative	O
model	O
structured	O
by	O
these	O
graphs	O
.	O

To	O
support	O
this	O
induction	O
,	O
we	O
augment	O
existing	O
annotations	O
found	O
in	O
the	O
UDS1	NLP-dataset
.	NLP-dataset
0	NLP-dataset
dataset	NLP-dataset
which	O
covers	O
the	O
entirety	O
of	O
the	O
English	NLP-dataset
Web	NLP-dataset
Treebank	NLP-dataset
with	O
an	O
array	O
of	O
inferential	O
properties	O
capturing	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
grained	AI/ML/DL-term
aspects	O
of	O
the	O
temporal	O
and	O
aspectual	O
structure	O
of	O
events	O
.	O

To	O
support	O
this	O
induction	O
,	O
we	O
augment	O
existing	O
annotations	O
found	O
in	O
the	O
UDS1	NLP-dataset
.	NLP-dataset
0	NLP-dataset
dataset	NLP-dataset
which	O
covers	O
the	O
entirety	O
of	O
the	O
English	NLP-dataset
Web	NLP-dataset
Treebank	NLP-dataset
with	O
an	O
array	O
of	O
inferential	O
properties	O
capturing	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
grained	AI/ML/DL-term
aspects	O
of	O
the	O
temporal	O
and	O
aspectual	O
structure	O
of	O
events	O
.	O

The	O
resulting	O
dataset	Miscellaneous-term
(	O
available	O
at	O
decomp	O
.	O
io	O
is	O
the	O
largest	O
annotation	O
of	O
event	O
structure	O
and	O
(	O
partial	O
)	O
event	O
coreference	O
to	O
date	O
.	O

Existing	O
table	O
question	O
answering	O
datasets	Miscellaneous-term
contain	O
abundant	O
factual	O
questions	O
that	O
primarily	O
evaluate	O
a	O
QA	O
system	O
s	O
comprehension	O
of	O
query	O
and	O
tabular	O
data	O
.	O

To	O
complement	O
the	O
existing	O
datasets	Miscellaneous-term
and	O
to	O
reveal	O
the	O
challenging	O
nature	O
of	O
the	O
table	O
-	O
based	O
question	O
answering	O
task	O
we	O
introduce	O
FeTaQA	NLP-dataset
dataset	Miscellaneous-term
ataset	O
with	O
10K	O
Wikipedia	O
-	O
based	O
table	NLP-term
question	NLP-term
ion	O
,	O
free	NLP-term
-	NLP-term
form	NLP-term
answer	NLP-term
supporting	NLP-term
table	NLP-term
cells	NLP-term
\}	O
pairs	O
.	O

To	O
complement	O
the	O
existing	O
datasets	Miscellaneous-term
and	O
to	O
reveal	O
the	O
challenging	O
nature	O
of	O
the	O
table	O
-	O
based	O
question	O
answering	O
task	O
we	O
introduce	O
FeTaQA	NLP-dataset
dataset	Miscellaneous-term
ataset	O
with	O
10K	O
Wikipedia	O
-	O
based	O
table	NLP-term
question	NLP-term
ion	O
,	O
free	NLP-term
-	NLP-term
form	NLP-term
answer	NLP-term
supporting	NLP-term
table	NLP-term
cells	NLP-term
\}	O
pairs	O
.	O

To	O
complement	O
the	O
existing	O
datasets	Miscellaneous-term
and	O
to	O
reveal	O
the	O
challenging	O
nature	O
of	O
the	O
table	O
-	O
based	O
question	O
answering	O
task	O
we	O
introduce	O
FeTaQA	NLP-dataset
dataset	Miscellaneous-term
ataset	O
with	O
10K	O
Wikipedia	O
-	O
based	O
table	NLP-term
question	NLP-term
ion	O
,	O
free	NLP-term
-	NLP-term
form	NLP-term
answer	NLP-term
supporting	NLP-term
table	NLP-term
cells	NLP-term
\}	O
pairs	O
.	O

FeTaQA	NLP-dataset
is	O
collected	O
from	O
noteworthy	O
descriptions	O
of	O
Wikipedia	O
tables	O
that	O
contain	O
information	O
people	O
tend	O
to	O
seek	O
;	O
generation	O
of	O
these	O
descriptions	O
requires	O
advanced	O
processing	O
that	O
humans	O
perform	O
on	O
a	O
daily	O
basis	O
:	O
Understand	O
the	O
question	O
and	O
table	O
,	O
retrieve	O
,	O
integrate	O
,	O
infer	O
,	O
and	O
conduct	O
text	O
planning	O
and	O
surface	O
realization	O
to	O
generate	O
an	O
answer	O
.	O

We	O
provide	O
two	O
benchmark	O
methods	O
for	O
the	O
proposed	O
task	O
:	O
a	O
pipeline	O
method	O
based	O
on	O
semantic	O
parsing	O
based	O
QA	O
systems	O
and	O
an	O
end	O
-	O
to	O
-	O
end	O
method	O
based	O
on	O
large	O
pretrained	O
text	O
generation	O
models	O
and	O
show	O
that	O
FeTaQA	NLP-dataset
poses	O
a	O
challenge	O
for	O
both	O
methods	O
.	O

With	O
the	O
success	O
of	O
large	AI/ML/DL-term
-	AI/ML/DL-term
scale	AI/ML/DL-term
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
multilingual	O
modeling	O
in	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
recent	O
years	O
have	O
seen	O
a	O
proliferation	O
of	O
large	O
,	O
Web	NLP-term
-	NLP-term
mined	NLP-term
text	NLP-term
datasets	NLP-term
covering	O
hundreds	O
of	O
languages	O
.	O

With	O
the	O
success	O
of	O
large	AI/ML/DL-term
-	AI/ML/DL-term
scale	AI/ML/DL-term
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
multilingual	O
modeling	O
in	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
recent	O
years	O
have	O
seen	O
a	O
proliferation	O
of	O
large	O
,	O
Web	NLP-term
-	NLP-term
mined	NLP-term
text	NLP-term
datasets	NLP-term
covering	O
hundreds	O
of	O
languages	O
.	O

We	O
manually	O
audit	O
the	O
quality	O
of	O
205	O
language	O
-	O
specific	O
corpora	O
released	O
with	O
five	O
major	O
public	O
datasets	O
(	O
CCAligned	NLP-dataset
ParaCrawl	NLP-dataset
WikiMatrix	NLP-dataset
OSCAR	NLP-dataset
mC4	NLP-dataset
.	O

Lower	NLP-term
-	NLP-term
resource	NLP-term
corpora	NLP-term
corpora	Miscellaneous-term
tematic	O
issues	O
:	O
At	O
least	O
15	O
corpora	O
have	O
no	O
usable	O
text	O
,	O
and	O
a	O
significant	O
fraction	O
contains	O
less	O
than	O
50	O
\\%	O
sentences	O
of	O
acceptable	O
quality	O
.	O

Lower	NLP-term
-	NLP-term
resource	NLP-term
corpora	NLP-term
corpora	Miscellaneous-term
tematic	O
issues	O
:	O
At	O
least	O
15	O
corpora	O
have	O
no	O
usable	O
text	O
,	O
and	O
a	O
significant	O
fraction	O
contains	O
less	O
than	O
50	O
\\%	O
sentences	O
of	O
acceptable	O
quality	O
.	O

In	O
addition	O
,	O
many	O
are	O
mislabeled	O
or	O
use	O
nonstandard	O
/	O
ambiguous	O
language	NLP-term
codes	NLP-term
.	O

Finally	O
,	O
we	O
recommend	O
techniques	O
to	O
evaluate	O
and	O
improve	O
multilingual	NLP-term
corpora	NLP-term
and	O
discuss	O
potential	O
risks	O
that	O
come	O
with	O
low	O
-	O
quality	O
data	O
releases	O
.	O

While	O
recent	O
tokenization	O
approaches	O
based	O
on	O
data	NLP-term
-	NLP-term
derived	NLP-term
subword	NLP-term
lexicons	NLP-term
are	O
less	O
brittle	O
than	O
manually	O
engineered	O
tokenizers	O
these	O
techniques	O
are	O
not	O
equally	O
suited	O
to	O
all	O
languages	O
,	O
and	O
the	O
use	O
of	O
any	O
fixed	O
vocabulary	NLP-term
may	O
limit	O
a	O
model	O
’	O
s	O
ability	O
to	O
adapt	O
.	O

To	O
use	O
its	O
finer	O
-	O
grained	O
input	O
effectively	O
and	O
efficiently	O
,	O
Canine	O
combines	O
downsampling	O
which	O
reduces	O
the	O
input	AI/ML/DL-term
sequence	AI/ML/DL-term
length	AI/ML/DL-term
with	O
a	O
deep	O
transformer	O
stack	O
which	O
encodes	O
context	O
.	O

Canine	O
outperforms	O
a	O
comparable	O
mBert	O
model	O
by	O
5	O
.	O
7	O
F1	O
on	O
TyDi	NLP-dataset
QA	NLP-dataset
a	O
challenging	O
multilingual	NLP-term
benchmark	NLP-term
despite	O
having	O
fewer	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

Canine	O
outperforms	O
a	O
comparable	O
mBert	O
model	O
by	O
5	O
.	O
7	O
F1	O
on	O
TyDi	NLP-dataset
QA	NLP-dataset
a	O
challenging	O
multilingual	NLP-term
benchmark	NLP-term
despite	O
having	O
fewer	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

Canine	O
outperforms	O
a	O
comparable	O
mBert	O
model	O
by	O
5	O
.	O
7	O
F1	O
on	O
TyDi	NLP-dataset
QA	NLP-dataset
a	O
challenging	O
multilingual	NLP-term
benchmark	NLP-term
despite	O
having	O
fewer	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

However	O
,	O
annotators	O
may	O
systematically	O
disagree	O
with	O
one	O
another	O
,	O
often	O
reflecting	O
their	O
individual	O
biases	O
and	O
values	O
,	O
especially	O
in	O
the	O
case	O
of	O
subjective	O
tasks	O
such	O
as	O
detecting	O
affect	Miscellaneous-term
aggression	Miscellaneous-term
and	O
hate	Miscellaneous-term
speech	Miscellaneous-term
.	O

In	O
particular	O
,	O
our	O
multi	Miscellaneous-term
-	Miscellaneous-term
task	Miscellaneous-term
based	Miscellaneous-term
approach	Miscellaneous-term
treats	O
predicting	O
each	O
annotators	O
’	O
judgements	O
as	O
separate	AI/ML/DL-term
subtasks	AI/ML/DL-term
while	O
sharing	O
a	O
common	AI/ML/DL-term
learned	AI/ML/DL-term
representation	AI/ML/DL-term
of	O
the	O
task	O
.	O

In	O
particular	O
,	O
our	O
multi	Miscellaneous-term
-	Miscellaneous-term
task	Miscellaneous-term
based	Miscellaneous-term
approach	Miscellaneous-term
treats	O
predicting	O
each	O
annotators	O
’	O
judgements	O
as	O
separate	AI/ML/DL-term
subtasks	AI/ML/DL-term
while	O
sharing	O
a	O
common	AI/ML/DL-term
learned	AI/ML/DL-term
representation	AI/ML/DL-term
of	O
the	O
task	O
.	O

We	O
show	O
that	O
this	O
approach	O
yields	O
same	O
or	O
better	O
performance	O
than	O
aggregating	O
labels	O
in	O
the	O
data	AI/ML/DL-term
prior	AI/ML/DL-term
to	O
training	O
across	O
seven	O
different	O
binary	O
classification	O
tasks	O
.	O

Recent	O
efforts	O
to	O
create	O
challenge	O
benchmarks	O
that	O
test	O
the	O
abilities	O
of	O
natural	O
language	O
understanding	O
models	O
have	O
largely	O
depended	O
on	O
human	Miscellaneous-term
annotations	Miscellaneous-term
.	O

In	O
this	O
work	O
,	O
we	O
introduce	O
the	O
“	O
Break	O
,	O
Perturb	O
,	O
Build	O
”	O
(	O
BPB	O
)	O
framework	O
for	O
automatic	O
reasoning	O
-	O
oriented	O
perturbation	O
of	O
question	NLP-term
-	NLP-term
answer	NLP-term
pairs	NLP-term
.	O

BPB	O
represents	O
a	O
question	O
by	O
decomposing	O
it	O
into	O
the	O
reasoning	O
steps	O
that	O
are	O
required	O
to	O
answer	O
it	O
,	O
symbolically	O
perturbs	O
the	O
decomposition	O
and	O
then	O
generates	O
new	O
question	NLP-term
-	NLP-term
answer	NLP-term
pairs	NLP-term
.	O

However	O
,	O
it	O
still	O
remains	O
challenging	O
to	O
utilize	O
discourse	O
parsing	O
for	O
real	Miscellaneous-term
-	Miscellaneous-term
world	Miscellaneous-term
applications	Miscellaneous-term
because	O
the	O
parsing	NLP-term
accuracy	NLP-term
degrades	O
significantly	O
on	O
out	NLP-term
-	NLP-term
of	NLP-term
-	NLP-term
domain	NLP-term
text	NLP-term
.	O

However	O
,	O
it	O
still	O
remains	O
challenging	O
to	O
utilize	O
discourse	O
parsing	O
for	O
real	Miscellaneous-term
-	Miscellaneous-term
world	Miscellaneous-term
applications	Miscellaneous-term
because	O
the	O
parsing	NLP-term
accuracy	NLP-term
degrades	O
significantly	O
on	O
out	NLP-term
-	NLP-term
of	NLP-term
-	NLP-term
domain	NLP-term
text	NLP-term
.	O

Specifically	O
,	O
we	O
investigate	O
self	O
-	O
training	O
co	O
-	O
training	O
tri	O
-	O
training	O
and	O
asymmetric	O
tri	O
-	O
training	O
of	O
graph	O
-	O
based	O
and	O
transition	O
-	O
based	O
discourse	O
dependency	O
parsing	O
models	O
,	O
as	O
well	O
as	O
confidence	O
measures	O
and	O
sample	O
selection	O
criteria	O
in	O
two	O
adaptation	O
scenarios	O
:	O
monologue	O
adaptation	O
between	O
scientific	Miscellaneous-term
disciplines	Miscellaneous-term
and	O
dialogue	O
genre	O
adaptation	O
.	O

We	O
also	O
release	O
COVID	NLP-dataset
-	NLP-dataset
19	NLP-dataset
Discourse	NLP-dataset
Dependency	NLP-dataset
Treebank	NLP-dataset
(	NLP-dataset
COVID19	NLP-dataset
-	NLP-dataset
DTB	NLP-dataset
)	NLP-dataset
a	O
new	O
manually	O
annotated	O
resource	O
for	O
discourse	O
dependency	O
parsing	O
of	O
biomedical	O
paper	O
abstracts	O
.	O

We	O
present	O
Samanantar	NLP-dataset
the	O
largest	Miscellaneous-term
publicly	Miscellaneous-term
available	Miscellaneous-term
parallel	Miscellaneous-term
corpora	Miscellaneous-term
collection	O
for	O
Indic	Miscellaneous-term
languages	Miscellaneous-term
.	O

We	O
present	O
Samanantar	NLP-dataset
the	O
largest	Miscellaneous-term
publicly	Miscellaneous-term
available	Miscellaneous-term
parallel	Miscellaneous-term
corpora	Miscellaneous-term
collection	O
for	O
Indic	Miscellaneous-term
languages	Miscellaneous-term
.	O

We	O
mine	O
the	O
parallel	O
sentences	O
from	O
the	O
Web	O
by	O
combining	O
many	O
corpora	O
,	O
tools	O
,	O
and	O
methods	O
:	O
(	O
a	O
)	O
Web	NLP-dataset
-	NLP-dataset
crawled	NLP-dataset
monolingual	NLP-dataset
corpora	NLP-dataset
(	O
b	O
)	O
document	O
OCR	O
for	O
extracting	O
sentences	O
from	O
scanned	O
documents	O
,	O
(	O
c	O
)	O
multilingual	O
representation	O
models	O
for	O
aligning	O
sentences	O
and	O
(	O
d	O
)	O
approximate	O
nearest	O
neighbor	O
search	O
for	O
searching	O
in	O
a	O
large	O
collection	O
of	O
sentences	O
.	O

Further	O
,	O
we	O
extract	O
83	O
.	O
4	O
million	O
sentence	O
pairs	O
between	O
all	O
55	O
Indic	O
language	O
pairs	O
from	O
the	O
English	O
-	O
centric	O
parallel	O
corpus	O
using	O
English	O
as	O
the	O
pivot	NLP-term
language	NLP-term
.	O

We	O
trained	O
multilingual	O
NMT	O
models	O
spanning	O
all	O
these	O
languages	O
on	O
Samanantar	NLP-dataset
which	O
outperform	O
existing	O
models	O
and	O
baselines	O
on	O
publicly	O
available	O
benchmarks	O
,	O
such	O
as	O
FLORES	NLP-dataset
Samanantar	NLP-dataset
ng	O
the	O
utility	O
of	O
Samanantar	O
.	O

Our	O
data	Miscellaneous-term
and	O
models	AI/ML/DL-term
are	O
available	O
publicly	O
at	O
Samanantar	O
and	O
we	O
hope	O
they	O
will	O
help	O
advance	O
research	O
in	O
NMT	O
and	O
multilingual	O
NLP	O
for	O
Indic	O
languages	O
.	O

Our	O
data	Miscellaneous-term
and	O
models	AI/ML/DL-term
are	O
available	O
publicly	O
at	O
Samanantar	O
and	O
we	O
hope	O
they	O
will	O
help	O
advance	O
research	O
in	O
NMT	O
and	O
multilingual	O
NLP	O
for	O
Indic	O
languages	O
.	O

In	O
this	O
work	O
,	O
we	O
revisit	O
the	O
use	O
of	O
NLI	O
for	O
inconsistency	O
detection	O
,	O
finding	O
that	O
past	O
work	O
suffered	O
from	O
a	O
mismatch	Miscellaneous-term
in	O
input	O
granularity	O
between	O
NLI	NLP-term
datasets	NLP-term
(	O
sentence	NLP-term
-	NLP-term
level	NLP-term
inconsistency	O
detection	O
ction	O
(	O
document	NLP-term
level	NLP-term
.	O

In	O
this	O
work	O
,	O
we	O
revisit	O
the	O
use	O
of	O
NLI	O
for	O
inconsistency	O
detection	O
,	O
finding	O
that	O
past	O
work	O
suffered	O
from	O
a	O
mismatch	Miscellaneous-term
in	O
input	O
granularity	O
between	O
NLI	NLP-term
datasets	NLP-term
(	O
sentence	NLP-term
-	NLP-term
level	NLP-term
inconsistency	O
detection	O
ction	O
(	O
document	NLP-term
level	NLP-term
.	O

We	O
provide	O
a	O
highly	O
effective	O
and	O
light	O
-	O
weight	O
method	O
called	O
SummaCConv	O
that	O
enables	O
NLI	O
models	O
to	O
be	O
successfully	O
used	O
for	O
this	O
task	O
by	O
segmenting	O
documents	O
into	O
sentence	NLP-term
units	NLP-term
and	O
aggregating	O
scores	O
between	O
pairs	NLP-term
of	NLP-term
sentences	NLP-term
.	O

We	O
furthermore	O
introduce	O
a	O
new	O
benchmark	O
called	O
SummaC	NLP-dataset
(	NLP-dataset
Summary	NLP-dataset
Consistency	NLP-dataset
)	NLP-dataset
which	O
consists	O
of	O
six	O
large	O
inconsistency	O
detection	O
datasets	O
.	O

On	O
this	O
dataset	O
,	O
SummaCConv	O
obtains	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
with	O
a	O
balanced	O
accuracy	O
of	O
74	O
.	O
4	O
\\%	O
a	O
5	O
\\%	O
improvement	O
compared	O
with	O
prior	O
work	O
.	O

In	O
this	O
process	O
,	O
we	O
present	O
an	O
overview	O
of	O
existing	O
datasets	Miscellaneous-term
and	O
models	AI/ML/DL-term
aiming	O
to	O
unify	O
the	O
various	O
definitions	O
given	O
and	O
identify	O
common	O
concepts	O
.	O

In	O
this	O
process	O
,	O
we	O
present	O
an	O
overview	O
of	O
existing	O
datasets	Miscellaneous-term
and	O
models	AI/ML/DL-term
aiming	O
to	O
unify	O
the	O
various	O
definitions	O
given	O
and	O
identify	O
common	O
concepts	O
.	O

This	O
paper	O
presents	O
a	O
new	O
task	O
of	O
predicting	O
the	O
coverage	O
of	O
a	O
text	O
document	O
for	O
relation	O
extraction	O
(	O
RE	O
)	O
Does	O
the	O
document	O
contain	O
many	O
relational	NLP-term
tuples	NLP-term
for	O
a	O
given	O
entity	O
?	O
Coverage	O
predictions	O
are	O
useful	O
in	O
selecting	O
the	O
best	O
documents	O
for	O
knowledge	O
base	O
construction	O
with	O
large	NLP-term
input	NLP-term
corpora	NLP-term
.	O

We	O
analyze	O
the	O
correlation	O
of	O
document	O
coverage	O
with	O
features	O
like	O
length	O
,	O
entity	NLP-term
mention	NLP-term
frequency	NLP-term
Alexa	O
rank	O
,	O
language	NLP-term
complexity	NLP-term
and	O
information	O
retrieval	O
scores	O
.	O

Pretrained	O
contextualized	O
language	O
models	O
such	O
as	O
BERT	O
and	O
T5	O
have	O
established	O
a	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
for	O
ad	O
-	O
hoc	O
search	O
.	O

We	O
present	O
a	O
new	O
comprehensive	O
framework	O
for	O
Analyzing	O
the	O
Behavior	O
of	O
Neural	O
IR	O
ModeLs	O
(	O
ABNIRML	O
)	O
which	O
includes	O
new	O
types	O
of	O
diagnostic	Miscellaneous-term
probes	Miscellaneous-term
that	O
allow	O
us	O
to	O
test	O
several	O
characteristics	O
—	O
such	O
as	O
writing	O
styles	O
factuality	O
sensitivity	O
to	O
paraphrasing	O
and	O
word	O
order	O
that	O
are	O
not	O
addressed	O
by	O
previous	O
techniques	O
.	O

To	O
demonstrate	O
the	O
value	O
of	O
the	O
framework	O
,	O
we	O
conduct	O
an	O
extensive	O
empirical	Miscellaneous-term
study	Miscellaneous-term
that	O
yields	O
insights	O
into	O
the	O
factors	O
that	O
contribute	O
to	O
the	O
neural	O
model	O
s	O
gains	O
,	O
and	O
identify	O
potential	O
unintended	O
biases	O
the	O
models	O
exhibit	O
.	O

Further	O
,	O
some	O
characteristics	O
vary	O
even	O
for	O
the	O
same	O
base	O
language	O
model	O
and	O
other	O
characteristics	O
can	O
appear	O
due	O
to	O
random	O
variations	O
during	O
model	Miscellaneous-term
training	Miscellaneous-term
1	O
.	O

The	O
model	O
samples	O
and	O
rewards	O
specific	AI/ML/DL-term
reasoning	AI/ML/DL-term
paths	AI/ML/DL-term
through	O
policy	O
gradient	O
in	O
which	O
the	O
introspective	O
revision	O
algorithm	O
modifies	O
intermediate	O
symbolic	O
reasoning	O
steps	O
to	O
discover	O
reward	O
-	O
earning	O
operations	O
as	O
well	O
as	O
leverages	O
external	O
knowledge	O
to	O
alleviate	O
spurious	O
reasoning	O
and	O
training	O
inefficiency	O
.	O

This	O
can	O
limit	O
their	O
utility	O
,	O
especially	O
in	O
the	O
closed	O
-	O
book	O
setting	O
where	O
the	O
pretraining	AI/ML/DL-term
corpus	AI/ML/DL-term
must	O
contain	O
the	O
facts	O
the	O
model	O
should	O
memorize	O
.	O

We	O
introduce	O
a	O
diagnostic	O
dataset	O
aimed	O
at	O
probing	O
LMs	O
for	O
factual	NLP-term
knowledge	NLP-term
LMs	O
changes	O
over	O
time	O
and	O
highlight	O
problems	O
with	O
LMs	O
at	O
either	O
end	O
of	O
the	O
spectrum	O
—	O
those	O
trained	O
on	O
specific	O
slices	O
of	O
temporal	AI/ML/DL-term
data	AI/ML/DL-term
temporal	AI/ML/DL-term
data	AI/ML/DL-term
ose	O
trained	O
on	O
a	O
wide	O
range	O
of	O
temporal	O
data	O
.	O

We	O
introduce	O
a	O
diagnostic	O
dataset	O
aimed	O
at	O
probing	O
LMs	O
for	O
factual	NLP-term
knowledge	NLP-term
LMs	O
changes	O
over	O
time	O
and	O
highlight	O
problems	O
with	O
LMs	O
at	O
either	O
end	O
of	O
the	O
spectrum	O
—	O
those	O
trained	O
on	O
specific	O
slices	O
of	O
temporal	AI/ML/DL-term
data	AI/ML/DL-term
temporal	AI/ML/DL-term
data	AI/ML/DL-term
ose	O
trained	O
on	O
a	O
wide	O
range	O
of	O
temporal	O
data	O
.	O

This	O
improves	O
memorization	O
of	O
seen	O
facts	O
from	O
the	O
training	AI/ML/DL-term
time	O
period	O
,	O
as	O
well	O
as	O
calibration	O
on	O
predictions	O
about	O
unseen	O
facts	O
from	O
future	O
time	O
periods	O
.	O

We	O
also	O
show	O
that	O
models	O
trained	O
with	O
temporal	AI/ML/DL-term
context	AI/ML/DL-term
can	O
be	O
efficiently	O
“	O
refreshed	O
”	O
as	O
new	O
data	O
arrives	O
,	O
without	O
the	O
need	O
for	O
retraining	O
from	O
scratch	O
.	O

For	O
a	O
mention	O
in	O
a	O
given	O
language	O
,	O
mGENRE	O
predicts	O
the	O
name	O
of	O
the	O
target	NLP-term
entity	NLP-term
left	O
-	O
to	O
-	O
right	O
,	O
token	NLP-term
-	NLP-term
by	NLP-term
-	NLP-term
token	NLP-term
in	O
an	O
autoregressive	AI/ML/DL-term
fashion	O
.	O

For	O
a	O
mention	O
in	O
a	O
given	O
language	O
,	O
mGENRE	O
predicts	O
the	O
name	O
of	O
the	O
target	NLP-term
entity	NLP-term
left	O
-	O
to	O
-	O
right	O
,	O
token	NLP-term
-	NLP-term
by	NLP-term
-	NLP-term
token	NLP-term
in	O
an	O
autoregressive	AI/ML/DL-term
fashion	O
.	O

The	O
autoregressive	AI/ML/DL-term
formulation	AI/ML/DL-term
allows	O
us	O
to	O
effectively	O
cross	O
-	O
encode	O
mention	O
string	O
and	O
entity	O
names	O
to	O
capture	O
more	O
interactions	O
than	O
the	O
standard	O
dot	O
product	O
mention	NLP-term
entity	NLP-term
and	O
entity	O
vectors	Miscellaneous-term
.	O

The	O
autoregressive	AI/ML/DL-term
formulation	AI/ML/DL-term
allows	O
us	O
to	O
effectively	O
cross	O
-	O
encode	O
mention	O
string	O
and	O
entity	O
names	O
to	O
capture	O
more	O
interactions	O
than	O
the	O
standard	O
dot	O
product	O
mention	NLP-term
entity	NLP-term
and	O
entity	O
vectors	Miscellaneous-term
.	O

The	O
autoregressive	AI/ML/DL-term
formulation	AI/ML/DL-term
allows	O
us	O
to	O
effectively	O
cross	O
-	O
encode	O
mention	O
string	O
and	O
entity	O
names	O
to	O
capture	O
more	O
interactions	O
than	O
the	O
standard	O
dot	O
product	O
mention	NLP-term
entity	NLP-term
and	O
entity	O
vectors	Miscellaneous-term
.	O

It	O
also	O
enables	O
fast	O
search	O
within	O
a	O
large	O
KB	NLP-term
even	O
for	O
mentions	O
that	O
do	O
not	O
appear	O
in	O
mention	O
tables	O
and	O
with	O
no	O
need	O
for	O
large	O
-	O
scale	O
vector	O
indices	O
.	O

While	O
prior	O
MEL	O
works	O
use	O
a	O
single	O
representation	O
for	O
each	O
entity	NLP-term
we	O
match	O
against	O
entity	NLP-term
names	NLP-term
of	O
as	O
many	O
languages	O
as	O
possible	O
,	O
which	O
allows	O
exploiting	O
language	O
connections	O
between	O
source	O
input	O
and	O
target	O
name	O
.	O

Moreover	O
,	O
in	O
a	O
zero	O
-	O
shot	O
setting	O
on	O
languages	O
with	O
no	O
training	O
data	O
at	O
all	O
,	O
mGENRE	O
treats	O
the	O
target	O
language	O
as	O
a	O
latent	AI/ML/DL-term
variable	AI/ML/DL-term
that	O
is	O
marginalized	O
at	O
prediction	O
time	O
.	O

We	O
show	O
the	O
efficacy	O
of	O
our	O
approach	O
through	O
extensive	O
evaluation	O
including	O
experiments	O
on	O
three	O
popular	O
MEL	O
benchmarks	O
where	O
we	O
establish	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
.	O

Source	O
code	Miscellaneous-term
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
facebookresearch	O
/	O
GENRE	O
.	O

Most	O
widely	O
used	O
pre	O
-	O
trained	O
language	O
models	O
operate	O
on	O
sequences	NLP-term
of	NLP-term
tokens	NLP-term
corresponding	O
to	O
word	Miscellaneous-term
or	Miscellaneous-term
subword	Miscellaneous-term
units	Miscellaneous-term
.	O

Most	O
widely	O
used	O
pre	O
-	O
trained	O
language	O
models	O
operate	O
on	O
sequences	NLP-term
of	NLP-term
tokens	NLP-term
corresponding	O
to	O
word	Miscellaneous-term
or	Miscellaneous-term
subword	Miscellaneous-term
units	Miscellaneous-term
.	O

By	O
comparison	O
,	O
token	O
-	O
free	O
models	O
that	O
operate	O
directly	O
on	O
raw	O
text	O
(	O
bytes	O
or	O
characters	O
)	O
have	O
many	O
benefits	O
:	O
They	O
can	O
process	O
text	O
in	O
any	O
language	O
out	O
of	O
the	O
box	O
,	O
they	O
are	O
more	O
robust	O
to	O
noise	O
,	O
and	O
they	O
minimize	O
technical	O
debt	O
by	O
removing	O
complex	Miscellaneous-term
and	O
error	Miscellaneous-term
-	Miscellaneous-term
prone	Miscellaneous-term
text	O
preprocessing	O
pipelines	O
.	O

Because	O
byte	NLP-term
or	O
character	NLP-term
sequences	NLP-term
are	O
longer	O
than	O
token	NLP-term
sequences	NLP-term
past	O
work	O
on	O
token	O
-	O
free	O
models	O
has	O
often	O
introduced	O
new	O
model	AI/ML/DL-term
architectures	AI/ML/DL-term
designed	O
to	O
amortize	O
the	O
cost	O
of	O
operating	O
directly	O
on	O
raw	O
text	O
.	O

Because	O
byte	NLP-term
or	O
character	NLP-term
sequences	NLP-term
are	O
longer	O
than	O
token	NLP-term
sequences	NLP-term
past	O
work	O
on	O
token	O
-	O
free	O
models	O
has	O
often	O
introduced	O
new	O
model	AI/ML/DL-term
architectures	AI/ML/DL-term
designed	O
to	O
amortize	O
the	O
cost	O
of	O
operating	O
directly	O
on	O
raw	O
text	O
.	O

In	O
this	O
paper	O
,	O
we	O
show	O
that	O
a	O
standard	O
Transformer	O
architecture	Miscellaneous-term
can	O
be	O
used	O
with	O
minimal	O
modifications	O
to	O
process	O
byte	O
sequences	O
.	O

We	O
characterize	O
the	O
trade	Miscellaneous-term
-	Miscellaneous-term
offs	Miscellaneous-term
in	O
terms	O
of	O
parameter	O
count	O
training	O
FLOPs	O
and	O
inference	O
speed	O
and	O
show	O
that	O
byte	O
-	O
level	O
models	O
are	O
competitive	O
with	O
their	O
token	O
-	O
level	O
counterparts	O
.	O

As	O
part	O
of	O
our	O
contribution	O
,	O
we	O
release	O
a	O
new	O
set	O
of	O
pre	O
-	O
trained	O
byte	O
-	O
level	O
Transformer	O
models	O
based	O
on	O
the	O
T5	O
architecture	AI/ML/DL-term
as	O
well	O
as	O
all	O
code	Miscellaneous-term
and	O
data	Miscellaneous-term
used	O
in	O
our	O
experiments	O
.	O
1	O
.	O

As	O
part	O
of	O
our	O
contribution	O
,	O
we	O
release	O
a	O
new	O
set	O
of	O
pre	O
-	O
trained	O
byte	O
-	O
level	O
Transformer	O
models	O
based	O
on	O
the	O
T5	O
architecture	AI/ML/DL-term
as	O
well	O
as	O
all	O
code	Miscellaneous-term
and	O
data	Miscellaneous-term
used	O
in	O
our	O
experiments	O
.	O
1	O
.	O

In	O
this	O
paper	O
we	O
consider	O
a	O
repeated	AI/ML/DL-technique
sender	AI/ML/DL-technique
(	AI/ML/DL-technique
expert	AI/ML/DL-technique
)	AI/ML/DL-technique
–	AI/ML/DL-technique
receiver	AI/ML/DL-technique
(	AI/ML/DL-technique
decision	AI/ML/DL-technique
maker	AI/ML/DL-technique
)	AI/ML/DL-technique
game	AI/ML/DL-technique
sender	O
the	O
sender	O
is	O
fully	O
informed	O
about	O
the	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
world	Miscellaneous-term
receiver	O
to	O
persuade	O
the	O
receiver	O
to	O
accept	O
a	O
deal	O
by	O
sending	O
one	O
of	O
several	O
possible	O
natural	NLP-term
language	NLP-term
reviews	NLP-term
.	O

In	O
this	O
paper	O
we	O
consider	O
a	O
repeated	AI/ML/DL-technique
sender	AI/ML/DL-technique
(	AI/ML/DL-technique
expert	AI/ML/DL-technique
)	AI/ML/DL-technique
–	AI/ML/DL-technique
receiver	AI/ML/DL-technique
(	AI/ML/DL-technique
decision	AI/ML/DL-technique
maker	AI/ML/DL-technique
)	AI/ML/DL-technique
game	AI/ML/DL-technique
sender	O
the	O
sender	O
is	O
fully	O
informed	O
about	O
the	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
world	Miscellaneous-term
receiver	O
to	O
persuade	O
the	O
receiver	O
to	O
accept	O
a	O
deal	O
by	O
sending	O
one	O
of	O
several	O
possible	O
natural	NLP-term
language	NLP-term
reviews	NLP-term
.	O

In	O
this	O
paper	O
we	O
consider	O
a	O
repeated	AI/ML/DL-technique
sender	AI/ML/DL-technique
(	AI/ML/DL-technique
expert	AI/ML/DL-technique
)	AI/ML/DL-technique
–	AI/ML/DL-technique
receiver	AI/ML/DL-technique
(	AI/ML/DL-technique
decision	AI/ML/DL-technique
maker	AI/ML/DL-technique
)	AI/ML/DL-technique
game	AI/ML/DL-technique
sender	O
the	O
sender	O
is	O
fully	O
informed	O
about	O
the	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
world	Miscellaneous-term
receiver	O
to	O
persuade	O
the	O
receiver	O
to	O
accept	O
a	O
deal	O
by	O
sending	O
one	O
of	O
several	O
possible	O
natural	NLP-term
language	NLP-term
reviews	NLP-term
.	O

Our	O
expert	O
is	O
implemented	O
within	O
the	O
Monte	O
Carlo	O
Tree	O
Search	O
(	O
MCTS	O
)	O
algorithm	Miscellaneous-term
with	O
deep	O
learning	O
models	O
that	O
exploit	O
behavioral	O
and	O
linguistic	O
signals	O
in	O
order	O
to	O
predict	O
the	O
next	O
action	O
of	O
the	O
decision	O
maker	O
,	O
and	O
the	O
future	O
payoff	O
of	O
the	O
expert	O
given	O
the	O
state	O
of	O
the	O
game	O
and	O
a	O
candidate	O
review	O
.	O

We	O
demonstrate	O
the	O
superiority	O
of	O
our	O
expert	O
over	O
strong	AI/ML/DL-term
baselines	AI/ML/DL-term
and	O
its	O
adaptability	O
to	O
different	O
decision	O
makers	O
and	O
potential	O
proposed	O
deals	O
.	O
1	O
.	O

We	O
derive	O
and	O
implement	O
an	O
inference	O
algorithm	O
that	O
reads	O
sentences	O
by	O
parsing	O
and	O
abducing	O
updates	O
to	O
its	O
latent	O
world	O
model	O
that	O
capture	O
the	O
semantics	O
of	O
those	O
sentences	O
,	O
and	O
evaluate	O
it	O
on	O
two	O
out	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
domain	Miscellaneous-term
question	NLP-term
-	NLP-term
answering	NLP-term
datasets	NLP-term
(	O
1	O
)	O
ProofWriter	NLP-dataset
and	O
(	O
2	O
)	O
a	O
new	O
dataset	O
we	O
call	O
FictionalGeoQA	NLP-dataset
designed	O
to	O
be	O
more	O
representative	O
of	O
real	O
language	O
but	O
still	O
simple	O
enough	O
to	O
focus	O
on	O
evaluating	O
reasoning	O
ability	O
,	O
while	O
being	O
robust	O
against	O
heuristics	O
.	O

We	O
derive	O
and	O
implement	O
an	O
inference	O
algorithm	O
that	O
reads	O
sentences	O
by	O
parsing	O
and	O
abducing	O
updates	O
to	O
its	O
latent	O
world	O
model	O
that	O
capture	O
the	O
semantics	O
of	O
those	O
sentences	O
,	O
and	O
evaluate	O
it	O
on	O
two	O
out	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
domain	Miscellaneous-term
question	NLP-term
-	NLP-term
answering	NLP-term
datasets	NLP-term
(	O
1	O
)	O
ProofWriter	NLP-dataset
and	O
(	O
2	O
)	O
a	O
new	O
dataset	O
we	O
call	O
FictionalGeoQA	NLP-dataset
designed	O
to	O
be	O
more	O
representative	O
of	O
real	O
language	O
but	O
still	O
simple	O
enough	O
to	O
focus	O
on	O
evaluating	O
reasoning	O
ability	O
,	O
while	O
being	O
robust	O
against	O
heuristics	O
.	O

We	O
derive	O
and	O
implement	O
an	O
inference	O
algorithm	O
that	O
reads	O
sentences	O
by	O
parsing	O
and	O
abducing	O
updates	O
to	O
its	O
latent	O
world	O
model	O
that	O
capture	O
the	O
semantics	O
of	O
those	O
sentences	O
,	O
and	O
evaluate	O
it	O
on	O
two	O
out	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
domain	Miscellaneous-term
question	NLP-term
-	NLP-term
answering	NLP-term
datasets	NLP-term
(	O
1	O
)	O
ProofWriter	NLP-dataset
and	O
(	O
2	O
)	O
a	O
new	O
dataset	O
we	O
call	O
FictionalGeoQA	NLP-dataset
designed	O
to	O
be	O
more	O
representative	O
of	O
real	O
language	O
but	O
still	O
simple	O
enough	O
to	O
focus	O
on	O
evaluating	O
reasoning	O
ability	O
,	O
while	O
being	O
robust	O
against	O
heuristics	O
.	O

Our	O
method	O
outperforms	O
baselines	Miscellaneous-term
on	O
both	O
,	O
thereby	O
demonstrating	O
its	O
value	O
as	O
a	O
proof	O
-	O
of	O
-	O
concept	O
.	O

In	O
existing	O
methods	O
,	O
text	O
augmentation	O
and	O
downstream	Miscellaneous-term
tasks	Miscellaneous-term
are	O
mostly	O
performed	O
separately	O
.	O

As	O
a	O
result	O
,	O
the	O
augmented	NLP-term
texts	NLP-term
may	O
not	O
be	O
optimal	O
to	O
train	O
the	O
downstream	O
model	O
.	O

To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
a	O
three	O
-	O
level	O
optimization	O
framework	O
to	O
perform	O
text	O
augmentation	O
and	O
the	O
downstream	Miscellaneous-term
task	Miscellaneous-term
end	O
-	O
to	O
-	O
end	O
.	O

The	O
augmentation	O
model	O
is	O
trained	O
in	O
a	O
way	O
tailored	O
to	O
the	O
downstream	Miscellaneous-term
task	Miscellaneous-term
.	O

A	O
text	O
summarization	O
model	O
is	O
trained	AI/ML/DL-term
to	O
perform	O
data	O
augmentation	O
at	O
the	O
first	O
stage	O
.	O

Each	O
summarization	O
example	O
is	O
associated	O
with	O
a	O
weight	AI/ML/DL-term
to	O
account	O
for	O
its	O
domain	O
difference	O
with	O
the	O
text	O
classification	O
data	O
.	O

At	O
the	O
second	O
stage	O
,	O
we	O
use	O
the	O
model	AI/ML/DL-term
trained	AI/ML/DL-term
at	O
the	O
first	O
stage	O
to	O
perform	O
text	O
augmentation	O
train	AI/ML/DL-term
ain	O
a	O
text	O
classification	O
model	O
on	O
the	O
augmented	NLP-term
texts	NLP-term
.	O

At	O
the	O
second	O
stage	O
,	O
we	O
use	O
the	O
model	AI/ML/DL-term
trained	AI/ML/DL-term
at	O
the	O
first	O
stage	O
to	O
perform	O
text	O
augmentation	O
train	AI/ML/DL-term
ain	O
a	O
text	O
classification	O
model	O
on	O
the	O
augmented	NLP-term
texts	NLP-term
.	O

At	O
the	O
third	O
stage	O
,	O
we	O
evaluate	O
the	O
text	O
classification	O
model	O
trained	AI/ML/DL-term
at	O
the	O
second	O
stage	O
and	O
update	O
weights	O
of	O
summarization	O
examples	O
by	O
minimizing	O
the	O
validation	AI/ML/DL-term
loss	AI/ML/DL-term
.	O

Code	Miscellaneous-term
is	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
Sai	O
-	O
Ashish	O
/	O
End	O
-	O
to	O
-	O
End	O
-	O
Text	O
-	O
Augmentation	O
.	O

Using	O
our	O
framework	O
,	O
we	O
compare	O
numerous	O
attribution	O
methods	O
for	O
text	O
classification	O
and	O
question	O
answering	O
and	O
observe	O
quantitative	O
differences	O
that	O
are	O
consistent	O
(	O
to	O
a	O
moderate	O
to	O
high	O
degree	O
)	O
across	O
different	O
student	AI/ML/DL-term
model	AI/ML/DL-term
architectures	AI/ML/DL-term
and	O
learning	AI/ML/DL-term
strategies	AI/ML/DL-term
1	O
.	O

Accurately	O
extracting	O
structured	O
content	O
from	O
PDFs	O
is	O
a	O
critical	O
first	O
step	O
for	O
NLP	O
over	O
scientific	Miscellaneous-term
papers	Miscellaneous-term
.	O

Recent	O
work	O
has	O
improved	O
extraction	AI/ML/DL-term
accuracy	AI/ML/DL-term
by	O
incorporating	O
elementary	O
layout	O
information	O
,	O
for	O
example	O
,	O
each	O
token	O
’	O
s	O
2D	O
position	O
on	O
the	O
page	O
,	O
into	O
language	O
model	O
pretraining	O
.	O

In	O
the	O
H	O
-	O
VILA	O
approach	O
,	O
we	O
show	O
that	O
hierarchical	O
encoding	O
of	O
layout	NLP-term
-	NLP-term
groups	NLP-term
can	O
result	O
in	O
up	O
to	O
47	O
\\%	O
inference	O
time	O
reduction	O
with	O
less	O
than	O
0	O
.	O
8	O
\\%	O
Macro	O
F1	O
loss	AI/ML/DL-term
Macro	O
F1	O
.	O

In	O
the	O
H	O
-	O
VILA	O
approach	O
,	O
we	O
show	O
that	O
hierarchical	O
encoding	O
of	O
layout	NLP-term
-	NLP-term
groups	NLP-term
can	O
result	O
in	O
up	O
to	O
47	O
\\%	O
inference	O
time	O
reduction	O
with	O
less	O
than	O
0	O
.	O
8	O
\\%	O
Macro	O
F1	O
loss	AI/ML/DL-term
Macro	O
F1	O
.	O

Unlike	O
prior	O
layout	O
-	O
aware	O
approaches	O
,	O
our	O
methods	O
do	O
not	O
require	O
expensive	O
additional	O
pretraining	AI/ML/DL-term
only	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuning	AI/ML/DL-term
which	O
we	O
show	O
can	O
reduce	O
training	O
cost	O
by	O
up	O
to	O
95	O
\\%	O
.	O

Pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
weights	AI/ML/DL-term
benchmark	AI/ML/DL-term
datasets	AI/ML/DL-term
and	O
source	Miscellaneous-term
code	Miscellaneous-term
are	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
allenai	O
/	O
VILA	O
.	O

Pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
weights	AI/ML/DL-term
benchmark	AI/ML/DL-term
datasets	AI/ML/DL-term
and	O
source	Miscellaneous-term
code	Miscellaneous-term
are	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
allenai	O
/	O
VILA	O
.	O

Common	O
designs	O
of	O
model	O
evaluation	O
typically	O
focus	O
on	O
monolingual	NLP-term
settings	NLP-term
where	O
different	O
models	AI/ML/DL-term
are	O
compared	O
according	O
to	O
their	O
performance	O
on	O
a	O
single	O
data	O
set	O
that	O
is	O
assumed	O
to	O
be	O
representative	O
of	O
all	O
possible	O
data	O
for	O
the	O
task	O
at	O
hand	O
.	O

Common	O
designs	O
of	O
model	O
evaluation	O
typically	O
focus	O
on	O
monolingual	NLP-term
settings	NLP-term
where	O
different	O
models	AI/ML/DL-term
are	O
compared	O
according	O
to	O
their	O
performance	O
on	O
a	O
single	O
data	O
set	O
that	O
is	O
assumed	O
to	O
be	O
representative	O
of	O
all	O
possible	O
data	O
for	O
the	O
task	O
at	O
hand	O
.	O

While	O
this	O
may	O
be	O
reasonable	O
for	O
a	O
large	O
data	Miscellaneous-term
set	Miscellaneous-term
this	O
assumption	O
is	O
difficult	O
to	O
maintain	O
in	O
low	O
-	O
resource	O
scenarios	O
,	O
where	O
artifacts	O
of	O
the	O
data	O
collection	O
can	O
yield	O
data	O
sets	O
that	O
are	O
outliers	AI/ML/DL-term
potentially	O
making	O
conclusions	O
about	O
model	O
performance	O
coincidental	O
.	O

While	O
this	O
may	O
be	O
reasonable	O
for	O
a	O
large	O
data	Miscellaneous-term
set	Miscellaneous-term
this	O
assumption	O
is	O
difficult	O
to	O
maintain	O
in	O
low	O
-	O
resource	O
scenarios	O
,	O
where	O
artifacts	O
of	O
the	O
data	O
collection	O
can	O
yield	O
data	O
sets	O
that	O
are	O
outliers	AI/ML/DL-term
potentially	O
making	O
conclusions	O
about	O
model	O
performance	O
coincidental	O
.	O

To	O
address	O
these	O
concerns	O
,	O
we	O
investigate	O
model	O
generalizability	O
in	O
crosslinguistic	NLP-term
low	O
-	O
resource	O
scenarios	O
.	O

Using	O
morphological	O
segmentation	O
as	O
the	O
test	O
case	O
,	O
we	O
compare	O
three	O
broad	O
classes	O
of	O
models	O
with	O
different	O
parameterizations	AI/ML/DL-term
taking	O
data	O
from	O
11	O
languages	O
across	O
6	O
language	O
families	O
.	O

In	O
each	O
experimental	O
setting	O
,	O
we	O
evaluate	O
all	O
models	O
on	O
a	O
first	O
data	Miscellaneous-term
set	Miscellaneous-term
then	O
examine	O
their	O
performance	O
consistency	O
when	O
introducing	O
new	O
randomly	O
sampled	O
data	O
sets	O
with	O
the	O
same	O
size	O
and	O
when	O
applying	O
the	O
trained	AI/ML/DL-term
models	AI/ML/DL-term
to	O
unseen	O
test	O
sets	O
of	O
varying	O
sizes	O
.	O

In	O
each	O
experimental	O
setting	O
,	O
we	O
evaluate	O
all	O
models	O
on	O
a	O
first	O
data	Miscellaneous-term
set	Miscellaneous-term
then	O
examine	O
their	O
performance	O
consistency	O
when	O
introducing	O
new	O
randomly	O
sampled	O
data	O
sets	O
with	O
the	O
same	O
size	O
and	O
when	O
applying	O
the	O
trained	AI/ML/DL-term
models	AI/ML/DL-term
to	O
unseen	O
test	O
sets	O
of	O
varying	O
sizes	O
.	O

The	O
results	O
demonstrate	O
that	O
the	O
extent	O
of	O
model	O
generalization	O
depends	O
on	O
the	O
characteristics	O
of	O
the	O
data	Miscellaneous-term
set	Miscellaneous-term
data	Miscellaneous-term
set	Miscellaneous-term
not	O
necessarily	O
rely	O
heavily	O
on	O
the	O
data	O
set	O
size	O
.	O

Among	O
the	O
characteristics	O
that	O
we	O
studied	O
,	O
the	O
ratio	O
of	O
morpheme	O
overlap	O
and	O
that	O
of	O
the	O
average	O
number	O
of	O
morphemes	O
per	O
word	O
between	O
the	O
training	AI/ML/DL-term
and	O
test	O
sets	O
are	O
the	O
two	O
most	O
prominent	O
factors	O
.	O

Our	O
findings	O
suggest	O
that	O
future	O
work	O
should	O
adopt	O
random	O
sampling	O
to	O
construct	O
data	Miscellaneous-term
sets	Miscellaneous-term
with	O
different	O
sizes	O
in	O
order	O
to	O
make	O
more	O
responsible	O
claims	O
about	O
model	O
evaluation	O
.	O

Natural	O
Language	O
Processing	O
algorithms	O
have	O
made	O
incredible	O
progress	O
,	O
but	O
they	O
still	O
struggle	O
when	O
applied	O
to	O
out	AI/ML/DL-term
-	AI/ML/DL-term
of	AI/ML/DL-term
-	AI/ML/DL-term
distribution	AI/ML/DL-term
examples	AI/ML/DL-term
.	O

We	O
address	O
a	O
challenging	O
and	O
underexplored	O
version	O
of	O
this	O
domain	O
adaptation	O
problem	O
,	O
where	O
an	O
algorithm	Miscellaneous-term
is	O
trained	O
on	O
several	O
source	O
domains	O
,	O
and	O
then	O
applied	O
to	O
examples	O
from	O
unseen	O
domains	O
that	O
are	O
unknown	O
at	O
training	Miscellaneous-term
time	O
.	O

We	O
present	O
PADA	O
An	O
example	O
-	O
based	O
autoregressive	AI/ML/DL-term
Prompt	O
learning	O
algorithm	O
for	O
on	O
-	O
the	O
-	O
fly	O
Any	O
-	O
Domain	O
Adaptation	O
based	O
on	O
the	O
T5	O
language	O
model	O
.	O

PADA	O
is	O
trained	O
to	O
generate	O
a	O
prompt	O
that	O
is	O
a	O
token	NLP-term
sequence	NLP-term
of	O
unrestricted	O
length	O
,	O
consisting	O
of	O
Domain	NLP-term
Related	NLP-term
Features	NLP-term
(	NLP-term
DRFs	NLP-term
)	NLP-term
that	O
characterize	O
each	O
of	O
the	O
source	O
domains	O
.	O

Intuitively	O
,	O
the	O
generated	AI/ML/DL-term
prompt	AI/ML/DL-term
is	O
a	O
unique	O
signature	O
that	O
maps	O
the	O
test	O
example	O
to	O
a	O
semantic	O
space	O
spanned	O
by	O
the	O
source	O
domains	O
.	O

Standard	O
multi	O
-	O
task	O
benchmarks	O
are	O
essential	O
for	O
developing	O
pretraining	O
models	O
that	O
can	O
generalize	O
to	O
various	O
downstream	Miscellaneous-term
tasks	Miscellaneous-term
.	O

Therefore	O
,	O
we	O
propose	O
a	O
story	O
-	O
centric	O
benchmark	O
named	O
LOT	NLP-dataset
for	O
evaluating	O
Chinese	O
long	O
text	O
modeling	O
which	O
aggregates	O
two	O
understanding	O
tasks	O
and	O
two	O
generation	O
tasks	O
.	O

Furthermore	O
,	O
we	O
release	O
an	O
encoder	O
-	O
decoder	O
-	O
based	O
Chinese	O
long	O
text	O
pretraining	O
model	O
named	O
LongLM	O
with	O
up	O
to	O
1	AI/ML/DL-term
billion	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

Extensive	O
experiments	O
show	O
that	O
LongLM	O
outperforms	O
similar	O
-	O
sized	O
pretraining	O
models	O
substantially	O
on	O
both	O
the	O
understanding	O
and	O
generation	O
tasks	O
in	O
LOT	NLP-dataset
.	O

We	O
introduce	O
a	O
large	O
and	O
diverse	O
Czech	O
corpus	Miscellaneous-term
annotated	O
for	O
grammatical	O
error	O
correction	O
(	O
GEC	O
)	O
with	O
the	O
aim	O
to	O
contribute	O
to	O
the	O
still	O
scarce	O
data	O
resources	O
in	O
this	O
domain	O
for	O
languages	O
other	O
than	O
English	O
.	O

The	O
Grammar	NLP-dataset
Error	NLP-dataset
Correction	NLP-dataset
Corpus	NLP-dataset
for	NLP-dataset
Czech	NLP-dataset
(	NLP-dataset
GECCC	NLP-dataset
)	NLP-dataset
offers	O
a	O
variety	O
of	O
four	O
domains	O
,	O
covering	O
error	O
distributions	O
ranging	O
from	O
high	O
error	O
density	O
essays	O
written	O
by	O
non	O
-	O
native	O
speakers	O
,	O
to	O
website	O
texts	O
,	O
where	O
errors	O
are	O
expected	O
to	O
be	O
much	O
less	O
common	O
.	O

We	O
make	O
the	O
new	O
Czech	NLP-dataset
GEC	NLP-dataset
corpus	Miscellaneous-term
publicly	O
available	O
under	O
the	O
CC	O
BY	O
-	O
SA	O
4	O
.	O
0	O
license	O
at	O
http	O
://	O
hdl	O
.	O
handle	O
.	O
net	O
/	O
11234	O
/	O
1	O
-	O
4639	O
.	O

We	O
make	O
the	O
new	O
Czech	NLP-dataset
GEC	NLP-dataset
corpus	Miscellaneous-term
publicly	O
available	O
under	O
the	O
CC	O
BY	O
-	O
SA	O
4	O
.	O
0	O
license	O
at	O
http	O
://	O
hdl	O
.	O
handle	O
.	O
net	O
/	O
11234	O
/	O
1	O
-	O
4639	O
.	O

We	O
introduce	O
TopiOCQA	NLP-dataset
(	O
pronounced	O
Tapioca	O
),	O
an	O
open	O
-	O
domain	O
conversational	O
dataset	O
with	O
topic	O
switches	O
based	O
on	O
Wikipedia	O
.	O

TopiOCQA	NLP-dataset
contains	O
3	O
,	O
920	O
conversations	O
with	O
information	O
-	O
seeking	O
questions	O
and	O
free	O
-	O
form	O
answers	O
.	O

On	O
average	O
,	O
a	O
conversation	Miscellaneous-term
in	O
our	O
dataset	O
spans	Miscellaneous-term
13	O
question	O
-	O
answer	O
turns	O
and	O
involves	O
four	O
topics	O
(	O
documents	O
)	O
.	O

TopiOCQA	NLP-dataset
poses	O
a	O
challenging	O
test	O
-	O
bed	O
for	O
models	O
,	O
where	O
efficient	O
retrieval	O
is	O
required	O
on	O
multiple	O
turns	O
of	O
the	O
same	O
conversation	O
,	O
in	O
conjunction	O
with	O
constructing	O
valid	O
responses	O
using	O
conversational	O
history	O
.	O

We	O
evaluate	O
several	O
baselines	O
,	O
by	O
combining	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
document	O
retrieval	O
methods	O
with	O
neural	O
reader	O
models	O
.	O

Our	O
dataset	Miscellaneous-term
and	O
code	Miscellaneous-term
are	O
available	O
at	O
https	O
://	O
mcgill	O
-	O
nlp	O
.	O
github	O
.	O
io	O
/	O
topiocqa	O
.	O

The	O
framework	O
is	O
based	O
on	O
a	O
nearest	AI/ML/DL-term
-	AI/ML/DL-term
neighbor	AI/ML/DL-term
architecture	AI/ML/DL-term
.	O

Our	O
framework	O
can	O
adapt	O
to	O
new	O
source	NLP-term
-	NLP-term
language	NLP-term
instances	NLP-term
without	O
the	O
need	O
to	O
be	O
retrained	O
from	O
scratch	O
.	O

Unlike	O
prior	O
work	O
on	O
neighborhood	O
-	O
based	O
approaches	O
,	O
we	O
encode	O
the	O
neighborhood	NLP-term
information	NLP-term
based	O
on	O
query	NLP-term
–	NLP-term
neighbor	NLP-term
interactions	NLP-term
.	O

On	O
average	O
,	O
we	O
achieve	O
3	O
.	O
6	O
absolute	O
F1	O
points	O
of	O
improvement	O
for	O
the	O
three	O
languages	O
in	O
the	O
Jigsaw	NLP-dataset
Multilingual	NLP-dataset
dataset	NLP-dataset
and	O
2	O
.	O
14	O
points	O
for	O
the	O
WUL	NLP-dataset
dataset	Miscellaneous-term
.	O

On	O
average	O
,	O
we	O
achieve	O
3	O
.	O
6	O
absolute	O
F1	O
points	O
of	O
improvement	O
for	O
the	O
three	O
languages	O
in	O
the	O
Jigsaw	NLP-dataset
Multilingual	NLP-dataset
dataset	NLP-dataset
and	O
2	O
.	O
14	O
points	O
for	O
the	O
WUL	NLP-dataset
dataset	Miscellaneous-term
.	O

Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
to	O
cross	O
-	O
modal	O
retrieval	O
process	O
text	NLP-term
and	O
visual	Computer/vision-term
input	Computer/vision-term
jointly	O
,	O
relying	O
on	O
Transformer	O
based	O
architectures	O
with	O
cross	O
-	O
attention	O
mechanisms	O
that	O
attend	O
over	O
all	O
words	O
and	O
objects	O
in	O
an	O
image	O
.	O

Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
to	O
cross	O
-	O
modal	O
retrieval	O
process	O
text	NLP-term
and	O
visual	Computer/vision-term
input	Computer/vision-term
jointly	O
,	O
relying	O
on	O
Transformer	O
based	O
architectures	O
with	O
cross	O
-	O
attention	O
mechanisms	O
that	O
attend	O
over	O
all	O
words	O
and	O
objects	O
in	O
an	O
image	O
.	O

The	O
framework	O
is	O
based	O
on	O
a	O
cooperative	AI/ML/DL-term
retrieve	AI/ML/DL-term
-	AI/ML/DL-term
and	AI/ML/DL-term
-	AI/ML/DL-term
rerank	AI/ML/DL-term
approach	O
that	O
combines	O
:	O
1	O
)	O
twin	O
networks	O
(	O
i	O
.	O
e	O
.,	O
a	O
bi	O
-	O
encoder	O
to	O
separately	O
encode	O
all	O
items	O
of	O
a	O
corpus	O
,	O
enabling	O
efficient	O
initial	O
retrieval	O
,	O
and	O
2	O
)	O
a	O
cross	O
-	O
encoder	O
component	O
for	O
a	O
more	O
nuanced	O
(	O
i	O
.	O
e	O
.,	O
smarter	O
)	O
ranking	O
of	O
the	O
retrieved	O
small	O
set	O
of	O
items	O
.	O

We	O
also	O
propose	O
to	O
jointly	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tune	AI/ML/DL-term
the	O
two	O
components	O
with	O
shared	O
weights	O
,	O
yielding	O
a	O
more	O
parameter	O
-	O
efficient	O
model	O
.	O

Our	O
experiments	O
on	O
a	O
series	O
of	O
standard	O
cross	O
-	O
modal	O
retrieval	O
benchmarks	O
in	O
monolingual	NLP-term
multilingual	NLP-term
and	O
zero	AI/ML/DL-term
-	AI/ML/DL-term
shot	AI/ML/DL-term
setups	O
,	O
demonstrate	O
improved	O
accuracy	O
and	O
huge	O
efficiency	O
benefits	O
over	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
cross	O
-	O
encoders	O
1	O
.	O

Our	O
experiments	O
on	O
a	O
series	O
of	O
standard	O
cross	O
-	O
modal	O
retrieval	O
benchmarks	O
in	O
monolingual	NLP-term
multilingual	NLP-term
and	O
zero	AI/ML/DL-term
-	AI/ML/DL-term
shot	AI/ML/DL-term
setups	O
,	O
demonstrate	O
improved	O
accuracy	O
and	O
huge	O
efficiency	O
benefits	O
over	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
cross	O
-	O
encoders	O
1	O
.	O

Our	O
experiments	O
on	O
a	O
series	O
of	O
standard	O
cross	O
-	O
modal	O
retrieval	O
benchmarks	O
in	O
monolingual	NLP-term
multilingual	NLP-term
and	O
zero	AI/ML/DL-term
-	AI/ML/DL-term
shot	AI/ML/DL-term
setups	O
,	O
demonstrate	O
improved	O
accuracy	O
and	O
huge	O
efficiency	O
benefits	O
over	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
cross	O
-	O
encoders	O
1	O
.	O

One	O
of	O
the	O
biggest	O
challenges	O
hindering	O
progress	O
in	O
low	AI/ML/DL-term
-	AI/ML/DL-term
resource	AI/ML/DL-term
and	O
multilingual	O
machine	O
translation	O
is	O
the	O
lack	O
of	O
good	O
evaluation	Miscellaneous-term
benchmarks	Miscellaneous-term
.	O

One	O
of	O
the	O
biggest	O
challenges	O
hindering	O
progress	O
in	O
low	AI/ML/DL-term
-	AI/ML/DL-term
resource	AI/ML/DL-term
and	O
multilingual	O
machine	O
translation	O
is	O
the	O
lack	O
of	O
good	O
evaluation	Miscellaneous-term
benchmarks	Miscellaneous-term
.	O

Current	O
evaluation	O
benchmarks	O
either	O
lack	O
good	O
coverage	O
of	O
low	NLP-term
-	NLP-term
resource	NLP-term
languages	NLP-term
consider	O
only	O
restricted	O
domains	O
,	O
or	O
are	O
low	O
quality	O
because	O
they	O
are	O
constructed	O
using	O
semi	O
-	O
automatic	O
procedures	O
.	O

In	O
this	O
work	O
,	O
we	O
introduce	O
the	O
Flores	NLP-dataset
-	NLP-dataset
101	NLP-dataset
evaluation	O
benchmark	O
,	O
consisting	O
of	O
3001	O
sentences	O
extracted	O
from	O
English	O
Wikipedia	O
and	O
covering	O
a	O
variety	O
of	O
different	O
topics	O
and	O
domains	O
.	O

The	O
resulting	O
dataset	O
enables	O
better	O
assessment	O
of	O
model	O
quality	O
on	O
the	O
long	O
tail	O
of	O
low	NLP-term
-	NLP-term
resource	NLP-term
languages	NLP-term
including	O
the	O
evaluation	O
of	O
many	O
-	O
to	O
-	O
many	O
multilingual	O
translation	O
systems	O
as	O
all	O
translations	O
are	O
fully	O
aligned	O
.	O

By	O
publicly	O
releasing	O
such	O
a	O
high	O
-	O
quality	O
and	O
high	Miscellaneous-term
-	Miscellaneous-term
coverage	Miscellaneous-term
dataset	Miscellaneous-term
we	O
hope	O
to	O
foster	O
progress	O
in	O
the	O
machine	O
translation	O
community	O
and	O
beyond	O
.	O

Multihop	O
reasoning	O
remains	O
an	O
elusive	O
goal	O
as	O
existing	O
multihop	NLP-term
benchmarks	NLP-term
are	O
known	O
to	O
be	O
largely	O
solvable	O
via	O
shortcuts	O
.	O

Can	O
we	O
create	O
a	O
question	NLP-term
answering	NLP-term
(	NLP-term
QA	NLP-term
)	NLP-term
dataset	NLP-term
that	O
,	O
by	O
construction	O
,	O
requires	O
proper	O
multihop	O
reasoning	O
To	O
this	O
end	O
,	O
we	O
introduce	O
a	O
bottom	Miscellaneous-term
–	Miscellaneous-term
up	Miscellaneous-term
approach	Miscellaneous-term
that	O
systematically	O
selects	O
composable	O
pairs	O
of	O
single	O
-	O
hop	O
questions	O
that	O
are	O
connected	O
,	O
that	O
is	O
,	O
where	O
one	O
reasoning	O
step	O
critically	O
relies	O
on	O
information	O
from	O
another	O
.	O

Can	O
we	O
create	O
a	O
question	NLP-term
answering	NLP-term
(	NLP-term
QA	NLP-term
)	NLP-term
dataset	NLP-term
that	O
,	O
by	O
construction	O
,	O
requires	O
proper	O
multihop	O
reasoning	O
To	O
this	O
end	O
,	O
we	O
introduce	O
a	O
bottom	Miscellaneous-term
–	Miscellaneous-term
up	Miscellaneous-term
approach	Miscellaneous-term
that	O
systematically	O
selects	O
composable	O
pairs	O
of	O
single	O
-	O
hop	O
questions	O
that	O
are	O
connected	O
,	O
that	O
is	O
,	O
where	O
one	O
reasoning	O
step	O
critically	O
relies	O
on	O
information	O
from	O
another	O
.	O

This	O
bottom	Miscellaneous-term
–	Miscellaneous-term
up	Miscellaneous-term
methodology	Miscellaneous-term
lets	O
us	O
explore	O
a	O
vast	O
space	O
of	O
questions	O
and	O
add	O
stringent	O
filters	O
as	O
well	O
as	O
other	O
mechanisms	O
targeting	O
connected	O
reasoning	O
.	O

It	O
provides	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
grained	AI/ML/DL-term
control	O
over	O
the	O
construction	O
process	O
and	O
the	O
properties	O
of	O
the	O
resulting	O
k	NLP-term
-	NLP-term
hop	NLP-term
questions	NLP-term
.	O

It	O
provides	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
grained	AI/ML/DL-term
control	O
over	O
the	O
construction	O
process	O
and	O
the	O
properties	O
of	O
the	O
resulting	O
k	NLP-term
-	NLP-term
hop	NLP-term
questions	NLP-term
.	O

We	O
use	O
this	O
methodology	O
to	O
create	O
MuSiQue	NLP-dataset
-	NLP-dataset
Ans	NLP-dataset
a	O
new	O
multihop	O
QA	O
dataset	O
with	O
25K	O
2	O
–	O
4	O
hop	O
questions	O
.	O

Relative	O
to	O
existing	O
datasets	O
,	O
MuSiQue	NLP-dataset
-	NLP-dataset
Ans	NLP-dataset
is	O
more	O
difficult	O
overall	O
(	O
3	O
×	O
increase	O
in	O
human	O
–	O
machine	O
gap	O
),	O
and	O
harder	O
to	O
cheat	O
via	O
disconnected	O
reasoning	O
(	O
e	O
.	O
g	O
.,	O
a	O
single	O
-	O
hop	O
model	O
has	O
a	O
30	O
-	O
point	O
drop	O
in	O
F1	O
.	O

We	O
further	O
add	O
unanswerable	O
contrast	O
questions	O
to	O
produce	O
a	O
more	O
stringent	O
dataset	O
,	O
MuSiQue	NLP-dataset
-	NLP-dataset
Full	NLP-dataset
.	O

We	O
present	O
a	O
memory	O
-	O
augmented	O
approach	O
to	O
condition	O
an	O
autoregressive	O
language	O
model	O
on	O
a	O
knowledge	NLP-term
graph	NLP-term
.	O

We	O
represent	O
the	O
graph	Miscellaneous-term
as	O
a	O
collection	O
of	O
relation	NLP-term
triples	NLP-term
and	O
retrieve	O
relevant	O
relations	O
for	O
a	O
given	O
context	O
to	O
improve	O
text	O
generation	O
.	O

We	O
represent	O
the	O
graph	Miscellaneous-term
as	O
a	O
collection	O
of	O
relation	NLP-term
triples	NLP-term
and	O
retrieve	O
relevant	O
relations	O
for	O
a	O
given	O
context	O
to	O
improve	O
text	O
generation	O
.	O

Experiments	O
on	O
WikiText	NLP-dataset
-	NLP-dataset
103	NLP-dataset
WMT19	NLP-dataset
and	O
enwik8	NLP-dataset
English	NLP-dataset
datasets	O
demonstrate	O
that	O
our	O
approach	O
produces	O
a	O
better	O
language	O
model	O
in	O
terms	O
of	O
perplexity	O
and	O
bits	O
per	O
character	O
.	O

Our	O
model	O
provides	O
a	O
simple	O
yet	O
effective	O
way	O
to	O
combine	O
an	O
autoregressive	O
language	O
model	O
and	O
a	O
knowledge	NLP-term
graph	NLP-term
for	O
more	O
coherent	O
and	O
logical	O
generation	O
.	O

Existing	O
methods	O
to	O
measure	O
sentence	O
similarity	O
are	O
faced	O
with	O
two	O
challenges	O
:	O
(	O
1	O
)	O
labeled	O
datasets	O
are	O
usually	O
limited	O
in	O
size	O
,	O
making	O
them	O
insufficient	O
to	O
train	O
supervised	O
neural	O
models	O
and	O
(	O
2	O
)	O
there	O
is	O
a	O
training	O
-	O
test	O
gap	O
for	O
unsupervised	O
language	O
modeling	O
(	O
LM	O
)	O
based	O
models	O
to	O
compute	O
semantic	NLP-term
scores	NLP-term
between	O
sentences	O
,	O
since	O
sentence	NLP-term
-	NLP-term
level	NLP-term
semantics	NLP-term
training	AI/ML/DL-term
xplicitly	O
modeled	O
at	O
training	O
.	O

Existing	O
methods	O
to	O
measure	O
sentence	O
similarity	O
are	O
faced	O
with	O
two	O
challenges	O
:	O
(	O
1	O
)	O
labeled	O
datasets	O
are	O
usually	O
limited	O
in	O
size	O
,	O
making	O
them	O
insufficient	O
to	O
train	O
supervised	O
neural	O
models	O
and	O
(	O
2	O
)	O
there	O
is	O
a	O
training	O
-	O
test	O
gap	O
for	O
unsupervised	O
language	O
modeling	O
(	O
LM	O
)	O
based	O
models	O
to	O
compute	O
semantic	NLP-term
scores	NLP-term
between	O
sentences	O
,	O
since	O
sentence	NLP-term
-	NLP-term
level	NLP-term
semantics	NLP-term
training	AI/ML/DL-term
xplicitly	O
modeled	O
at	O
training	O
.	O

The	O
proposed	O
framework	O
is	O
based	O
on	O
the	O
core	O
idea	O
that	O
the	O
meaning	O
of	O
a	O
sentence	O
should	O
be	O
defined	O
by	O
its	O
contexts	O
,	O
and	O
that	O
sentence	NLP-term
similarity	NLP-term
can	O
be	O
measured	O
by	O
comparing	O
the	O
probabilities	O
of	O
generating	O
two	O
sentences	O
given	O
the	O
same	O
context	O
.	O

The	O
proposed	O
framework	O
is	O
able	O
to	O
generate	O
high	O
-	O
quality	O
,	O
large	O
-	O
scale	O
dataset	O
with	O
semantic	NLP-term
similarity	NLP-term
scores	O
between	O
two	O
sentences	O
in	O
an	O
unsupervised	O
manner	O
,	O
with	O
which	O
the	O
train	O
-	O
test	O
gap	O
can	O
be	O
largely	O
bridged	O
.	O

Extensive	O
experiments	O
show	O
that	O
the	O
proposed	O
framework	O
achieves	O
significant	O
performance	O
boosts	O
over	O
existing	O
baselines	O
under	O
both	O
the	O
supervised	AI/ML/DL-term
and	O
unsupervised	AI/ML/DL-term
settings	O
across	O
different	O
datasets	O
.	O

Figurative	NLP-term
language	NLP-term
is	O
ubiquitous	O
in	O
English	O
.	O

Existing	O
text	O
representations	O
by	O
design	O
rely	O
on	O
compositionality	NLP-term
while	O
figurative	NLP-term
language	NLP-term
is	O
often	O
non	NLP-term
-	NLP-term
compositional	NLP-term
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
the	O
interpretation	O
of	O
two	O
non	NLP-term
-	NLP-term
compositional	NLP-term
figurative	NLP-term
languages	NLP-term
(	O
idioms	O
and	O
similes	O
).	O

We	O
then	O
trained	AI/ML/DL-term
models	AI/ML/DL-term
to	O
choose	O
or	O
generate	O
the	O
plausible	O
continuation	O
.	O

The	O
knowledge	O
-	O
enhanced	O
models	O
improve	O
the	O
performance	O
on	O
both	O
the	O
discriminative	AI/ML/DL-term
and	O
generative	AI/ML/DL-term
tasks	AI/ML/DL-term
further	O
bridging	O
the	O
gap	O
from	O
human	O
performance	O
.	O

The	O
task	O
of	O
ultra	O
-	O
fine	O
entity	O
typing	O
(	O
UFET	O
)	O
seeks	O
to	O
predict	O
diverse	O
and	O
free	O
-	O
form	O
words	O
or	O
phrases	O
that	O
describe	O
the	O
appropriate	O
types	O
of	O
entities	NLP-term
mentioned	O
in	O
sentences	O
.	O

A	O
key	O
challenge	O
for	O
this	O
task	O
lies	O
in	O
the	O
large	O
number	O
of	O
types	O
and	O
the	O
scarcity	O
of	O
annotated	AI/ML/DL-term
data	AI/ML/DL-term
per	O
type	O
.	O

This	O
causes	O
two	O
issues	O
:	O
(	O
i	O
)	O
the	O
classifiers	O
do	O
not	O
capture	O
the	O
type	O
semantics	O
because	O
types	O
are	O
often	O
converted	O
into	O
indices	O
;	O
(	O
ii	O
)	O
systems	O
developed	O
in	O
this	O
way	O
are	O
limited	O
to	O
predicting	O
within	O
a	O
pre	O
-	O
defined	O
type	O
set	O
,	O
and	O
often	O
fall	O
short	O
of	O
generalizing	O
to	O
types	O
that	O
are	O
rarely	O
seen	O
or	O
unseen	O
in	O
training	AI/ML/DL-term
This	O
work	O
presents	O
LITE	O
a	O
new	O
approach	O
that	O
formulates	O
entity	O
typing	O
as	O
a	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
problem	O
,	O
making	O
use	O
of	O
(	O
i	O
)	O
the	O
indirect	O
supervision	O
NLI	O
NLI	O
to	O
infer	O
type	O
information	O
meaningfully	O
represented	O
as	O
textual	O
hypotheses	O
and	O
alleviate	O
the	O
data	O
scarcity	O
issue	O
,	O
as	O
well	O
as	O
(	O
ii	O
)	O
a	O
learning	AI/ML/DL-term
-	AI/ML/DL-term
to	AI/ML/DL-term
-	AI/ML/DL-term
rank	AI/ML/DL-term
objective	AI/ML/DL-term
to	O
avoid	O
the	O
pre	O
-	O
defining	O
of	O
a	O
type	O
set	O
.	O

Experiments	O
show	O
that	O
,	O
with	O
limited	O
training	AI/ML/DL-term
data	AI/ML/DL-term
LITE	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
UFET	O
task	O
.	O

The	O
availability	O
of	O
large	Miscellaneous-term
-	Miscellaneous-term
scale	Miscellaneous-term
datasets	Miscellaneous-term
has	O
driven	O
the	O
development	O
of	O
neural	O
models	O
that	O
create	O
generic	O
summaries	O
for	O
single	O
or	O
multiple	O
documents	O
.	O

We	O
provide	O
a	O
unified	AI/ML/DL-term
modeling	AI/ML/DL-term
framework	AI/ML/DL-term
for	O
any	O
kind	O
of	O
summarization	O
under	O
the	O
assumption	O
that	O
all	O
summaries	O
are	O
a	O
response	O
to	O
a	O
query	NLP-term
which	O
is	O
observed	O
in	O
the	O
case	O
of	O
QFS	O
and	O
latent	O
in	O
the	O
case	O
of	O
generic	O
summarization	O
.	O

We	O
provide	O
a	O
unified	AI/ML/DL-term
modeling	AI/ML/DL-term
framework	AI/ML/DL-term
for	O
any	O
kind	O
of	O
summarization	O
under	O
the	O
assumption	O
that	O
all	O
summaries	O
are	O
a	O
response	O
to	O
a	O
query	NLP-term
which	O
is	O
observed	O
in	O
the	O
case	O
of	O
QFS	O
and	O
latent	O
in	O
the	O
case	O
of	O
generic	O
summarization	O
.	O

We	O
model	O
queries	O
as	O
discrete	AI/ML/DL-term
latent	AI/ML/DL-term
variables	AI/ML/DL-term
over	O
document	O
tokens	O
,	O
and	O
learn	O
representations	O
compatible	O
with	O
observed	O
and	O
unobserved	O
query	O
verbalizations	O
.	O

Our	O
framework	O
formulates	O
summarization	O
as	O
a	O
generative	AI/ML/DL-term
process	AI/ML/DL-term
and	O
jointly	O
optimizes	O
a	O
latent	O
query	O
model	O
and	O
a	O
conditional	O
language	O
model	O
.	O

To	O
address	O
this	O
issue	O
,	O
we	O
expand	O
the	O
training	AI/ML/DL-term
data	AI/ML/DL-term
with	O
various	O
auxiliary	O
argument	O
mining	O
corpora	Miscellaneous-term
and	O
propose	O
an	O
end	O
-	O
to	O
-	O
end	O
cross	O
-	O
corpus	O
training	O
method	O
called	O
Multi	O
-	O
Task	O
Argument	O
Mining	O
(	O
MT	O
-	O
AM	O
)	O

To	O
address	O
this	O
issue	O
,	O
we	O
expand	O
the	O
training	AI/ML/DL-term
data	AI/ML/DL-term
with	O
various	O
auxiliary	O
argument	O
mining	O
corpora	Miscellaneous-term
and	O
propose	O
an	O
end	O
-	O
to	O
-	O
end	O
cross	O
-	O
corpus	O
training	O
method	O
called	O
Multi	O
-	O
Task	O
Argument	O
Mining	O
(	O
MT	O
-	O
AM	O
)	O

Also	O
,	O
the	O
smaller	O
the	O
target	Miscellaneous-term
corpus	Miscellaneous-term
was	O
,	O
the	O
better	O
the	O
MT	O
-	O
AM	O
performed	O
.	O

Our	O
extensive	O
analyses	O
suggest	O
that	O
the	O
improvement	O
of	O
MT	O
-	O
AM	O
depends	O
on	O
several	O
factors	O
of	O
transferability	O
among	O
auxiliary	O
and	O
target	Miscellaneous-term
corpora	Miscellaneous-term
.	O

Neural	O
models	O
command	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
across	O
NLP	O
tasks	O
,	O
including	O
ones	O
involving	O
“	O
reasoning	O
”.	O

Models	O
claiming	O
to	O
reason	O
about	O
the	O
evidence	O
presented	O
to	O
them	O
should	O
attend	O
to	O
the	O
correct	O
parts	O
of	O
the	O
input	O
while	O
avoiding	O
spurious	O
patterns	O
therein	O
,	O
be	O
self	O
-	O
consistent	O
in	O
their	O
predictions	O
across	O
inputs	O
,	O
and	O
be	O
immune	O
to	O
biases	O
derived	O
from	O
their	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
in	O
a	O
nuanced	O
,	O
context	O
-	O
sensitive	O
fashion	O
.	O

Our	O
experiments	O
demonstrate	O
that	O
a	O
RoBERTa	O
-	O
based	O
model	O
representative	O
of	O
the	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
fails	O
at	O
reasoning	O
on	O
the	O
following	O
counts	O
:	O
it	O
(	O
a	O
)	O
ignores	O
relevant	O
parts	O
of	O
the	O
evidence	O
,	O
(	O
b	O
)	O
is	O
over	O
-	O
sensitive	O
to	O
annotation	O
artifacts	O
,	O
and	O
(	O
c	O
)	O
relies	O
on	O
the	O
knowledge	O
encoded	O
in	O
the	O
pre	O
-	O
trained	O
language	O
model	O
rather	O
than	O
the	O
evidence	O
presented	O
in	O
its	O
tabular	O
inputs	O
.	O

Finally	O
,	O
through	O
inoculation	O
experiments	O
,	O
we	O
show	O
that	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuning	AI/ML/DL-term
the	O
model	O
on	O
perturbed	O
data	O
does	O
not	O
help	O
it	O
overcome	O
the	O
above	O
challenges	O
.	O

While	O
recent	O
work	O
has	O
focused	O
on	O
calibration	O
of	O
classifiers	O
there	O
is	O
almost	O
no	O
work	O
in	O
NLP	O
calibration	O
on	O
in	O
a	O
regression	AI/ML/DL-term
setting	AI/ML/DL-term
.	O

We	O
further	O
apply	O
uncertainty	O
estimates	O
to	O
augment	O
training	AI/ML/DL-term
data	AI/ML/DL-term
in	O
low	O
-	O
resource	O
domains	O
.	O

Our	O
experiments	O
on	O
three	O
regression	O
tasks	O
in	O
both	O
self	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
active	AI/ML/DL-term
-	AI/ML/DL-term
learning	AI/ML/DL-term
settings	AI/ML/DL-term
show	O
that	O
uncertainty	O
estimation	O
can	O
be	O
used	O
to	O
increase	O
overall	O
performance	O
and	O
enhance	O
model	O
generalization	O
.	O

We	O
consider	O
the	O
task	O
of	O
data	O
-	O
to	O
-	O
text	O
generation	O
which	O
aims	O
to	O
create	O
textual	NLP-term
output	NLP-term
from	O
non	NLP-term
-	NLP-term
linguistic	NLP-term
input	NLP-term
.	O

Experiments	O
on	O
two	O
data	O
-	O
to	O
-	O
text	O
benchmarks	O
(	O
RotoWire	NLP-dataset
and	O
MLB	NLP-dataset
show	O
that	O
our	O
model	O
outperforms	O
strong	O
baselines	O
and	O
is	O
sample	O
-	O
efficient	O
in	O
the	O
face	O
of	O
limited	O
training	Miscellaneous-term
data	Miscellaneous-term
(	O
e	O
.	O
g	O
.,	O
a	O
few	O
hundred	O
instances	O
).	O

Experiments	O
on	O
two	O
data	O
-	O
to	O
-	O
text	O
benchmarks	O
(	O
RotoWire	NLP-dataset
and	O
MLB	NLP-dataset
show	O
that	O
our	O
model	O
outperforms	O
strong	O
baselines	O
and	O
is	O
sample	O
-	O
efficient	O
in	O
the	O
face	O
of	O
limited	O
training	Miscellaneous-term
data	Miscellaneous-term
(	O
e	O
.	O
g	O
.,	O
a	O
few	O
hundred	O
instances	O
).	O

Prompt	AI/ML/DL-term
based	O
approaches	O
excel	O
at	O
few	O
-	O
shot	O
learning	O
.	O

(	O
2021	O
)	O
recently	O
cast	O
doubt	O
on	O
their	O
performance	O
as	O
they	O
had	O
difficulty	O
getting	O
good	O
results	O
in	O
a	O
“	O
true	O
”	O
few	AI/ML/DL-term
-	AI/ML/DL-term
shot	AI/ML/DL-term
setting	AI/ML/DL-term
in	O
which	O
prompts	AI/ML/DL-term
and	O
hyperparameters	AI/ML/DL-term
cannot	O
be	O
tuned	O
on	O
a	O
dev	AI/ML/DL-term
set	AI/ML/DL-term
.	O

We	O
show	O
that	O
,	O
if	O
correctly	O
configured	O
,	O
Pet	O
performs	O
strongly	O
in	O
true	O
few	AI/ML/DL-term
-	AI/ML/DL-term
shot	AI/ML/DL-term
settings	AI/ML/DL-term
without	O
a	O
dev	AI/ML/DL-term
set	AI/ML/DL-term
.	O

We	O
put	O
our	O
findings	O
to	O
a	O
real	O
-	O
world	O
test	O
by	O
running	O
Pet	O
on	O
RAFT	NLP-dataset
a	O
benchmark	O
of	O
tasks	O
taken	O
from	O
realistic	O
NLP	O
applications	O
for	O
which	O
no	O
labeled	O
dev	AI/ML/DL-term
or	O
test	AI/ML/DL-term
sets	AI/ML/DL-term
are	O
available	O
.	O

We	O
put	O
our	O
findings	O
to	O
a	O
real	O
-	O
world	O
test	O
by	O
running	O
Pet	O
on	O
RAFT	NLP-dataset
a	O
benchmark	O
of	O
tasks	O
taken	O
from	O
realistic	O
NLP	O
applications	O
for	O
which	O
no	O
labeled	O
dev	AI/ML/DL-term
or	O
test	AI/ML/DL-term
sets	AI/ML/DL-term
are	O
available	O
.	O

Pet	O
achieves	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
RAFT	NLP-dataset
and	O
performs	O
close	O
to	O
non	O
-	O
expert	O
humans	O
for	O
7	O
out	O
of	O
11	O
tasks	O
.	O

These	O
results	O
demonstrate	O
that	O
prompt	O
-	O
based	O
learners	O
can	O
successfully	O
be	O
applied	O
in	O
true	O
few	NLP-term
-	NLP-term
shot	NLP-term
settings	NLP-term
and	O
underpin	O
our	O
belief	O
that	O
learning	O
from	O
instructions	O
will	O
play	O
an	O
important	O
role	O
on	O
the	O
path	O
towards	O
human	O
-	O
like	O
few	O
-	O
shot	O
learning	O
capabilities	O
.	O

We	O
identify	O
when	O
models	O
consider	O
the	O
remaining	O
evidence	O
(	O
in	O
)	O
sufficient	O
for	O
FC	O
based	O
on	O
three	O
trained	O
models	O
with	O
different	O
Transformer	O
FC	O
hitectures	O
and	O
three	O
FC	O
datasets	Miscellaneous-term
.	O

Second	O
,	O
we	O
ask	O
annotators	O
whether	O
the	O
omitted	O
evidence	O
was	O
important	O
for	O
FC	O
resulting	O
in	O
a	O
novel	O
diagnostic	Miscellaneous-term
dataset	Miscellaneous-term
SufficientFacts1	NLP-dataset
for	O
FC	O
with	O
omitted	O
evidence	O
.	O

Second	O
,	O
we	O
ask	O
annotators	O
whether	O
the	O
omitted	O
evidence	O
was	O
important	O
for	O
FC	O
resulting	O
in	O
a	O
novel	O
diagnostic	Miscellaneous-term
dataset	Miscellaneous-term
SufficientFacts1	NLP-dataset
for	O
FC	O
with	O
omitted	O
evidence	O
.	O

We	O
find	O
that	O
models	AI/ML/DL-term
are	O
least	O
successful	O
in	O
detecting	O
missing	O
evidence	O
when	O
adverbial	O
modifiers	O
are	O
omitted	O
(	O
21	O
\\%	O
accuracy	O
,	O
whereas	O
it	O
is	O
easiest	O
for	O
omitted	O
date	O
modifiers	O
(	O
63	O
\\%	O
accuracy	O
.	O

Understanding	O
the	O
relations	NLP-term
between	O
entities	NLP-term
denoted	O
by	O
NPs	NLP-term
in	O
a	O
text	O
is	O
a	O
critical	O
part	O
of	O
human	O
-	O
like	O
natural	O
language	O
understanding	O
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
novel	O
task	O
termed	O
t	O
ext	O
-	O
based	O
NP	O
enrichment	O
(	O
TNE	O
)	O
NP	NLP-term
which	O
we	O
aim	O
to	O
enrich	O
each	O
NP	O
in	O
a	O
text	O
with	O
all	O
the	O
preposition	O
-	O
mediated	O
relations	O
—	O
either	O
explicit	O
or	O
implicit	O
—	O
that	O
hold	O
between	O
it	O
and	O
other	O
NPs	NLP-term
in	O
the	O
text	O
.	O

The	O
relations	NLP-term
are	O
represented	O
as	O
triplets	O
each	O
denoted	O
by	O
two	O
NPs	NLP-term
related	O
via	O
a	O
preposition	O
.	O

Humans	O
recover	O
such	O
relations	O
seamlessly	O
,	O
while	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
struggle	O
with	O
them	O
due	O
to	O
the	O
implicit	O
nature	O
of	O
the	O
problem	O
.	O

We	O
build	O
the	O
first	O
large	O
-	O
scale	O
dataset	O
for	O
the	O
problem	O
,	O
provide	O
the	O
formal	NLP-term
framing	NLP-term
and	O
scope	O
of	O
annotation	O
,	O
analyze	O
the	O
data	O
,	O
and	O
report	O
the	O
results	O
of	O
fine	O
-	O
tuned	O
language	O
models	O
on	O
the	O
task	O
,	O
demonstrating	O
the	O
challenge	O
it	O
poses	O
to	O
current	O
technology	O
.	O

A	O
webpage	O
with	O
a	O
data	NLP-term
-	NLP-term
exploration	NLP-term
UI	NLP-term
a	O
demo	O
,	O
and	O
links	O
to	O
the	O
code	Miscellaneous-term
models	O
,	O
and	O
leaderboard	O
,	O
to	O
foster	O
further	O
research	O
into	O
this	O
challenging	O
problem	O
can	O
be	O
found	O
at	O
:	O
yanaiela	O
.	O
github	O
.	O
io	O
/	O
TNE	O
/	O
.	O

A	O
webpage	O
with	O
a	O
data	NLP-term
-	NLP-term
exploration	NLP-term
UI	NLP-term
a	O
demo	O
,	O
and	O
links	O
to	O
the	O
code	Miscellaneous-term
models	O
,	O
and	O
leaderboard	O
,	O
to	O
foster	O
further	O
research	O
into	O
this	O
challenging	O
problem	O
can	O
be	O
found	O
at	O
:	O
yanaiela	O
.	O
github	O
.	O
io	O
/	O
TNE	O
/	O
.	O

We	O
train	O
neural	O
networks	O
to	O
optimize	O
a	O
Minimum	O
Description	O
Length	O
score	O
,	O
that	O
is	O
,	O
to	O
balance	O
between	O
the	O
complexity	Miscellaneous-term
of	O
the	O
network	O
and	O
its	O
accuracy	O
at	O
a	O
task	O
.	O

We	O
show	O
that	O
networks	O
optimizing	O
this	O
objective	O
function	O
master	O
tasks	O
involving	O
memory	O
challenges	O
and	O
go	O
beyond	O
context	Miscellaneous-term
-	Miscellaneous-term
free	Miscellaneous-term
languages	Miscellaneous-term
.	O

We	O
show	O
that	O
UHAT	O
and	O
GUHAT	O
Transformers	O
viewed	O
as	O
string	O
acceptors	O
,	O
can	O
only	O
recognize	O
formal	Miscellaneous-term
languages	Miscellaneous-term
in	O
the	O
complexity	Miscellaneous-term
class	Miscellaneous-term
AC0	Miscellaneous-term
the	O
class	O
of	O
languages	O
recognizable	O
by	O
families	O
of	O
Boolean	O
circuits	O
of	O
constant	O
depth	O
and	O
polynomial	O
size	O
.	O

This	O
upper	O
bound	O
subsumes	O
Hahn	O
’	O
s	O
(	O
2020	O
)	O
results	O
that	O
GUHAT	O
cannot	O
recognize	O
the	O
DYCK	Miscellaneous-term
languages	O
or	O
the	O
PARITY	Miscellaneous-term
language	O
,	O
since	O
those	O
languages	O
are	O
outside	O
AC0	Miscellaneous-term
(	O
Furst	O
et	O
al	O
.,	O
1984	O
).	O

In	O
contrast	O
,	O
the	O
non	Miscellaneous-term
-	Miscellaneous-term
AC0	Miscellaneous-term
languages	O
MAJORITY	Miscellaneous-term
and	O
DYCK	Miscellaneous-term
-	Miscellaneous-term
1	Miscellaneous-term
are	O
recognizable	O
by	O
AHAT	O
AHAT	O
rks	O
,	O
implying	O
that	O
AHAT	O
can	O
recognize	O
languages	O
that	O
UHAT	O
and	O
GUHAT	O
cannot	O
.	O

Our	O
experiments	O
show	O
that	O
the	O
combination	O
of	O
a	O
neural	O
translation	O
model	O
with	O
a	O
neural	AI/ML/DL-term
reference	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
metric	AI/ML/DL-term
Bleurt	O
results	O
in	O
significant	O
improvement	O
in	O
human	O
evaluations	O
.	O

This	O
paper	O
studies	O
the	O
use	O
of	O
language	O
models	O
as	O
a	O
source	O
of	O
synthetic	NLP-term
unlabeled	NLP-term
text	NLP-term
for	O
NLP	O
.	O

We	O
formulate	O
a	O
general	O
framework	O
called	O
“	O
generate	O
,	O
annotate	O
,	O
and	O
learn	O
(	O
GAL	O
)”	O
to	O
take	O
advantage	O
of	O
synthetic	NLP-term
text	NLP-term
within	O
knowledge	O
distillation	O
self	O
-	O
training	O
and	O
few	O
-	O
shot	O
learning	O
applications	O
.	O

To	O
generate	O
high	O
-	O
quality	O
task	O
-	O
specific	O
text	O
,	O
we	O
either	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tune	AI/ML/DL-term
LMs	O
on	O
inputs	O
from	O
the	O
task	O
of	O
interest	O
,	O
or	O
prompt	AI/ML/DL-term
LMs	O
e	O
LMs	O
with	O
few	O
examples	O
.	O

We	O
use	O
the	O
best	O
available	O
classifier	O
to	O
annotate	O
synthetic	AI/ML/DL-term
text	AI/ML/DL-term
with	O
soft	AI/ML/DL-term
pseudo	AI/ML/DL-term
labels	AI/ML/DL-term
for	O
knowledge	O
distillation	O
and	O
self	O
-	O
training	O
and	O
use	O
LMs	O
to	O
obtain	O
hard	O
labels	O
for	O
few	O
-	O
shot	O
learning	O
.	O

We	O
train	O
new	O
supervised	O
models	O
on	O
the	O
combination	O
of	O
labeled	O
and	O
pseudo	AI/ML/DL-term
-	AI/ML/DL-term
labeled	AI/ML/DL-term
data	AI/ML/DL-term
which	O
results	O
in	O
significant	O
gains	O
across	O
several	O
applications	O
.	O

We	O
investigate	O
key	O
components	O
of	O
GAL	O
and	O
present	O
theoretical	Miscellaneous-term
and	O
empirical	Miscellaneous-term
arguments	O
against	O
the	O
use	O
of	O
class	O
-	O
conditional	O
LMs	O
to	O
generate	O
synthetic	AI/ML/DL-term
labeled	AI/ML/DL-term
text	AI/ML/DL-term
instead	O
of	O
unlabeled	AI/ML/DL-term
text	AI/ML/DL-term
.	O

We	O
investigate	O
key	O
components	O
of	O
GAL	O
and	O
present	O
theoretical	Miscellaneous-term
and	O
empirical	Miscellaneous-term
arguments	O
against	O
the	O
use	O
of	O
class	O
-	O
conditional	O
LMs	O
to	O
generate	O
synthetic	AI/ML/DL-term
labeled	AI/ML/DL-term
text	AI/ML/DL-term
instead	O
of	O
unlabeled	AI/ML/DL-term
text	AI/ML/DL-term
.	O

GAL	O
achieves	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
knowledge	O
distillation	O
results	O
for	O
6	O
-	O
layer	O
transformers	O
on	O
the	O
GLUE	NLP-dataset
leaderboard	O
.	O

GAL	O
achieves	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
knowledge	O
distillation	O
results	O
for	O
6	O
-	O
layer	O
transformers	O
on	O
the	O
GLUE	NLP-dataset
leaderboard	O
.	O

Transformers	O
have	O
become	O
a	O
standard	O
neural	O
network	O
architecture	O
for	O
many	O
NLP	O
problems	O
,	O
motivating	O
theoretical	O
analysis	O
of	O
their	O
power	O
in	O
terms	O
of	O
formal	Miscellaneous-term
languages	Miscellaneous-term
.	O

We	O
then	O
prove	O
saturated	O
transformers	O
with	O
floating	O
-	O
point	O
values	O
can	O
be	O
simulated	O
by	O
constant	O
-	O
depth	O
threshold	O
circuits	O
giving	O
the	O
class	O
TC0	Miscellaneous-term
as	O
an	O
upper	O
bound	O
on	O
the	O
formal	Miscellaneous-term
languages	Miscellaneous-term
they	O
recognize	O
.	O

While	O
improving	O
neural	O
dialogue	O
agents	O
factual	O
accuracy	O
neural	NLP-term
dialogue	NLP-term
much	O
research	O
,	O
another	O
important	O
aspect	O
of	O
communication	O
,	O
less	O
studied	O
in	O
the	O
setting	O
of	O
neural	O
dialogue	O
,	O
is	O
transparency	O
about	O
ignorance	O
.	O

In	O
this	O
work	O
,	O
we	O
analyze	O
to	O
what	O
extent	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
chit	O
-	O
chat	O
models	O
are	O
linguistically	NLP-term
calibrated	NLP-term
in	O
the	O
sense	O
that	O
their	O
verbalized	O
expression	O
of	O
doubt	O
(	O
or	O
confidence	O
)	O
matches	O
the	O
likelihood	O
that	O
the	O
model	O
’	O
s	O
responses	O
are	O
factually	O
incorrect	O
(	O
or	O
correct	O
).	O

In	O
this	O
work	O
,	O
we	O
analyze	O
to	O
what	O
extent	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
chit	O
-	O
chat	O
models	O
are	O
linguistically	NLP-term
calibrated	NLP-term
in	O
the	O
sense	O
that	O
their	O
verbalized	O
expression	O
of	O
doubt	O
(	O
or	O
confidence	O
)	O
matches	O
the	O
likelihood	O
that	O
the	O
model	O
’	O
s	O
responses	O
are	O
factually	O
incorrect	O
(	O
or	O
correct	O
).	O

By	O
incorporating	O
such	O
metacognitive	O
features	O
into	O
the	O
training	O
of	O
a	O
controllable	O
generation	O
model	O
we	O
obtain	O
a	O
dialogue	O
agent	O
with	O
greatly	O
improved	O
linguistic	NLP-term
calibration	NLP-term
.	O

Specifically	O
,	O
this	O
survey	O
:	O
1	O
)	O
introduces	O
the	O
challenges	O
in	O
Text	O
Game	O
Reinforcement	O
Learning	O
problems	O
,	O
2	O
)	O
outlines	O
the	O
generation	O
tools	O
for	O
rendering	O
Text	O
Games	O
and	O
the	O
subsequent	O
environments	O
generated	O
,	O
and	O
3	O
)	O
compares	O
the	O
agent	O
architectures	O
currently	O
applied	O
to	O
provide	O
a	O
systematic	O
review	O
of	O
benchmark	Miscellaneous-term
methodologies	Miscellaneous-term
and	O
opportunities	O
for	O
future	O
researchers	O
.	O

Greedy	O
algorithms	O
for	O
NLP	O
such	O
as	O
transition	O
-	O
based	O
parsing	O
are	O
prone	O
to	O
error	AI/ML/DL-term
propagation	AI/ML/DL-term
.	O

In	O
order	O
to	O
implement	O
such	O
a	O
behavior	O
,	O
we	O
use	O
reinforcement	O
learning	O
and	O
let	O
the	O
algorithm	Miscellaneous-term
backtrack	O
in	O
cases	O
where	O
such	O
an	O
action	O
gets	O
a	O
better	O
reward	O
than	O
continuing	O
to	O
explore	O
the	O
current	O
solution	O
.	O

We	O
test	O
this	O
idea	O
on	O
both	O
POS	O
tagging	O
and	O
dependency	O
parsing	O
and	O
show	O
that	O
backtracking	O
is	O
an	O
effective	O
means	O
to	O
fight	O
against	O
error	AI/ML/DL-term
propagation	AI/ML/DL-term
.	O

However	O
,	O
parsers	O
are	O
mostly	O
designed	O
for	O
and	O
evaluated	O
on	O
English	O
resources	O
,	O
such	O
as	O
CFQ	NLP-dataset
(	O
Keysers	O
et	O
al	O
.,	O
2020	O
),	O
the	O
current	O
standard	O
benchmark	O
based	O
on	O
English	O
data	O
generated	O
from	O
grammar	Miscellaneous-term
rules	Miscellaneous-term
and	O
oriented	O
towards	O
Freebase	NLP-dataset
an	O
outdated	O
knowledge	NLP-term
base	NLP-term
.	O

However	O
,	O
parsers	O
are	O
mostly	O
designed	O
for	O
and	O
evaluated	O
on	O
English	O
resources	O
,	O
such	O
as	O
CFQ	NLP-dataset
(	O
Keysers	O
et	O
al	O
.,	O
2020	O
),	O
the	O
current	O
standard	O
benchmark	O
based	O
on	O
English	O
data	O
generated	O
from	O
grammar	Miscellaneous-term
rules	Miscellaneous-term
and	O
oriented	O
towards	O
Freebase	NLP-dataset
an	O
outdated	O
knowledge	NLP-term
base	NLP-term
.	O

However	O
,	O
parsers	O
are	O
mostly	O
designed	O
for	O
and	O
evaluated	O
on	O
English	O
resources	O
,	O
such	O
as	O
CFQ	NLP-dataset
(	O
Keysers	O
et	O
al	O
.,	O
2020	O
),	O
the	O
current	O
standard	O
benchmark	O
based	O
on	O
English	O
data	O
generated	O
from	O
grammar	Miscellaneous-term
rules	Miscellaneous-term
and	O
oriented	O
towards	O
Freebase	NLP-dataset
an	O
outdated	O
knowledge	NLP-term
base	NLP-term
.	O

We	O
propose	O
a	O
method	O
for	O
creating	O
a	O
multilingual	NLP-term
parallel	O
dataset	O
of	O
question	NLP-term
-	NLP-term
query	NLP-term
pairs	NLP-term
grounded	O
in	O
Wikidata	O
.	O

We	O
introduce	O
such	O
a	O
dataset	O
,	O
which	O
we	O
call	O
Multilingual	NLP-dataset
Compositional	NLP-dataset
Wikidata	NLP-dataset
Questions	NLP-dataset
(	NLP-dataset
MCWQ	NLP-dataset
)	NLP-dataset
and	O
use	O
it	O
to	O
analyze	O
the	O
compositional	O
generalization	O
of	O
semantic	O
parsers	O
in	O
Hebrew	O
,	O
Kannada	O
,	O
Chinese	O
,	O
and	O
English	O
.	O

While	O
within	O
-	O
language	O
generalization	O
is	O
comparable	O
across	O
languages	O
,	O
experiments	O
on	O
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
transfer	O
demonstrate	O
that	O
cross	O
-	O
lingual	O
compositional	O
generalization	O
fails	O
,	O
even	O
with	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
pretrained	O
multilingual	O
encoders	O
.	O

Natural	O
language	O
understanding	O
(	O
NLU	O
)	O
has	O
made	O
massive	O
progress	O
driven	O
by	O
large	O
benchmarks	O
,	O
but	O
benchmarks	O
often	O
leave	O
a	O
long	NLP-term
tail	NLP-term
of	O
infrequent	Miscellaneous-term
phenomena	Miscellaneous-term
underrepresented	O
.	O

Natural	O
language	O
understanding	O
(	O
NLU	O
)	O
has	O
made	O
massive	O
progress	O
driven	O
by	O
large	O
benchmarks	O
,	O
but	O
benchmarks	O
often	O
leave	O
a	O
long	NLP-term
tail	NLP-term
of	O
infrequent	Miscellaneous-term
phenomena	Miscellaneous-term
underrepresented	O
.	O

We	O
reflect	O
on	O
the	O
question	O
:	O
Have	O
transfer	O
learning	O
methods	O
sufficiently	O
addressed	O
the	O
poor	O
performance	O
of	O
benchmark	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
models	AI/ML/DL-term
on	O
the	O
long	NLP-term
tail	NLP-term
long	NLP-term
tail	NLP-term
tualize	O
the	O
long	O
tail	O
using	O
macro	Miscellaneous-term
-	Miscellaneous-term
level	Miscellaneous-term
dimensions	Miscellaneous-term
(	O
underrepresented	O
genres	O
,	O
topics	O
,	O
etc	O
.),	O
and	O
perform	O
a	O
qualitative	Miscellaneous-term
meta	Miscellaneous-term
-	Miscellaneous-term
analysis	Miscellaneous-term
transfer	O
learning	O
ive	O
papers	O
on	O
transfer	O
learning	O
research	O
for	O
NLU	O
.	O

We	O
reflect	O
on	O
the	O
question	O
:	O
Have	O
transfer	O
learning	O
methods	O
sufficiently	O
addressed	O
the	O
poor	O
performance	O
of	O
benchmark	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
models	AI/ML/DL-term
on	O
the	O
long	NLP-term
tail	NLP-term
long	NLP-term
tail	NLP-term
tualize	O
the	O
long	O
tail	O
using	O
macro	Miscellaneous-term
-	Miscellaneous-term
level	Miscellaneous-term
dimensions	Miscellaneous-term
(	O
underrepresented	O
genres	O
,	O
topics	O
,	O
etc	O
.),	O
and	O
perform	O
a	O
qualitative	Miscellaneous-term
meta	Miscellaneous-term
-	Miscellaneous-term
analysis	Miscellaneous-term
transfer	O
learning	O
ive	O
papers	O
on	O
transfer	O
learning	O
research	O
for	O
NLU	O
.	O

We	O
reflect	O
on	O
the	O
question	O
:	O
Have	O
transfer	O
learning	O
methods	O
sufficiently	O
addressed	O
the	O
poor	O
performance	O
of	O
benchmark	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
models	AI/ML/DL-term
on	O
the	O
long	NLP-term
tail	NLP-term
long	NLP-term
tail	NLP-term
tualize	O
the	O
long	O
tail	O
using	O
macro	Miscellaneous-term
-	Miscellaneous-term
level	Miscellaneous-term
dimensions	Miscellaneous-term
(	O
underrepresented	O
genres	O
,	O
topics	O
,	O
etc	O
.),	O
and	O
perform	O
a	O
qualitative	Miscellaneous-term
meta	Miscellaneous-term
-	Miscellaneous-term
analysis	Miscellaneous-term
transfer	O
learning	O
ive	O
papers	O
on	O
transfer	O
learning	O
research	O
for	O
NLU	O
.	O

Our	O
analysis	O
asks	O
three	O
questions	O
:	O
(	O
i	O
)	O
Which	O
long	NLP-term
tail	NLP-term
dimensions	NLP-term
do	O
transfer	O
learning	O
long	NLP-term
tail	NLP-term
long	NLP-term
tail	NLP-term
long	NLP-term
tail	NLP-term
perties	O
of	O
adaptation	O
methods	O
help	O
improve	O
performance	O
on	O
the	O
long	O
tail	O
?	O
(	O
iii	O
)	O
Which	O
methodological	O
gaps	O
have	O
greatest	O
negative	O
impact	O
on	O
long	O
tail	O
performance	O
?	O
Our	O
answers	O
highlight	O
major	O
avenues	O
for	O
future	O
research	O
in	O
transfer	O
learning	O
for	O
the	O
long	O
tail	O
.	O

Lastly	O
,	O
using	O
our	O
meta	Miscellaneous-term
-	Miscellaneous-term
analysis	Miscellaneous-term
framework	Miscellaneous-term
we	O
perform	O
a	O
case	O
study	O
comparing	O
the	O
performance	O
of	O
various	O
adaptation	O
methods	O
on	O
clinical	O
narratives	O
,	O
which	O
provides	O
interesting	O
insights	O
that	O
may	O
enable	O
us	O
to	O
make	O
progress	O
along	O
these	O
future	O
avenues	O
.	O

Pretrained	AI/ML/DL-term
embeddings	AI/ML/DL-term
based	O
on	O
the	O
Transformer	O
architecture	O
have	O
taken	O
the	O
NLP	O
community	O
by	O
storm	O
.	O

This	O
approach	O
allows	O
us	O
to	O
draw	O
connections	O
to	O
a	O
wide	O
range	O
of	O
previous	O
studies	O
,	O
from	O
vector	NLP-term
space	NLP-term
anisotropy	NLP-term
to	O
attention	AI/ML/DL-term
weights	AI/ML/DL-term
.	O

This	O
approach	O
allows	O
us	O
to	O
draw	O
connections	O
to	O
a	O
wide	O
range	O
of	O
previous	O
studies	O
,	O
from	O
vector	NLP-term
space	NLP-term
anisotropy	NLP-term
to	O
attention	AI/ML/DL-term
weights	AI/ML/DL-term
.	O

These	O
proofs	O
consist	O
of	O
lexical	NLP-term
mutations	NLP-term
between	O
spans	NLP-term
in	O
the	O
claim	NLP-term
and	O
the	O
evidence	O
retrieved	O
,	O
each	O
marked	O
with	O
a	O
natural	O
logic	O
operator	O
.	O

Currently	O
,	O
ProoFVer	O
has	O
the	O
highest	O
label	O
accuracy	O
and	O
the	O
second	O
best	O
score	O
in	O
the	O
FEVER	NLP-dataset
leaderboard	O
.	O

Furthermore	O
,	O
it	O
improves	O
by	O
13	O
.	O
21	O
\\%	O
points	O
over	O
the	O
next	O
best	O
model	O
on	O
a	O
dataset	Miscellaneous-term
with	O
counterfactual	O
instances	O
,	O
demonstrating	O
its	O
robustness	O
.	O

As	O
explanations	O
,	O
the	O
proofs	O
show	O
better	O
overlap	O
with	O
human	O
rationales	O
than	O
attention	AI/ML/DL-term
based	O
highlights	O
and	O
the	O
proofs	O
help	O
humans	O
predict	O
model	O
decisions	O
correctly	O
more	O
often	O
than	O
using	O
the	O
evidence	O
directly	O
.	O

Popular	O
Bayesian	O
non	O
-	O
parametric	O
models	O
for	O
text	O
segmentation	O
(	O
Goldwater	O
et	O
al	O
.,	O
2006	O
,	O
2009	O
)	O
use	O
a	O
Dirichlet	O
process	O
to	O
jointly	O
segment	O
sentences	O
and	O
build	O
a	O
lexicon	NLP-term
of	O
word	O
types	O
.	O

On	O
the	O
Zero	NLP-dataset
Resource	NLP-dataset
Speech	NLP-dataset
Benchmark	NLP-dataset
2017	NLP-dataset
our	O
model	O
sets	O
a	O
new	O
speech	O
segmentation	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
in	O
5	O
languages	O
.	O

On	O
the	O
Zero	NLP-dataset
Resource	NLP-dataset
Speech	NLP-dataset
Benchmark	NLP-dataset
2017	NLP-dataset
our	O
model	O
sets	O
a	O
new	O
speech	O
segmentation	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
in	O
5	O
languages	O
.	O

The	O
algorithm	Miscellaneous-term
monotonically	O
improves	O
with	O
better	O
input	O
representations	O
,	O
achieving	O
yet	O
higher	O
scores	O
when	O
fed	O
with	O
weakly	O
supervised	O
inputs	O
.	O

Despite	O
lacking	O
a	O
type	O
lexicon	O
,	O
DP	O
-	O
Parse	O
can	O
be	O
pipelined	O
to	O
a	O
language	O
model	O
and	O
learn	O
semantic	NLP-term
and	O
syntactic	NLP-term
representations	NLP-term
as	O
assessed	O
by	O
a	O
new	O
spoken	O
word	O
embedding	O
benchmark	O
.	O

To	O
this	O
end	O
,	O
we	O
introduce	O
the	O
Benchmark	NLP-dataset
for	NLP-dataset
Evaluation	NLP-dataset
of	NLP-dataset
Grounded	NLP-dataset
INteraction	NLP-dataset
(	NLP-dataset
Begin	NLP-dataset
)	NLP-dataset
comprising	O
12k	O
dialogue	O
turns	O
generated	O
by	O
neural	O
dialogue	O
systems	O
trained	O
on	O
three	O
knowledge	NLP-term
-	NLP-term
grounded	NLP-term
dialogue	NLP-term
corpora	Miscellaneous-term
.	O

To	O
this	O
end	O
,	O
we	O
introduce	O
the	O
Benchmark	NLP-dataset
for	NLP-dataset
Evaluation	NLP-dataset
of	NLP-dataset
Grounded	NLP-dataset
INteraction	NLP-dataset
(	NLP-dataset
Begin	NLP-dataset
)	NLP-dataset
comprising	O
12k	O
dialogue	O
turns	O
generated	O
by	O
neural	O
dialogue	O
systems	O
trained	O
on	O
three	O
knowledge	NLP-term
-	NLP-term
grounded	NLP-term
dialogue	NLP-term
corpora	Miscellaneous-term
.	O

To	O
this	O
end	O
,	O
we	O
introduce	O
the	O
Benchmark	NLP-dataset
for	NLP-dataset
Evaluation	NLP-dataset
of	NLP-dataset
Grounded	NLP-dataset
INteraction	NLP-dataset
(	NLP-dataset
Begin	NLP-dataset
)	NLP-dataset
comprising	O
12k	O
dialogue	O
turns	O
generated	O
by	O
neural	O
dialogue	O
systems	O
trained	O
on	O
three	O
knowledge	NLP-term
-	NLP-term
grounded	NLP-term
dialogue	NLP-term
corpora	Miscellaneous-term
.	O

We	O
then	O
use	O
Begin	NLP-dataset
to	O
analyze	O
eight	O
evaluation	O
metrics	O
.	O

We	O
make	O
Begin	NLP-dataset
publicly	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
google	O
/	O
BEGIN	O
-	O
dataset	O
.	O

Thus	O
,	O
we	O
investigate	O
the	O
ability	O
of	O
agents	O
to	O
identify	O
non	NLP-term
-	NLP-term
cooperative	NLP-term
interlocutors	NLP-term
while	O
completing	O
a	O
concurrent	O
visual	O
-	O
dialogue	O
task	O
.	O

Within	O
this	O
novel	O
setting	O
,	O
we	O
study	O
the	O
optimality	O
of	O
communication	O
strategies	O
for	O
achieving	O
this	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
task	AI/ML/DL-term
objective	AI/ML/DL-term
.	O

This	O
paper	O
presents	O
Diff	O
-	O
Explainer	O
the	O
first	O
hybrid	Miscellaneous-term
framework	Miscellaneous-term
for	O
explainable	O
multi	O
-	O
hop	O
inference	O
that	O
integrates	O
explicit	O
constraints	O
with	O
neural	O
architectures	O
through	O
differentiable	O
convex	O
optimization	O
.	O

Specifically	O
,	O
Diff	O
-	O
Explainer	O
allows	O
for	O
the	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuning	AI/ML/DL-term
of	O
neural	AI/ML/DL-term
representations	AI/ML/DL-term
within	O
a	O
constrained	O
optimization	O
framework	O
to	O
answer	O
and	O
explain	O
multi	NLP-term
-	NLP-term
hop	NLP-term
questions	NLP-term
in	O
natural	O
language	O
.	O

Specifically	O
,	O
Diff	O
-	O
Explainer	O
allows	O
for	O
the	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuning	AI/ML/DL-term
of	O
neural	AI/ML/DL-term
representations	AI/ML/DL-term
within	O
a	O
constrained	O
optimization	O
framework	O
to	O
answer	O
and	O
explain	O
multi	NLP-term
-	NLP-term
hop	NLP-term
questions	NLP-term
in	O
natural	O
language	O
.	O

Idiomatic	NLP-term
expressions	NLP-term
(	NLP-term
IEs	NLP-term
)	NLP-term
characterized	O
by	O
their	O
non	O
-	O
compositionality	O
,	O
are	O
an	O
important	O
part	O
of	O
natural	O
language	O
.	O

They	O
have	O
been	O
a	O
classical	O
challenge	O
to	O
NLP	O
including	O
pre	O
-	O
trained	O
language	O
models	O
that	O
drive	O
today	O
’	O
s	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
.	O

In	O
this	O
work	O
,	O
we	O
take	O
a	O
first	O
-	O
principles	O
approach	O
to	O
build	O
idiomaticity	NLP-term
into	O
BART	O
using	O
an	O
adapter	O
as	O
a	O
lightweight	O
non	O
-	O
compositional	O
language	O
expert	O
trained	O
on	O
idiomatic	O
sentences	O
.	O

In	O
addition	O
,	O
we	O
explore	O
potential	O
uses	O
of	O
causal	O
inference	O
to	O
improve	O
the	O
robustness	O
,	O
fairness	O
,	O
and	O
interpretability	AI/ML/DL-term
of	O
NLP	O
models	O
.	O

We	O
present	O
a	O
novel	Miscellaneous-term
debiasing	Miscellaneous-term
technique	Miscellaneous-term
Fairness	O
-	O
aware	O
Rate	O
Maximization	O
(	O
FaRM	O
)	O
that	O
removes	O
protected	O
information	O
by	O
making	O
representations	O
of	O
instances	O
belonging	O
to	O
the	O
same	O
protected	O
attribute	O
class	O
uncorrelated	O
,	O
using	O
the	O
rate	O
-	O
distortion	O
function	O
FaRM	O

Empirical	O
evaluations	O
show	O
that	O
FaRM	O
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
on	O
several	O
datasets	Miscellaneous-term
and	O
learned	O
representations	O
leak	O
significantly	O
less	O
protected	O
attribute	O
information	O
against	O
an	O
attack	O
by	O
a	O
non	O
-	O
linear	O
probing	O
network	O
.	O

Generalizing	O
dialogue	O
state	O
tracking	O
(	O
DST	O
)	O
to	O
new	O
data	O
is	O
especially	O
challenging	O
due	O
to	O
the	O
strong	O
reliance	O
on	O
abundant	O
and	O
fine	O
-	O
grained	O
supervision	O
during	O
training	AI/ML/DL-term
.	O

In	O
this	O
paper	O
we	O
propose	O
a	O
training	AI/ML/DL-term
strategy	O
to	O
build	O
extractive	O
DST	O
models	O
without	O
the	O
need	O
for	O
fine	O
-	O
grained	O
manual	O
span	O
labels	O
.	O

We	O
propose	O
a	O
new	O
model	AI/ML/DL-term
architecture	AI/ML/DL-term
with	O
a	O
unified	O
encoder	O
that	O
supports	O
value	O
as	O
well	O
as	O
slot	O
independence	O
by	O
leveraging	O
the	O
attention	O
mechanism	O
.	O

Our	O
experiments	O
demonstrate	O
that	O
an	O
extractive	O
DST	O
model	O
can	O
be	O
trained	O
without	O
manual	O
span	NLP-term
labels	NLP-term
.	O

Our	O
architecture	O
and	O
training	AI/ML/DL-term
strategies	O
improve	O
robustness	O
towards	O
sample	O
sparsity	O
,	O
new	O
concepts	O
,	O
and	O
topics	O
,	O
leading	O
to	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
on	O
a	O
range	O
of	O
benchmarks	O
.	O

Our	O
architecture	O
and	O
training	AI/ML/DL-term
strategies	O
improve	O
robustness	O
towards	O
sample	O
sparsity	O
,	O
new	O
concepts	O
,	O
and	O
topics	O
,	O
leading	O
to	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
on	O
a	O
range	O
of	O
benchmarks	O
.	O

We	O
further	O
highlight	O
our	O
model	O
’	O
s	O
ability	O
to	O
effectively	O
learn	O
from	O
non	NLP-term
-	NLP-term
dialogue	NLP-term
data	NLP-term
.	O

Yet	O
,	O
multi	O
-	O
task	O
active	O
learning	O
(	O
MT	O
-	O
AL	O
)	O
has	O
not	O
been	O
applied	O
to	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
pre	O
-	O
trained	O
Transformer	O
-	O
based	O
NLP	O
models	O
.	O

We	O
explore	O
various	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
task	AI/ML/DL-term
multi	AI/ML/DL-term
-	AI/ML/DL-term
task	AI/ML/DL-term
riteria	O
in	O
three	O
realistic	O
multi	O
-	O
task	O
scenarios	O
,	O
reflecting	O
different	O
relations	O
between	O
the	O
participating	O
tasks	O
,	O
and	O
demonstrate	O
the	O
effectiveness	O
of	O
multi	O
-	O
task	O
compared	O
to	O
single	O
-	O
task	O
selection	O
.	O

We	O
introduce	O
the	O
task	O
of	O
microblog	O
opinion	O
summarization	O
(	O
MOS	O
)	O
and	O
share	O
a	O
dataset	Miscellaneous-term
of	O
3100	O
gold	O
-	O
standard	O
opinion	O
summaries	O
to	O
facilitate	O
research	O
in	O
this	O
domain	O
.	O

The	O
dataset	Miscellaneous-term
contains	O
summaries	O
of	O
tweets	O
spanning	O
a	O
2	O
-	O
year	O
period	O
and	O
covers	O
more	O
topics	O
than	O
any	O
other	O
public	O
Twitter	NLP-dataset
summarization	NLP-dataset
dataset	Miscellaneous-term
.	O

The	O
dataset	Miscellaneous-term
contains	O
summaries	O
of	O
tweets	O
spanning	O
a	O
2	O
-	O
year	O
period	O
and	O
covers	O
more	O
topics	O
than	O
any	O
other	O
public	O
Twitter	NLP-dataset
summarization	NLP-dataset
dataset	Miscellaneous-term
.	O

To	O
showcase	O
the	O
dataset	Miscellaneous-term
’	Miscellaneous-term
s	Miscellaneous-term
utility	O
and	O
challenges	O
,	O
we	O
benchmark	O
a	O
range	O
of	O
abstractive	O
and	O
extractive	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
summarization	O
models	O
and	O
achieve	O
good	O
performance	O
,	O
with	O
the	O
former	O
outperforming	O
the	O
latter	O
.	O

We	O
also	O
show	O
that	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuning	AI/ML/DL-term
is	O
necessary	O
to	O
improve	O
performance	O
and	O
investigate	O
the	O
benefits	O
of	O
using	O
different	O
sample	AI/ML/DL-term
sizes	AI/ML/DL-term
.	O

Finetuning	O
requires	O
modifying	O
all	O
of	O
the	O
parameters	AI/ML/DL-term
and	O
having	O
enough	O
data	O
to	O
avoid	O
overfitting	O
while	O
prompting	O
requires	O
no	O
training	O
and	O
few	O
examples	O
but	O
limits	O
performance	O
.	O

This	O
difference	O
is	O
expressed	O
in	O
terms	O
of	O
model	AI/ML/DL-term
weights	AI/ML/DL-term
and	O
sublayer	O
structure	O
through	O
our	O
proposed	O
dynamic	O
low	O
-	O
rank	O
reparameterization	O
and	O
learned	O
architecture	O
controller	O
.	O

Against	O
this	O
background	O
,	O
we	O
introduce	O
JSICK	NLP-dataset
a	O
Japanese	O
NLI	O
STS	O
dataset	Miscellaneous-term
that	O
was	O
manually	O
translated	O
from	O
the	O
English	Miscellaneous-term
dataset	Miscellaneous-term
SICK	NLP-dataset
.	O

Against	O
this	O
background	O
,	O
we	O
introduce	O
JSICK	NLP-dataset
a	O
Japanese	O
NLI	O
STS	O
dataset	Miscellaneous-term
that	O
was	O
manually	O
translated	O
from	O
the	O
English	Miscellaneous-term
dataset	Miscellaneous-term
SICK	NLP-dataset
.	O

We	O
also	O
present	O
a	O
stress	Miscellaneous-term
-	Miscellaneous-term
test	Miscellaneous-term
dataset	Miscellaneous-term
for	O
compositional	O
inference	O
,	O
created	O
by	O
transforming	O
syntactic	NLP-term
structures	NLP-term
of	O
sentences	O
in	O
JSICK	NLP-dataset
to	O
investigate	O
whether	O
language	O
models	O
are	O
sensitive	O
to	O
word	O
order	O
and	O
case	O
particles	O
.	O

We	O
also	O
present	O
a	O
stress	Miscellaneous-term
-	Miscellaneous-term
test	Miscellaneous-term
dataset	Miscellaneous-term
for	O
compositional	O
inference	O
,	O
created	O
by	O
transforming	O
syntactic	NLP-term
structures	NLP-term
of	O
sentences	O
in	O
JSICK	NLP-dataset
to	O
investigate	O
whether	O
language	O
models	O
are	O
sensitive	O
to	O
word	O
order	O
and	O
case	O
particles	O
.	O

We	O
also	O
present	O
a	O
stress	Miscellaneous-term
-	Miscellaneous-term
test	Miscellaneous-term
dataset	Miscellaneous-term
for	O
compositional	O
inference	O
,	O
created	O
by	O
transforming	O
syntactic	NLP-term
structures	NLP-term
of	O
sentences	O
in	O
JSICK	NLP-dataset
to	O
investigate	O
whether	O
language	O
models	O
are	O
sensitive	O
to	O
word	O
order	O
and	O
case	O
particles	O
.	O

The	O
results	O
of	O
the	O
stress	Miscellaneous-term
-	Miscellaneous-term
test	Miscellaneous-term
experiments	O
suggest	O
that	O
the	O
current	O
pre	O
-	O
trained	O
language	O
models	O
are	O
insensitive	O
to	O
word	O
order	O
and	O
case	O
marking	O
.	O

However	O
,	O
a	O
recent	O
branch	O
of	O
work	O
has	O
concentrated	O
on	O
interpretability	O
at	O
a	O
more	O
granular	O
level	O
of	O
analyzing	O
neurons	Miscellaneous-term
within	O
these	O
models	O
.	O

In	O
this	O
paper	O
,	O
we	O
survey	O
the	O
work	O
done	O
on	O
neuron	O
analysis	O
including	O
:	O
i	O
)	O
methods	O
to	O
discover	O
and	O
understand	O
neurons	AI/ML/DL-term
neuron	O
analysis	O
)	O
evaluation	O
methods	O
;	O
iii	O
)	O
major	O
findings	O
including	O
cross	O
architectural	O
comparisons	O
that	O
neuron	O
analysis	O
has	O
unraveled	O
;	O
iv	O
)	O
applications	O
of	O
neuron	O
probing	O
such	O
as	O
:	O
controlling	O
the	O
model	O
,	O
domain	O
adaptation	O
and	O
so	O
forth	O
;	O
and	O
v	O
)	O
a	O
discussion	O
on	O
open	O
issues	O
and	O
future	O
research	O
directions	O
.	O

Therefore	O
,	O
we	O
present	O
the	O
first	O
systematic	O
critical	O
review	O
on	O
the	O
datasets	Miscellaneous-term
approaches	O
,	O
and	O
challenges	O
in	O
this	O
field	O
.	O

Specifically	O
,	O
we	O
carefully	O
organize	O
existing	O
datasets	Miscellaneous-term
and	O
approaches	O
according	O
to	O
different	O
construction	O
methods	O
and	O
solution	O
paradigms	O
,	O
respectively	O
.	O

For	O
each	O
type	O
of	O
dataset	Miscellaneous-term
or	O
approach	O
,	O
we	O
thoroughly	O
introduce	O
and	O
summarize	O
previous	O
efforts	O
and	O
further	O
compare	O
them	O
with	O
each	O
other	O
to	O
provide	O
deeper	O
analyses	O
.	O

Contrastive	O
learning	O
learns	O
data	O
representations	O
by	O
predicting	O
whether	O
two	O
augmented	NLP-term
data	NLP-term
instances	O
are	O
generated	O
from	O
the	O
same	O
original	O
data	O
example	O
.	O

As	O
a	O
result	O
,	O
the	O
augmented	NLP-term
data	NLP-term
may	O
not	O
be	O
optimal	O
for	O
contrastive	O
learning	O
.	O

To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
a	O
four	O
-	O
level	O
optimization	O
framework	O
that	O
performs	O
data	O
augmentation	O
and	O
contrastive	O
learning	O
end	O
-	O
to	O
-	O
end	O
,	O
to	O
enable	O
the	O
augmented	NLP-term
data	NLP-term
contrastive	O
learning	O
contrastive	O
learning	O
task	O
.	O

This	O
framework	O
consists	O
of	O
four	O
learning	O
stages	O
,	O
including	O
training	O
machine	O
translation	O
models	O
for	O
sentence	O
augmentation	O
pretraining	O
a	O
text	O
encoder	O
using	O
contrastive	O
learning	O
finetuning	O
a	O
text	O
classification	O
model	O
and	O
updating	O
weights	O
of	O
translation	O
data	O
by	O
minimizing	O
the	O
validation	AI/ML/DL-term
loss	AI/ML/DL-term
classification	O
model	O
model	O
,	O
which	O
are	O
performed	O
in	O
a	O
unified	O
way	O
.	O

Experiments	O
on	O
datasets	O
in	O
the	O
GLUE	NLP-dataset
datasets	Miscellaneous-term
(	O
Wang	O
et	O
al	O
.,	O
2018a	O
)	O
and	O
on	O
datasets	O
used	O
in	O
Gururangan	O
et	O
al	O
.	O

Experiments	O
on	O
datasets	O
in	O
the	O
GLUE	NLP-dataset
datasets	Miscellaneous-term
(	O
Wang	O
et	O
al	O
.,	O
2018a	O
)	O
and	O
on	O
datasets	O
used	O
in	O
Gururangan	O
et	O
al	O
.	O

We	O
found	O
that	O
some	O
disagreements	O
are	O
due	O
to	O
uncertainty	O
in	O
the	O
sentence	O
meaning	O
,	O
others	O
to	O
annotator	O
biases	O
and	O
task	O
artifacts	O
,	O
leading	O
to	O
different	O
interpretations	O
of	O
the	O
label	NLP-term
distribution	NLP-term
.	O

We	O
explore	O
two	O
modeling	O
approaches	O
for	O
detecting	O
items	O
with	O
potential	O
disagreement	O
:	O
a	O
4	O
-	O
way	O
classification	O
with	O
a	O
“	O
Complicated	O
”	O
label	O
in	O
addition	O
to	O
the	O
three	O
standard	O
NLI	NLP-term
labels	NLP-term
and	O
a	O
multilabel	O
classification	O
approach	O
.	O

Previous	O
work	O
focused	O
on	O
tasks	O
where	O
agents	O
refer	O
to	O
a	O
single	O
entity	NLP-term
.	O

In	O
contrast	O
,	O
we	O
study	O
how	O
agents	O
predicate	O
,	O
that	O
is	O
,	O
how	O
they	O
express	O
that	O
some	O
relation	O
holds	O
between	O
several	O
entities	NLP-term
.	O

We	O
introduce	O
a	O
setup	O
where	O
agents	O
talk	O
about	O
a	O
variable	O
number	O
of	O
entities	NLP-term
that	O
can	O
be	O
partially	O
observed	O
by	O
the	O
listener	O
.	O

In	O
the	O
presence	O
of	O
a	O
least	O
-	O
effort	O
pressure	O
,	O
they	O
tend	O
to	O
discuss	O
only	O
entities	NLP-term
that	O
are	O
not	O
observed	O
by	O
the	O
listener	O
.	O

Thus	O
we	O
can	O
obtain	O
artificial	NLP-term
phrases	NLP-term
that	O
denote	O
a	O
single	O
entity	NLP-term
as	O
well	O
as	O
artificial	O
sentences	O
that	O
denote	O
several	O
entities	NLP-term
.	O

Additionally	O
,	O
we	O
find	O
that	O
the	O
recursive	O
syntactic	O
composition	O
bottleneck	O
which	O
represents	O
each	O
sentence	O
as	O
a	O
single	O
vector	O
harms	O
perplexity	O
on	O
document	O
-	O
level	O
language	O
modeling	O
providing	O
evidence	O
that	O
a	O
different	O
kind	O
of	O
memory	O
mechanism	O
—	O
one	O
that	O
is	O
independent	O
of	O
composed	O
syntactic	NLP-term
representations	NLP-term
plays	O
an	O
important	O
role	O
in	O
current	O
successful	O
models	O
of	O
long	O
text	O
.	O

In	O
contrast	O
,	O
most	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
learn	O
what	O
abuse	O
is	O
from	O
labeled	O
examples	O
and	O
as	O
a	O
result	O
base	O
their	O
predictions	O
on	O
spurious	O
cues	O
,	O
such	O
as	O
the	O
presence	O
of	O
group	O
identifiers	O
,	O
which	O
can	O
be	O
unreliable	O
.	O

We	O
propose	O
a	O
machine	O
-	O
friendly	O
representation	O
of	O
the	O
policy	O
that	O
moderators	O
wish	O
to	O
enforce	O
,	O
by	O
breaking	O
it	O
down	O
into	O
a	O
collection	O
of	O
intents	NLP-term
and	O
slots	O
.	O

However	O
,	O
a	O
closer	O
inspection	O
of	O
these	O
data	O
reveals	O
profound	O
cross	NLP-term
-	NLP-term
linguistic	NLP-term
inconsistencies	O
,	O
which	O
arise	O
from	O
the	O
lack	O
of	O
a	O
clear	O
linguistic	O
and	O
operational	O
definition	O
of	O
what	O
is	O
a	O
word	O
,	O
and	O
which	O
severely	O
impair	O
the	O
universality	O
of	O
the	O
derived	O
tasks	O
.	O

We	O
deliver	O
MightyMorph	NLP-dataset
a	O
novel	O
dataset	Miscellaneous-term
for	O
clause	O
-	O
level	O
morphology	O
covering	O
4	O
typologically	O
different	O
languages	O
:	O
English	Miscellaneous-term
German	Miscellaneous-term
Turkish	Miscellaneous-term
and	O
Hebrew	Miscellaneous-term
.	O

We	O
deliver	O
MightyMorph	NLP-dataset
a	O
novel	O
dataset	Miscellaneous-term
for	O
clause	O
-	O
level	O
morphology	O
covering	O
4	O
typologically	O
different	O
languages	O
:	O
English	Miscellaneous-term
German	Miscellaneous-term
Turkish	Miscellaneous-term
and	O
Hebrew	Miscellaneous-term
.	O

Taken	O
together	O
,	O
this	O
work	O
opens	O
up	O
new	O
horizons	O
in	O
the	O
study	O
of	O
computational	O
morphology	O
,	O
leaving	O
ample	O
space	O
for	O
studying	O
neural	O
morphology	O
cross	NLP-term
-	NLP-term
linguistically	NLP-term
.	O

The	O
goal	O
of	O
information	NLP-term
-	NLP-term
seeking	NLP-term
dialogue	NLP-term
is	O
to	O
respond	O
to	O
seeker	O
queries	O
with	O
natural	O
language	O
utterances	O
that	O
are	O
grounded	O
on	O
knowledge	O
sources	O
.	O

To	O
mitigate	O
this	O
behavior	O
,	O
we	O
adopt	O
a	O
data	O
-	O
centric	O
solution	O
and	O
create	O
FaithDial	NLP-dataset
a	O
new	O
benchmark	O
for	O
hallucination	O
-	O
free	O
dialogues	O
,	O
by	O
editing	O
hallucinated	O
responses	O
in	O
the	O
Wizard	NLP-dataset
of	NLP-dataset
Wikipedia	NLP-dataset
(	NLP-dataset
WoW	NLP-dataset
)	NLP-dataset
benchmark	O
.	O

We	O
observe	O
that	O
FaithDial	NLP-dataset
is	O
more	O
faithful	O
than	O
WoW	NLP-dataset
while	O
also	O
maintaining	O
engaging	O
conversations	O
.	O

We	O
show	O
that	O
FaithDial	NLP-dataset
can	O
serve	O
as	O
training	O
signal	O
for	O
:	O
i	O
)	O
a	O
hallucination	O
critic	O
,	O
which	O
discriminates	O
whether	O
an	O
utterance	O
is	O
faithful	O
or	O
not	O
,	O
and	O
boosts	O
the	O
performance	O
by	O
12	O
.	O
8	O
F1	O
score	O
on	O
the	O
BEGIN	NLP-dataset
benchmark	O
compared	O
to	O
existing	O
datasets	O
for	O
dialogue	O
coherence	O
;	O
ii	O
)	O
high	O
-	O
quality	O
dialogue	O
generation	O
.	O

We	O
benchmark	O
a	O
series	O
of	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
and	O
propose	O
an	O
auxiliary	O
contrastive	O
objective	O
that	O
achieves	O
the	O
highest	O
level	O
of	O
faithfulness	O
and	O
abstractiveness	O
based	O
on	O
several	O
automated	O
metrics	O
.	O

Further	O
,	O
we	O
find	O
that	O
the	O
benefits	O
of	O
FaithDial	NLP-dataset
generalize	O
to	O
zero	O
-	O
shot	O
transfer	O
on	O
other	O
datasets	Miscellaneous-term
such	O
as	O
CMU	NLP-dataset
-	NLP-dataset
Dog	NLP-dataset
and	O
TopicalChat	NLP-dataset
.	O

Further	O
,	O
we	O
find	O
that	O
the	O
benefits	O
of	O
FaithDial	NLP-dataset
generalize	O
to	O
zero	O
-	O
shot	O
transfer	O
on	O
other	O
datasets	Miscellaneous-term
such	O
as	O
CMU	NLP-dataset
-	NLP-dataset
Dog	NLP-dataset
and	O
TopicalChat	NLP-dataset
.	O

Finally	O
,	O
human	O
evaluation	O
reveals	O
that	O
responses	O
generated	O
by	O
models	O
trained	O
on	O
FaithDial	NLP-dataset
are	O
perceived	O
as	O
more	O
interpretable	O
,	O
cooperative	O
,	O
and	O
engaging	O
.	O

Active	O
learning	O
(	O
AL	O
)	O
uses	O
a	O
data	O
selection	O
algorithm	Miscellaneous-term
to	O
select	O
useful	O
training	O
samples	O
to	O
minimize	O
annotation	O
cost	O
.	O

However	O
,	O
in	O
an	O
empirical	O
study	O
across	O
six	O
typologically	O
diverse	O
languages	O
(	O
German	Miscellaneous-term
Swedish	Miscellaneous-term
Galician	Miscellaneous-term
North	Miscellaneous-term
Sami	Miscellaneous-term
Persian	Miscellaneous-term
and	O
Ukrainian	O
),	O
we	O
found	O
the	O
surprising	O
result	O
that	O
even	O
in	O
an	O
oracle	O
scenario	O
where	O
we	O
know	O
the	O
true	O
uncertainty	O
of	O
predictions	O
,	O
these	O
current	O
heuristics	O
are	O
far	O
from	O
optimal	O
.	O

We	O
also	O
present	O
auxiliary	O
results	O
demonstrating	O
the	O
importance	O
of	O
proper	O
calibration	O
of	O
models	O
,	O
which	O
we	O
ensure	O
through	O
cross	O
-	O
view	O
training	O
and	O
analysis	O
demonstrating	O
how	O
our	O
proposed	O
strategy	O
selects	O
examples	O
that	O
more	O
closely	O
follow	O
the	O
oracle	O
data	AI/ML/DL-term
distribution	AI/ML/DL-term
.	O

The	O
code	Miscellaneous-term
is	O
publicly	O
released	O
here	O
.	O
1	O
.	O

When	O
building	O
machine	O
translation	O
systems	O
,	O
one	O
often	O
needs	O
to	O
make	O
the	O
best	O
out	O
of	O
heterogeneous	O
sets	O
of	O
parallel	O
data	O
in	O
training	AI/ML/DL-term
and	O
to	O
robustly	O
handle	O
inputs	O
from	O
unexpected	O
domains	O
in	O
testing	O
.	O

This	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
domain	AI/ML/DL-term
scenario	O
has	O
attracted	O
a	O
lot	O
of	O
recent	O
work	O
that	O
fall	O
under	O
the	O
general	O
umbrella	O
of	O
transfer	O
learning	O
.	O

However	O
,	O
existing	O
datasets	Miscellaneous-term
are	O
often	O
limited	O
in	O
size	O
con	O
-	O
sidering	O
the	O
complexity	O
of	O
the	O
dialogues	O
.	O

Additionally	O
,	O
conventional	O
training	O
signal	O
in	O
-	O
ference	O
is	O
not	O
suitable	O
for	O
non	Miscellaneous-term
-	Miscellaneous-term
deterministic	Miscellaneous-term
agent	Miscellaneous-term
behavior	O
,	O
namely	O
,	O
considering	O
multiple	O
actions	O
as	O
valid	O
in	O
identical	O
dialogue	NLP-term
states	NLP-term
.	O

Additionally	O
,	O
conventional	O
training	O
signal	O
in	O
-	O
ference	O
is	O
not	O
suitable	O
for	O
non	Miscellaneous-term
-	Miscellaneous-term
deterministic	Miscellaneous-term
agent	Miscellaneous-term
behavior	O
,	O
namely	O
,	O
considering	O
multiple	O
actions	O
as	O
valid	O
in	O
identical	O
dialogue	NLP-term
states	NLP-term
.	O

This	O
work	O
builds	O
upon	O
two	O
lines	O
of	O
research	O
:	O
It	O
combines	O
the	O
modeling	AI/ML/DL-term
flexibility	AI/ML/DL-term
of	O
prior	O
work	O
on	O
content	O
-	O
based	O
sparse	O
attention	O
with	O
the	O
efficiency	O
gains	O
from	O
approaches	O
based	O
on	O
local	O
,	O
temporal	O
sparse	O
attention	O
.	O

Our	O
model	O
,	O
the	O
Routing	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
endows	O
self	O
-	O
attention	O
with	O
a	O
sparse	O
routing	O
module	O
based	O
on	O
online	O
k	O
-	O
means	O
while	O
reducing	O
the	O
overall	O
complexity	O
of	O
attention	O
to	O
O	O
(	O
n1	O
.	O
5d	O
)	O
from	O
O	O
(	O
n2d	O
)	O
for	O
sequence	O
length	O
n	O
and	O
hidden	O
dimension	O
d	O
.	O

We	O
show	O
that	O
our	O
model	O
outperforms	O
comparable	O
sparse	O
attention	O
models	O
on	O
language	O
modeling	O
on	O
Wikitext	NLP-dataset
-	NLP-dataset
103	NLP-dataset
(	O
15	O
.	O
8	O
vs	O
18	O
.	O
3	O
perplexity	O
),	O
as	O
well	O
as	O
on	O
image	O
generation	O
on	O
ImageNet	O
-	O
64	O
(	O
3	O
.	O
43	O
vs	O
3	O
.	O
44	O
bits	O
/	O
dim	O
)	O
while	O
using	O
fewer	O
self	O
-	O
attention	O
layers	O
.	O

Additionally	O
,	O
we	O
set	O
a	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
on	O
the	O
newly	O
released	O
PG	O
-	O
19	O
data	O
-	O
set	O
,	O
obtaining	O
a	O
test	O
perplexity	O
of	O
33	O
.	O
2	O
with	O
a	O
22	O
layer	O
Routing	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
model	O
trained	O
on	O
sequences	O
of	O
length	O
8192	O
.	O

Additionally	O
,	O
we	O
set	O
a	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
on	O
the	O
newly	O
released	O
PG	O
-	O
19	O
data	O
-	O
set	O
,	O
obtaining	O
a	O
test	O
perplexity	O
of	O
33	O
.	O
2	O
with	O
a	O
22	O
layer	O
Routing	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
model	O
trained	O
on	O
sequences	O
of	O
length	O
8192	O
.	O

We	O
open	O
-	O
source	O
the	O
code	O
for	O
Routing	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
in	O
Tensorflow	O
.	O
1	O
.	O

We	O
capture	O
the	O
natural	O
phonological	NLP-term
geometry	NLP-term
by	O
learning	O
character	O
embeddings	O
based	O
on	O
the	O
International	NLP-term
Phonetic	NLP-term
Alphabet	NLP-term
(	NLP-term
IPA	NLP-term
)	NLP-term
.	O

We	O
propose	O
the	O
Recursive	AI/ML/DL-technique
Non	AI/ML/DL-technique
-	AI/ML/DL-technique
autoregressive	AI/ML/DL-technique
Graph	AI/ML/DL-technique
-	AI/ML/DL-technique
to	AI/ML/DL-technique
-	AI/ML/DL-technique
Graph	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
architecture	AI/ML/DL-technique
(	AI/ML/DL-technique
RNGTr	AI/ML/DL-technique
)	AI/ML/DL-technique
for	O
the	O
iterative	O
refinement	O
of	O
arbitrary	O
graphs	O
through	O
the	O
recursive	O
application	O
of	O
a	O
non	O
-	O
autoregressive	O
Graph	O
-	O
to	O
-	O
Graph	O
Transformer	O
and	O
apply	O
it	O
to	O
syntactic	O
dependency	O
parsing	O
.	O

We	O
demonstrate	O
the	O
power	O
and	O
effectiveness	O
of	O
RNGTr	AI/ML/DL-technique
on	O
several	O
dependency	O
corpora	O
,	O
using	O
a	O
refinement	O
model	O
pre	O
-	O
trained	O
with	O
BERT	O
.	O

We	O
also	O
introduce	O
Syntactic	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
(	AI/ML/DL-technique
SynTr	AI/ML/DL-technique
)	AI/ML/DL-technique
a	O
non	O
-	O
recursive	O
parser	O
similar	O
to	O
our	O
refinement	O
model	O
.	O
RNGTr	AI/ML/DL-technique
.	O

RNGTr	O
can	O
improve	O
the	O
accuracy	O
of	O
a	O
variety	O
of	O
initial	O
parsers	O
on	O
13	O
languages	O
from	O
the	O
Universal	NLP-dataset
Dependencies	NLP-dataset
Treebanks	NLP-dataset
English	NLP-dataset
and	NLP-dataset
Chinese	NLP-dataset
Penn	NLP-dataset
Treebanks	NLP-dataset
and	O
the	O
German	NLP-dataset
CoNLL2009	NLP-dataset
corpus	O
,	O
even	O
improving	O
over	O
the	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
achieved	O
by	O
SynTr	AI/ML/DL-technique
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
proving	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
all	O
corpora	O
tested	O
.	O

RNGTr	O
can	O
improve	O
the	O
accuracy	O
of	O
a	O
variety	O
of	O
initial	O
parsers	O
on	O
13	O
languages	O
from	O
the	O
Universal	NLP-dataset
Dependencies	NLP-dataset
Treebanks	NLP-dataset
English	NLP-dataset
and	NLP-dataset
Chinese	NLP-dataset
Penn	NLP-dataset
Treebanks	NLP-dataset
and	O
the	O
German	NLP-dataset
CoNLL2009	NLP-dataset
corpus	O
,	O
even	O
improving	O
over	O
the	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
achieved	O
by	O
SynTr	AI/ML/DL-technique
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
proving	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
all	O
corpora	O
tested	O
.	O

RNGTr	O
can	O
improve	O
the	O
accuracy	O
of	O
a	O
variety	O
of	O
initial	O
parsers	O
on	O
13	O
languages	O
from	O
the	O
Universal	NLP-dataset
Dependencies	NLP-dataset
Treebanks	NLP-dataset
English	NLP-dataset
and	NLP-dataset
Chinese	NLP-dataset
Penn	NLP-dataset
Treebanks	NLP-dataset
and	O
the	O
German	NLP-dataset
CoNLL2009	NLP-dataset
corpus	O
,	O
even	O
improving	O
over	O
the	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
achieved	O
by	O
SynTr	AI/ML/DL-technique
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
proving	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
all	O
corpora	O
tested	O
.	O

Neural	AI/ML/DL-term
-	AI/ML/DL-term
symbolic	AI/ML/DL-term
representations	AI/ML/DL-term
have	O
emerged	O
as	O
a	O
way	O
to	O
combine	O
the	O
reasoning	O
capabilities	O
of	O
symbolic	O
methods	O
,	O
with	O
the	O
expressiveness	O
of	O
neural	O
networks	O
.	O

However	O
,	O
most	O
of	O
the	O
existing	O
frameworks	O
for	O
combining	O
neural	O
and	O
symbolic	O
representations	O
have	O
been	O
designed	O
for	O
classic	O
relational	O
learning	O
tasks	O
that	O
work	O
over	O
a	O
universe	O
of	O
symbolic	O
entities	NLP-term
and	O
relations	NLP-term
.	O

Our	O
framework	O
supports	O
easy	O
integration	O
with	O
expressive	O
language	O
encoders	O
and	O
provides	O
an	O
interface	O
to	O
study	O
the	O
interactions	O
between	O
representation	O
,	O
inference	AI/ML/DL-term
and	O
learning	AI/ML/DL-term
.	O

We	O
use	O
large	Miscellaneous-term
-	Miscellaneous-term
scale	Miscellaneous-term
corpora	Miscellaneous-term
in	O
six	O
different	O
gendered	O
languages	O
,	O
along	O
with	O
tools	O
from	O
NLP	O
and	O
information	O
theory	O
to	O
test	O
whether	O
there	O
is	O
a	O
relationship	O
between	O
the	O
grammatical	O
genders	O
of	O
inanimate	O
nouns	O
and	O
the	O
adjectives	O
used	O
to	O
describe	O
those	O
nouns	O
.	O

For	O
all	O
six	O
languages	O
,	O
we	O
find	O
that	O
there	O
is	O
a	O
statistically	AI/ML/DL-term
significant	AI/ML/DL-term
relationship	AI/ML/DL-term
.	O

We	O
also	O
find	O
that	O
there	O
are	O
statistically	AI/ML/DL-term
significant	AI/ML/DL-term
relationships	AI/ML/DL-term
between	O
the	O
grammatical	O
genders	O
of	O
inanimate	O
nouns	O
and	O
the	O
verbs	O
that	O
take	O
those	O
nouns	O
as	O
direct	O
objects	O
,	O
as	O
indirect	O
objects	O
,	O
and	O
as	O
subjects	O
.	O

Our	O
method	O
,	O
Amnesic	AI/ML/DL-technique
Probing	AI/ML/DL-technique
follows	O
the	O
intuition	O
that	O
the	O
utility	O
of	O
a	O
property	O
for	O
a	O
given	O
task	O
can	O
be	O
assessed	O
by	O
measuring	O
the	O
influence	O
of	O
a	O
causal	O
intervention	O
that	O
removes	O
it	O
from	O
the	O
representation	O
.	O

In	O
contrast	O
,	O
knowledge	O
embedding	O
(	O
KE	O
)	O
methods	O
can	O
effectively	O
represent	O
the	O
relational	O
facts	O
in	O
knowledge	NLP-term
graphs	NLP-term
(	NLP-term
KGs	NLP-term
)	NLP-term
with	O
informative	O
entity	NLP-term
embeddings	NLP-term
but	O
conventional	O
KE	O
models	O
cannot	O
take	O
full	O
advantage	O
of	O
the	O
abundant	O
textual	O
information	O
.	O

In	O
KEPLER	O
we	O
encode	O
textual	O
entity	O
descriptions	O
with	O
a	O
PLM	O
as	O
their	O
embeddings	AI/ML/DL-term
KE	NLP-term
d	O
then	O
jointly	O
optimize	O
the	O
KE	O
and	O
language	NLP-term
modeling	NLP-term
objectives	NLP-term
.	O

In	O
KEPLER	O
we	O
encode	O
textual	O
entity	O
descriptions	O
with	O
a	O
PLM	O
as	O
their	O
embeddings	AI/ML/DL-term
KE	NLP-term
d	O
then	O
jointly	O
optimize	O
the	O
KE	O
and	O
language	NLP-term
modeling	NLP-term
objectives	NLP-term
.	O

Experimental	O
results	O
show	O
that	O
KEPLER	O
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performances	O
on	O
various	O
NLP	O
tasks	O
,	O
and	O
also	O
works	O
remarkably	O
well	O
as	O
an	O
inductive	O
KE	O
model	O
on	O
KG	O
link	O
prediction	O
.	O

Furthermore	O
,	O
for	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
evaluating	O
KEPLER	O
we	O
construct	O
Wikidata5M1	NLP-dataset
,	O
a	O
large	O
-	O
scale	O
KG	O
dataset	O
with	O
aligned	NLP-term
entity	NLP-term
descriptions	NLP-term
and	O
benchmark	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
KE	NLP-term
methods	O
on	O
it	O
.	O

Furthermore	O
,	O
for	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
evaluating	O
KEPLER	O
we	O
construct	O
Wikidata5M1	NLP-dataset
,	O
a	O
large	O
-	O
scale	O
KG	O
dataset	O
with	O
aligned	NLP-term
entity	NLP-term
descriptions	NLP-term
and	O
benchmark	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
KE	NLP-term
methods	O
on	O
it	O
.	O

Furthermore	O
,	O
for	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
evaluating	O
KEPLER	O
we	O
construct	O
Wikidata5M1	NLP-dataset
,	O
a	O
large	O
-	O
scale	O
KG	O
dataset	O
with	O
aligned	NLP-term
entity	NLP-term
descriptions	NLP-term
and	O
benchmark	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
KE	NLP-term
methods	O
on	O
it	O
.	O

Furthermore	O
,	O
for	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
evaluating	O
KEPLER	O
we	O
construct	O
Wikidata5M1	NLP-dataset
,	O
a	O
large	O
-	O
scale	O
KG	O
dataset	O
with	O
aligned	NLP-term
entity	NLP-term
descriptions	NLP-term
and	O
benchmark	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
KE	NLP-term
methods	O
on	O
it	O
.	O

However	O
,	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
in	O
grounded	O
question	O
answering	O
often	O
do	O
not	O
explicitly	O
perform	O
decomposition	O
,	O
leading	O
to	O
difficulties	O
in	O
generalization	O
to	O
out	O
-	O
of	O
-	O
distribution	O
examples	O
.	O

We	O
show	O
that	O
this	O
inductive	AI/ML/DL-term
bias	AI/ML/DL-term
towards	O
tree	O
structures	O
dramatically	O
improves	O
systematic	O
generalization	O
to	O
out	O
-	O
of	O
-	O
distribution	O
examples	O
,	O
compared	O
to	O
strong	O
baselines	O
on	O
an	O
arithmetic	O
expressions	O
benchmark	O
as	O
well	O
as	O
on	O
C	NLP-dataset
losure	NLP-dataset
a	O
dataset	Miscellaneous-term
that	O
focuses	O
on	O
systematic	O
generalization	O
for	O
grounded	O
question	O
answering	O
.	O

We	O
show	O
that	O
this	O
inductive	AI/ML/DL-term
bias	AI/ML/DL-term
towards	O
tree	O
structures	O
dramatically	O
improves	O
systematic	O
generalization	O
to	O
out	O
-	O
of	O
-	O
distribution	O
examples	O
,	O
compared	O
to	O
strong	O
baselines	O
on	O
an	O
arithmetic	O
expressions	O
benchmark	O
as	O
well	O
as	O
on	O
C	NLP-dataset
losure	NLP-dataset
a	O
dataset	Miscellaneous-term
that	O
focuses	O
on	O
systematic	O
generalization	O
for	O
grounded	O
question	O
answering	O
.	O

We	O
show	O
that	O
this	O
inductive	AI/ML/DL-term
bias	AI/ML/DL-term
towards	O
tree	O
structures	O
dramatically	O
improves	O
systematic	O
generalization	O
to	O
out	O
-	O
of	O
-	O
distribution	O
examples	O
,	O
compared	O
to	O
strong	O
baselines	O
on	O
an	O
arithmetic	O
expressions	O
benchmark	O
as	O
well	O
as	O
on	O
C	NLP-dataset
losure	NLP-dataset
a	O
dataset	Miscellaneous-term
that	O
focuses	O
on	O
systematic	O
generalization	O
for	O
grounded	O
question	O
answering	O
.	O

On	O
this	O
challenging	O
dataset	O
,	O
our	O
model	O
reaches	O
an	O
accuracy	O
of	O
96	O
.	O
1	O
\\%	O
significantly	O
higher	O
than	O
prior	O
models	O
that	O
almost	O
perfectly	O
solve	O
the	O
task	O
on	O
a	O
random	O
,	O
in	AI/ML/DL-term
-	AI/ML/DL-term
distribution	AI/ML/DL-term
split	AI/ML/DL-term
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
WikiAsp	NLP-dataset
1	O
a	O
large	O
-	O
scale	O
dataset	O
for	O
multi	O
-	O
domain	O
aspect	O
-	O
based	O
summarization	O
that	O
attempts	O
to	O
spur	O
research	O
in	O
the	O
direction	O
of	O
open	O
-	O
domain	O
aspect	O
-	O
based	O
summarization	O
.	O

Specifically	O
,	O
we	O
build	O
the	O
dataset	Miscellaneous-term
using	O
Wikipedia	O
articles	O
from	O
20	O
different	O
domains	O
,	O
using	O
the	O
section	O
titles	O
and	O
boundaries	O
of	O
each	O
article	O
as	O
a	O
proxy	O
for	O
aspect	O
annotation	O
.	O

We	O
propose	O
several	O
straightforward	O
baseline	O
models	O
for	O
this	O
task	O
and	O
conduct	O
experiments	O
on	O
the	O
dataset	Miscellaneous-term
.	O

We	O
apply	O
novel	O
probes	O
to	O
recent	O
language	O
models	O
specifically	O
focusing	O
on	O
predicate	NLP-term
-	NLP-term
argument	NLP-term
structure	O
as	O
operationalized	O
by	O
semantic	O
dependencies	O
(	O
Ivanova	O
et	O
al	O
.,	O
2012	O
)—	O
and	O
find	O
that	O
,	O
unlike	O
syntax	O
,	O
semantics	O
is	O
not	O
brought	O
to	O
the	O
surface	O
.	O

We	O
then	O
use	O
convolutional	O
graph	O
encoders	O
to	O
explicitly	O
incorporate	O
semantic	NLP-term
parses	NLP-term
into	O
task	O
-	O
specific	O
finetuning	O
yielding	O
benefits	O
to	O
natural	O
language	O
understanding	O
(	O
NLU	O
)	O
tasks	O
in	O
the	O
GLUE	NLP-dataset
benchmark	O
.	O

We	O
then	O
use	O
convolutional	O
graph	O
encoders	O
to	O
explicitly	O
incorporate	O
semantic	NLP-term
parses	NLP-term
into	O
task	O
-	O
specific	O
finetuning	O
yielding	O
benefits	O
to	O
natural	O
language	O
understanding	O
(	O
NLU	O
)	O
tasks	O
in	O
the	O
GLUE	NLP-dataset
benchmark	O
.	O

Although	O
current	O
CCG	O
supertaggers	O
achieve	O
high	O
accuracy	O
on	O
the	O
standard	O
WSJ	NLP-dataset
test	O
set	O
,	O
few	O
systems	O
make	O
use	O
of	O
the	O
categories	O
’	O
internal	O
structure	O
that	O
will	O
drive	O
the	O
syntactic	O
derivation	O
during	O
parsing	O
.	O

However	O
,	O
supertags	NLP-term
are	O
themselves	O
trees	O
.	O

Our	O
best	O
tagger	O
is	O
capable	O
of	O
recovering	O
a	O
sizeable	O
fraction	O
of	O
the	O
long	NLP-term
-	NLP-term
tail	NLP-term
supertags	NLP-term
and	O
even	O
generates	O
CCG	O
categories	O
that	O
have	O
never	O
been	O
seen	O
in	O
training	AI/ML/DL-term
while	O
approximating	O
the	O
prior	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
in	O
overall	O
tag	O
accuracy	O
with	O
fewer	O
parameters	O
.	O

Our	O
best	O
tagger	O
is	O
capable	O
of	O
recovering	O
a	O
sizeable	O
fraction	O
of	O
the	O
long	NLP-term
-	NLP-term
tail	NLP-term
supertags	NLP-term
and	O
even	O
generates	O
CCG	O
categories	O
that	O
have	O
never	O
been	O
seen	O
in	O
training	AI/ML/DL-term
while	O
approximating	O
the	O
prior	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
in	O
overall	O
tag	O
accuracy	O
with	O
fewer	O
parameters	O
.	O

Our	O
best	O
tagger	O
is	O
capable	O
of	O
recovering	O
a	O
sizeable	O
fraction	O
of	O
the	O
long	NLP-term
-	NLP-term
tail	NLP-term
supertags	NLP-term
and	O
even	O
generates	O
CCG	O
categories	O
that	O
have	O
never	O
been	O
seen	O
in	O
training	AI/ML/DL-term
while	O
approximating	O
the	O
prior	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
in	O
overall	O
tag	O
accuracy	O
with	O
fewer	O
parameters	O
.	O

We	O
compile	O
a	O
larger	O
corpus	O
of	O
145	O
Bible	O
translations	O
in	O
92	O
languages	O
and	O
a	O
larger	O
number	O
of	O
typological	NLP-term
features	O
.	O
1	O
We	O
fill	O
in	O
missing	O
typological	O
data	O
for	O
several	O
languages	O
and	O
consider	O
corpus	O
-	O
based	O
measures	O
of	O
morphological	NLP-term
complexity	NLP-term
in	O
addition	O
to	O
expert	O
-	O
produced	O
typological	O
features	O
.	O

We	O
find	O
that	O
several	O
morphological	O
measures	O
are	O
significantly	O
associated	O
with	O
higher	O
surprisal	O
when	O
LSTM	O
models	O
are	O
trained	O
with	O
BPE	NLP-term
-	NLP-term
segmented	NLP-term
data	NLP-term
.	O

It	O
uses	O
a	O
clustering	O
interpretation	O
of	O
the	O
quantized	O
space	O
and	O
a	O
novel	O
extraction	O
algorithm	Miscellaneous-term
to	O
discover	O
popular	O
opinions	O
among	O
hundreds	O
of	O
reviews	O
,	O
a	O
significant	O
step	O
towards	O
opinion	O
summarization	O
of	O
practical	O
scope	O
.	O

We	O
also	O
make	O
publicly	O
available	O
Space	NLP-dataset
a	O
large	O
-	O
scale	O
evaluation	O
benchmark	O
for	O
opinion	O
summarizers	O
comprising	O
general	O
and	O
aspect	O
-	O
specific	O
summaries	O
for	O
50	O
hotels	O
.	O

Borrowing	O
concepts	O
from	O
social	O
science	O
,	O
we	O
identify	O
that	O
the	O
problem	O
is	O
a	O
misalignment	O
between	O
the	O
causal	O
chain	O
of	O
decisions	O
(	O
causal	Miscellaneous-term
attribution	Miscellaneous-term
and	O
the	O
attribution	O
of	O
human	O
behavior	O
to	O
the	O
interpretation	O
(	O
social	O
attribution	O
).	O

With	O
this	O
formalization	O
,	O
we	O
characterize	O
various	O
failures	O
of	O
misaligned	AI/ML/DL-term
faithful	AI/ML/DL-term
highlight	AI/ML/DL-term
interpretations	AI/ML/DL-term
and	O
propose	O
an	O
alternative	O
causal	O
chain	O
to	O
remedy	O
the	O
issues	O
.	O

We	O
introduce	O
an	O
Edit	O
-	O
Based	O
TransfOrmer	O
with	O
Repositioning	O
(	O
EDITOR	O
)	O
which	O
makes	O
sequence	O
generation	O
flexible	O
by	O
seamlessly	O
allowing	O
users	O
to	O
specify	O
preferences	O
in	O
output	O
lexical	NLP-term
choice	O
.	O

It	O
relies	O
on	O
a	O
novel	O
reposition	O
operation	O
designed	O
to	O
disentangle	O
lexical	NLP-term
choice	O
from	O
word	NLP-term
positioning	NLP-term
decisions	O
,	O
while	O
enabling	O
efficient	O
oracles	O
for	O
imitation	O
learning	O
and	O
parallel	O
edits	O
at	O
decoding	O
time	O
.	O

EDITOR	O
also	O
achieves	O
comparable	O
or	O
better	O
translation	O
quality	O
with	O
faster	O
decoding	O
speed	O
than	O
the	O
Levenshtein	O
Transformer	O
on	O
standard	O
Romanian	Miscellaneous-term
-	Miscellaneous-term
English	Miscellaneous-term
English	Miscellaneous-term
-	Miscellaneous-term
German	Miscellaneous-term
and	O
English	Miscellaneous-term
-	Miscellaneous-term
Japanese	Miscellaneous-term
machine	O
translation	O
tasks	O
.	O

Dual	O
encoders	O
perform	O
retrieval	O
by	O
encoding	O
documents	O
and	O
queries	O
into	O
dense	O
low	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
vectors	AI/ML/DL-term
scoring	O
each	O
document	O
by	O
its	O
inner	O
product	O
with	O
the	O
query	O
.	O

Using	O
both	O
theoretical	O
and	O
empirical	O
analysis	O
,	O
we	O
establish	O
connections	O
between	O
the	O
encoding	AI/ML/DL-term
dimension	AI/ML/DL-term
the	O
margin	O
between	O
gold	O
and	O
lower	NLP-term
-	NLP-term
ranked	NLP-term
documents	NLP-term
and	O
the	O
document	O
length	O
,	O
suggesting	O
limitations	O
in	O
the	O
capacity	O
of	O
fixed	AI/ML/DL-term
-	AI/ML/DL-term
length	AI/ML/DL-term
encodings	AI/ML/DL-term
to	O
support	O
precise	O
retrieval	O
of	O
long	O
documents	O
.	O

Using	O
both	O
theoretical	O
and	O
empirical	O
analysis	O
,	O
we	O
establish	O
connections	O
between	O
the	O
encoding	AI/ML/DL-term
dimension	AI/ML/DL-term
the	O
margin	O
between	O
gold	O
and	O
lower	NLP-term
-	NLP-term
ranked	NLP-term
documents	NLP-term
and	O
the	O
document	O
length	O
,	O
suggesting	O
limitations	O
in	O
the	O
capacity	O
of	O
fixed	AI/ML/DL-term
-	AI/ML/DL-term
length	AI/ML/DL-term
encodings	AI/ML/DL-term
to	O
support	O
precise	O
retrieval	O
of	O
long	O
documents	O
.	O

A	O
key	O
limitation	O
in	O
current	O
datasets	Miscellaneous-term
for	O
multi	O
-	O
hop	O
reasoning	O
is	O
that	O
the	O
required	O
steps	O
for	O
answering	O
the	O
question	O
are	O
mentioned	O
in	O
it	O
explicitly	O
.	O

In	O
this	O
work	O
,	O
we	O
introduce	O
StrategyQA	NLP-dataset
a	O
question	O
answering	O
(	O
QA	O
)	O
benchmark	O
where	O
the	O
required	O
reasoning	O
steps	O
are	O
implicit	O
in	O
the	O
question	O
,	O
and	O
should	O
be	O
inferred	O
using	O
a	O
strategy	O
.	O

Moreover	O
,	O
we	O
annotate	O
each	O
question	O
with	O
(	O
1	O
)	O
a	O
decomposition	NLP-term
into	O
reasoning	O
steps	O
for	O
answering	O
it	O
,	O
and	O
(	O
2	O
)	O
Wikipedia	Miscellaneous-term
paragraphs	Miscellaneous-term
that	O
contain	O
the	O
answers	O
to	O
each	O
step	O
.	O

Moreover	O
,	O
we	O
annotate	O
each	O
question	O
with	O
(	O
1	O
)	O
a	O
decomposition	NLP-term
into	O
reasoning	O
steps	O
for	O
answering	O
it	O
,	O
and	O
(	O
2	O
)	O
Wikipedia	Miscellaneous-term
paragraphs	Miscellaneous-term
that	O
contain	O
the	O
answers	O
to	O
each	O
step	O
.	O

Overall	O
,	O
StrategyQA	NLP-dataset
includes	O
2	O
,	O
780	O
examples	O
each	O
consisting	O
of	O
a	O
strategy	O
question	O
,	O
its	O
decomposition	NLP-term
and	O
evidence	O
paragraphs	O
.	O

Overall	O
,	O
StrategyQA	NLP-dataset
includes	O
2	O
,	O
780	O
examples	O
each	O
consisting	O
of	O
a	O
strategy	O
question	O
,	O
its	O
decomposition	NLP-term
and	O
evidence	O
paragraphs	O
.	O

Analysis	O
shows	O
that	O
questions	O
in	O
StrategyQA	NLP-dataset
are	O
short	O
,	O
topic	O
-	O
diverse	O
,	O
and	O
cover	O
a	O
wide	O
range	O
of	O
strategies	O
.	O

We	O
present	O
a	O
language	O
model	O
that	O
combines	O
a	O
large	O
parametric	O
neural	O
network	O
(	O
i	O
.	O
e	O
.,	O
a	O
transformer	O
with	O
a	O
non	AI/ML/DL-term
-	AI/ML/DL-term
parametric	AI/ML/DL-term
episodic	AI/ML/DL-term
memory	AI/ML/DL-term
component	O
in	O
an	O
integrated	O
architecture	O
.	O

This	O
mechanism	O
allows	O
the	O
model	O
to	O
use	O
either	O
local	O
context	O
,	O
short	Miscellaneous-term
-	Miscellaneous-term
term	Miscellaneous-term
memory	Miscellaneous-term
or	O
long	Miscellaneous-term
-	Miscellaneous-term
term	Miscellaneous-term
memory	Miscellaneous-term
(	O
or	O
any	O
combination	O
of	O
them	O
)	O
on	O
an	O
ad	O
hoc	O
basis	O
depending	O
on	O
the	O
context	O
.	O

Task	O
-	O
oriented	O
dialog	O
(	O
TOD	O
)	O
systems	O
often	O
need	O
to	O
formulate	O
knowledge	NLP-term
base	NLP-term
(	NLP-term
KB	NLP-term
)	NLP-term
queries	NLP-term
corresponding	O
to	O
the	O
user	O
intent	O
and	O
use	O
the	O
query	O
results	O
to	O
generate	O
system	O
responses	O
.	O

Existing	O
approaches	O
require	O
dialog	NLP-term
datasets	NLP-term
to	O
explicitly	O
annotate	O
these	O
KB	NLP-term
queries	NLP-term
these	O
annotations	O
can	O
be	O
time	O
consuming	O
,	O
and	O
expensive	O
.	O

In	O
response	O
,	O
we	O
define	O
the	O
novel	O
problems	O
of	O
predicting	O
the	O
KB	NLP-term
query	NLP-term
and	O
training	O
the	O
dialog	O
agent	O
,	O
without	O
explicit	O
KB	O
query	O
annotation	O
.	O

For	O
query	O
prediction	O
we	O
propose	O
a	O
reinforcement	O
learning	O
(	O
RL	O
)	O
baseline	O
,	O
which	O
rewards	O
the	O
generation	O
of	O
those	O
queries	O
whose	O
KB	NLP-term
results	O
cover	O
the	O
entities	NLP-term
mentioned	O
in	O
subsequent	O
dialog	O
.	O

Further	O
analysis	O
reveals	O
that	O
correlation	O
among	O
query	O
attributes	O
in	O
KB	NLP-term
can	O
significantly	O
confuse	O
memory	O
augmented	O
policy	O
optimization	O
(	O
MAPO	O
)	O
an	O
existing	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
RL	O
MAPO	O
.	O
To	O
address	O
this	O
,	O
we	O
improve	O
the	O
MAPO	O
baseline	O
with	O
simple	O
but	O
important	O
modifications	O
suited	O
to	O
our	O
task	O
.	O

Further	O
analysis	O
reveals	O
that	O
correlation	O
among	O
query	O
attributes	O
in	O
KB	NLP-term
can	O
significantly	O
confuse	O
memory	O
augmented	O
policy	O
optimization	O
(	O
MAPO	O
)	O
an	O
existing	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
RL	O
MAPO	O
.	O
To	O
address	O
this	O
,	O
we	O
improve	O
the	O
MAPO	O
baseline	O
with	O
simple	O
but	O
important	O
modifications	O
suited	O
to	O
our	O
task	O
.	O

To	O
train	O
the	O
full	O
TOD	O
system	O
for	O
our	O
setting	O
,	O
we	O
propose	O
a	O
pipelined	O
approach	O
:	O
it	O
independently	O
predicts	O
when	O
to	O
make	O
a	O
KB	NLP-term
query	NLP-term
(	O
query	O
position	O
predictor	O
KB	NLP-term
query	NLP-term
edicts	O
a	O
KB	O
query	O
at	O
the	O
predicted	O
position	O
(	O
query	O
predictor	O
),	O
and	O
uses	O
the	O
results	O
of	O
predicted	O
query	O
in	O
subsequent	O
dialog	O
(	O
next	O
response	O
predictor	O
).	O

We	O
address	O
the	O
existing	O
shortcomings	O
of	O
summarization	O
evaluation	O
methods	O
along	O
five	O
dimensions	O
:	O
1	O
)	O
we	O
re	O
-	O
evaluate	O
14	O
automatic	O
evaluation	O
metrics	O
in	O
a	O
comprehensive	O
and	O
consistent	O
fashion	O
using	O
neural	O
summarization	O
model	O
outputs	O
along	O
with	O
expert	O
and	O
crowd	O
-	O
sourced	O
human	O
annotations	O
;	O
2	O
)	O
we	O
consistently	O
benchmark	O
23	O
recent	O
summarization	O
models	O
using	O
the	O
aforementioned	O
automatic	O
evaluation	O
metrics	O
;	O
3	O
)	O
we	O
assemble	O
the	O
largest	O
collection	O
of	O
summaries	O
generated	O
by	O
models	O
trained	O
on	O
the	O
CNN	NLP-dataset
/	NLP-dataset
DailyMail	NLP-dataset
news	NLP-dataset
summarization	O
models	O
in	O
a	O
unified	O
format	O
;	O
4	O
)	O
we	O
implement	O
and	O
share	O
a	O
toolkit	O
that	O
provides	O
an	O
extensible	O
and	O
unified	O
API	O
for	O
evaluating	O
summarization	O
models	O
across	O
a	O
broad	O
range	O
of	O
automatic	O
metrics	O
;	O
and	O
5	O
)	O
we	O
assemble	O
and	O
share	O
the	O
largest	O
and	O
most	O
diverse	O
,	O
in	O
terms	O
of	O
model	O
types	O
,	O
collection	O
of	O
human	O
judgments	O
of	O
model	O
-	O
generated	O
summaries	O
on	O
the	O
CNN	NLP-dataset
/	NLP-dataset
Daily	NLP-dataset
Mail	NLP-dataset
dataset	O
annotated	O
by	O
both	O
expert	O
judges	O
and	O
crowd	O
-	O
source	O
workers	O
.	O

Most	O
combinations	O
of	O
NLP	O
tasks	O
and	O
language	O
varieties	O
lack	O
in	AI/ML/DL-term
-	AI/ML/DL-term
domain	AI/ML/DL-term
examples	AI/ML/DL-term
for	O
supervised	O
training	O
because	O
of	O
the	O
paucity	O
of	O
annotated	O
data	O
.	O

For	O
instance	O
,	O
given	O
training	AI/ML/DL-term
data	AI/ML/DL-term
for	O
named	O
entity	O
recognition	O
(	O
NER	O
)	O
in	O
Vietnamese	Miscellaneous-term
and	O
for	O
part	O
-	O
of	O
-	O
speech	O
(	O
POS	O
)	O
tagging	O
in	O
Wolof	Miscellaneous-term
NER	O
Wolof	Miscellaneous-term
can	O
perform	O
accurate	O
predictions	O
for	O
NER	O
in	O
Wolof	O
.	O

For	O
instance	O
,	O
given	O
training	AI/ML/DL-term
data	AI/ML/DL-term
for	O
named	O
entity	O
recognition	O
(	O
NER	O
)	O
in	O
Vietnamese	Miscellaneous-term
and	O
for	O
part	O
-	O
of	O
-	O
speech	O
(	O
POS	O
)	O
tagging	O
in	O
Wolof	Miscellaneous-term
NER	O
Wolof	Miscellaneous-term
can	O
perform	O
accurate	O
predictions	O
for	O
NER	O
in	O
Wolof	O
.	O

In	O
particular	O
,	O
we	O
experiment	O
with	O
a	O
typologically	O
diverse	O
sample	O
of	O
33	O
languages	O
from	O
4	O
continents	O
and	O
11	O
families	O
,	O
and	O
show	O
that	O
our	O
model	O
yields	O
comparable	O
or	O
better	O
results	O
than	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
transfer	O
methods	O
.	O

Focusing	O
on	O
Surface	O
Realization	O
(	O
SR	O
)	O
the	O
task	O
of	O
converting	O
an	O
unordered	NLP-term
dependency	NLP-term
tree	NLP-term
into	O
a	O
well	O
-	O
formed	O
sentence	O
,	O
we	O
propose	O
a	O
framework	O
for	O
error	O
analysis	O
which	O
permits	O
identifying	O
which	O
features	O
of	O
the	O
input	O
affect	O
the	O
models	O
’	O
results	O
.	O

This	O
framework	O
consists	O
of	O
two	O
main	O
components	O
:	O
(	O
i	O
)	O
correlation	O
analyses	O
between	O
a	O
wide	O
range	O
of	O
syntactic	NLP-term
metrics	NLP-term
and	O
standard	O
performance	O
metrics	O
and	O
(	O
ii	O
)	O
a	O
set	O
of	O
techniques	O
to	O
automatically	O
identify	O
syntactic	NLP-term
constructs	NLP-term
that	O
often	O
co	O
-	O
occur	O
with	O
low	O
performance	O
scores	O
.	O

The	O
framework	O
is	O
available	O
in	O
the	O
form	O
of	O
a	O
toolkit	O
which	O
can	O
be	O
used	O
both	O
by	O
campaign	O
organizers	O
to	O
provide	O
detailed	O
,	O
linguistically	O
interpretable	O
feedback	O
on	O
the	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
in	O
multilingual	O
SR	O
and	O
by	O
individual	O
researchers	O
to	O
improve	O
models	O
and	O
datasets	Miscellaneous-term
1	O
.	O

We	O
describe	O
an	O
annotation	O
procedure	O
,	O
collect	O
data	O
on	O
the	O
Wikipedia	NLP-term
corpus	NLP-term
and	O
use	O
the	O
data	O
to	O
train	O
models	O
to	O
automatically	O
decontextualize	NLP-term
sentences	O
.	O

We	O
perform	O
rigorous	O
evaluations	O
on	O
three	O
slang	O
dictionaries	O
and	O
show	O
that	O
our	O
approach	O
not	O
only	O
outperforms	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
language	O
models	O
but	O
also	O
better	O
predicts	O
the	O
historical	O
emergence	O
of	O
slang	O
word	O
usages	O
from	O
1960s	O
to	O
2000s	O
.	O

We	O
interpret	O
the	O
proposed	O
models	O
and	O
find	O
that	O
the	O
contrastively	NLP-term
learned	NLP-term
semantic	NLP-term
space	NLP-term
is	O
sensitive	O
to	O
the	O
similarities	O
between	O
slang	O
and	O
conventional	O
senses	O
of	O
words	O
.	O

For	O
digital	O
corpora	O
of	O
historical	O
prints	O
,	O
the	O
errors	O
are	O
further	O
exacerbated	O
due	O
to	O
low	O
scan	O
quality	O
and	O
lack	O
of	O
language	O
standardization	O
.	O
For	O
the	O
task	O
of	O
OCR	O
post	O
-	O
hoc	O
correction	O
we	O
propose	O
a	O
neural	AI/ML/DL-term
approach	AI/ML/DL-term
based	O
on	O
a	O
combination	O
of	O
recurrent	O
(	O
RNN	O
)	O
and	O
deep	O
convolutional	O
network	O
(	O
ConvNet	O
)	O
to	O
correct	O
OCR	O
transcription	O
errors	O
.	O

Accounting	O
for	O
the	O
input	O
and	O
output	O
similarity	O
,	O
we	O
propose	O
a	O
new	O
loss	AI/ML/DL-term
function	AI/ML/DL-term
that	O
rewards	O
the	O
model	O
’	O
s	O
correcting	O
behavior	O
.	O
Evaluation	O
on	O
a	O
historical	O
book	O
corpus	O
in	O
German	O
language	O
shows	O
that	O
our	O
models	O
are	O
robust	O
in	O
capturing	O
diverse	O
OCR	O
transcription	O
errors	O
and	O
reduce	O
the	O
word	O
error	O
rate	O
of	O
32	O
.	O
3	O
\\%	O
by	O
more	O
than	O
89	O
\\%.	O

Our	O
approach	O
allows	O
for	O
the	O
large	O
-	O
scale	O
expansion	O
of	O
existing	O
datasets	Miscellaneous-term
datasets	Miscellaneous-term
pid	O
creation	O
of	O
new	O
datasets	O
using	O
a	O
small	O
,	O
manually	O
produced	O
seed	O
corpus	O
.	O

We	O
demonstrate	O
our	O
approach	O
with	O
experiments	O
on	O
the	O
Berkeley	NLP-dataset
FrameNet	NLP-dataset
Project	NLP-dataset
a	O
large	O
-	O
scale	O
language	O
understanding	O
effort	O
spanning	O
more	O
than	O
two	O
decades	O
of	O
human	O
labor	O
.	O

The	O
resulting	O
dataset	Miscellaneous-term
is	O
intrinsically	O
and	O
extrinsically	O
evaluated	O
in	O
detail	O
,	O
showing	O
positive	O
results	O
on	O
a	O
downstream	O
task	O
.	O

Macro	O
plans	O
represent	O
high	O
level	O
organization	O
of	O
important	O
content	O
such	O
as	O
entities	NLP-term
events	O
,	O
and	O
their	O
interactions	O
;	O
they	O
are	O
learned	O
from	O
data	O
and	O
given	O
as	O
input	O
to	O
the	O
generator	O
.	O

Extensive	O
experiments	O
on	O
two	O
data	O
-	O
to	O
-	O
text	O
benchmarks	O
(	O
RotoWire	NLP-dataset
and	O
MLB	NLP-dataset
show	O
that	O
our	O
approach	O
outperforms	O
competitive	O
baselines	O
in	O
terms	O
of	O
automatic	O
and	O
human	O
evaluation	O
.	O

This	O
paper	O
demonstrates	O
that	O
Optimality	O
Theory	O
is	O
capable	O
of	O
generating	O
non	NLP-term
-	NLP-term
context	NLP-term
-	NLP-term
free	NLP-term
languages	NLP-term
contributing	O
to	O
the	O
characterization	O
of	O
its	O
generative	O
capacity	O
.	O

Empirical	O
results	O
demonstrate	O
that	O
our	O
method	O
outperforms	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
in	O
terms	O
of	O
joint	O
belief	O
accuracy	O
for	O
MultiWOZ	NLP-dataset
2	NLP-dataset
.	NLP-dataset
1	NLP-dataset
a	O
large	O
-	O
scale	O
human	O
--	O
human	O
dialogue	O
dataset	Miscellaneous-term
across	O
multiple	O
domains	O
.	O

Empirical	O
results	O
demonstrate	O
that	O
our	O
method	O
outperforms	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
in	O
terms	O
of	O
joint	O
belief	O
accuracy	O
for	O
MultiWOZ	NLP-dataset
2	NLP-dataset
.	NLP-dataset
1	NLP-dataset
a	O
large	O
-	O
scale	O
human	O
--	O
human	O
dialogue	O
dataset	Miscellaneous-term
across	O
multiple	O
domains	O
.	O

Focusing	O
on	O
zero	O
-	O
shot	O
image	O
retrieval	O
tasks	O
,	O
we	O
study	O
three	O
important	O
factors	O
that	O
can	O
impact	O
the	O
quality	O
of	O
learned	AI/ML/DL-term
representations	AI/ML/DL-term
pretraining	AI/ML/DL-term
data	AI/ML/DL-term
the	O
attention	O
mechanism	O
and	O
loss	AI/ML/DL-term
functions	AI/ML/DL-term
.	O

By	O
pretraining	O
models	O
on	O
six	O
datasets	O
,	O
we	O
observe	O
that	O
dataset	AI/ML/DL-term
noise	AI/ML/DL-term
and	O
language	O
similarity	O
to	O
our	O
downstream	O
task	O
are	O
important	O
indicators	O
of	O
model	O
performance	O
.	O

In	O
this	O
work	O
,	O
we	O
examine	O
the	O
ability	O
of	O
NER	O
models	O
to	O
use	O
contextual	O
information	O
when	O
predicting	O
the	O
type	O
of	O
an	O
ambiguous	NLP-term
entity	NLP-term
.	O

Our	O
results	O
indicate	O
that	O
all	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
we	O
tested	O
show	O
such	O
a	O
bias	O
;	O
BERT	O
fine	O
-	O
tuned	O
models	O
significantly	O
outperforming	O
feature	NLP-term
-	NLP-term
based	NLP-term
(	O
LSTM	O
-	O
CRF	O
ones	O
on	O
NRB	O
despite	O
having	O
comparable	O
(	O
sometimes	O
lower	O
)	O
performance	O
on	O
standard	O
benchmarks	O
.	O
To	O
mitigate	O
this	O
bias	O
,	O
we	O
propose	O
a	O
novel	O
model	AI/ML/DL-term
-	AI/ML/DL-term
agnostic	AI/ML/DL-term
training	AI/ML/DL-term
method	O
that	O
adds	O
learnable	O
adversarial	AI/ML/DL-term
noise	AI/ML/DL-term
NRB	O
ome	O
entity	O
mentions	O
,	O
thus	O
enforcing	O
models	O
to	O
focus	O
more	O
strongly	O
on	O
the	O
contextual	O
signal	O
,	O
leading	O
to	O
significant	O
gains	O
on	O
NRB	O
.	O

Our	O
results	O
indicate	O
that	O
all	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
we	O
tested	O
show	O
such	O
a	O
bias	O
;	O
BERT	O
fine	O
-	O
tuned	O
models	O
significantly	O
outperforming	O
feature	NLP-term
-	NLP-term
based	NLP-term
(	O
LSTM	O
-	O
CRF	O
ones	O
on	O
NRB	O
despite	O
having	O
comparable	O
(	O
sometimes	O
lower	O
)	O
performance	O
on	O
standard	O
benchmarks	O
.	O
To	O
mitigate	O
this	O
bias	O
,	O
we	O
propose	O
a	O
novel	O
model	AI/ML/DL-term
-	AI/ML/DL-term
agnostic	AI/ML/DL-term
training	AI/ML/DL-term
method	O
that	O
adds	O
learnable	O
adversarial	AI/ML/DL-term
noise	AI/ML/DL-term
NRB	O
ome	O
entity	O
mentions	O
,	O
thus	O
enforcing	O
models	O
to	O
focus	O
more	O
strongly	O
on	O
the	O
contextual	O
signal	O
,	O
leading	O
to	O
significant	O
gains	O
on	O
NRB	O
.	O

To	O
address	O
these	O
challenges	O
,	O
we	O
introduce	O
LimGen	O
a	O
novel	O
and	O
fully	O
automated	O
system	O
for	O
limerick	O
generation	O
that	O
outperforms	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
LimGen	O
network	O
-	O
based	O
poetry	O
models	O
,	O
as	O
well	O
as	O
prior	O
rule	O
-	O
based	O
poetry	O
models	O
.	O

LimGen	O
consists	O
of	O
three	O
important	O
pieces	O
:	O
the	O
Adaptive	O
Multi	O
-	O
Templated	O
Constraint	O
algorithm	O
that	O
constrains	O
our	O
search	O
to	O
the	O
space	O
of	O
realistic	O
poems	O
,	O
the	O
Multi	O
-	O
Templated	O
Beam	O
Search	O
algorithm	Miscellaneous-term
which	O
searches	O
efficiently	O
through	O
the	O
space	O
,	O
and	O
the	O
probabilistic	O
Storyline	O
algorithm	Miscellaneous-term
that	O
provides	O
coherent	O
storylines	O
related	O
to	O
a	O
user	O
-	O
provided	O
prompt	O
word	O
.	O

While	O
pretrained	O
language	O
models	O
(	O
LMs	O
)	O
have	O
driven	O
impressive	O
gains	O
over	O
morpho	NLP-term
-	NLP-term
syntactic	NLP-term
and	O
semantic	NLP-term
tasks	O
,	O
their	O
ability	O
to	O
model	O
discourse	O
and	O
pragmatic	O
phenomena	O
is	O
less	O
clear	O
.	O

We	O
examine	O
the	O
performance	O
of	O
a	O
broad	O
range	O
of	O
pretrained	O
LMs	O
on	O
this	O
detection	O
task	O
for	O
English	Miscellaneous-term
.	O

Lacking	O
a	O
dataset	Miscellaneous-term
for	O
the	O
task	O
,	O
we	O
introduce	O
INSteD	NLP-dataset
a	O
novel	O
intruder	O
sentence	O
detection	O
dataset	O
,	O
containing	O
170	O
,	O
000	O
+	O
documents	O
constructed	O
from	O
English	O
Wikipedia	O
and	O
CNN	O
news	O
articles	O
.	O

Lacking	O
a	O
dataset	Miscellaneous-term
for	O
the	O
task	O
,	O
we	O
introduce	O
INSteD	NLP-dataset
a	O
novel	O
intruder	O
sentence	O
detection	O
dataset	O
,	O
containing	O
170	O
,	O
000	O
+	O
documents	O
constructed	O
from	O
English	O
Wikipedia	O
and	O
CNN	O
news	O
articles	O
.	O

We	O
validate	O
our	O
metrics	O
using	O
user	O
-	O
created	O
glossaries	O
and	O
draw	O
on	O
sociolinguistic	NLP-term
theories	NLP-term
to	O
connect	O
language	O
variation	O
with	O
trends	O
in	O
community	O
behavior	O
.	O

We	O
find	O
that	O
communities	O
with	O
highly	O
distinctive	O
language	O
are	O
medium	O
-	O
sized	O
,	O
and	O
their	O
loyal	O
and	O
highly	O
engaged	O
users	O
interact	O
in	O
dense	Data/Mining/Information/Retrieval-term
networks	Data/Mining/Information/Retrieval-term
.	O

SSL	O
(	O
Devlin	O
et	O
al	O
.,	O
2019a	O
)	O
is	O
an	O
unsupervised	O
learning	O
approach	O
that	O
defines	O
auxiliary	Miscellaneous-term
tasks	Miscellaneous-term
on	O
input	O
data	O
without	O
using	O
any	O
human	O
-	O
provided	O
labels	O
and	O
learns	O
data	O
representations	O
by	O
solving	O
these	O
auxiliary	O
tasks	O
.	O

Training	O
a	O
model	O
using	O
an	O
SSL	O
task	O
can	O
prevent	O
the	O
model	O
from	O
being	O
overfitted	O
to	O
a	O
limited	O
number	O
of	O
class	AI/ML/DL-term
labels	AI/ML/DL-term
in	O
the	O
classification	O
task	O
.	O

We	O
present	O
extensive	O
experiments	O
showing	O
that	O
a	O
noisy	O
channel	O
model	O
decodes	O
better	O
responses	O
compared	O
to	O
direct	O
decoding	AI/ML/DL-term
and	O
that	O
a	O
two	O
-	O
stage	O
pretraining	O
strategy	O
,	O
employing	O
both	O
open	O
-	O
domain	O
and	O
task	NLP-term
-	NLP-term
oriented	NLP-term
dialogue	NLP-term
data	O
,	O
improves	O
over	O
randomly	O
initialized	O
models	O
.	O

We	O
present	O
extensive	O
experiments	O
showing	O
that	O
a	O
noisy	O
channel	O
model	O
decodes	O
better	O
responses	O
compared	O
to	O
direct	O
decoding	AI/ML/DL-term
and	O
that	O
a	O
two	O
-	O
stage	O
pretraining	O
strategy	O
,	O
employing	O
both	O
open	O
-	O
domain	O
and	O
task	NLP-term
-	NLP-term
oriented	NLP-term
dialogue	NLP-term
data	O
,	O
improves	O
over	O
randomly	O
initialized	O
models	O
.	O

We	O
propose	O
unified	O
algorithms	Miscellaneous-term
for	O
the	O
important	O
cases	O
of	O
first	O
-	O
order	O
expectations	O
and	O
second	O
-	O
order	O
expectations	O
in	O
edge	AI/ML/DL-term
-	AI/ML/DL-term
factored	AI/ML/DL-term
non	AI/ML/DL-term
-	AI/ML/DL-term
projective	AI/ML/DL-term
spanning	O
-	O
tree	O
models	O
.	O

We	O
propose	O
unified	O
algorithms	Miscellaneous-term
for	O
the	O
important	O
cases	O
of	O
first	O
-	O
order	O
expectations	O
and	O
second	O
-	O
order	O
expectations	O
in	O
edge	AI/ML/DL-term
-	AI/ML/DL-term
factored	AI/ML/DL-term
non	AI/ML/DL-term
-	AI/ML/DL-term
projective	AI/ML/DL-term
spanning	O
-	O
tree	O
models	O
.	O

Our	O
algorithms	Miscellaneous-term
exploit	O
a	O
fundamental	O
connection	O
between	O
gradients	AI/ML/DL-term
and	O
expectations	O
algorithms	Miscellaneous-term
ws	O
us	O
to	O
derive	O
efficient	O
algorithms	O
.	O

Our	O
algorithms	Miscellaneous-term
exploit	O
a	O
fundamental	O
connection	O
between	O
gradients	AI/ML/DL-term
and	O
expectations	O
algorithms	Miscellaneous-term
ws	O
us	O
to	O
derive	O
efficient	O
algorithms	O
.	O

These	O
algorithms	Miscellaneous-term
are	O
easy	O
to	O
implement	O
with	O
or	O
without	O
automatic	O
differentiation	O
software	O
.	O

We	O
motivate	O
the	O
development	O
of	O
our	O
framework	O
with	O
several	O
cautionary	O
tales	O
of	O
previous	O
research	O
,	O
which	O
has	O
developed	O
numerous	O
inefficient	O
algorithms	O
for	O
computing	O
expectations	O
and	O
their	O
gradients	AI/ML/DL-term
.	O

We	O
find	O
our	O
algorithms	O
are	O
up	O
to	O
15	O
and	O
9	O
times	O
faster	O
than	O
previous	O
algorithms	O
for	O
computing	O
the	O
Shannon	O
entropy	O
and	O
the	O
gradient	AI/ML/DL-term
of	O
the	O
generalized	O
expectation	O
objective	O
,	O
respectively	O
.	O

Focusing	O
on	O
the	O
realistic	O
scenario	O
of	O
FSL	O
FSL	O
which	O
a	O
test	O
instance	O
might	O
not	O
belong	O
to	O
any	O
of	O
the	O
target	O
categories	O
(	O
none	O
-	O
of	O
-	O
the	O
-	O
above	O
,	O
[	O
NOTA	O
]),	O
we	O
first	O
revisit	O
the	O
recent	O
popular	O
dataset	O
structure	O
for	O
FSL	O
,	O
pointing	O
out	O
its	O
unrealistic	O
data	AI/ML/DL-term
distribution	AI/ML/DL-term
.	O

To	O
remedy	O
this	O
,	O
we	O
propose	O
a	O
novel	O
methodology	O
for	O
deriving	O
more	O
realistic	O
few	O
-	O
shot	O
test	O
data	O
from	O
available	O
datasets	O
for	O
supervised	O
RC	O
and	O
apply	O
it	O
to	O
the	O
TACRED	NLP-dataset
dataset	Miscellaneous-term
.	O

To	O
remedy	O
this	O
,	O
we	O
propose	O
a	O
novel	O
methodology	O
for	O
deriving	O
more	O
realistic	O
few	O
-	O
shot	O
test	O
data	O
from	O
available	O
datasets	O
for	O
supervised	O
RC	O
and	O
apply	O
it	O
to	O
the	O
TACRED	NLP-dataset
dataset	Miscellaneous-term
.	O

This	O
yields	O
a	O
new	O
challenging	O
benchmark	O
for	O
FSL	O
-	O
RC	O
,	O
on	O
which	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
models	O
show	O
poor	O
performance	O
.	O

Tree	NLP-term
-	NLP-term
adjoining	NLP-term
grammar	NLP-term
(	NLP-term
TAG	NLP-term
)	NLP-term
and	O
combinatory	NLP-term
categorial	NLP-term
grammar	NLP-term
(	NLP-term
CCG	NLP-term
)	NLP-term
are	O
two	O
well	O
-	O
established	O
mildly	O
context	NLP-term
-	NLP-term
sensitive	NLP-term
grammar	NLP-term
formalisms	NLP-term
that	O
are	O
known	O
to	O
have	O
the	O
same	O
expressive	O
power	O
on	O
strings	O
(	O
i	O
.	O
e	O
.,	O
generate	O
the	O
same	O
class	O
of	O
string	O
languages	O
).	O

In	O
fact	O
,	O
CCG	NLP-term
without	O
lexicon	O
entries	O
for	O
the	O
empty	O
string	O
and	O
only	O
first	AI/ML/DL-term
-	AI/ML/DL-term
order	AI/ML/DL-term
rules	AI/ML/DL-term
of	O
degree	O
at	O
most	O
2	O
are	O
sufficient	O
for	O
its	O
full	O
expressive	O
power	O
.	O

In	O
fact	O
,	O
CCG	NLP-term
without	O
lexicon	O
entries	O
for	O
the	O
empty	O
string	O
and	O
only	O
first	AI/ML/DL-term
-	AI/ML/DL-term
order	AI/ML/DL-term
rules	AI/ML/DL-term
of	O
degree	O
at	O
most	O
2	O
are	O
sufficient	O
for	O
its	O
full	O
expressive	O
power	O
.	O

While	O
argument	O
mining	O
has	O
achieved	O
significant	O
success	O
in	O
classifying	O
argumentative	NLP-term
relations	NLP-term
between	O
statements	O
(	O
support	O
,	O
attack	O
,	O
and	O
neutral	O
),	O
we	O
have	O
a	O
limited	O
computational	O
understanding	O
of	O
logical	O
mechanisms	O
that	O
constitute	O
those	O
relations	O
.	O

On	O
the	O
other	O
hand	O
,	O
earlier	O
studies	O
use	O
rather	O
simple	O
lexical	NLP-term
features	NLP-term
missing	O
logical	O
relations	O
between	O
statements	O
.	O

To	O
overcome	O
these	O
limitations	O
,	O
our	O
work	O
classifies	O
argumentative	NLP-term
relations	NLP-term
based	O
on	O
four	O
logical	O
and	O
theory	O
-	O
informed	O
mechanisms	O
between	O
two	O
statements	O
,	O
namely	O
,	O
(	O
i	O
)	O
factual	NLP-term
consistency	NLP-term
(	O
ii	O
)	O
sentiment	NLP-term
coherence	NLP-term
(	O
iii	O
)	O
causal	O
relation	O
,	O
and	O
(	O
iv	O
)	O
normative	O
relation	O
.	O

To	O
better	O
understand	O
the	O
root	O
of	O
the	O
under	O
-	O
translation	O
of	O
negation	O
,	O
we	O
study	O
the	O
model	O
’	O
s	O
information	O
flow	O
and	O
training	AI/ML/DL-term
data	AI/ML/DL-term
.	O

We	O
explore	O
multiple	O
model	O
architectures	O
that	O
allow	O
us	O
to	O
exploit	O
the	O
rich	O
syntactic	O
and	O
semantic	O
annotations	O
contained	O
in	O
the	O
Universal	NLP-dataset
Decompositional	NLP-dataset
Semantics	NLP-dataset
(	NLP-dataset
UDS	NLP-dataset
)	NLP-dataset
dataset	Miscellaneous-term
jointly	O
parsing	O
Universal	NLP-term
Dependencies	NLP-term
and	O
UDS	O
to	O
obtain	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
in	O
both	O
formalisms	O
.	O

We	O
explore	O
multiple	O
model	O
architectures	O
that	O
allow	O
us	O
to	O
exploit	O
the	O
rich	O
syntactic	O
and	O
semantic	O
annotations	O
contained	O
in	O
the	O
Universal	NLP-dataset
Decompositional	NLP-dataset
Semantics	NLP-dataset
(	NLP-dataset
UDS	NLP-dataset
)	NLP-dataset
dataset	Miscellaneous-term
jointly	O
parsing	O
Universal	NLP-term
Dependencies	NLP-term
and	O
UDS	O
to	O
obtain	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
in	O
both	O
formalisms	O
.	O

We	O
explore	O
multiple	O
model	O
architectures	O
that	O
allow	O
us	O
to	O
exploit	O
the	O
rich	O
syntactic	O
and	O
semantic	O
annotations	O
contained	O
in	O
the	O
Universal	NLP-dataset
Decompositional	NLP-dataset
Semantics	NLP-dataset
(	NLP-dataset
UDS	NLP-dataset
)	NLP-dataset
dataset	Miscellaneous-term
jointly	O
parsing	O
Universal	NLP-term
Dependencies	NLP-term
and	O
UDS	O
to	O
obtain	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
in	O
both	O
formalisms	O
.	O

Traditional	O
text	O
overlap	O
based	O
metrics	O
such	O
as	O
ROUGE	O
fail	O
to	O
achieve	O
this	O
because	O
they	O
are	O
limited	O
to	O
matching	O
tokens	O
,	O
either	O
lexically	O
or	O
via	O
embeddings	NLP-term
.	O

QA	O
-	O
based	O
methods	O
directly	O
measure	O
a	O
summary	O
’	O
s	O
information	O
overlap	O
with	O
a	O
reference	O
,	O
making	O
them	O
fundamentally	O
different	O
than	O
text	NLP-term
overlap	NLP-term
metrics	NLP-term
.	O

QAEval	O
outperforms	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
metrics	O
on	O
most	O
evaluations	O
using	O
benchmark	O
datasets	Miscellaneous-term
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
etitive	O
on	O
others	O
due	O
to	O
limitations	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O

To	O
this	O
end	O
,	O
we	O
propose	O
QED	O
a	O
linguistically	NLP-term
informed	NLP-term
extensible	Miscellaneous-term
framework	Miscellaneous-term
for	O
explanations	O
in	O
question	O
answering	O
QED	O

To	O
this	O
end	O
,	O
we	O
propose	O
QED	O
a	O
linguistically	NLP-term
informed	NLP-term
extensible	Miscellaneous-term
framework	Miscellaneous-term
for	O
explanations	O
in	O
question	O
answering	O
QED	O

We	O
describe	O
and	O
publicly	O
release	O
an	O
expert	Miscellaneous-term
-	Miscellaneous-term
annotated	Miscellaneous-term
dataset	Miscellaneous-term
of	O
QED	O
explanations	O
built	O
upon	O
a	O
subset	O
of	O
the	O
Google	NLP-dataset
Natural	NLP-dataset
Questions	NLP-dataset
dataset	O
,	O
and	O
report	O
baseline	O
models	O
on	O
two	O
tasks	O
—	O
post	O
-	O
hoc	O
explanation	O
generation	O
given	O
an	O
answer	O
,	O
and	O
joint	O
question	O
answering	O
explanation	O
generation	O
ion	O
.	O

We	O
describe	O
and	O
publicly	O
release	O
an	O
expert	Miscellaneous-term
-	Miscellaneous-term
annotated	Miscellaneous-term
dataset	Miscellaneous-term
of	O
QED	O
explanations	O
built	O
upon	O
a	O
subset	O
of	O
the	O
Google	NLP-dataset
Natural	NLP-dataset
Questions	NLP-dataset
dataset	O
,	O
and	O
report	O
baseline	O
models	O
on	O
two	O
tasks	O
—	O
post	O
-	O
hoc	O
explanation	O
generation	O
given	O
an	O
answer	O
,	O
and	O
joint	O
question	O
answering	O
explanation	O
generation	O
ion	O
.	O

Experiments	O
show	O
that	O
(	O
i	O
)	O
Soloist	O
creates	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
on	O
well	O
-	O
studied	O
task	O
-	O
oriented	O
dialog	O
benchmarks	O
,	O
including	O
CamRest676	NLP-dataset
and	O
MultiWOZ	NLP-dataset
Soloist	O
the	O
few	O
-	O
shot	O
fine	O
-	O
tuning	O
settings	O
,	O
Soloist	O
significantly	O
outperforms	O
existing	O
methods	O
;	O
and	O
(	O
iii	O
)	O
the	O
use	O
of	O
machine	O
teaching	O
substantially	O
reduces	O
the	O
labeling	O
cost	O
of	O
fine	O
-	O
tuning	O
.	O

Experiments	O
show	O
that	O
(	O
i	O
)	O
Soloist	O
creates	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
on	O
well	O
-	O
studied	O
task	O
-	O
oriented	O
dialog	O
benchmarks	O
,	O
including	O
CamRest676	NLP-dataset
and	O
MultiWOZ	NLP-dataset
Soloist	O
the	O
few	O
-	O
shot	O
fine	O
-	O
tuning	O
settings	O
,	O
Soloist	O
significantly	O
outperforms	O
existing	O
methods	O
;	O
and	O
(	O
iii	O
)	O
the	O
use	O
of	O
machine	O
teaching	O
substantially	O
reduces	O
the	O
labeling	O
cost	O
of	O
fine	O
-	O
tuning	O
.	O

Pre	O
-	O
trained	O
language	O
models	O
(	O
LMs	O
)	O
encode	O
rich	O
information	O
about	O
linguistic	NLP-term
structure	NLP-term
but	O
their	O
knowledge	O
about	O
lexical	O
polysemy	O
remains	O
unclear	O
.	O

We	O
propose	O
a	O
novel	Miscellaneous-term
experimental	Miscellaneous-term
setup	Miscellaneous-term
for	O
analyzing	O
this	O
knowledge	O
in	O
LMs	O
specifically	O
trained	O
for	O
different	O
languages	O
(	O
English	O
,	O
French	O
,	O
Spanish	O
,	O
and	O
Greek	O
)	O
and	O
in	O
multilingual	O
BERT	O
.	O

Polysemy	O
-	O
related	O
information	O
is	O
more	O
clearly	O
present	O
in	O
English	NLP-term
BERT	NLP-term
embeddings	NLP-term
but	O
models	O
in	O
other	O
languages	O
also	O
manage	O
to	O
establish	O
relevant	O
distinctions	O
between	O
words	O
at	O
different	O
polysemy	O
levels	O
.	O

These	O
classifiers	O
apply	O
to	O
spatial	O
regions	O
(	O
events	O
)	O
and	O
NES	O
derives	O
its	O
semantic	NLP-term
structure	NLP-term
classifier	O
ge	O
by	O
routing	O
events	O
to	O
different	O
classifier	O
argument	O
inputs	O
via	O
soft	O
attention	O
NES	O

NES	O
offers	O
stronger	O
generalization	O
capability	O
than	O
standard	O
function	O
-	O
based	O
compositional	O
frameworks	O
,	O
while	O
improving	O
accuracy	O
over	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
neural	O
methods	O
on	O
real	O
-	O
world	O
language	O
tasks	O
.	O

We	O
introduce	O
a	O
theoretical	Miscellaneous-term
framework	Miscellaneous-term
for	O
understanding	O
and	O
predicting	O
the	O
complexity	Miscellaneous-term
of	O
sequence	O
classification	O
tasks	O
,	O
using	O
a	O
novel	O
extension	O
of	O
the	O
theory	O
of	O
Boolean	O
function	O
sensitivity	O
.	O

We	O
then	O
estimate	O
sensitivity	O
on	O
15	O
NLP	O
tasks	O
,	O
finding	O
that	O
sensitivity	O
is	O
higher	O
on	O
challenging	O
tasks	O
collected	O
in	O
GLUE	NLP-dataset
than	O
on	O
simple	O
text	O
classification	O
tasks	O
,	O
and	O
that	O
sensitivity	O
predicts	O
the	O
performance	O
both	O
of	O
simple	O
lexical	O
classifiers	O
and	O
of	O
vanilla	O
BiLSTMs	O
without	O
pretrained	NLP-term
contextualized	NLP-term
embeddings	NLP-term
.	O

We	O
then	O
estimate	O
sensitivity	O
on	O
15	O
NLP	O
tasks	O
,	O
finding	O
that	O
sensitivity	O
is	O
higher	O
on	O
challenging	O
tasks	O
collected	O
in	O
GLUE	NLP-dataset
than	O
on	O
simple	O
text	O
classification	O
tasks	O
,	O
and	O
that	O
sensitivity	O
predicts	O
the	O
performance	O
both	O
of	O
simple	O
lexical	O
classifiers	O
and	O
of	O
vanilla	O
BiLSTMs	O
without	O
pretrained	NLP-term
contextualized	NLP-term
embeddings	NLP-term
.	O

Named	O
Entity	O
Recognition	O
(	O
NER	O
)	O
is	O
a	O
fundamental	O
NLP	O
task	O
,	O
commonly	O
formulated	O
as	O
classification	O
over	O
a	O
sequence	NLP-term
of	NLP-term
tokens	NLP-term
.	O

Morphologically	NLP-term
rich	NLP-term
languages	NLP-term
(	NLP-term
MRLs	NLP-term
)	NLP-term
pose	O
a	O
challenge	O
to	O
this	O
basic	O
formulation	O
,	O
as	O
the	O
boundaries	O
of	O
named	NLP-term
entities	NLP-term
do	O
not	O
necessarily	O
coincide	O
with	O
token	O
boundaries	O
,	O
rather	O
,	O
they	O
respect	O
morphological	O
boundaries	O
.	O

To	O
address	O
NER	O
in	O
MRLs	NLP-term
we	O
then	O
need	O
to	O
answer	O
two	O
fundamental	O
questions	O
,	O
namely	O
,	O
what	O
are	O
the	O
basic	O
units	O
to	O
be	O
labeled	O
,	O
and	O
how	O
can	O
these	O
units	O
be	O
detected	O
and	O
classified	O
in	O
realistic	O
settings	O
(	O
i	O
.	O
e	O
.,	O
where	O
no	O
gold	O
morphology	O
is	O
available	O
).	O

We	O
argue	O
that	O
this	O
modeling	O
choice	O
is	O
insufficiently	O
expressive	O
for	O
dealing	O
with	O
the	O
complexity	O
of	O
natural	Miscellaneous-term
language	Miscellaneous-term
questions	Miscellaneous-term
.	O

This	O
greatly	O
improves	O
OpenQA	O
retrieval	O
on	O
Natural	NLP-dataset
Questions	NLP-dataset
SQuAD	NLP-dataset
and	O
TriviaQA	NLP-dataset
and	O
the	O
resulting	O
system	O
attains	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
OpenQA	O
ive	O
OpenQA	O
performance	O
on	O
all	O
three	O
datasets	O
.	O

This	O
greatly	O
improves	O
OpenQA	O
retrieval	O
on	O
Natural	NLP-dataset
Questions	NLP-dataset
SQuAD	NLP-dataset
and	O
TriviaQA	NLP-dataset
and	O
the	O
resulting	O
system	O
attains	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
OpenQA	O
ive	O
OpenQA	O
performance	O
on	O
all	O
three	O
datasets	O
.	O

This	O
paper	O
presents	O
a	O
novel	O
unsupervised	O
abstractive	O
summarization	O
method	O
for	O
opinionated	NLP-term
texts	NLP-term
.	O

While	O
the	O
basic	O
variational	O
autoencoder	O
-	O
based	O
models	O
assume	O
a	O
unimodal	O
Gaussian	O
prior	O
for	O
the	O
latent	O
code	O
of	O
sentences	O
,	O
we	O
alternate	O
it	O
with	O
a	O
recursive	AI/ML/DL-term
Gaussian	AI/ML/DL-term
mixture	AI/ML/DL-term
where	O
each	O
mixture	O
component	O
corresponds	O
to	O
the	O
latent	O
code	O
of	O
a	O
topic	O
sentence	O
and	O
is	O
mixed	O
by	O
a	O
tree	O
-	O
structured	O
topic	O
distribution	O
.	O

By	O
decoding	O
each	O
Gaussian	AI/ML/DL-term
component	AI/ML/DL-term
we	O
generate	O
sentences	O
with	O
tree	O
-	O
structured	O
topic	O
guidance	O
,	O
where	O
the	O
root	O
sentence	O
conveys	O
generic	O
content	O
,	O
and	O
the	O
leaf	O
sentences	O
describe	O
specific	O
topics	O
.	O

Furthermore	O
,	O
we	O
demonstrate	O
that	O
the	O
variance	O
of	O
latent	AI/ML/DL-term
Gaussians	AI/ML/DL-term
represents	O
the	O
granularity	O
of	O
sentences	O
,	O
analogous	O
to	O
Gaussian	O
word	O
embedding	O
(	O
Vilnis	O
and	O
McCallum	O
,	O
2015	O
).	O

We	O
then	O
examine	O
methods	O
to	O
calibrate	O
such	O
models	O
to	O
make	O
their	O
confidence	O
scores	O
correlate	O
better	O
with	O
the	O
likelihood	O
of	O
correctness	O
through	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuning	AI/ML/DL-term
post	O
-	O
hoc	O
probability	O
modification	O
,	O
or	O
adjustment	O
of	O
the	O
predicted	O
outputs	O
or	O
inputs	O
.	O

Experiments	O
on	O
a	O
diverse	O
range	O
of	O
datasets	Miscellaneous-term
demonstrate	O
the	O
effectiveness	O
of	O
our	O
methods	O
.	O

While	O
various	O
task	O
settings	O
have	O
been	O
proposed	O
in	O
existing	O
literature	O
,	O
they	O
mostly	O
focus	O
on	O
creating	O
common	O
ground	O
under	O
a	O
static	O
context	O
and	O
ignore	O
the	O
aspect	O
of	O
maintaining	O
them	O
overtime	O
under	O
dynamic	NLP-term
context	NLP-term
.	O

Based	O
on	O
our	O
minimal	AI/ML/DL-term
task	AI/ML/DL-term
formulation	AI/ML/DL-term
we	O
collected	O
a	O
large	O
-	O
scale	O
dataset	Miscellaneous-term
of	O
5	O
,	O
617	O
dialogues	O
to	O
enable	O
fine	O
-	O
grained	O
evaluation	O
and	O
analysis	O
of	O
various	O
dialogue	O
systems	O
.	O

Based	O
on	O
our	O
minimal	AI/ML/DL-term
task	AI/ML/DL-term
formulation	AI/ML/DL-term
we	O
collected	O
a	O
large	O
-	O
scale	O
dataset	Miscellaneous-term
of	O
5	O
,	O
617	O
dialogues	O
to	O
enable	O
fine	O
-	O
grained	O
evaluation	O
and	O
analysis	O
of	O
various	O
dialogue	O
systems	O
.	O

Through	O
our	O
dataset	Miscellaneous-term
analyses	O
,	O
we	O
highlight	O
novel	O
challenges	O
introduced	O
in	O
our	O
setting	O
,	O
such	O
as	O
the	O
usage	O
of	O
complex	O
spatio	AI/ML/DL-term
-	AI/ML/DL-term
temporal	AI/ML/DL-term
expressions	AI/ML/DL-term
to	O
create	O
and	O
maintain	O
common	O
ground	O
.	O

Through	O
our	O
dataset	Miscellaneous-term
analyses	O
,	O
we	O
highlight	O
novel	O
challenges	O
introduced	O
in	O
our	O
setting	O
,	O
such	O
as	O
the	O
usage	O
of	O
complex	O
spatio	AI/ML/DL-term
-	AI/ML/DL-term
temporal	AI/ML/DL-term
expressions	AI/ML/DL-term
to	O
create	O
and	O
maintain	O
common	O
ground	O
.	O

In	O
this	O
paper	O
we	O
study	O
the	O
question	O
:	O
Are	O
Pretrained	O
Language	O
Models	O
(	O
PLMs	O
)	O
consistent	O
with	O
respect	O
to	O
factual	O
knowledge	O
?	O
To	O
this	O
end	O
,	O
we	O
create	O
ParaRel	NLP-dataset
a	O
high	O
-	O
quality	O
resource	O
of	O
cloze	O
-	O
style	O
query	O
English	O
paraphrases	O
.	O

Using	O
ParaRel	NLP-dataset
we	O
show	O
that	O
the	O
consistency	O
of	O
all	O
PLMs	O
we	O
experiment	O
with	O
is	O
poor	O
—	O
though	O
with	O
high	O
variance	O
between	O
relations	O
.	O

Recent	O
advancements	O
in	O
open	O
-	O
domain	O
question	O
answering	O
(	O
ODQA	O
)	O
that	O
is	O
,	O
finding	O
answers	O
from	O
large	O
open	Miscellaneous-term
-	Miscellaneous-term
domain	Miscellaneous-term
corpus	Miscellaneous-term
like	O
Wikipedia	O
,	O
have	O
led	O
to	O
human	O
-	O
level	O
performance	O
on	O
many	O
datasets	O
.	O

This	O
work	O
provides	O
a	O
comprehensive	O
and	O
quantitative	O
analysis	O
about	O
the	O
difficulty	O
of	O
Book	O
QA	O
(	O
1	O
)	O
We	O
benchmark	O
the	O
research	O
on	O
the	O
NarrativeQA	NLP-dataset
dataset	O
with	O
extensive	O
experiments	O
with	O
cutting	O
-	O
edge	O
ODQA	O
techniques	O
.	O

This	O
quantifies	O
the	O
challenges	O
Book	O
QA	O
poses	O
,	O
as	O
well	O
as	O
advances	O
the	O
published	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
with	O
a	O
∼	O
7	O
\\%	O
absolute	O
improvement	O
on	O
ROUGE	O
-	O
L	O
.	O

We	O
study	O
whether	O
assertions	O
enable	O
a	O
system	O
to	O
emulate	O
representations	O
preserving	O
semantic	NLP-term
relations	NLP-term
like	O
equivalence	O
.	O

We	O
find	O
that	O
assertions	O
enable	O
semantic	NLP-term
emulation	NLP-term
of	O
languages	O
that	O
satisfy	O
a	O
strong	O
notion	O
of	O
semantic	O
transparency	O
.	O

Finally	O
,	O
we	O
discuss	O
differences	O
between	O
our	O
formal	O
model	O
and	O
natural	O
language	O
,	O
exploring	O
how	O
our	O
results	O
generalize	O
to	O
a	O
modal	O
setting	O
and	O
other	O
semantic	NLP-term
relations	NLP-term
.	O

Together	O
,	O
our	O
results	O
suggest	O
that	O
assertions	O
in	O
code	O
or	O
language	O
do	O
not	O
provide	O
sufficient	O
signal	O
to	O
fully	O
emulate	O
semantic	NLP-term
representations	NLP-term
.	O

Pre	O
-	O
trained	O
Transformer	O
-	O
based	O
models	O
have	O
achieved	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
for	O
various	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
tasks	O
.	O

However	O
,	O
these	O
models	O
often	O
have	O
billions	O
of	O
parameters	AI/ML/DL-term
and	O
thus	O
are	O
too	O
resource	O
-	O
hungry	O
and	O
computation	O
-	O
intensive	O
to	O
suit	O
low	O
-	O
capability	O
devices	O
or	O
applications	O
with	O
strict	O
latency	O
requirements	O
.	O

Open	O
-	O
domain	O
Question	O
Answering	O
models	O
that	O
directly	O
leverage	O
question	NLP-term
-	NLP-term
answer	NLP-term
(	NLP-term
QA	NLP-term
)	NLP-term
pairs	NLP-term
such	O
as	O
closed	O
-	O
book	O
QA	O
(	O
CBQA	O
)	O
models	O
and	O
QA	O
-	O
pair	O
retrievers	O
show	O
promise	O
in	O
terms	O
of	O
speed	O
and	O
memory	O
compared	O
with	O
conventional	O
models	O
which	O
retrieve	O
and	O
read	O
from	O
text	O
corpora	O
.	O

To	O
facilitate	O
improved	O
QA	O
-	O
pair	O
models	O
,	O
we	O
introduce	O
Probably	NLP-dataset
Asked	NLP-dataset
Questions	NLP-dataset
(	NLP-dataset
PAQ	NLP-dataset
)	NLP-dataset
a	O
very	O
large	O
resource	O
of	O
65M	O
automatically	O
generated	O
QA	O
-	O
pairs	O
.	O

We	O
introduce	O
a	O
new	O
QA	O
-	O
pair	O
retriever	O
RePAQ	O
PAQ	NLP-dataset
complement	O
PAQ	O
.	O

We	O
find	O
that	O
PAQ	NLP-dataset
preempts	O
and	O
caches	O
test	O
questions	O
,	O
enabling	O
RePAQ	O
to	O
match	O
the	O
accuracy	O
of	O
recent	O
retrieve	O
-	O
and	O
-	O
read	O
models	O
,	O
whilst	O
being	O
significantly	O
faster	O
.	O

Using	O
PAQ	NLP-dataset
we	O
train	O
CBQA	O
models	O
which	O
outperform	O
comparable	O
baselines	O
by	O
5	O
\\%,	O
but	O
trail	O
RePAQ	O
RePAQ	O
r	O
15	O
\\%,	O
indicating	O
the	O
effectiveness	O
of	O
explicit	O
retrieval	O
.	O

This	O
enables	O
RePAQ	O
to	O
“	O
back	O
-	O
off	O
”	O
to	O
a	O
more	O
expensive	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
a	O
combined	O
system	O
which	O
is	O
both	O
more	O
accurate	O
and	O
2x	O
faster	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
alone	O
.	O

We	O
analyze	O
our	O
datasets	O
and	O
conduct	O
an	O
extensive	O
empirical	O
evaluation	O
of	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
across	O
both	O
supervised	O
and	O
transfer	O
learning	O
settings	O
.	O

We	O
introduce	O
ParsiNLU	NLP-dataset
the	O
first	O
benchmark	O
in	O
Persian	O
language	O
that	O
includes	O
a	O
range	O
of	O
language	O
understanding	O
tasks	O
—	O
reading	O
comprehension	O
textual	O
entailment	O
and	O
so	O
on	O
.	O

Additionally	O
,	O
we	O
present	O
the	O
first	O
results	O
on	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
monolingual	NLP-term
and	O
multilingual	O
pre	O
-	O
trained	O
language	O
models	O
on	O
this	O
benchmark	O
and	O
compare	O
them	O
with	O
human	O
performance	O
,	O
which	O
provides	O
valuable	O
insights	O
into	O
our	O
ability	O
to	O
tackle	O
natural	O
language	O
understanding	O
challenges	O
in	O
Persian	O
.	O

Additionally	O
,	O
we	O
present	O
the	O
first	O
results	O
on	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
monolingual	NLP-term
and	O
multilingual	O
pre	O
-	O
trained	O
language	O
models	O
on	O
this	O
benchmark	O
and	O
compare	O
them	O
with	O
human	O
performance	O
,	O
which	O
provides	O
valuable	O
insights	O
into	O
our	O
ability	O
to	O
tackle	O
natural	O
language	O
understanding	O
challenges	O
in	O
Persian	O
.	O

We	O
hope	O
ParsiNLU	NLP-dataset
fosters	O
further	O
research	O
and	O
advances	O
in	O
Persian	O
language	O
understanding	O
1	O
.	O

Dialog	NLP-term
acts	NLP-term
can	O
be	O
interpreted	O
as	O
the	O
atomic	O
units	O
of	O
a	O
conversation	O
,	O
more	O
fine	O
-	O
grained	O
than	O
utterances	O
,	O
characterized	O
by	O
a	O
specific	O
communicative	O
function	O
.	O

The	O
ability	O
to	O
structure	O
a	O
conversational	O
transcript	O
as	O
a	O
sequence	O
of	O
dialog	NLP-term
acts	NLP-term
dialog	O
act	O
recognition	O
including	O
the	O
segmentation	O
is	O
critical	O
for	O
understanding	O
dialog	O
.	O

We	O
apply	O
two	O
pre	O
-	O
trained	O
transformer	O
models	O
XLNet	O
and	O
Longformer	O
to	O
this	O
task	O
in	O
English	O
and	O
achieve	O
strong	O
results	O
on	O
Switchboard	NLP-dataset
Dialog	NLP-dataset
Act	NLP-dataset
and	O
Meeting	NLP-dataset
Recorder	NLP-dataset
Dialog	NLP-dataset
Act	NLP-dataset
corpora	O
with	O
dialog	O
act	O
segmentation	O
error	O
rates	O
(	O
DSER	O
)	O
of	O
8	O
.	O
4	O
\\%	O
and	O
14	O
.	O
2	O
\\%	O
.	O

We	O
propose	O
a	O
technique	O
to	O
wug	O
-	O
test	O
CNNs	O
trained	O
on	O
speech	O
and	O
,	O
based	O
on	O
four	O
generative	O
tests	O
,	O
argue	O
that	O
the	O
network	O
learns	O
to	O
represent	O
an	O
identity	O
-	O
based	O
pattern	O
in	O
its	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
.	O

By	O
manipulating	O
only	O
two	O
categorical	O
variables	O
in	O
the	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
we	O
can	O
actively	O
turn	O
an	O
unreduplicated	O
form	O
into	O
a	O
reduplicated	O
form	O
with	O
no	O
other	O
substantial	O
changes	O
to	O
the	O
output	O
in	O
the	O
majority	O
of	O
cases	O
.	O

Our	O
framework	O
can	O
be	O
applied	O
to	O
control	O
important	O
attributes	O
of	O
summarization	O
including	O
length	O
,	O
covered	O
entities	NLP-term
and	O
abstractiveness	O
,	O
as	O
we	O
devise	O
specific	O
constraints	O
for	O
each	O
of	O
these	O
aspects	O
.	O

Free	NLP-term
-	NLP-term
order	NLP-term
case	NLP-term
-	NLP-term
marking	NLP-term
languages	NLP-term
such	O
as	O
Russian	O
,	O
Latin	O
,	O
or	O
Tamil	O
,	O
have	O
proved	O
more	O
challenging	O
than	O
fixed	O
-	O
order	O
languages	O
for	O
the	O
tasks	O
of	O
syntactic	O
parsing	O
and	O
subject	O
-	O
verb	O
agreement	O
prediction	O
.	O

In	O
this	O
work	O
,	O
we	O
investigate	O
whether	O
this	O
class	O
of	O
languages	O
is	O
also	O
more	O
difficult	O
to	O
translate	O
by	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
Neural	O
Machine	O
Translation	O
(	O
NMT	O
)	O
models	O
.	O

Using	O
a	O
variety	O
of	O
synthetic	O
languages	O
and	O
a	O
newly	O
introduced	O
translation	O
challenge	O
set	O
,	O
we	O
find	O
that	O
word	O
order	O
flexibility	O
in	O
the	O
source	O
language	O
only	O
leads	O
to	O
a	O
very	O
small	O
loss	O
of	O
NMT	O
quality	O
,	O
even	O
though	O
the	O
core	O
verb	O
arguments	O
become	O
impossible	O
to	O
disambiguate	O
in	O
sentences	O
without	O
semantic	NLP-term
cues	NLP-term
.	O

We	O
instantiate	O
this	O
general	O
framework	O
to	O
four	O
special	O
cases	O
:	O
long	AI/ML/DL-term
path	AI/ML/DL-term
path	AI/ML/DL-term
-	AI/ML/DL-term
to	AI/ML/DL-term
-	AI/ML/DL-term
path	AI/ML/DL-term
router	AI/ML/DL-term
and	O
graph	AI/ML/DL-term
-	AI/ML/DL-term
node	AI/ML/DL-term
-	AI/ML/DL-term
path	AI/ML/DL-term
.	O

The	O
code	Miscellaneous-term
will	O
be	O
released	O
via	O
the	O
public	O
GitHub	O
repository	O
.	O

Experimentally	O
,	O
we	O
find	O
that	O
it	O
meets	O
or	O
exceeds	O
performance	O
of	O
strong	O
and	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
across	O
a	O
variety	O
of	O
languages	O
,	O
annotation	O
scenarios	O
,	O
and	O
amounts	O
of	O
labeled	O
data	O
.	O

We	O
introduce	O
Generative	O
Spoken	O
Language	O
Modeling	O
the	O
task	O
of	O
learning	O
the	O
acoustic	NLP-term
and	O
linguistic	NLP-term
characteristics	NLP-term
acoustic	NLP-term
uage	O
from	O
raw	O
audio	O
(	O
no	O
text	O
,	O
no	O
labels	O
),	O
and	O
a	O
set	O
of	O
metrics	O
to	O
automatically	O
evaluate	O
the	O
learned	O
representations	O
at	O
acoustic	O
and	O
linguistic	NLP-term
levels	NLP-term
for	O
both	O
encoding	AI/ML/DL-term
and	O
generation	AI/ML/DL-term
.	O

We	O
introduce	O
Generative	O
Spoken	O
Language	O
Modeling	O
the	O
task	O
of	O
learning	O
the	O
acoustic	NLP-term
and	O
linguistic	NLP-term
characteristics	NLP-term
acoustic	NLP-term
uage	O
from	O
raw	O
audio	O
(	O
no	O
text	O
,	O
no	O
labels	O
),	O
and	O
a	O
set	O
of	O
metrics	O
to	O
automatically	O
evaluate	O
the	O
learned	O
representations	O
at	O
acoustic	O
and	O
linguistic	NLP-term
levels	NLP-term
for	O
both	O
encoding	AI/ML/DL-term
and	O
generation	AI/ML/DL-term
.	O

We	O
set	O
up	O
baseline	O
systems	O
consisting	O
of	O
a	O
discrete	O
speech	O
encoder	O
(	O
returning	O
pseudo	NLP-term
-	NLP-term
text	NLP-term
units	O
),	O
a	O
generative	O
language	O
model	O
(	O
trained	O
on	O
pseudo	NLP-term
-	NLP-term
text	NLP-term
,	O
and	O
a	O
speech	O
decoder	O
(	O
generating	O
a	O
waveform	NLP-term
pseudo	NLP-term
-	NLP-term
text	NLP-term
trained	AI/ML/DL-term
l	O
trained	O
without	O
supervision	AI/ML/DL-term
and	O
validate	O
the	O
proposed	O
metrics	O
with	O
human	O
evaluation	O
.	O

We	O
set	O
up	O
baseline	O
systems	O
consisting	O
of	O
a	O
discrete	O
speech	O
encoder	O
(	O
returning	O
pseudo	NLP-term
-	NLP-term
text	NLP-term
units	O
),	O
a	O
generative	O
language	O
model	O
(	O
trained	O
on	O
pseudo	NLP-term
-	NLP-term
text	NLP-term
,	O
and	O
a	O
speech	O
decoder	O
(	O
generating	O
a	O
waveform	NLP-term
pseudo	NLP-term
-	NLP-term
text	NLP-term
trained	AI/ML/DL-term
l	O
trained	O
without	O
supervision	AI/ML/DL-term
and	O
validate	O
the	O
proposed	O
metrics	O
with	O
human	O
evaluation	O
.	O

Across	O
3	O
speech	O
encoders	O
(	O
CPC	O
wav2vec	O
2	O
.	O
0	O
HuBERT	O
,	O
we	O
find	O
that	O
the	O
number	O
of	O
discrete	O
units	O
(	O
50	O
,	O
100	O
,	O
or	O
200	O
)	O
matters	O
in	O
a	O
task	Miscellaneous-term
-	Miscellaneous-term
dependent	Miscellaneous-term
and	O
encoder	AI/ML/DL-term
-	AI/ML/DL-term
dependent	AI/ML/DL-term
way	O
,	O
and	O
that	O
some	O
combinations	O
approach	O
text	O
-	O
based	O
systems	O
.	O
1	O
.	O

Across	O
3	O
speech	O
encoders	O
(	O
CPC	O
wav2vec	O
2	O
.	O
0	O
HuBERT	O
,	O
we	O
find	O
that	O
the	O
number	O
of	O
discrete	O
units	O
(	O
50	O
,	O
100	O
,	O
or	O
200	O
)	O
matters	O
in	O
a	O
task	Miscellaneous-term
-	Miscellaneous-term
dependent	Miscellaneous-term
and	O
encoder	AI/ML/DL-term
-	AI/ML/DL-term
dependent	AI/ML/DL-term
way	O
,	O
and	O
that	O
some	O
combinations	O
approach	O
text	O
-	O
based	O
systems	O
.	O
1	O
.	O

Recent	O
improvements	O
in	O
the	O
predictive	O
quality	O
of	O
natural	O
language	O
processing	O
systems	O
are	O
often	O
dependent	O
on	O
a	O
substantial	O
increase	O
in	O
the	O
number	O
of	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

We	O
choose	O
to	O
address	O
this	O
problem	O
from	O
a	O
causal	O
perspective	O
,	O
attempting	O
to	O
estimate	O
the	O
average	AI/ML/DL-term
treatment	AI/ML/DL-term
effect	AI/ML/DL-term
(	AI/ML/DL-term
ATE	AI/ML/DL-term
)	AI/ML/DL-term
of	O
a	O
model	O
component	O
,	O
such	O
as	O
a	O
single	O
layer	O
,	O
on	O
the	O
model	O
’	O
s	O
predictions	O
.	O

We	O
describe	O
a	O
parser	O
of	O
English	O
effectuated	O
by	O
biologically	O
plausible	O
neurons	O
and	O
synapses	O
,	O
and	O
implemented	O
through	O
the	O
Assembly	O
Calculus	O
a	O
recently	O
proposed	O
computational	Miscellaneous-term
framework	Miscellaneous-term
for	O
cognitive	AI/ML/DL-term
function	AI/ML/DL-term
.	O

We	O
describe	O
a	O
parser	O
of	O
English	O
effectuated	O
by	O
biologically	O
plausible	O
neurons	O
and	O
synapses	O
,	O
and	O
implemented	O
through	O
the	O
Assembly	O
Calculus	O
a	O
recently	O
proposed	O
computational	Miscellaneous-term
framework	Miscellaneous-term
for	O
cognitive	AI/ML/DL-term
function	AI/ML/DL-term
.	O

Progress	O
in	O
cross	O
-	O
lingual	O
modeling	O
depends	O
on	O
challenging	O
,	O
realistic	O
,	O
and	O
diverse	O
evaluation	Miscellaneous-term
sets	Miscellaneous-term
.	O

We	O
introduce	O
Multilingual	NLP-dataset
Knowledge	NLP-dataset
Questions	NLP-dataset
and	NLP-dataset
Answers	NLP-dataset
(	NLP-dataset
MKQA	NLP-dataset
)	NLP-dataset
an	O
open	O
-	O
domain	O
question	O
answering	O
evaluation	Miscellaneous-term
set	Miscellaneous-term
comprising	O
10k	O
question	O
-	O
answer	O
pairs	O
aligned	O
across	O
26	O
typologically	O
diverse	O
languages	O
(	O
260k	O
question	O
-	O
answer	O
pairs	O
in	O
total	O
).	O

We	O
introduce	O
Multilingual	NLP-dataset
Knowledge	NLP-dataset
Questions	NLP-dataset
and	NLP-dataset
Answers	NLP-dataset
(	NLP-dataset
MKQA	NLP-dataset
)	NLP-dataset
an	O
open	O
-	O
domain	O
question	O
answering	O
evaluation	Miscellaneous-term
set	Miscellaneous-term
comprising	O
10k	O
question	O
-	O
answer	O
pairs	O
aligned	O
across	O
26	O
typologically	O
diverse	O
languages	O
(	O
260k	O
question	O
-	O
answer	O
pairs	O
in	O
total	O
).	O

We	O
benchmark	O
a	O
variety	O
of	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
and	O
baselines	O
for	O
generative	O
and	O
extractive	O
question	O
answering	O
trained	O
on	O
Natural	O
Questions	O
,	O
in	O
zero	O
shot	O
and	O
translation	O
settings	O
.	O

⚠	O
This	O
paper	O
contains	O
prompts	O
and	O
model	O
outputs	O
that	O
are	O
offensive	O
in	O
nature	O
.	O
When	O
trained	O
on	O
large	O
,	O
unfiltered	O
crawls	O
from	O
the	O
Internet	Miscellaneous-term
language	O
models	O
pick	O
up	O
and	O
reproduce	O
all	O
kinds	O
of	O
undesirable	O
biases	O
that	O
can	O
be	O
found	O
in	O
the	O
data	O
:	O
They	O
often	O
generate	O
racist	O
,	O
sexist	O
,	O
violent	O
,	O
or	O
otherwise	O
toxic	O
language	O
.	O

Moreover	O
,	O
the	O
current	O
metrics	O
have	O
complementary	O
strengths	O
and	O
weaknesses	O
:	O
Some	O
emphasize	O
speed	O
,	O
while	O
others	O
make	O
the	O
alignment	O
of	O
graph	Miscellaneous-term
structures	Miscellaneous-term
explicit	O
,	O
at	O
the	O
price	O
of	O
a	O
costly	O
alignment	O
step	O
.	O
In	O
this	O
work	O
we	O
propose	O
new	O
Weisfeiler	O
-	O
Leman	O
AMR	O
similarity	O
metrics	O
that	O
unify	O
the	O
strengths	O
of	O
previous	O
metrics	O
,	O
while	O
mitigating	O
their	O
weaknesses	O
.	O

Furthermore	O
,	O
we	O
introduce	O
a	O
Benchmark	NLP-dataset
for	NLP-dataset
AMR	NLP-dataset
Metrics	NLP-dataset
based	NLP-dataset
on	NLP-dataset
Overt	NLP-dataset
Objectives	NLP-dataset
(	NLP-dataset
Bamboo	NLP-dataset
)	NLP-dataset
the	O
first	O
benchmark	O
to	O
support	O
empirical	O
assessment	O
of	O
graph	NLP-term
-	NLP-term
based	NLP-term
MR	NLP-term
similarity	NLP-term
metrics	NLP-term
Bamboo	NLP-dataset
.	O

Furthermore	O
,	O
we	O
introduce	O
a	O
Benchmark	NLP-dataset
for	NLP-dataset
AMR	NLP-dataset
Metrics	NLP-dataset
based	NLP-dataset
on	NLP-dataset
Overt	NLP-dataset
Objectives	NLP-dataset
(	NLP-dataset
Bamboo	NLP-dataset
)	NLP-dataset
the	O
first	O
benchmark	O
to	O
support	O
empirical	O
assessment	O
of	O
graph	NLP-term
-	NLP-term
based	NLP-term
MR	NLP-term
similarity	NLP-term
metrics	NLP-term
Bamboo	NLP-dataset
.	O

We	O
show	O
the	O
benefits	O
of	O
Bamboo	NLP-dataset
by	O
profiling	O
previous	O
metrics	O
and	O
our	O
own	O
metrics	O
.	O

Our	O
work	O
introduces	O
a	O
new	O
head	O
pruning	O
technique	O
that	O
we	O
term	O
differentiable	AI/ML/DL-technique
subset	AI/ML/DL-technique
pruning	AI/ML/DL-technique
.	O

he	O
importance	O
variables	O
are	O
learned	O
via	O
stochastic	AI/ML/DL-term
gradient	AI/ML/DL-term
descent	AI/ML/DL-term
.	O

e	O
conduct	O
experiments	O
on	O
natural	O
language	O
inference	O
and	O
machine	O
translation	O
we	O
show	O
that	O
differentiable	AI/ML/DL-technique
subset	AI/ML/DL-technique
pruning	AI/ML/DL-technique
performs	O
comparably	O
or	O
better	O
than	O
previous	O
works	O
while	O
offering	O
precise	O
control	O
of	O
the	O
sparsity	O
level	O
.	O

We	O
carry	O
out	O
the	O
largest	O
MQM	O
research	O
study	O
to	O
date	O
,	O
scoring	O
the	O
outputs	O
of	O
top	O
systems	O
from	O
the	O
WMT	NLP-dataset
2020	NLP-dataset
shared	O
task	O
in	O
two	O
language	O
pairs	O
using	O
annotations	O
provided	O
by	O
professional	O
translators	O
with	O
access	O
to	O
full	O
document	O
context	O
.	O

We	O
analyze	O
the	O
resulting	O
data	O
extensively	O
,	O
finding	O
among	O
other	O
results	O
a	O
substantially	O
different	O
ranking	O
of	O
evaluated	O
systems	O
from	O
the	O
one	O
established	O
by	O
the	O
WMT	NLP-term
crowd	NLP-term
workers	NLP-term
exhibiting	O
a	O
clear	O
preference	O
for	O
human	O
over	O
machine	O
output	O
.	O

Surprisingly	O
,	O
we	O
also	O
find	O
that	O
automatic	O
metrics	O
based	O
on	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
embeddings	AI/ML/DL-term
can	O
outperform	O
human	O
crowd	O
workers	O
.	O

We	O
make	O
our	O
corpus	Miscellaneous-term
publicly	O
available	O
for	O
further	O
research	O
.	O

Specifically	O
,	O
we	O
prepend	O
(	O
or	O
prompt	AI/ML/DL-term
target	O
summaries	O
with	O
entity	O
chains	O
—	O
ordered	O
sequences	O
of	O
entities	O
mentioned	O
in	O
the	O
summary	O
.	O

When	O
evaluated	O
on	O
CNN	NLP-dataset
/	NLP-dataset
DailyMail	NLP-dataset
XSum	NLP-dataset
SAMSum	NLP-dataset
and	O
BillSum	NLP-dataset
we	O
demonstrate	O
empirically	O
that	O
the	O
grounded	O
generation	O
with	O
the	O
planning	O
objective	O
improves	O
entity	O
specificity	O
and	O
planning	O
in	O
summaries	O
for	O
all	O
datasets	O
,	O
and	O
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
XSum	NLP-dataset
rmance	O
on	O
XSum	O
and	O
SAMSum	O
in	O
terms	O
of	O
rouge	O
.	O

When	O
evaluated	O
on	O
CNN	NLP-dataset
/	NLP-dataset
DailyMail	NLP-dataset
XSum	NLP-dataset
SAMSum	NLP-dataset
and	O
BillSum	NLP-dataset
we	O
demonstrate	O
empirically	O
that	O
the	O
grounded	O
generation	O
with	O
the	O
planning	O
objective	O
improves	O
entity	O
specificity	O
and	O
planning	O
in	O
summaries	O
for	O
all	O
datasets	O
,	O
and	O
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
XSum	NLP-dataset
rmance	O
on	O
XSum	O
and	O
SAMSum	O
in	O
terms	O
of	O
rouge	O
.	O

Interpretable	AI/ML/DL-term
rationales	AI/ML/DL-term
for	O
model	AI/ML/DL-term
predictions	AI/ML/DL-term
are	O
crucial	O
in	O
practical	O
applications	O
.	O

We	O
develop	O
neural	O
models	O
that	O
possess	O
an	O
interpretable	AI/ML/DL-term
inference	AI/ML/DL-term
process	O
for	O
dependency	O
parsing	O
.	O

Specifically	O
,	O
we	O
propose	O
a	O
variety	O
of	O
psycholinguistic	NLP-term
factors	O
—	O
semantic	NLP-term
distributional	NLP-term
and	O
phonological	NLP-term
that	O
we	O
hypothesize	O
are	O
predictive	O
of	O
lexical	NLP-term
decline	NLP-term
in	O
which	O
words	O
greatly	O
decrease	O
in	O
frequency	O
over	O
time	O
.	O

Moreover	O
,	O
logistic	O
regression	O
analyses	O
show	O
that	O
semantic	NLP-term
and	O
distributional	AI/ML/DL-term
factors	O
are	O
significant	O
in	O
predicting	O
declining	O
words	O
.	O

Moreover	O
,	O
logistic	O
regression	O
analyses	O
show	O
that	O
semantic	NLP-term
and	O
distributional	AI/ML/DL-term
factors	O
are	O
significant	O
in	O
predicting	O
declining	O
words	O
.	O

Further	O
diachronic	O
analysis	O
reveals	O
that	O
declining	O
words	O
tend	O
to	O
decrease	O
in	O
the	O
diversity	O
of	O
their	O
lexical	NLP-term
contexts	NLP-term
over	O
time	O
,	O
gradually	O
narrowing	O
their	O
‘	O
ecological	O
niches	O
’.	O

Idiomatic	NLP-term
expressions	NLP-term
are	O
an	O
integral	O
part	O
of	O
natural	O
language	O
and	O
constantly	O
being	O
added	O
to	O
a	O
language	O
.	O

To	O
address	O
this	O
challenge	O
,	O
we	O
study	O
the	O
task	O
of	O
detecting	O
whether	O
a	O
sentence	O
has	O
an	O
idiomatic	NLP-term
expression	NLP-term
and	O
localizing	O
it	O
when	O
it	O
occurs	O
in	O
a	O
figurative	O
sense	O
.	O

The	O
network	O
effectively	O
fuses	O
contextual	O
and	O
lexical	O
information	O
at	O
different	O
levels	O
using	O
word	O
and	O
sub	NLP-term
-	NLP-term
word	NLP-term
representations	NLP-term
.	O

Empirical	O
evaluations	O
on	O
three	O
of	O
the	O
largest	O
benchmark	O
datasets	Miscellaneous-term
with	O
idiomatic	NLP-term
expressions	NLP-term
of	O
varied	O
syntactic	NLP-term
patterns	NLP-term
and	O
degrees	O
of	O
non	O
-	O
compositionality	O
show	O
that	O
our	O
proposed	O
model	O
achieves	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
.	O

Empirical	O
evaluations	O
on	O
three	O
of	O
the	O
largest	O
benchmark	O
datasets	Miscellaneous-term
with	O
idiomatic	NLP-term
expressions	NLP-term
of	O
varied	O
syntactic	NLP-term
patterns	NLP-term
and	O
degrees	O
of	O
non	O
-	O
compositionality	O
show	O
that	O
our	O
proposed	O
model	O
achieves	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
.	O

A	O
salient	O
feature	O
of	O
the	O
model	O
is	O
its	O
ability	O
to	O
identify	O
idioms	O
unseen	O
during	O
training	O
with	O
gains	O
from	O
1	O
.	O
4	O
\\%	O
to	O
30	O
.	O
8	O
\\%	O
over	O
competitive	O
baselines	O
on	O
the	O
largest	O
dataset	Miscellaneous-term
.	O

This	O
study	O
carries	O
out	O
a	O
systematic	O
intrinsic	O
evaluation	O
of	O
the	O
semantic	NLP-term
representations	NLP-term
learned	O
by	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
pre	O
-	O
trained	O
multimodal	O
Transformers	O
.	O

This	O
study	O
carries	O
out	O
a	O
systematic	O
intrinsic	O
evaluation	O
of	O
the	O
semantic	NLP-term
representations	NLP-term
learned	O
by	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
pre	O
-	O
trained	O
multimodal	O
Transformers	O
.	O

However	O
,	O
the	O
extent	O
to	O
which	O
they	O
align	O
with	O
human	NLP-term
semantic	NLP-term
intuitions	NLP-term
remains	O
unclear	O
.	O

We	O
then	O
evaluate	O
them	O
against	O
the	O
semantic	NLP-term
judgments	NLP-term
provided	O
by	O
human	O
speakers	O
.	O

In	O
line	O
with	O
previous	O
evidence	O
,	O
we	O
observe	O
a	O
generalized	O
advantage	O
of	O
multimodal	AI/ML/DL-term
representations	AI/ML/DL-term
over	O
language	O
-	O
only	O
ones	O
on	O
concrete	O
word	O
pairs	O
,	O
but	O
not	O
on	O
abstract	O
ones	O
.	O

We	O
present	O
methods	O
for	O
calculating	O
a	O
measure	O
of	O
phonotactic	O
complexity	O
bits	O
per	O
phoneme	NLP-term
that	O
permits	O
a	O
straightforward	O
cross	NLP-term
-	NLP-term
linguistic	NLP-term
comparison	O
.	O

When	O
given	O
a	O
word	O
,	O
represented	O
as	O
a	O
sequence	O
of	O
phonemic	O
segments	O
such	O
as	O
symbols	O
in	O
the	O
international	O
phonetic	O
alphabet	O
,	O
and	O
a	O
statistical	O
model	O
trained	O
on	O
a	O
sample	O
of	O
word	O
types	O
from	O
the	O
language	O
,	O
we	O
can	O
approximately	O
measure	O
bits	O
per	O
phoneme	NLP-term
using	O
the	O
negative	O
log	O
-	O
probability	O
of	O
that	O
word	O
under	O
the	O
model	O
.	O

Using	O
a	O
collection	O
of	O
1016	O
basic	O
concept	O
words	O
across	O
106	O
languages	O
we	O
demonstrate	O
a	O
very	O
strong	O
negative	O
correlation	O
of	O
−	O
0	O
.	O
74	O
between	O
bits	O
per	O
phoneme	NLP-term
and	O
the	O
average	O
length	O
of	O
words	O
.	O

The	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
use	O
graph	O
-	O
to	O
-	O
sequence	O
models	O
however	O
,	O
they	O
still	O
cannot	O
significantly	O
outperform	O
the	O
previous	O
sequence	O
-	O
to	O
-	O
sequence	O
models	O
or	O
statistical	O
approaches	O
.	O

The	O
model	O
directly	O
encodes	O
the	O
AMR	O
graphs	O
and	O
learns	O
the	O
node	Miscellaneous-term
representations	Miscellaneous-term
.	O

A	O
pairwise	O
interaction	O
function	O
is	O
used	O
for	O
computing	O
the	O
semantic	NLP-term
relations	NLP-term
between	O
the	O
concepts	O
.	O

Our	O
model	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
approach	O
by	O
1	O
.	O
5	O
BLEU	O
points	O
on	O
LDC2015E86	NLP-dataset
and	O
4	O
.	O
8	O
BLEU	O
points	O
on	O
LDC2017T10	NLP-dataset
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
.	O

Our	O
model	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
approach	O
by	O
1	O
.	O
5	O
BLEU	O
points	O
on	O
LDC2015E86	NLP-dataset
and	O
4	O
.	O
8	O
BLEU	O
points	O
on	O
LDC2017T10	NLP-dataset
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
.	O

Pre	O
-	O
training	O
by	O
language	O
modeling	O
has	O
become	O
a	O
popular	O
and	O
successful	O
approach	O
to	O
NLP	O
tasks	O
,	O
but	O
we	O
have	O
yet	O
to	O
understand	O
exactly	O
what	O
linguistic	NLP-term
capacities	NLP-term
these	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
processes	O
confer	O
upon	O
models	O
.	O

Pre	O
-	O
training	O
by	O
language	O
modeling	O
has	O
become	O
a	O
popular	O
and	O
successful	O
approach	O
to	O
NLP	O
tasks	O
,	O
but	O
we	O
have	O
yet	O
to	O
understand	O
exactly	O
what	O
linguistic	NLP-term
capacities	NLP-term
these	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
processes	O
confer	O
upon	O
models	O
.	O

As	O
a	O
case	O
study	O
,	O
we	O
apply	O
these	O
diagnostics	O
to	O
the	O
popular	O
BERT	O
model	O
finding	O
that	O
it	O
can	O
generally	O
distinguish	O
good	O
from	O
bad	O
completions	O
involving	O
shared	O
category	O
or	O
role	O
reversal	O
,	O
albeit	O
with	O
less	O
sensitivity	O
than	O
humans	O
,	O
and	O
it	O
robustly	O
retrieves	O
noun	NLP-term
hypernyms	NLP-term
but	O
it	O
struggles	O
with	O
challenging	O
inference	O
and	O
role	O
-	O
based	O
event	O
prediction	O
—	O
and	O
,	O
in	O
particular	O
,	O
it	O
shows	O
clear	O
insensitivity	O
to	O
the	O
contextual	O
impacts	O
of	O
negation	O
.	O

We	O
focus	O
on	O
the	O
problem	O
of	O
membership	O
inference	O
attacks	O
Given	O
a	O
data	O
sample	O
and	O
black	O
-	O
box	O
access	O
to	O
a	O
model	Miscellaneous-term
’	Miscellaneous-term
s	Miscellaneous-term
API	Miscellaneous-term
determine	O
whether	O
the	O
sample	O
existed	O
in	O
the	O
model	O
’	O
s	O
training	O
data	O
.	O

We	O
define	O
the	O
membership	O
inference	O
problem	O
for	O
sequence	O
generation	O
provide	O
an	O
open	O
dataset	Miscellaneous-term
based	O
on	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
machine	O
translation	O
models	O
and	O
report	O
initial	O
results	O
on	O
whether	O
these	O
models	O
leak	O
private	O
information	O
against	O
several	O
kinds	O
of	O
membership	O
inference	O
attacks	O
.	O

In	O
particular	O
,	O
with	O
the	O
same	O
training	O
data	O
and	O
model	O
size	O
as	O
BERTlarge	O
our	O
single	O
model	O
obtains	O
94	O
.	O
6	O
\\%	O
and	O
88	O
.	O
7	O
\\%	O
F1	O
on	O
SQuAD	NLP-dataset
1	O
.	O
1	O
and	O
2	O
.	O
0	O
respectively	O
.	O

We	O
also	O
achieve	O
a	O
new	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
on	O
the	O
OntoNotes	NLP-dataset
coreference	O
resolution	O
task	O
(	O
79	O
.	O
6	O
\\%	O
F1	O
,	O
strong	O
performance	O
on	O
the	O
TACRED	NLP-dataset
relation	O
extraction	O
benchmark	O
,	O
and	O
even	O
gains	O
on	O
GLUE	NLP-dataset
.	O

We	O
also	O
achieve	O
a	O
new	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
on	O
the	O
OntoNotes	NLP-dataset
coreference	O
resolution	O
task	O
(	O
79	O
.	O
6	O
\\%	O
F1	O
,	O
strong	O
performance	O
on	O
the	O
TACRED	NLP-dataset
relation	O
extraction	O
benchmark	O
,	O
and	O
even	O
gains	O
on	O
GLUE	NLP-dataset
.	O

Our	O
graph	O
-	O
based	O
joint	O
model	O
achieves	O
better	O
performance	O
than	O
previous	O
joint	O
models	O
and	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
in	O
both	O
Chinese	O
word	O
segmentation	O
and	O
dependency	O
parsing	O
.	O

Additionally	O
,	O
when	O
BERT	O
is	O
combined	O
,	O
our	O
model	O
can	O
substantially	O
reduce	O
the	O
performance	O
gap	O
of	O
dependency	O
parsing	O
between	O
joint	O
models	O
and	O
gold	O
-	O
segmented	O
word	O
-	O
based	O
models	O
code	Miscellaneous-term
.	O

Story	O
generation	O
namely	O
,	O
generating	O
a	O
reasonable	O
story	O
from	O
a	O
leading	NLP-term
context	NLP-term
is	O
an	O
important	O
but	O
challenging	O
task	O
.	O

In	O
spite	O
of	O
the	O
success	O
in	O
modeling	O
fluency	O
and	O
local	O
coherence	O
,	O
existing	O
neural	O
language	O
generation	O
models	O
(	O
e	O
.	O
g	O
.,	O
GPT	O
-	O
2	O
still	O
suffer	O
from	O
repetition	O
,	O
logic	O
conflicts	O
,	O
and	O
lack	O
of	O
long	NLP-term
-	NLP-term
range	NLP-term
coherence	NLP-term
in	O
generated	O
stories	O
.	O

We	O
conjecture	O
that	O
this	O
is	O
because	O
of	O
the	O
difficulty	O
of	O
associating	O
relevant	O
commonsense	O
knowledge	O
,	O
understanding	O
the	O
causal	O
relationships	O
,	O
and	O
planning	O
entities	NLP-term
and	O
events	O
with	O
proper	O
temporal	O
order	O
.	O

We	O
propose	O
to	O
utilize	O
commonsense	O
knowledge	O
from	O
external	NLP-term
knowledge	NLP-term
bases	NLP-term
to	O
generate	O
reasonable	O
stories	O
.	O

To	O
further	O
capture	O
the	O
causal	O
and	O
temporal	O
dependencies	O
between	O
the	O
sentences	O
in	O
a	O
reasonable	O
story	O
,	O
we	O
use	O
multi	O
-	O
task	O
learning	O
which	O
combines	O
a	O
discriminative	O
objective	O
to	O
distinguish	O
true	O
and	O
fake	O
stories	O
during	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuning	AI/ML/DL-term
.	O

Automatic	O
and	O
manual	O
evaluation	O
shows	O
that	O
our	O
model	O
can	O
generate	O
more	O
reasonable	O
stories	O
than	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
,	O
particularly	O
in	O
terms	O
of	O
logic	Miscellaneous-term
and	O
global	AI/ML/DL-term
coherence	AI/ML/DL-term
.	O

Automatic	O
and	O
manual	O
evaluation	O
shows	O
that	O
our	O
model	O
can	O
generate	O
more	O
reasonable	O
stories	O
than	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
,	O
particularly	O
in	O
terms	O
of	O
logic	Miscellaneous-term
and	O
global	AI/ML/DL-term
coherence	AI/ML/DL-term
.	O

Cross	O
-	O
lingual	O
entity	O
linking	O
(	O
XEL	O
)	O
is	O
the	O
task	O
of	O
finding	O
referents	O
in	O
a	O
target	NLP-term
-	NLP-term
language	NLP-term
knowledge	NLP-term
base	NLP-term
(	NLP-term
KB	NLP-term
)	NLP-term
for	O
mentions	O
extracted	O
from	O
source	O
-	O
language	O
texts	O
.	O

The	O
first	O
step	O
of	O
(	O
X	O
)	O
EL	O
is	O
candidate	O
generation	O
,	O
which	O
retrieves	O
a	O
list	O
of	O
plausible	O
candidate	O
entities	O
from	O
the	O
target	NLP-term
-	NLP-term
language	NLP-term
KB	NLP-term
for	O
each	O
mention	O
.	O

In	O
this	O
paper	O
,	O
we	O
first	O
assess	O
the	O
problems	O
faced	O
by	O
current	O
entity	O
candidate	O
generation	O
methods	O
for	O
low	O
-	O
resource	O
XEL	O
then	O
propose	O
three	O
improvements	O
that	O
(	O
1	O
)	O
reduce	O
the	O
disconnect	O
between	O
entity	NLP-term
mentions	NLP-term
and	O
KB	NLP-term
entries	NLP-term
and	O
(	O
2	O
)	O
improve	O
the	O
robustness	O
of	O
the	O
model	AI/ML/DL-term
to	O
low	Miscellaneous-term
-	Miscellaneous-term
resource	Miscellaneous-term
scenarios	Miscellaneous-term
.	O

In	O
this	O
paper	O
,	O
we	O
first	O
assess	O
the	O
problems	O
faced	O
by	O
current	O
entity	O
candidate	O
generation	O
methods	O
for	O
low	O
-	O
resource	O
XEL	O
then	O
propose	O
three	O
improvements	O
that	O
(	O
1	O
)	O
reduce	O
the	O
disconnect	O
between	O
entity	NLP-term
mentions	NLP-term
and	O
KB	NLP-term
entries	NLP-term
and	O
(	O
2	O
)	O
improve	O
the	O
robustness	O
of	O
the	O
model	AI/ML/DL-term
to	O
low	Miscellaneous-term
-	Miscellaneous-term
resource	Miscellaneous-term
scenarios	Miscellaneous-term
.	O

In	O
this	O
paper	O
,	O
we	O
first	O
assess	O
the	O
problems	O
faced	O
by	O
current	O
entity	O
candidate	O
generation	O
methods	O
for	O
low	O
-	O
resource	O
XEL	O
then	O
propose	O
three	O
improvements	O
that	O
(	O
1	O
)	O
reduce	O
the	O
disconnect	O
between	O
entity	NLP-term
mentions	NLP-term
and	O
KB	NLP-term
entries	NLP-term
and	O
(	O
2	O
)	O
improve	O
the	O
robustness	O
of	O
the	O
model	AI/ML/DL-term
to	O
low	Miscellaneous-term
-	Miscellaneous-term
resource	Miscellaneous-term
scenarios	Miscellaneous-term
.	O

The	O
methods	O
are	O
simple	O
,	O
but	O
effective	O
:	O
We	O
experiment	O
with	O
our	O
approach	O
on	O
seven	O
XEL	O
datasets	O
and	O
find	O
that	O
they	O
yield	O
an	O
average	Miscellaneous-term
gain	Miscellaneous-term
of	O
16	O
.	O
9	O
\\%	O
in	O
Top	O
-	O
30	O
gold	O
candidate	O
recall	O
compared	O
with	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
.	O

Our	O
improved	O
model	O
also	O
yields	O
an	O
average	Miscellaneous-term
gain	Miscellaneous-term
of	O
7	O
.	O
9	O
\\%	O
in	O
in	O
-	O
KB	O
accuracy	O
of	O
end	O
-	O
to	O
-	O
end	O
XEL	O
1	O
.	O

Learners	O
that	O
are	O
exposed	O
to	O
the	O
same	O
training	O
data	O
might	O
generalize	O
differently	O
due	O
to	O
differing	O
inductive	AI/ML/DL-term
biases	AI/ML/DL-term
.	O

In	O
neural	O
network	O
models	O
inductive	AI/ML/DL-term
biases	AI/ML/DL-term
could	O
in	O
theory	O
arise	O
from	O
any	O
aspect	O
of	O
the	O
model	O
architecture	O
.	O

We	O
investigate	O
which	O
architectural	O
factors	O
affect	O
the	O
generalization	O
behavior	O
of	O
neural	O
sequence	O
-	O
to	O
-	O
sequence	O
models	O
trained	O
on	O
two	O
syntactic	NLP-term
tasks	O
,	O
English	O
question	O
formation	O
and	O
English	O
tense	O
reinflection	O
.	O

For	O
both	O
tasks	O
,	O
the	O
training	Miscellaneous-term
set	Miscellaneous-term
is	O
consistent	O
with	O
a	O
generalization	O
based	O
on	O
hierarchical	O
structure	O
and	O
a	O
generalization	O
based	O
on	O
linear	O
order	O
.	O

However	O
,	O
the	O
only	O
factor	O
that	O
consistently	O
contributed	O
a	O
hierarchical	AI/ML/DL-term
bias	AI/ML/DL-term
across	O
tasks	O
was	O
the	O
use	O
of	O
a	O
tree	O
-	O
structured	O
model	O
rather	O
than	O
a	O
model	O
with	O
sequential	Miscellaneous-term
recurrence	Miscellaneous-term
suggesting	O
that	O
human	O
-	O
like	O
syntactic	O
generalization	O
requires	O
architectural	O
syntactic	O
structure	O
.	O

However	O
,	O
the	O
only	O
factor	O
that	O
consistently	O
contributed	O
a	O
hierarchical	AI/ML/DL-term
bias	AI/ML/DL-term
across	O
tasks	O
was	O
the	O
use	O
of	O
a	O
tree	O
-	O
structured	O
model	O
rather	O
than	O
a	O
model	O
with	O
sequential	Miscellaneous-term
recurrence	Miscellaneous-term
suggesting	O
that	O
human	O
-	O
like	O
syntactic	O
generalization	O
requires	O
architectural	O
syntactic	O
structure	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
the	O
first	O
free	O
-	O
form	O
multiple	O
-	O
Choice	O
Chinese	O
machine	O
reading	O
Comprehension	O
dataset	O
(	O
C3	NLP-dataset
,	O
containing	O
13	O
,	O
369	O
documents	O
(	O
dialogues	O
or	O
more	O
formally	O
written	O
mixed	O
-	O
genre	O
texts	O
)	O
and	O
their	O
associated	O
19	O
,	O
577	O
multiple	O
-	O
choice	O
free	O
-	O
form	O
questions	O
collected	O
from	O
Chinese	O
-	O
as	O
-	O
a	O
-	O
second	O
-	O
language	O
examinations	O
.	O

We	O
present	O
a	O
comprehensive	O
analysis	O
of	O
the	O
prior	O
knowledge	O
(	O
i	O
.	O
e	O
.,	O
linguistic	NLP-term
domain	AI/ML/DL-term
-	AI/ML/DL-term
specific	AI/ML/DL-term
and	O
general	Miscellaneous-term
world	Miscellaneous-term
knowledge	Miscellaneous-term
needed	O
for	O
these	O
real	O
-	O
world	O
problems	O
.	O

We	O
present	O
a	O
comprehensive	O
analysis	O
of	O
the	O
prior	O
knowledge	O
(	O
i	O
.	O
e	O
.,	O
linguistic	NLP-term
domain	AI/ML/DL-term
-	AI/ML/DL-term
specific	AI/ML/DL-term
and	O
general	Miscellaneous-term
world	Miscellaneous-term
knowledge	Miscellaneous-term
needed	O
for	O
these	O
real	O
-	O
world	O
problems	O
.	O

We	O
present	O
a	O
comprehensive	O
analysis	O
of	O
the	O
prior	O
knowledge	O
(	O
i	O
.	O
e	O
.,	O
linguistic	NLP-term
domain	AI/ML/DL-term
-	AI/ML/DL-term
specific	AI/ML/DL-term
and	O
general	Miscellaneous-term
world	Miscellaneous-term
knowledge	Miscellaneous-term
needed	O
for	O
these	O
real	O
-	O
world	O
problems	O
.	O

We	O
expect	O
C3	NLP-dataset
C3	NLP-dataset
C3	NLP-dataset
sent	O
great	O
challenges	O
to	O
existing	O
systems	O
as	O
answering	O
86	O
.	O
8	O
\\%	O
of	O
questions	O
requires	O
both	O
knowledge	O
within	O
and	O
beyond	O
the	O
accompanying	O
document	O
,	O
and	O
we	O
hope	O
that	O
C3	O
can	O
serve	O
as	O
a	O
platform	O
to	O
study	O
how	O
to	O
leverage	O
various	O
kinds	O
of	O
prior	O
knowledge	O
to	O
better	O
understand	O
a	O
given	O
written	O
or	O
orally	O
oriented	O
text	O
.	O

These	O
limitations	O
seem	O
surprising	O
given	O
the	O
practical	O
success	O
of	O
self	O
-	O
attention	O
and	O
the	O
prominent	O
role	O
assigned	O
to	O
hierarchical	AI/ML/DL-term
structure	AI/ML/DL-term
in	O
linguistics	O
,	O
suggesting	O
that	O
natural	NLP-term
language	NLP-term
can	O
be	O
approximated	O
well	O
with	O
models	O
that	O
are	O
too	O
weak	O
for	O
the	O
formal	O
languages	O
typically	O
assumed	O
in	O
theoretical	NLP-term
linguistics	NLP-term
.	O

These	O
limitations	O
seem	O
surprising	O
given	O
the	O
practical	O
success	O
of	O
self	O
-	O
attention	O
and	O
the	O
prominent	O
role	O
assigned	O
to	O
hierarchical	AI/ML/DL-term
structure	AI/ML/DL-term
in	O
linguistics	O
,	O
suggesting	O
that	O
natural	NLP-term
language	NLP-term
can	O
be	O
approximated	O
well	O
with	O
models	O
that	O
are	O
too	O
weak	O
for	O
the	O
formal	O
languages	O
typically	O
assumed	O
in	O
theoretical	NLP-term
linguistics	NLP-term
.	O

First	O
,	O
TG	O
-	O
SAN	O
outperforms	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
by	O
up	O
to	O
1	O
.	O
61	O
\\%	O
and	O
3	O
.	O
58	O
\\%	O
in	O
terms	O
of	O
accuracy	O
and	O
Marco	O
-	O
F1	O
respectively	O
.	O

Second	O
,	O
it	O
shows	O
a	O
strong	O
advantage	O
in	O
determining	O
the	O
sentiment	O
of	O
a	O
target	O
when	O
the	O
context	O
sentence	O
contains	O
multiple	O
semantic	NLP-term
segments	NLP-term
.	O

Understanding	O
natural	NLP-term
language	NLP-term
questions	NLP-term
entails	O
the	O
ability	O
to	O
break	O
down	O
a	O
question	O
into	O
the	O
requisite	O
steps	O
for	O
computing	O
its	O
answer	O
.	O

We	O
develop	O
a	O
crowdsourcing	O
pipeline	O
,	O
showing	O
that	O
quality	O
QDMRs	O
can	O
be	O
annotated	O
at	O
scale	O
,	O
and	O
release	O
the	O
Break	NLP-dataset
dataset	O
,	O
containing	O
over	O
83K	O
pairs	O
of	O
questions	O
QDMRs	O
eir	O
QDMRs	O
.	O

We	O
demonstrate	O
the	O
utility	O
of	O
QDMR	O
by	O
showing	O
that	O
(	O
a	O
)	O
it	O
can	O
be	O
used	O
to	O
improve	O
open	O
-	O
domain	O
question	O
answering	O
on	O
the	O
HotpotQA	NLP-dataset
dataset	O
,	O
(	O
b	O
)	O
it	O
can	O
be	O
deterministically	O
converted	O
to	O
a	O
pseudo	O
-	O
SQL	O
formal	O
language	O
which	O
can	O
alleviate	O
annotation	O
in	O
semantic	O
parsing	O
applications	O
.	O

Last	O
,	O
we	O
use	O
Break	NLP-dataset
to	O
train	O
a	O
sequence	O
-	O
to	O
-	O
sequence	O
model	O
with	O
copying	O
that	O
parses	O
questions	O
into	O
QDMR	O
structures	O
,	O
and	O
show	O
that	O
it	O
substantially	O
outperforms	O
several	O
natural	O
baselines	O
.	O

Our	O
results	O
show	O
that	O
,	O
although	O
several	O
prosodic	NLP-term
and	O
lexical	NLP-term
features	NLP-term
were	O
consistently	O
perceived	O
as	O
trustworthy	O
,	O
they	O
were	O
not	O
reliable	O
cues	O
.	O

We	O
use	O
Viterbi	O
EM	O
with	O
a	O
margin	O
-	O
based	O
criterion	O
to	O
train	O
a	O
span	O
-	O
based	O
discourse	O
parser	O
in	O
an	O
unsupervised	AI/ML/DL-term
manner	O
.	O

We	O
evaluate	O
a	O
range	O
of	O
semantic	O
models	O
(	O
word	NLP-term
embeddings	NLP-term
compositional	O
,	O
and	O
visual	O
models	O
in	O
their	O
ability	O
to	O
decode	O
brain	O
activity	O
associated	O
with	O
reading	O
of	O
both	O
literal	O
and	O
metaphoric	O
sentences	O
.	O

Our	O
results	O
suggest	O
that	O
compositional	O
models	O
and	O
word	NLP-term
embedding	NLP-term
are	O
able	O
to	O
capture	O
differences	O
in	O
the	O
processing	O
of	O
literal	O
and	O
metaphoric	O
sentences	O
,	O
providing	O
support	O
for	O
the	O
idea	O
that	O
the	O
literal	O
meaning	O
is	O
not	O
fully	O
accessible	O
during	O
familiar	O
metaphor	O
comprehension	O
.	O

By	O
warm	O
-	O
starting	O
from	O
the	O
publicly	O
released	O
checkpoints	O
,	O
NLP	O
practitioners	O
have	O
pushed	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
on	O
multiple	O
benchmarks	O
while	O
saving	O
significant	O
amounts	O
of	O
compute	O
time	O
.	O

In	O
this	O
paper	O
,	O
we	O
demonstrate	O
the	O
efficacy	O
of	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
checkpoints	AI/ML/DL-term
for	O
Sequence	O
Generation	O
.	O

We	O
developed	O
a	O
Transformer	O
based	O
sequence	O
-	O
to	O
-	O
sequence	O
model	O
that	O
is	O
compatible	O
with	O
publicly	O
available	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
BERT	O
GPT	O
-	O
2	O
and	O
RoBERTa	O
checkpoints	O
and	O
conducted	O
an	O
extensive	O
empirical	O
study	O
on	O
the	O
utility	O
of	O
initializing	O
our	O
model	O
,	O
both	O
encoder	O
and	O
decoder	O
with	O
these	O
checkpoints	O
.	O

Our	O
models	O
result	O
in	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
on	O
Machine	O
Translation	O
Text	O
Summarization	O
Sentence	O
Splitting	O
and	O
Sentence	O
Fusion	O
.	O

To	O
advance	O
multi	O
-	O
domain	O
(	O
cross	O
-	O
domain	O
)	O
dialogue	O
modeling	O
as	O
well	O
as	O
alleviate	O
the	O
shortage	O
of	O
Chinese	O
task	O
-	O
oriented	O
datasets	Miscellaneous-term
we	O
propose	O
CrossWOZ	NLP-dataset
the	O
first	O
large	O
-	O
scale	O
Chinese	NLP-dataset
Cross	NLP-dataset
-	NLP-dataset
Domain	NLP-dataset
Wizard	NLP-dataset
-	NLP-dataset
of	NLP-dataset
-	NLP-dataset
Oz	NLP-dataset
task	O
-	O
oriented	O
dataset	O
.	O

To	O
advance	O
multi	O
-	O
domain	O
(	O
cross	O
-	O
domain	O
)	O
dialogue	O
modeling	O
as	O
well	O
as	O
alleviate	O
the	O
shortage	O
of	O
Chinese	O
task	O
-	O
oriented	O
datasets	Miscellaneous-term
we	O
propose	O
CrossWOZ	NLP-dataset
the	O
first	O
large	O
-	O
scale	O
Chinese	NLP-dataset
Cross	NLP-dataset
-	NLP-dataset
Domain	NLP-dataset
Wizard	NLP-dataset
-	NLP-dataset
of	NLP-dataset
-	NLP-dataset
Oz	NLP-dataset
task	O
-	O
oriented	O
dataset	O
.	O

About	O
60	O
\\%	O
of	O
the	O
dialogues	O
have	O
cross	AI/ML/DL-term
-	AI/ML/DL-term
domain	AI/ML/DL-term
user	O
goals	O
that	O
favor	O
inter	O
-	O
domain	O
dependency	O
and	O
encourage	O
natural	O
transition	O
across	O
domains	O
in	O
conversation	O
.	O

We	O
also	O
provide	O
a	O
user	O
simulator	O
and	O
several	O
benchmark	O
models	O
for	O
pipelined	O
task	O
-	O
oriented	O
dialogue	O
systems	O
which	O
will	O
facilitate	O
researchers	O
to	O
compare	O
and	O
evaluate	O
their	O
models	O
on	O
this	O
corpus	Miscellaneous-term
.	O

The	O
large	O
size	O
and	O
rich	O
annotation	O
of	O
CrossWOZ	NLP-dataset
make	O
it	O
suitable	O
to	O
investigate	O
a	O
variety	O
of	O
tasks	O
in	O
cross	O
-	O
domain	O
dialogue	O
modeling	O
such	O
as	O
dialogue	O
state	O
tracking	O
,	O
policy	O
learning	O
,	O
user	O
simulation	O
,	O
etc	O
.	O

The	O
bidirectional	O
models	O
show	O
very	O
promising	O
results	O
,	O
with	O
the	O
best	O
model	O
achieving	O
a	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
for	O
unsupervised	O
acceptability	O
prediction	O
.	O

We	O
inject	O
knowledge	O
about	O
lexical	O
-	O
semantic	O
relations	O
into	O
distributional	NLP-term
word	NLP-term
embeddings	NLP-term
by	O
defining	O
subspaces	O
of	O
the	O
distributional	O
vector	O
space	O
in	O
which	O
a	O
lexical	O
relation	O
should	O
hold	O
.	O

Our	O
framework	O
can	O
handle	O
symmetric	O
attract	O
and	O
repel	O
relations	O
(	O
e	O
.	O
g	O
.,	O
synonymy	NLP-term
and	O
antonymy	NLP-term
respectively	O
),	O
as	O
well	O
as	O
asymmetric	O
relations	O
(	O
e	O
.	O
g	O
.,	O
hypernymy	NLP-term
and	O
meronomy	NLP-term
.	O

We	O
perform	O
extensive	O
automated	O
and	O
human	O
evaluations	O
over	O
multiple	O
real	O
-	O
world	O
English	O
language	O
datasets	O
to	O
demonstrate	O
the	O
efficacy	O
of	O
Sgcp	O
over	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
.	O

The	O
alignment	O
of	O
word	NLP-term
embedding	NLP-term
spaces	NLP-term
in	O
different	O
languages	O
into	O
a	O
common	O
crosslingual	O
space	O
has	O
recently	O
been	O
in	O
vogue	O
.	O

These	O
strategies	O
,	O
however	O
,	O
are	O
biased	O
towards	O
the	O
choice	O
of	O
the	O
pivot	NLP-term
language	NLP-term
given	O
that	O
language	O
proximity	O
and	O
the	O
linguistic	O
characteristics	O
of	O
the	O
target	O
language	O
can	O
strongly	O
impact	O
the	O
resultant	O
crosslingual	NLP-term
space	O
in	O
detriment	O
of	O
topologically	O
distant	O
languages	O
.	O

We	O
present	O
a	O
strategy	O
that	O
eliminates	O
the	O
need	O
for	O
a	O
pivot	NLP-term
language	NLP-term
by	O
learning	O
the	O
mappings	O
across	O
languages	O
in	O
a	O
hierarchical	O
way	O
.	O

We	O
introduce	O
The	O
Benchmark	NLP-dataset
of	NLP-dataset
Linguistic	NLP-dataset
Minimal	NLP-dataset
Pairs	NLP-dataset
(	NLP-dataset
BLiMP	NLP-dataset
)	NLP-dataset
1	O
a	O
challenge	O
set	O
for	O
evaluating	O
the	O
linguistic	O
knowledge	O
of	O
language	O
models	O
(	O
LMs	O
)	O
BLiMP	NLP-dataset
or	O
grammatical	O
phenomena	O
in	O
English	O
.	O

BLiMP	O
consists	O
of	O
67	O
individual	O
datasets	Miscellaneous-term
each	O
containing	O
1	O
,	O
000	O
minimal	O
pairs	O
that	O
is	O
,	O
pairs	O
of	O
minimally	O
different	O
sentences	O
that	O
contrast	O
in	O
grammatical	O
acceptability	O
and	O
isolate	O
specific	O
phenomenon	O
in	O
syntax	O
,	O
morphology	NLP-term
or	O
semantics	NLP-term
.	O

BLiMP	O
consists	O
of	O
67	O
individual	O
datasets	Miscellaneous-term
each	O
containing	O
1	O
,	O
000	O
minimal	O
pairs	O
that	O
is	O
,	O
pairs	O
of	O
minimally	O
different	O
sentences	O
that	O
contrast	O
in	O
grammatical	O
acceptability	O
and	O
isolate	O
specific	O
phenomenon	O
in	O
syntax	O
,	O
morphology	NLP-term
or	O
semantics	NLP-term
.	O

We	O
find	O
that	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
identify	O
morphological	O
contrasts	O
related	O
to	O
agreement	O
reliably	O
,	O
but	O
they	O
struggle	O
with	O
some	O
subtle	O
semantic	O
and	O
syntactic	O
phenomena	O
,	O
such	O
as	O
negative	O
polarity	O
items	O
and	O
extraction	O
islands	O
.	O

Fine	O
-	O
grained	O
adjustments	O
to	O
a	O
model	O
’	O
s	O
architecture	O
or	O
training	O
recipe	O
can	O
mean	O
the	O
difference	O
between	O
a	O
positive	O
and	O
negative	O
research	O
result	O
or	O
between	O
a	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
and	O
underperforming	O
system	O
.	O

Our	O
contributions	O
include	O
(	O
1	O
)	O
the	O
release	O
of	O
a	O
large	O
collection	O
of	O
trained	O
NMT	O
models	O
covering	O
a	O
wide	O
range	O
of	O
hyperparameters	AI/ML/DL-term
(	O
2	O
)	O
the	O
proposal	O
of	O
targeted	O
metrics	O
for	O
evaluating	O
HPO	O
NMT	O
HPO	O
on	O
NMT	O
,	O
and	O
(	O
3	O
)	O
a	O
reproducible	O
benchmark	O
of	O
several	O
HPO	O
methods	O
against	O
our	O
model	O
library	O
,	O
including	O
novel	O
graph	O
-	O
based	O
and	O
multiobjective	O
methods	O
.	O

Learning	O
probabilistic	O
context	O
-	O
free	O
grammars	O
(	O
PCFGs	O
)	O
from	O
strings	NLP-term
is	O
a	O
classic	O
problem	O
in	O
computational	O
linguistics	O
since	O
Horning	O
(	O
1969	O
).	O

Recent	O
work	O
has	O
presented	O
intriguing	O
results	O
examining	O
the	O
knowledge	O
contained	O
in	O
language	O
models	O
(	O
LMs	O
)	O
LM	O
having	O
the	O
LM	O
fill	O
in	O
the	O
blanks	O
of	O
prompts	AI/ML/DL-term
such	O
as	O
“	O
Obama	O
is	O
a	O
\	O
_	O
\	O
_	O
by	O
profession	O
”.	O

Because	O
of	O
this	O
,	O
given	O
an	O
inappropriate	O
prompt	AI/ML/DL-term
we	O
might	O
fail	O
to	O
retrieve	O
facts	O
that	O
the	O
LM	O
prompt	AI/ML/DL-term
ow	O
,	O
and	O
thus	O
any	O
given	O
prompt	O
only	O
provides	O
a	O
lower	Miscellaneous-term
bound	Miscellaneous-term
estimate	Miscellaneous-term
LM	O
the	O
knowledge	O
contained	O
in	O
an	O
LM	O
.	O

Because	O
of	O
this	O
,	O
given	O
an	O
inappropriate	O
prompt	AI/ML/DL-term
we	O
might	O
fail	O
to	O
retrieve	O
facts	O
that	O
the	O
LM	O
prompt	AI/ML/DL-term
ow	O
,	O
and	O
thus	O
any	O
given	O
prompt	O
only	O
provides	O
a	O
lower	Miscellaneous-term
bound	Miscellaneous-term
estimate	Miscellaneous-term
LM	O
the	O
knowledge	O
contained	O
in	O
an	O
LM	O
.	O

In	O
this	O
paper	O
,	O
we	O
attempt	O
to	O
more	O
accurately	O
estimate	O
the	O
knowledge	O
contained	O
in	O
LMs	O
by	O
automatically	O
discovering	O
better	O
prompts	AI/ML/DL-term
to	O
use	O
in	O
this	O
querying	O
process	O
.	O

Specifically	O
,	O
we	O
propose	O
mining	O
-	O
based	O
and	O
paraphrasing	O
-	O
based	O
methods	O
to	O
automatically	O
generate	O
high	O
-	O
quality	O
and	O
diverse	O
prompts	AI/ML/DL-term
prompts	AI/ML/DL-term
as	O
ensemble	O
methods	O
to	O
combine	O
answers	O
from	O
different	O
prompts	O
.	O

Extensive	O
experiments	O
on	O
the	O
LAMA	NLP-dataset
benchmark	O
for	O
extracting	O
relational	O
knowledge	O
from	O
LMs	O
demonstrate	O
that	O
our	O
methods	O
can	O
improve	O
accuracy	O
from	O
31	O
.	O
1	O
\\%	O
to	O
39	O
.	O
6	O
\\%	O
providing	O
a	O
tighter	Miscellaneous-term
lower	Miscellaneous-term
bound	Miscellaneous-term
LMs	O
hat	O
LMs	O
know	O
.	O

Extensive	O
experiments	O
on	O
the	O
LAMA	NLP-dataset
benchmark	O
for	O
extracting	O
relational	O
knowledge	O
from	O
LMs	O
demonstrate	O
that	O
our	O
methods	O
can	O
improve	O
accuracy	O
from	O
31	O
.	O
1	O
\\%	O
to	O
39	O
.	O
6	O
\\%	O
providing	O
a	O
tighter	Miscellaneous-term
lower	Miscellaneous-term
bound	Miscellaneous-term
LMs	O
hat	O
LMs	O
know	O
.	O

We	O
have	O
released	O
the	O
code	Miscellaneous-term
and	O
the	O
resulting	O
LM	NLP-dataset
Prompt	NLP-dataset
And	NLP-dataset
Query	NLP-dataset
Archive	NLP-dataset
(	NLP-dataset
LPAQA	NLP-dataset
)	NLP-dataset
at	O
https	O
://	O
github	O
.	O
com	O
/	O
jzbjyb	O
/	O
LPAQA	O
.	O

We	O
have	O
released	O
the	O
code	Miscellaneous-term
and	O
the	O
resulting	O
LM	NLP-dataset
Prompt	NLP-dataset
And	NLP-dataset
Query	NLP-dataset
Archive	NLP-dataset
(	NLP-dataset
LPAQA	NLP-dataset
)	NLP-dataset
at	O
https	O
://	O
github	O
.	O
com	O
/	O
jzbjyb	O
/	O
LPAQA	O
.	O

However	O
,	O
existing	O
topic	O
models	O
fail	O
to	O
learn	O
interpretable	NLP-term
topics	NLP-term
when	O
working	O
with	O
large	O
and	O
heavy	O
-	O
tailed	O
vocabularies	NLP-term
.	O

To	O
this	O
end	O
,	O
we	O
develop	O
the	O
embedded	O
topic	O
model	O
(	O
etm	O
)	O
a	O
generative	O
model	O
of	O
documents	O
that	O
marries	O
traditional	O
topic	O
models	O
with	O
word	NLP-term
embeddings	NLP-term
.	O

More	O
specifically	O
,	O
the	O
etm	O
models	O
each	O
word	O
with	O
a	O
categorical	O
distribution	O
whose	O
natural	O
parameter	O
is	O
the	O
inner	O
product	O
between	O
the	O
word	NLP-term
’	NLP-term
s	NLP-term
embedding	NLP-term
embedding	AI/ML/DL-term
edding	O
of	O
its	O
assigned	O
topic	NLP-term
.	O

More	O
specifically	O
,	O
the	O
etm	O
models	O
each	O
word	O
with	O
a	O
categorical	O
distribution	O
whose	O
natural	O
parameter	O
is	O
the	O
inner	O
product	O
between	O
the	O
word	NLP-term
’	NLP-term
s	NLP-term
embedding	NLP-term
embedding	AI/ML/DL-term
edding	O
of	O
its	O
assigned	O
topic	NLP-term
.	O

The	O
etm	O
discovers	O
interpretable	NLP-term
topics	NLP-term
even	O
with	O
large	O
vocabularies	NLP-term
that	O
include	O
rare	O
words	O
and	O
stop	NLP-term
words	NLP-term
.	O

We	O
present	O
TyDi	NLP-dataset
QA	NLP-dataset
a	O
question	O
answering	O
dataset	O
covering	O
11	O
typologically	O
diverse	O
languages	O
with	O
204K	O
question	O
-	O
answer	O
pairs	O
.	O

The	O
languages	O
of	O
TyDi	NLP-dataset
QA	NLP-dataset
are	O
diverse	O
with	O
regard	O
to	O
their	O
typology	O
—	O
the	O
set	O
of	O
linguistic	NLP-term
features	NLP-term
each	O
language	O
expresses	O
—	O
such	O
that	O
we	O
expect	O
models	O
performing	O
well	O
on	O
this	O
set	O
to	O
generalize	O
across	O
a	O
large	O
number	O
of	O
the	O
world	O
’	O
s	O
languages	O
.	O

The	O
languages	O
of	O
TyDi	NLP-dataset
QA	NLP-dataset
are	O
diverse	O
with	O
regard	O
to	O
their	O
typology	O
—	O
the	O
set	O
of	O
linguistic	NLP-term
features	NLP-term
each	O
language	O
expresses	O
—	O
such	O
that	O
we	O
expect	O
models	O
performing	O
well	O
on	O
this	O
set	O
to	O
generalize	O
across	O
a	O
large	O
number	O
of	O
the	O
world	O
’	O
s	O
languages	O
.	O

We	O
present	O
a	O
quantitative	Miscellaneous-term
analysis	Miscellaneous-term
of	O
the	O
data	O
quality	O
and	O
example	O
-	O
level	O
qualitative	O
linguistic	O
analyses	O
of	O
observed	O
language	O
phenomena	O
that	O
would	O
not	O
be	O
found	O
in	O
English	Miscellaneous-term
-	Miscellaneous-term
only	Miscellaneous-term
corpora	Miscellaneous-term
.	O

We	O
propose	O
a	O
novel	O
generative	O
model	O
to	O
explore	O
both	O
local	O
and	O
global	O
context	O
for	O
joint	O
learning	O
topics	O
and	O
topic	NLP-term
-	NLP-term
specific	NLP-term
word	NLP-term
embeddings	NLP-term
.	O

In	O
particular	O
,	O
we	O
assume	O
that	O
global	O
latent	O
topics	O
are	O
shared	O
across	O
documents	O
,	O
a	O
word	O
is	O
generated	O
by	O
a	O
hidden	NLP-term
semantic	NLP-term
vector	NLP-term
encoding	O
its	O
contextual	NLP-term
semantic	NLP-term
meaning	NLP-term
and	O
its	O
context	NLP-term
words	NLP-term
hidden	NLP-term
semantic	NLP-term
vector	NLP-term
global	NLP-term
latent	NLP-term
topics	NLP-term
semantic	O
vector	O
and	O
global	O
latent	O
topics	O
.	O

Topics	O
are	O
trained	O
jointly	O
with	O
the	O
word	NLP-term
embeddings	NLP-term
.	O

The	O
trained	AI/ML/DL-term
model	AI/ML/DL-term
maps	O
words	O
to	O
topic	NLP-term
-	NLP-term
dependent	NLP-term
embeddings	NLP-term
which	O
naturally	O
addresses	O
the	O
issue	O
of	O
word	O
polysemy	O
.	O

The	O
trained	AI/ML/DL-term
model	AI/ML/DL-term
maps	O
words	O
to	O
topic	NLP-term
-	NLP-term
dependent	NLP-term
embeddings	NLP-term
which	O
naturally	O
addresses	O
the	O
issue	O
of	O
word	O
polysemy	O
.	O

Furthermore	O
,	O
the	O
model	O
also	O
extracts	O
more	O
coherent	O
topics	O
compared	O
with	O
existing	O
neural	O
topic	O
models	O
or	O
other	O
models	O
for	O
joint	O
learning	O
of	O
topics	O
and	O
word	NLP-term
embeddings	NLP-term
.	O

Word	NLP-term
embeddings	NLP-term
are	O
the	O
standard	O
model	O
for	O
semantic	NLP-term
and	O
syntactic	NLP-term
representations	NLP-term
of	O
words	O
.	O

Existing	O
post	O
-	O
processing	O
methods	O
for	O
debiasing	O
word	NLP-term
embeddings	NLP-term
are	O
unable	O
to	O
mitigate	O
gender	O
bias	O
hidden	O
in	O
the	O
spatial	O
arrangement	O
of	O
word	NLP-term
vectors	NLP-term
.	O

Experiments	O
based	O
on	O
a	O
suite	O
of	O
evaluation	O
metrics	O
show	O
that	O
RAN	O
-	O
Debias	O
significantly	O
outperforms	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
in	O
reducing	O
proximity	O
bias	O
(	O
GIPE	O
by	O
at	O
least	O
42	O
.	O
02	O
\\%	O
.	O

It	O
also	O
reduces	O
direct	O
bias	AI/ML/DL-term
adding	O
minimal	O
semantic	O
disturbance	O
,	O
and	O
achieves	O
the	O
best	O
performance	O
in	O
a	O
downstream	O
application	O
task	O
(	O
coreference	O
resolution	O
.	O

The	O
recent	O
SemBleu	O
metric	O
(	O
Song	O
and	O
Gildea	O
,	O
2019	O
)	O
is	O
based	O
on	O
the	O
machine	O
-	O
translation	O
Bleu	NLP-term
c	O
Bleu	O
(	O
Papineni	O
et	O
al	O
.,	O
2002	O
)	O
and	O
increases	O
computational	O
efficiency	O
by	O
ablating	O
the	O
variable	O
-	O
alignment	O
.	O

Existing	O
approaches	O
require	O
large	O
amounts	O
of	O
expert	O
annotated	O
data	O
,	O
computation	O
,	O
and	O
time	O
for	O
training	AI/ML/DL-term
.	O

As	O
an	O
alternative	O
,	O
we	O
devise	O
an	O
unsupervised	AI/ML/DL-term
approach	O
to	O
QE	O
where	O
no	O
training	AI/ML/DL-term
or	O
access	O
to	O
additional	O
resources	O
besides	O
the	O
MT	O
system	O
itself	O
is	O
required	O
.	O

By	O
utilizing	O
methods	O
for	O
uncertainty	O
quantification	O
,	O
we	O
achieve	O
very	O
good	O
correlation	O
with	O
human	O
judgments	O
of	O
quality	O
,	O
rivaling	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
supervised	O
QE	O
models	O
.	O

We	O
describe	O
an	O
approach	O
to	O
task	O
-	O
oriented	O
dialogue	O
in	O
which	O
dialogue	NLP-term
state	NLP-term
is	O
represented	O
as	O
a	O
dataflow	O
graph	O
.	O

A	O
dialogue	NLP-term
agent	NLP-term
maps	O
each	O
user	O
utterance	O
to	O
a	O
program	O
that	O
extends	O
this	O
graph	O
.	O

We	O
introduce	O
a	O
new	O
dataset	O
,	O
SMCalFlow	NLP-dataset
featuring	O
complex	O
dialogues	O
about	O
events	O
,	O
weather	O
,	O
places	O
,	O
and	O
people	O
.	O

Additional	O
experiments	O
on	O
the	O
MultiWOZ	NLP-dataset
dataset	O
show	O
that	O
our	O
dataflow	O
representation	O
enables	O
an	O
otherwise	O
off	O
-	O
the	O
-	O
shelf	O
sequence	O
-	O
to	O
-	O
sequence	O
model	O
to	O
match	O
the	O
best	O
existing	O
task	O
-	O
specific	O
state	O
tracking	O
model	O
.	O

The	O
SMCalFlow	NLP-dataset
dataset	O
,	O
code	O
for	O
replicating	O
experiments	O
,	O
and	O
a	O
public	O
leaderboard	O
are	O
available	O
at	O
https	O
://	O
www	O
.	O
microsoft	O
.	O
com	O
/	O
en	O
-	O
us	O
/	O
research	O
/	O
project	O
/	O
dataflow	O
-	O
based	O
-	O
dialogue	O
-	O
semantic	O
-	O
machines	O
.	O

Our	O
evaluati	O
o	O
confirms	O
that	O
transformer	O
-	O
based	O
multiple	O
-	O
choice	O
QA	O
models	O
are	O
already	O
predisposed	O
to	O
recognize	O
certain	O
types	O
of	O
structural	NLP-term
linguistic	NLP-term
knowledge	NLP-term
.	O

Global	Data/Mining/Information/Retrieval-term
node	Data/Mining/Information/Retrieval-term
encoding	Data/Mining/Information/Retrieval-term
allows	O
explicit	O
communication	O
between	O
two	O
distant	O
nodes	O
,	O
thereby	O
neglecting	O
graph	Data/Mining/Information/Retrieval-term
topology	Data/Mining/Information/Retrieval-term
as	O
all	O
nodes	O
are	O
directly	O
connected	O
.	O

In	O
this	O
work	O
,	O
we	O
gather	O
both	O
encoding	O
strategies	O
,	O
proposing	O
novel	O
neural	O
models	O
that	O
encode	O
an	O
input	O
graph	O
combining	O
both	O
global	O
and	O
local	O
node	O
contexts	O
,	O
in	O
order	O
to	O
learn	O
better	O
contextualized	NLP-term
node	NLP-term
embeddings	NLP-term
.	O

In	O
our	O
experiments	O
,	O
we	O
demonstrate	O
that	O
our	O
approaches	O
lead	O
to	O
significant	O
improvements	O
on	O
two	O
graph	O
-	O
to	O
-	O
text	O
datasets	O
achieving	O
BLEU	O
scores	O
of	O
18	O
.	O
01	O
on	O
the	O
AGENDA	NLP-dataset
dataset	O
,	O
and	O
63	O
.	O
69	O
on	O
the	O
WebNLG	NLP-dataset
dataset	O
for	O
seen	O
categories	O
,	O
outperforming	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
by	O
3	O
.	O
7	O
and	O
3	O
.	O
1	O
points	O
,	O
respectively	O
.	O
1	O
.	O

In	O
our	O
experiments	O
,	O
we	O
demonstrate	O
that	O
our	O
approaches	O
lead	O
to	O
significant	O
improvements	O
on	O
two	O
graph	O
-	O
to	O
-	O
text	O
datasets	O
achieving	O
BLEU	O
scores	O
of	O
18	O
.	O
01	O
on	O
the	O
AGENDA	NLP-dataset
dataset	O
,	O
and	O
63	O
.	O
69	O
on	O
the	O
WebNLG	NLP-dataset
dataset	O
for	O
seen	O
categories	O
,	O
outperforming	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
by	O
3	O
.	O
7	O
and	O
3	O
.	O
1	O
points	O
,	O
respectively	O
.	O
1	O
.	O

When	O
an	O
entity	NLP-term
name	NLP-term
contains	O
other	O
names	O
within	O
it	O
,	O
the	O
identification	O
of	O
all	O
combinations	O
of	O
names	O
can	O
become	O
difficult	O
and	O
expensive	O
.	O

We	O
design	O
an	O
objective	O
function	O
for	O
training	O
a	O
neural	O
model	O
that	O
treats	O
the	O
tag	O
sequence	O
for	O
nested	NLP-term
entities	NLP-term
as	O
the	O
second	O
best	O
path	O
within	O
the	O
span	O
of	O
their	O
parent	O
entity	O
.	O

Experiments	O
demonstrate	O
that	O
our	O
method	O
performs	O
better	O
than	O
or	O
at	O
least	O
as	O
well	O
as	O
existing	O
methods	O
capable	O
of	O
handling	O
nested	NLP-term
entities	NLP-term
achieving	O
F1	O
scores	O
of	O
85	O
.	O
82	O
\\%	O
84	O
.	O
34	O
\\%	O
and	O
77	O
.	O
36	O
\\%	O
on	O
ACE	NLP-dataset
-	NLP-dataset
2004	NLP-dataset
ACE	NLP-dataset
-	NLP-dataset
2005	NLP-dataset
and	O
GENIA	NLP-dataset
datasets	O
,	O
respectively	O
.	O

Experiments	O
demonstrate	O
that	O
our	O
method	O
performs	O
better	O
than	O
or	O
at	O
least	O
as	O
well	O
as	O
existing	O
methods	O
capable	O
of	O
handling	O
nested	NLP-term
entities	NLP-term
achieving	O
F1	O
scores	O
of	O
85	O
.	O
82	O
\\%	O
84	O
.	O
34	O
\\%	O
and	O
77	O
.	O
36	O
\\%	O
on	O
ACE	NLP-dataset
-	NLP-dataset
2004	NLP-dataset
ACE	NLP-dataset
-	NLP-dataset
2005	NLP-dataset
and	O
GENIA	NLP-dataset
datasets	O
,	O
respectively	O
.	O

Recent	O
progress	O
in	O
the	O
task	O
of	O
Grammatical	O
Error	O
Correction	O
(	O
GEC	O
)	O
has	O
been	O
driven	O
by	O
addressing	O
data	O
sparsity	O
,	O
both	O
through	O
new	O
methods	O
for	O
generating	O
large	O
and	O
noisy	O
pretraining	O
data	O
and	O
through	O
the	O
publication	O
of	O
small	O
and	O
higher	O
-	O
quality	O
finetuning	O
data	O
in	O
the	O
BEA	NLP-dataset
-	NLP-dataset
2019	NLP-dataset
shared	O
task	O
.	O

Models	O
trained	O
on	O
scored	O
data	O
achieve	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
results	O
on	O
common	O
GEC	O
test	O
sets	O
.	O

This	O
allows	O
us	O
to	O
explore	O
questions	O
such	O
as	O
the	O
reproducibility	O
of	O
the	O
adversarial	AI/ML/DL-term
effect	AI/ML/DL-term
transfer	O
from	O
data	O
collected	O
with	O
varying	O
model	O
-	O
in	O
-	O
the	O
-	O
loop	O
strengths	O
,	O
and	O
generalization	O
to	O
data	O
collected	O
without	O
a	O
model	O
.	O

We	O
find	O
that	O
training	AI/ML/DL-term
on	O
adversarially	AI/ML/DL-term
collected	AI/ML/DL-term
samples	AI/ML/DL-term
leads	O
to	O
strong	O
generalization	O
to	O
non	O
-	O
adversarially	O
collected	O
datasets	Miscellaneous-term
yet	O
with	O
progressive	O
performance	O
deterioration	O
with	O
increasingly	O
stronger	O
models	O
-	O
in	O
-	O
the	O
-	O
loop	O
.	O

We	O
find	O
that	O
training	AI/ML/DL-term
on	O
adversarially	AI/ML/DL-term
collected	AI/ML/DL-term
samples	AI/ML/DL-term
leads	O
to	O
strong	O
generalization	O
to	O
non	O
-	O
adversarially	O
collected	O
datasets	Miscellaneous-term
yet	O
with	O
progressive	O
performance	O
deterioration	O
with	O
increasingly	O
stronger	O
models	O
-	O
in	O
-	O
the	O
-	O
loop	O
.	O

When	O
trained	O
on	O
data	O
collected	O
with	O
a	O
BiDAF	O
model	O
in	O
the	O
loop	O
,	O
RoBERTa	O
achieves	O
39	O
.	O
9	O
F1	O
n	O
questions	O
that	O
it	O
cannot	O
answer	O
when	O
trained	O
on	O
SQuAD	NLP-dataset
RoBERTa	O
ginally	O
lower	O
than	O
when	O
trained	O
on	O
data	O
collected	O
using	O
RoBERTa	O
itself	O
(	O
41	O
.	O
0	O
F1	O
.	O

Recent	O
systems	O
for	O
converting	O
natural	NLP-term
language	NLP-term
descriptions	NLP-term
into	O
regular	Miscellaneous-term
expressions	Miscellaneous-term
(	Miscellaneous-term
regexes	Miscellaneous-term
)	Miscellaneous-term
have	O
achieved	O
some	O
success	O
,	O
but	O
typically	O
deal	O
with	O
short	O
,	O
formulaic	O
text	O
and	O
can	O
only	O
produce	O
simple	O
regexes	O
.	O

Recent	O
systems	O
for	O
converting	O
natural	NLP-term
language	NLP-term
descriptions	NLP-term
into	O
regular	Miscellaneous-term
expressions	Miscellaneous-term
(	Miscellaneous-term
regexes	Miscellaneous-term
)	Miscellaneous-term
have	O
achieved	O
some	O
success	O
,	O
but	O
typically	O
deal	O
with	O
short	O
,	O
formulaic	O
text	O
and	O
can	O
only	O
produce	O
simple	O
regexes	O
.	O

We	O
present	O
a	O
framework	O
for	O
regex	O
synthesis	O
in	O
this	O
setting	O
where	O
both	O
natural	NLP-term
language	NLP-term
(	NLP-term
NL	NLP-term
)	NLP-term
and	O
examples	O
are	O
available	O
.	O

2016	O
)	O
and	O
a	O
real	O
-	O
world	O
dataset	O
from	O
Stack	NLP-dataset
Overflow	NLP-dataset
.	O

Our	O
system	O
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
on	O
the	O
prior	O
datasets	O
and	O
solves	O
57	O
\\%	O
of	O
the	O
real	O
-	O
world	O
dataset	O
,	O
which	O
existing	O
neural	AI/ML/DL-term
systems	AI/ML/DL-term
completely	O
fail	O
on	O
.	O
1	O
.	O

Our	O
system	O
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
on	O
the	O
prior	O
datasets	O
and	O
solves	O
57	O
\\%	O
of	O
the	O
real	O
-	O
world	O
dataset	O
,	O
which	O
existing	O
neural	AI/ML/DL-term
systems	AI/ML/DL-term
completely	O
fail	O
on	O
.	O
1	O
.	O

However	O
,	O
as	O
demonstrated	O
by	O
previous	O
work	O
,	O
the	O
translation	O
quality	O
significantly	O
worsens	O
when	O
translating	O
noisy	O
texts	O
,	O
such	O
as	O
user	NLP-term
-	NLP-term
generated	NLP-term
texts	NLP-term
(	NLP-term
UGT	NLP-term
)	NLP-term
from	O
online	O
social	O
media	O
.	O

Given	O
the	O
lack	O
of	O
parallel	O
data	O
of	O
UGT	NLP-term
that	O
can	O
be	O
used	O
to	O
train	O
or	O
adapt	O
NMT	O
UGT	NLP-term
UGT	NLP-term
we	O
synthesize	O
parallel	O
data	O
of	O
UGT	O
,	O
exploiting	O
monolingual	O
data	O
of	O
UGT	O
through	O
crosslingual	O
language	O
model	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
zero	O
-	O
shot	O
NMT	O
systems	O
.	O

Given	O
the	O
lack	O
of	O
parallel	O
data	O
of	O
UGT	NLP-term
that	O
can	O
be	O
used	O
to	O
train	O
or	O
adapt	O
NMT	O
UGT	NLP-term
UGT	NLP-term
we	O
synthesize	O
parallel	O
data	O
of	O
UGT	O
,	O
exploiting	O
monolingual	O
data	O
of	O
UGT	O
through	O
crosslingual	O
language	O
model	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
and	O
zero	O
-	O
shot	O
NMT	O
systems	O
.	O

This	O
paper	O
presents	O
two	O
different	O
but	O
complementary	O
approaches	O
:	O
One	O
alters	O
given	O
clean	O
parallel	O
data	O
into	O
UGT	NLP-term
UGT	NLP-term
parallel	O
data	O
whereas	O
the	O
other	O
generates	O
translations	O
from	O
monolingual	O
data	O
of	O
UGT	O
.	O

On	O
the	O
MTNT	O
translation	O
tasks	O
,	O
we	O
show	O
that	O
our	O
synthesized	O
parallel	O
data	O
can	O
lead	O
to	O
better	O
NMT	O
systems	O
for	O
UGT	NLP-term
while	O
making	O
them	O
more	O
robust	O
in	O
translating	O
texts	O
from	O
various	O
domains	O
and	O
styles	O
.	O

We	O
present	O
mBART	O
a	O
sequence	O
-	O
to	O
-	O
sequence	O
denoising	O
auto	O
-	O
encoder	O
pre	O
-	O
trained	O
on	O
large	O
-	O
scale	O
monolingual	NLP-term
corpora	NLP-term
in	O
many	O
languages	O
using	O
the	O
BART	O
objective	O
mBART	O
et	O
al	O
.,	O
2019	O
).	O

mBART	O
is	O
the	O
first	O
method	O
for	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
a	O
complete	O
sequence	O
-	O
to	O
-	O
sequence	O
model	O
by	O
denoising	O
full	O
texts	O
in	O
multiple	O
languages	O
,	O
whereas	O
previous	O
approaches	O
have	O
focused	O
only	O
on	O
the	O
encoder	O
decoder	O
or	O
reconstructing	O
parts	O
of	O
the	O
text	O
.	O

Pre	O
-	O
training	O
a	O
complete	O
model	O
allows	O
it	O
to	O
be	O
directly	O
fine	AI/ML/DL-term
-	AI/ML/DL-term
tuned	AI/ML/DL-term
for	O
supervised	AI/ML/DL-term
(	O
both	O
sentence	O
-	O
level	O
and	O
document	O
-	O
level	O
)	O
and	O
unsupervised	O
machine	O
translation	O
with	O
no	O
task	O
-	O
specific	O
modifications	O
.	O

We	O
also	O
show	O
that	O
it	O
enables	O
transfer	O
to	O
language	O
pairs	O
with	O
no	O
bi	O
-	O
text	O
or	O
that	O
were	O
not	O
in	O
the	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
corpus	AI/ML/DL-term
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
extensive	O
analysis	O
of	O
which	O
factors	O
contribute	O
the	O
most	O
to	O
effective	O
pre	O
-	O
training	O
.	O
1	O
.	O

Our	O
findings	O
and	O
infrastructure	O
can	O
help	O
future	O
work	O
on	O
designing	O
new	O
datasets	O
,	O
models	O
,	O
and	O
objective	AI/ML/DL-term
functions	AI/ML/DL-term
for	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
.	O

We	O
also	O
show	O
that	O
the	O
ranking	O
function	O
learned	O
by	O
our	O
method	O
is	O
an	O
effective	O
reward	O
function	O
for	O
reinforcement	O
learning	O
which	O
improves	O
the	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
for	O
interactive	O
summarization	O
.	O

Hence	O
,	O
it	O
remains	O
an	O
open	O
question	O
whether	O
scalable	O
learners	O
like	O
BERT	O
can	O
become	O
fully	O
proficient	O
in	O
the	O
syntax	O
of	O
natural	NLP-term
language	NLP-term
by	O
virtue	O
of	O
data	O
scale	O
alone	O
,	O
or	O
whether	O
they	O
still	O
benefit	O
from	O
more	O
explicit	O
syntactic	O
biases	O
.	O

To	O
answer	O
this	O
question	O
,	O
we	O
introduce	O
a	O
knowledge	O
distillation	O
strategy	O
for	O
injecting	O
syntactic	O
biases	O
into	O
BERT	O
pretraining	AI/ML/DL-term
by	O
distilling	O
the	O
syntactically	O
informative	O
predictions	O
of	O
a	O
hierarchical	O
—	O
albeit	O
harder	O
to	O
scale	O
—	O
syntactic	O
language	O
model	O
.	O

Our	O
approach	O
reduces	O
relative	O
error	O
by	O
2	O
–	O
21	O
\\%	O
on	O
a	O
diverse	O
set	O
of	O
structured	O
prediction	O
tasks	O
,	O
although	O
we	O
obtain	O
mixed	O
results	O
on	O
the	O
GLUE	NLP-dataset
benchmark	O
.	O

Our	O
method	O
assumes	O
that	O
the	O
scoring	O
function	O
is	O
monotonic	AI/ML/DL-term
in	O
the	O
sequence	O
length	O
,	O
which	O
allows	O
us	O
to	O
safely	O
prune	O
hypotheses	O
that	O
cannot	O
be	O
in	O
the	O
final	O
set	O
of	O
hypotheses	O
early	O
on	O
.	O

We	O
devise	O
effective	O
monotonic	AI/ML/DL-term
approximations	AI/ML/DL-term
to	O
popular	O
nonmonontic	O
scoring	O
functions	O
including	O
length	O
normalization	O
and	O
mutual	O
information	O
decoding	O
.	O

To	O
allow	O
for	O
better	O
training	O
and	O
robust	O
evaluation	O
of	O
model	O
-	O
based	O
metrics	O
,	O
we	O
introduce	O
the	O
DailyDialog	NLP-dataset
++	NLP-dataset
dataset	O
,	O
consisting	O
of	O
(	O
i	O
)	O
five	O
relevant	O
responses	O
for	O
each	O
context	O
and	O
(	O
ii	O
)	O
five	O
adversarially	O
crafted	O
irrelevant	O
responses	O
for	O
each	O
context	O
.	O

To	O
check	O
if	O
large	O
scale	O
pretraining	O
could	O
help	O
,	O
we	O
propose	O
a	O
new	O
BERT	O
based	O
evaluation	O
metric	O
called	O
DEB	O
which	O
is	O
pretrained	O
on	O
727M	Miscellaneous-term
Reddit	Miscellaneous-term
conversations	Miscellaneous-term
DEB	O
then	O
finetuned	O
on	O
our	O
dataset	O
.	O

We	O
describe	O
an	O
unsupervised	AI/ML/DL-term
method	O
to	O
create	O
pseudo	O
-	O
parallel	O
corpora	O
for	O
machine	O
translation	O
(	O
MT	O
)	O
from	O
unaligned	O
text	O
.	O

We	O
use	O
multilingual	O
BERT	O
to	O
create	O
source	O
and	O
target	O
sentence	NLP-term
embeddings	NLP-term
for	O
nearest	O
-	O
neighbor	O
search	O
and	O
adapt	O
the	O
model	O
via	O
self	O
-	O
training	O
.	O

We	O
validate	O
our	O
technique	O
by	O
extracting	O
parallel	O
sentence	O
pairs	O
on	O
the	O
BUCC	NLP-dataset
2017	NLP-dataset
bitext	O
mining	O
task	O
and	O
observe	O
up	O
to	O
a	O
24	O
.	O
5	O
point	O
increase	O
(	O
absolute	O
)	O
in	O
F1	O
scores	O
over	O
previous	O
unsupervised	AI/ML/DL-term
methods	O
.	O

We	O
validate	O
our	O
technique	O
by	O
extracting	O
parallel	O
sentence	O
pairs	O
on	O
the	O
BUCC	NLP-dataset
2017	NLP-dataset
bitext	O
mining	O
task	O
and	O
observe	O
up	O
to	O
a	O
24	O
.	O
5	O
point	O
increase	O
(	O
absolute	O
)	O
in	O
F1	O
scores	O
over	O
previous	O
unsupervised	AI/ML/DL-term
methods	O
.	O

We	O
then	O
improve	O
an	O
XLM	O
-	O
based	O
unsupervised	O
neural	O
MT	O
system	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
on	O
Wikipedia	O
by	O
supplementing	O
it	O
with	O
pseudo	O
-	O
parallel	O
text	O
mined	O
from	O
the	O
same	O
corpus	O
,	O
boosting	O
unsupervised	O
translation	O
performance	O
by	O
up	O
to	O
3	O
.	O
5	O
BLEU	O
on	O
the	O
WMT	NLP-dataset
’	NLP-dataset
14	NLP-dataset
French	NLP-dataset
-	NLP-dataset
English	NLP-dataset
and	O
WMT	NLP-dataset
’	NLP-dataset
16	NLP-dataset
German	NLP-dataset
-	NLP-dataset
English	NLP-dataset
tasks	O
and	O
outperforming	O
the	O
previous	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
.	O

We	O
then	O
improve	O
an	O
XLM	O
-	O
based	O
unsupervised	O
neural	O
MT	O
system	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
on	O
Wikipedia	O
by	O
supplementing	O
it	O
with	O
pseudo	O
-	O
parallel	O
text	O
mined	O
from	O
the	O
same	O
corpus	O
,	O
boosting	O
unsupervised	O
translation	O
performance	O
by	O
up	O
to	O
3	O
.	O
5	O
BLEU	O
on	O
the	O
WMT	NLP-dataset
’	NLP-dataset
14	NLP-dataset
French	NLP-dataset
-	NLP-dataset
English	NLP-dataset
and	O
WMT	NLP-dataset
’	NLP-dataset
16	NLP-dataset
German	NLP-dataset
-	NLP-dataset
English	NLP-dataset
tasks	O
and	O
outperforming	O
the	O
previous	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
.	O

We	O
then	O
improve	O
an	O
XLM	O
-	O
based	O
unsupervised	O
neural	O
MT	O
system	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
trained	AI/ML/DL-term
on	O
Wikipedia	O
by	O
supplementing	O
it	O
with	O
pseudo	O
-	O
parallel	O
text	O
mined	O
from	O
the	O
same	O
corpus	O
,	O
boosting	O
unsupervised	O
translation	O
performance	O
by	O
up	O
to	O
3	O
.	O
5	O
BLEU	O
on	O
the	O
WMT	NLP-dataset
’	NLP-dataset
14	NLP-dataset
French	NLP-dataset
-	NLP-dataset
English	NLP-dataset
and	O
WMT	NLP-dataset
’	NLP-dataset
16	NLP-dataset
German	NLP-dataset
-	NLP-dataset
English	NLP-dataset
tasks	O
and	O
outperforming	O
the	O
previous	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
.	O

Finally	O
,	O
we	O
enrich	O
the	O
IWSLT	NLP-dataset
’	NLP-dataset
15	NLP-dataset
English	NLP-dataset
-	NLP-dataset
Vietnamese	NLP-dataset
corpus	O
with	O
pseudo	O
-	O
parallel	O
Wikipedia	O
sentence	O
pairs	O
yielding	O
a	O
1	O
.	O
2	O
BLEU	O
improvement	O
on	O
the	O
low	O
-	O
resource	O
MT	O
task	O
.	O

We	O
demonstrate	O
that	O
unsupervised	O
bitext	O
mining	O
is	O
an	O
effective	O
way	O
of	O
augmenting	O
MT	O
datasets	Miscellaneous-term
and	O
complements	O
existing	O
techniques	O
like	O
initializing	O
with	O
pre	NLP-term
-	NLP-term
trained	NLP-term
contextual	NLP-term
embeddings	NLP-term
.	O

We	O
demonstrate	O
that	O
unsupervised	O
bitext	O
mining	O
is	O
an	O
effective	O
way	O
of	O
augmenting	O
MT	O
datasets	Miscellaneous-term
and	O
complements	O
existing	O
techniques	O
like	O
initializing	O
with	O
pre	NLP-term
-	NLP-term
trained	NLP-term
contextual	NLP-term
embeddings	NLP-term
.	O

Transformer	O
based	O
models	O
have	O
pushed	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
in	O
many	O
areas	O
of	O
NLP	O
but	O
our	O
understanding	O
of	O
what	O
is	O
behind	O
their	O
success	O
is	O
still	O
limited	O
.	O

We	O
review	O
the	O
current	O
state	O
of	O
knowledge	O
about	O
how	O
BERT	O
works	O
,	O
what	O
kind	O
of	O
information	O
it	O
learns	O
and	O
how	O
it	O
is	O
represented	O
,	O
common	O
modifications	O
to	O
its	O
training	AI/ML/DL-term
objectives	AI/ML/DL-term
and	O
architecture	O
,	O
the	O
overparameterization	O
issue	O
,	O
and	O
approaches	O
to	O
compression	O
.	O

We	O
address	O
the	O
task	O
of	O
correcting	O
writing	O
mistakes	O
in	O
morphologically	NLP-term
rich	O
languages	O
,	O
with	O
a	O
focus	O
on	O
Russian	O
.	O

We	O
present	O
a	O
corrected	O
and	O
error	O
-	O
tagged	O
corpus	O
of	O
Russian	Miscellaneous-term
learner	Miscellaneous-term
writing	Miscellaneous-term
and	O
develop	O
models	O
that	O
make	O
use	O
of	O
existing	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
that	O
have	O
been	O
well	O
studied	O
for	O
English	O
.	O

Although	O
impressive	O
results	O
have	O
recently	O
been	O
achieved	O
for	O
grammar	O
error	O
correction	O
of	O
non	O
-	O
native	O
English	O
writing	O
,	O
these	O
results	O
are	O
limited	O
to	O
domains	O
where	O
plentiful	O
training	AI/ML/DL-term
data	AI/ML/DL-term
are	O
available	O
.	O

The	O
results	O
demonstrate	O
that	O
these	O
methods	O
are	O
particularly	O
useful	O
for	O
correcting	O
mistakes	O
in	O
grammatical	O
phenomena	O
that	O
involve	O
rich	O
morphology	NLP-term
.	O

It	O
is	O
intuitive	O
that	O
semantic	NLP-term
representations	NLP-term
can	O
be	O
useful	O
for	O
machine	O
translation	O
mainly	O
because	O
they	O
can	O
help	O
in	O
enforcing	O
meaning	O
preservation	O
and	O
handling	O
data	O
sparsity	O
(	O
many	O
sentences	O
correspond	O
to	O
one	O
meaning	O
)	O
of	O
machine	O
translation	O
models	O
.	O

In	O
this	O
work	O
,	O
we	O
study	O
the	O
usefulness	O
of	O
AMR	NLP-term
(	NLP-term
abstract	NLP-term
meaning	NLP-term
representation	NLP-term
)	NLP-term
on	O
NMT	O
.	O

Experiments	O
on	O
a	O
standard	O
English	O
-	O
to	O
-	O
German	O
dataset	Miscellaneous-term
show	O
that	O
incorporating	O
AMR	NLP-term
as	O
additional	O
knowledge	O
can	O
significantly	O
improve	O
a	O
strong	O
attention	O
-	O
based	O
sequence	O
-	O
to	O
-	O
sequence	O
neural	O
translation	O
model	O
.	O

Experiments	O
on	O
a	O
standard	O
English	O
-	O
to	O
-	O
German	O
dataset	Miscellaneous-term
show	O
that	O
incorporating	O
AMR	NLP-term
as	O
additional	O
knowledge	O
can	O
significantly	O
improve	O
a	O
strong	O
attention	O
-	O
based	O
sequence	O
-	O
to	O
-	O
sequence	O
neural	O
translation	O
model	O
.	O

Consensus	O
clustering	O
provides	O
an	O
elegant	O
framework	Miscellaneous-term
clustering	O
e	O
multiple	O
weak	O
clustering	O
results	O
to	O
learn	O
a	O
consensus	O
one	O
that	O
is	O
more	O
robust	O
and	O
stable	O
than	O
a	O
single	O
result	O
.	O

At	O
first	O
,	O
we	O
construct	O
an	O
initial	O
bipartite	O
graph	O
from	O
the	O
base	O
results	O
,	O
where	O
the	O
nodes	Miscellaneous-term
represent	O
the	O
clusters	AI/ML/DL-term
and	O
instances	O
,	O
and	O
the	O
edges	Miscellaneous-term
cluster	AI/ML/DL-term
that	O
an	O
instance	O
belongs	O
to	O
a	O
cluster	O
.	O

At	O
first	O
,	O
we	O
construct	O
an	O
initial	O
bipartite	O
graph	O
from	O
the	O
base	O
results	O
,	O
where	O
the	O
nodes	Miscellaneous-term
represent	O
the	O
clusters	AI/ML/DL-term
and	O
instances	O
,	O
and	O
the	O
edges	Miscellaneous-term
cluster	AI/ML/DL-term
that	O
an	O
instance	O
belongs	O
to	O
a	O
cluster	O
.	O

Then	O
,	O
we	O
adaptively	O
learn	O
a	O
structured	O
bipartite	O
graph	O
from	O
this	O
initial	O
one	O
by	O
self	O
-	O
paced	O
learning	O
i	O
.	O
e	O
.,	O
we	O
automatically	O
determine	O
the	O
reliability	O
of	O
each	O
edge	Miscellaneous-term
with	O
adaptive	AI/ML/DL-term
cluster	AI/ML/DL-term
similarity	O
measuring	O
and	O
involve	O
the	O
edges	Miscellaneous-term
in	O
bipartite	O
graph	O
learning	O
in	O
order	O
of	O
their	O
reliability	O
.	O

Then	O
,	O
we	O
adaptively	O
learn	O
a	O
structured	O
bipartite	O
graph	O
from	O
this	O
initial	O
one	O
by	O
self	O
-	O
paced	O
learning	O
i	O
.	O
e	O
.,	O
we	O
automatically	O
determine	O
the	O
reliability	O
of	O
each	O
edge	Miscellaneous-term
with	O
adaptive	AI/ML/DL-term
cluster	AI/ML/DL-term
similarity	O
measuring	O
and	O
involve	O
the	O
edges	Miscellaneous-term
in	O
bipartite	O
graph	O
learning	O
in	O
order	O
of	O
their	O
reliability	O
.	O

First	O
,	O
DSTM	O
-	O
DWT	O
decomposes	O
traffic	O
flow	O
into	O
discrete	AI/ML/DL-term
attributes	AI/ML/DL-term
such	O
as	O
flow	Miscellaneous-term
trend	Miscellaneous-term
discrete	Miscellaneous-term
amplitude	Miscellaneous-term
and	O
discrete	Miscellaneous-term
baseline	Miscellaneous-term
.	O

First	O
,	O
DSTM	O
-	O
DWT	O
decomposes	O
traffic	O
flow	O
into	O
discrete	AI/ML/DL-term
attributes	AI/ML/DL-term
such	O
as	O
flow	Miscellaneous-term
trend	Miscellaneous-term
discrete	Miscellaneous-term
amplitude	Miscellaneous-term
and	O
discrete	Miscellaneous-term
baseline	Miscellaneous-term
.	O

Second	O
,	O
we	O
design	O
the	O
spatial	Miscellaneous-term
relationship	Miscellaneous-term
of	O
the	O
transportation	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
as	O
a	O
graph	O
and	O
integrate	O
the	O
new	O
crown	O
pneumonia	O
epidemic	O
data	O
into	O
the	O
characteristics	O
of	O
each	O
transportation	O
node	O
.	O

Second	O
,	O
we	O
design	O
the	O
spatial	Miscellaneous-term
relationship	Miscellaneous-term
of	O
the	O
transportation	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
as	O
a	O
graph	O
and	O
integrate	O
the	O
new	O
crown	O
pneumonia	O
epidemic	O
data	O
into	O
the	O
characteristics	O
of	O
each	O
transportation	O
node	O
.	O

In	O
order	O
to	O
solve	O
the	O
problem	O
of	O
high	O
discreteness	O
of	O
traffic	O
flow	O
data	O
during	O
the	O
epidemic	O
,	O
this	O
article	O
proposes	O
a	O
graph	O
memory	O
network	O
(	O
GMN	O
)	O
which	O
is	O
used	O
to	O
convert	O
discrete	Miscellaneous-term
magnitudes	Miscellaneous-term
separated	O
by	O
discrete	O
wavelet	O
transform	O
into	O
high	O
-	O
dimensional	O
discrete	AI/ML/DL-term
features	AI/ML/DL-term
.	O

In	O
order	O
to	O
solve	O
the	O
problem	O
of	O
high	O
discreteness	O
of	O
traffic	O
flow	O
data	O
during	O
the	O
epidemic	O
,	O
this	O
article	O
proposes	O
a	O
graph	O
memory	O
network	O
(	O
GMN	O
)	O
which	O
is	O
used	O
to	O
convert	O
discrete	Miscellaneous-term
magnitudes	Miscellaneous-term
separated	O
by	O
discrete	O
wavelet	O
transform	O
into	O
high	O
-	O
dimensional	O
discrete	AI/ML/DL-term
features	AI/ML/DL-term
.	O

Finally	O
,	O
use	O
DWT	O
to	O
segment	O
the	O
predicted	O
traffic	O
data	O
,	O
and	O
then	O
perform	O
the	O
inverse	O
discrete	O
wavelet	O
transform	O
between	O
the	O
newly	O
segmented	O
traffic	O
trend	O
and	O
discrete	Miscellaneous-term
baseline	Miscellaneous-term
and	O
the	O
discrete	O
model	O
predicted	O
by	O
GMN	O
to	O
obtain	O
the	O
final	O
traffic	O
flow	O
prediction	O
result	O
.	O

Although	O
crowdsourced	Data/Mining/Information/Retrieval-term
triples	Data/Mining/Information/Retrieval-term
can	O
be	O
converted	O
into	O
various	O
crowdsourced	Data/Mining/Information/Retrieval-term
relationships	Data/Mining/Information/Retrieval-term
the	O
available	O
related	O
methods	O
are	O
not	O
effective	O
in	O
capturing	O
these	O
relationships	O
to	O
alleviate	O
the	O
harm	O
to	O
inference	O
that	O
is	O
caused	O
by	O
conflicting	O
answers	O
.	O

In	O
this	O
research	O
,	O
we	O
propose	O
a	O
Reliability	O
-	O
driven	O
Multi	O
-	O
view	O
Graph	O
Embedding	O
framework	O
for	O
Truth	O
inference	O
(	O
TiReMGE	O
)	O
which	O
explores	O
multiple	O
crowdsourced	Data/Mining/Information/Retrieval-term
relationships	Data/Mining/Information/Retrieval-term
by	O
organically	O
integrating	O
worker	O
reliabilities	O
into	O
a	O
graph	O
space	O
that	O
is	O
constructed	O
from	O
crowdsourced	Data/Mining/Information/Retrieval-term
triples	Data/Mining/Information/Retrieval-term
.	O

From	O
the	O
perspective	O
of	O
multiple	O
crowdsourced	Data/Mining/Information/Retrieval-term
relationships	Data/Mining/Information/Retrieval-term
a	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
embedding	Data/Mining/Information/Retrieval-term
framework	Data/Mining/Information/Retrieval-term
is	O
proposed	O
for	O
reliability	O
information	O
interaction	O
on	O
a	O
task	O
-	O
worker	O
graph	O
which	O
encodes	O
latent	Data/Mining/Information/Retrieval-term
crowdsourced	Data/Mining/Information/Retrieval-term
relationships	Data/Mining/Information/Retrieval-term
into	O
vectors	O
of	O
workers	O
and	O
tasks	O
for	O
reliability	O
update	O
and	O
truth	O
inference	O
.	O

Our	O
ultimate	O
goal	O
is	O
to	O
minimize	O
the	O
Euclidean	O
distance	O
between	O
the	O
encoded	Data/Mining/Information/Retrieval-term
task	Data/Mining/Information/Retrieval-term
vector	Data/Mining/Information/Retrieval-term
and	O
the	O
answer	O
that	O
is	O
provided	O
by	O
a	O
worker	O
with	O
high	O
reliability	O
.	O

Extensive	O
experimental	O
results	O
on	O
nine	O
real	O
-	O
world	O
datasets	O
demonstrate	O
that	O
TiReMGE	O
significantly	O
outperforms	O
the	O
nine	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
.	O

Given	O
a	O
dense	O
tensor	O
how	O
can	O
we	O
efficiently	O
discover	O
hidden	O
relations	O
and	O
patterns	O
in	O
static	Miscellaneous-term
and	Miscellaneous-term
online	Miscellaneous-term
streaming	Miscellaneous-term
settings	Miscellaneous-term
Tucker	O
decomposition	O
is	O
a	O
fundamental	O
tool	O
to	O
analyze	O
multidimensional	O
arrays	O
in	O
the	O
form	O
of	O
tensors	O
.	O

However	O
,	O
existing	O
Tucker	O
decomposition	O
methods	O
in	O
both	O
s	O
tatic	Miscellaneous-term
and	Miscellaneous-term
online	Miscellaneous-term
streaming	Miscellaneous-term
settings	Miscellaneous-term
Tucker	O
decomposition	O
fficiency	O
since	O
they	O
directly	O
deal	O
with	O
large	O
dense	O
tensors	O
for	O
the	O
result	O
of	O
Tucker	O
decomposition	O
.	O

Moreover	O
,	O
streaming	O
versions	O
of	O
Tucker	O
decomposition	O
are	O
still	O
time	O
-	O
consuming	O
to	O
deal	O
with	O
newly	O
arrived	O
tensors	O
We	O
propose	O
D	O
-	O
Tucker	O
and	O
D	O
-	O
TuckerO	O
Tucker	O
decomposition	O
omposition	O
methods	O
for	O
large	O
dense	O
tensors	O
in	O
static	Miscellaneous-term
and	Miscellaneous-term
online	Miscellaneous-term
streaming	Miscellaneous-term
settings	Miscellaneous-term
respectively	O
.	O

Hidden	Data/Mining/Information/Retrieval-term
community	Data/Mining/Information/Retrieval-term
is	O
a	O
useful	O
concept	O
proposed	O
recently	O
for	O
social	O
network	O
analysis	O
.	O

Hidden	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
indicate	O
some	O
weak	O
communities	O
whose	O
most	O
members	O
also	O
belong	O
to	O
other	O
stronger	O
dominant	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
.	O

Dominant	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
could	O
form	O
a	O
layer	O
that	O
partitions	O
all	O
the	O
individuals	O
of	O
a	O
network	O
,	O
and	O
hidden	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
could	O
form	O
other	O
layer	O
(	O
s	O
)	O
underneath	O
.	O

To	O
handle	O
the	O
rapid	O
growth	O
of	O
network	O
scale	O
,	O
in	O
this	O
work	O
,	O
we	O
explore	O
the	O
detection	O
of	O
hidden	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
from	O
the	O
local	O
perspective	O
,	O
and	O
propose	O
a	O
new	O
method	O
that	O
detects	O
and	O
boosts	O
each	O
layer	O
iteratively	O
on	O
a	O
subgraph	O
sampled	O
from	O
the	O
original	O
network	O
.	O

We	O
first	O
expand	O
the	O
seed	O
set	O
from	O
a	O
single	O
seed	O
node	O
based	O
on	O
our	O
modified	O
local	O
spectral	O
method	O
and	O
detect	O
an	O
initial	O
dominant	Data/Mining/Information/Retrieval-term
local	Data/Mining/Information/Retrieval-term
community	Data/Mining/Information/Retrieval-term
.	O

Then	O
we	O
temporarily	O
remove	O
the	O
members	O
of	O
this	O
community	O
as	O
well	O
as	O
their	O
connections	O
to	O
other	O
nodes	O
,	O
and	O
detect	O
all	O
the	O
neighborhood	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
in	O
the	O
remaining	O
subgraph	O
including	O
some	O
“	O
broken	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
that	O
only	O
contain	O
a	O
fraction	O
of	O
members	O
in	O
the	O
original	O
network	O
.	O

The	O
local	Data/Mining/Information/Retrieval-term
community	Data/Mining/Information/Retrieval-term
and	O
neighborhood	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
form	O
a	O
dominant	O
layer	O
,	O
and	O
by	O
reducing	O
the	O
edge	O
weights	O
inside	O
these	O
communities	O
,	O
we	O
weaken	O
this	O
layer	O
’	O
s	O
structure	O
to	O
reveal	O
the	O
hidden	Miscellaneous-term
layers	Miscellaneous-term
.	O

The	O
local	Data/Mining/Information/Retrieval-term
community	Data/Mining/Information/Retrieval-term
and	O
neighborhood	Data/Mining/Information/Retrieval-term
communities	Data/Mining/Information/Retrieval-term
form	O
a	O
dominant	O
layer	O
,	O
and	O
by	O
reducing	O
the	O
edge	O
weights	O
inside	O
these	O
communities	O
,	O
we	O
weaken	O
this	O
layer	O
’	O
s	O
structure	O
to	O
reveal	O
the	O
hidden	Miscellaneous-term
layers	Miscellaneous-term
.	O

We	O
theoretically	O
show	O
that	O
our	O
method	O
can	O
avoid	O
some	O
situations	O
that	O
a	O
broken	Data/Mining/Information/Retrieval-term
community	Data/Mining/Information/Retrieval-term
and	O
the	O
local	Data/Mining/Information/Retrieval-term
community	Data/Mining/Information/Retrieval-term
are	O
regarded	O
as	O
one	O
community	O
in	O
the	O
subgraph	O
leading	O
to	O
the	O
inaccuracy	O
of	O
detection	O
which	O
can	O
be	O
caused	O
by	O
global	O
hidden	O
community	O
detection	O
methods	O
.	O

Extensive	O
experiments	O
show	O
that	O
our	O
method	O
could	O
significantly	O
outperform	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
designed	O
for	O
either	O
global	O
hidden	O
community	O
detection	O
or	O
multiple	O
local	O
community	O
detection	O
.	O

Urban	Miscellaneous-term
vibrancy	Miscellaneous-term
describes	O
the	O
prosperity	O
,	O
diversity	O
,	O
and	O
accessibility	O
of	O
urban	O
areas	O
,	O
which	O
is	O
vital	O
to	O
a	O
city	O
’	O
s	O
socio	O
-	O
economic	O
development	O
and	O
sustainability	O
.	O

While	O
many	O
efforts	O
have	O
been	O
made	O
for	O
statically	O
measuring	O
and	O
evaluating	O
urban	Miscellaneous-term
vibrancy	Miscellaneous-term
urban	Miscellaneous-term
vibrancy	Miscellaneous-term
studies	O
on	O
the	O
evolutionary	O
process	O
of	O
urban	O
vibrancy	O
,	O
yet	O
we	O
know	O
little	O
about	O
the	O
relationship	O
between	O
urban	O
vibrancy	O
evolution	O
and	O
sophisticated	O
spatiotemporal	O
dynamics	O
.	O

In	O
this	O
article	O
,	O
we	O
make	O
use	O
of	O
multi	O
-	O
sourced	O
urban	O
data	O
to	O
develop	O
a	O
data	Miscellaneous-term
-	Miscellaneous-term
driven	Miscellaneous-term
framework	Miscellaneous-term
U	O
-	O
Evolve	O
to	O
investigate	O
urban	O
vibrancy	O
evolution	O
.	O

Then	O
,	O
we	O
analyze	O
the	O
contextual	Data/Mining/Information/Retrieval-term
features	Data/Mining/Information/Retrieval-term
and	O
graph	Data/Mining/Information/Retrieval-term
patterns	Data/Mining/Information/Retrieval-term
of	O
multi	O
-	O
view	O
time	O
-	O
dependent	O
graphs	O
in	O
terms	O
of	O
informing	O
future	O
urban	O
vibrancy	O
variations	O
.	O

After	O
that	O
,	O
we	O
construct	O
a	O
feature	O
based	O
model	O
to	O
forecast	O
future	O
urban	O
vibrancy	O
evolution	O
and	O
quantify	O
each	O
feature	AI/ML/DL-term
’	AI/ML/DL-term
s	AI/ML/DL-term
importance	O
.	O

Finally	O
,	O
extensive	O
experiments	O
on	O
two	O
metropolises	O
,	O
Beijing	Miscellaneous-term
and	O
Shanghai	Miscellaneous-term
demonstrate	O
the	O
effectiveness	O
of	O
our	O
forecasting	O
models	O
.	O

The	O
U	O
-	O
Evolve	O
framework	O
has	O
also	O
been	O
deployed	O
in	O
the	O
production	O
environment	O
to	O
deliver	O
real	O
-	O
world	O
urban	O
development	O
and	O
planning	O
insights	O
for	O
various	O
cities	O
in	O
China	Miscellaneous-term
.	O

However	O
,	O
most	O
existing	O
approaches	O
construct	O
similarity	O
graphs	O
from	O
the	O
original	O
multi	O
-	O
view	O
data	O
,	O
the	O
accuracy	O
of	O
which	O
heavily	O
and	O
implicitly	O
relies	O
on	O
the	O
quality	O
of	O
the	O
original	O
multiple	O
features	AI/ML/DL-term
.	O

In	O
this	O
work	O
,	O
we	O
design	O
a	O
novel	O
GMVC	O
framework	O
via	O
cOmmoNality	O
and	O
Individuality	O
discOvering	O
in	O
lateNt	O
subspace	O
(	O
ONION	O
)	O
seeking	O
for	O
a	O
robust	O
and	O
discriminative	Data/Mining/Information/Retrieval-term
subspace	Data/Mining/Information/Retrieval-term
representation	Data/Mining/Information/Retrieval-term
GMVC	O
tible	O
across	O
multiple	O
features	O
for	O
GMVC	O
.	O

To	O
be	O
specific	O
,	O
our	O
method	O
simultaneously	O
formulates	O
the	O
unsupervised	Data/Mining/Information/Retrieval-term
sparse	Data/Mining/Information/Retrieval-term
feature	Data/Mining/Information/Retrieval-term
selection	Data/Mining/Information/Retrieval-term
and	O
the	O
robust	Data/Mining/Information/Retrieval-term
subspace	Data/Mining/Information/Retrieval-term
extraction	Data/Mining/Information/Retrieval-term
as	O
well	O
as	O
the	O
target	O
graph	O
learning	O
in	O
a	O
unified	O
optimization	O
model	O
,	O
which	O
can	O
help	O
the	O
learning	O
of	O
the	O
discriminative	Data/Mining/Information/Retrieval-term
subspace	Data/Mining/Information/Retrieval-term
representation	Data/Mining/Information/Retrieval-term
and	O
the	O
target	O
graph	O
in	O
a	O
mutual	O
reinforcement	O
manner	O
.	O

However	O
,	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
unsupervised	O
deep	O
learning	O
models	O
for	O
MTS	O
anomaly	O
detection	O
are	O
vulnerable	O
to	O
noise	AI/ML/DL-term
and	O
have	O
poor	O
performance	O
on	O
the	O
training	AI/ML/DL-term
data	AI/ML/DL-term
containing	O
anomalies	Data/Mining/Information/Retrieval-term
.	O

However	O
,	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
unsupervised	O
deep	O
learning	O
models	O
for	O
MTS	O
anomaly	O
detection	O
are	O
vulnerable	O
to	O
noise	AI/ML/DL-term
and	O
have	O
poor	O
performance	O
on	O
the	O
training	AI/ML/DL-term
data	AI/ML/DL-term
containing	O
anomalies	Data/Mining/Information/Retrieval-term
.	O

However	O
,	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
unsupervised	O
deep	O
learning	O
models	O
for	O
MTS	O
anomaly	O
detection	O
are	O
vulnerable	O
to	O
noise	AI/ML/DL-term
and	O
have	O
poor	O
performance	O
on	O
the	O
training	AI/ML/DL-term
data	AI/ML/DL-term
containing	O
anomalies	Data/Mining/Information/Retrieval-term
.	O

The	O
generator	O
is	O
learned	O
to	O
capture	O
the	O
normal	AI/ML/DL-term
data	AI/ML/DL-term
distribution	AI/ML/DL-term
and	O
the	O
discriminator	O
is	O
learned	O
to	O
amplify	O
the	O
reconstruction	AI/ML/DL-term
error	AI/ML/DL-term
of	O
abnormal	O
data	O
for	O
better	O
recognition	O
.	O

Extensive	O
experiments	O
based	O
on	O
six	O
open	O
MTS	O
datasets	O
show	O
that	O
STAD	O
-	O
GAN	O
is	O
robust	O
to	O
noise	O
and	O
achieves	O
significant	O
performance	O
improvement	O
compared	O
to	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
.	O

When	O
the	O
difference	O
value	O
between	O
the	O
number	O
of	O
current	O
instances	O
and	O
the	O
number	O
of	O
warning	O
instances	O
reaches	O
the	O
passive	O
warning	O
value	O
,	O
the	O
algorithm	Miscellaneous-term
selects	O
the	O
optimal	O
base	O
classifiers	O
from	O
AEC	O
and	O
PEC	O
according	O
to	O
the	O
subset	O
accuracy	O
and	O
hamming	O
score	O
and	O
puts	O
them	O
into	O
the	O
predictive	O
ensemble	O
classifiers	O
.	O

In	O
this	O
study	O
,	O
sentiment	O
classification	O
and	O
emotion	O
distribution	O
learning	O
across	O
domains	O
are	O
both	O
formulated	O
as	O
a	O
semi	O
-	O
supervised	O
domain	O
adaptation	O
problem	O
which	O
utilizes	O
a	O
small	O
amount	O
of	O
labeled	O
documents	O
in	O
the	O
target	Miscellaneous-term
domain	Miscellaneous-term
for	O
model	AI/ML/DL-term
training	AI/ML/DL-term
.	O

In	O
this	O
study	O
,	O
sentiment	O
classification	O
and	O
emotion	O
distribution	O
learning	O
across	O
domains	O
are	O
both	O
formulated	O
as	O
a	O
semi	O
-	O
supervised	O
domain	O
adaptation	O
problem	O
which	O
utilizes	O
a	O
small	O
amount	O
of	O
labeled	O
documents	O
in	O
the	O
target	Miscellaneous-term
domain	Miscellaneous-term
for	O
model	AI/ML/DL-term
training	AI/ML/DL-term
.	O

However	O
,	O
the	O
existing	O
NMTF	O
based	O
models	O
ignore	O
the	O
incompatible	O
relationship	O
of	O
sentiment	NLP-term
polarities	NLP-term
and	O
the	O
relatedness	O
among	O
emotions	O
.	O

Besides	O
,	O
their	O
applications	O
on	O
large	Miscellaneous-term
-	Miscellaneous-term
scale	Miscellaneous-term
datasets	Miscellaneous-term
are	O
limited	O
by	O
the	O
high	Miscellaneous-term
computation	Miscellaneous-term
complexity	Miscellaneous-term
.	O

Based	O
on	O
a	O
many	O
-	O
to	O
-	O
many	O
mapping	O
between	O
document	NLP-term
clusters	NLP-term
and	O
sentiment	NLP-term
polarities	NLP-term
(	O
or	O
emotions	O
),	O
we	O
first	O
incorporate	O
the	O
prior	O
information	O
of	O
label	AI/ML/DL-term
dependency	AI/ML/DL-term
to	O
improve	O
the	O
model	AI/ML/DL-term
performance	AI/ML/DL-term
.	O

Based	O
on	O
a	O
many	O
-	O
to	O
-	O
many	O
mapping	O
between	O
document	NLP-term
clusters	NLP-term
and	O
sentiment	NLP-term
polarities	NLP-term
(	O
or	O
emotions	O
),	O
we	O
first	O
incorporate	O
the	O
prior	O
information	O
of	O
label	AI/ML/DL-term
dependency	AI/ML/DL-term
to	O
improve	O
the	O
model	AI/ML/DL-term
performance	AI/ML/DL-term
.	O

Then	O
,	O
we	O
develop	O
a	O
parallel	Miscellaneous-term
algorithm	Miscellaneous-term
based	O
on	O
message	O
passing	O
interface	O
(	O
MPI	O
)	O
to	O
further	O
enhance	O
the	O
model	AI/ML/DL-term
scalability	AI/ML/DL-term
.	O

Then	O
,	O
we	O
develop	O
a	O
parallel	Miscellaneous-term
algorithm	Miscellaneous-term
based	O
on	O
message	O
passing	O
interface	O
(	O
MPI	O
)	O
to	O
further	O
enhance	O
the	O
model	AI/ML/DL-term
scalability	AI/ML/DL-term
.	O

Extensive	O
experiments	O
on	O
real	Miscellaneous-term
-	Miscellaneous-term
world	Miscellaneous-term
datasets	Miscellaneous-term
validate	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O

As	O
the	O
scope	O
of	O
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
and	O
the	O
depth	O
of	O
Graph	O
Neural	O
Networks	O
(	O
GNNs	O
)	O
are	O
two	O
completely	O
orthogonal	O
aspects	O
for	O
graph	O
learning	O
GNNs	O
ting	O
GNNs	O
often	O
have	O
shallow	AI/ML/DL-term
layers	AI/ML/DL-term
with	O
truncated	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
and	O
far	O
from	O
achieving	O
satisfactory	O
performance	O
.	O

As	O
the	O
scope	O
of	O
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
and	O
the	O
depth	O
of	O
Graph	O
Neural	O
Networks	O
(	O
GNNs	O
)	O
are	O
two	O
completely	O
orthogonal	O
aspects	O
for	O
graph	O
learning	O
GNNs	O
ting	O
GNNs	O
often	O
have	O
shallow	AI/ML/DL-term
layers	AI/ML/DL-term
with	O
truncated	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
and	O
far	O
from	O
achieving	O
satisfactory	O
performance	O
.	O

In	O
this	O
article	O
,	O
we	O
follow	O
the	O
idea	O
of	O
decoupling	O
graph	O
convolution	O
into	O
propagation	AI/ML/DL-term
and	O
transformation	AI/ML/DL-term
processes	AI/ML/DL-term
,	AI/ML/DL-term
which	O
generates	O
representations	O
over	O
a	O
sequence	O
of	O
increasingly	O
larger	O
neighborhoods	O
.	O

Though	O
this	O
manner	O
can	O
enlarge	O
the	O
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
ical	O
problems	O
unsolved	O
:	O
how	O
to	O
find	O
the	O
suitable	O
receptive	O
field	O
to	O
avoid	O
under	O
-	O
smoothing	O
or	O
over	O
-	O
smoothing	O
and	O
how	O
to	O
balance	O
different	O
diffusion	Data/Mining/Information/Retrieval-term
operators	Data/Mining/Information/Retrieval-term
for	O
better	O
capturing	O
the	O
local	Miscellaneous-term
and	O
global	Miscellaneous-term
dependencies	Miscellaneous-term
We	O
tackle	O
these	O
challenges	O
and	O
propose	O
a	O
Scalable	O
,	O
Adaptive	O
Graph	O
Convolutional	O
Networks	O
(	O
SAGCN	O
)	O
with	O
Transformer	O
architecture	O
.	O

Though	O
this	O
manner	O
can	O
enlarge	O
the	O
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
ical	O
problems	O
unsolved	O
:	O
how	O
to	O
find	O
the	O
suitable	O
receptive	O
field	O
to	O
avoid	O
under	O
-	O
smoothing	O
or	O
over	O
-	O
smoothing	O
and	O
how	O
to	O
balance	O
different	O
diffusion	Data/Mining/Information/Retrieval-term
operators	Data/Mining/Information/Retrieval-term
for	O
better	O
capturing	O
the	O
local	Miscellaneous-term
and	O
global	Miscellaneous-term
dependencies	Miscellaneous-term
We	O
tackle	O
these	O
challenges	O
and	O
propose	O
a	O
Scalable	O
,	O
Adaptive	O
Graph	O
Convolutional	O
Networks	O
(	O
SAGCN	O
)	O
with	O
Transformer	O
architecture	O
.	O

Concretely	O
,	O
we	O
propose	O
a	O
novel	O
non	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
heuristic	Data/Mining/Information/Retrieval-term
metric	Data/Mining/Information/Retrieval-term
method	O
that	O
quickly	O
finds	O
the	O
suitable	O
number	O
of	O
diffusing	O
iterations	O
and	O
produces	O
smoothed	Data/Mining/Information/Retrieval-term
local	Data/Mining/Information/Retrieval-term
embeddings	Data/Mining/Information/Retrieval-term
that	O
enable	O
the	O
truncated	Data/Mining/Information/Retrieval-term
receptive	Data/Mining/Information/Retrieval-term
field	Data/Mining/Information/Retrieval-term
to	O
become	O
scalable	O
and	O
independent	O
of	O
prior	O
experience	O
.	O

Furthermore	O
,	O
we	O
devise	O
smooth2seq	O
and	O
diffusion	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
position	Data/Mining/Information/Retrieval-term
schemes	Data/Mining/Information/Retrieval-term
introduced	O
into	O
Transformer	O
architecture	O
for	O
better	O
capturing	O
local	Miscellaneous-term
and	O
global	Miscellaneous-term
information	Miscellaneous-term
among	O
embeddings	O
.	O

Furthermore	O
,	O
we	O
devise	O
smooth2seq	O
and	O
diffusion	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
position	Data/Mining/Information/Retrieval-term
schemes	Data/Mining/Information/Retrieval-term
introduced	O
into	O
Transformer	O
architecture	O
for	O
better	O
capturing	O
local	Miscellaneous-term
and	O
global	Miscellaneous-term
information	Miscellaneous-term
among	O
embeddings	O
.	O

Experimental	O
results	O
show	O
that	O
SAGCN	O
enjoys	O
high	O
accuracy	O
scalability	Miscellaneous-term
and	O
efficiency	Miscellaneous-term
on	O
various	O
open	O
benchmarks	O
and	O
is	O
competitive	O
with	O
other	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
competitors	O
.	O

This	O
article	O
proposes	O
a	O
novel	O
algorithm	Miscellaneous-term
called	O
truth	O
inference	O
based	O
on	O
label	O
confidence	O
clustering	O
(	O
TILCC	O
)	O
to	O
improve	O
the	O
quality	O
of	O
integrated	O
labels	O
for	O
the	O
single	O
-	O
choice	O
classification	O
problem	O
in	O
crowdsourcing	O
labeling	O
tasks	O
.	O

We	O
obtain	O
the	O
label	O
confidence	O
via	O
worker	O
reliability	O
,	O
which	O
is	O
calculated	O
from	O
multiple	O
noise	O
labels	O
using	O
a	O
truth	O
discovery	O
method	O
,	O
and	O
then	O
we	O
generate	O
the	O
clustering	O
features	O
and	O
use	O
the	O
K	O
-	O
means	O
algorithm	O
to	O
cluster	O
all	O
the	O
tasks	O
into	O
K	O
different	O
clusters	AI/ML/DL-term
.	O

Each	O
cluster	AI/ML/DL-term
cluster	AI/ML/DL-term
nds	O
to	O
a	O
specific	O
class	O
,	O
and	O
the	O
tasks	O
in	O
the	O
cluster	O
are	O
assigned	O
a	O
label	O
.	O

Compared	O
with	O
the	O
performances	O
of	O
six	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
,	O
MV	O
ZenCrowd	O
PM	O
CATD	O
GLAD	O
and	O
GTIC	O
on	O
12	O
randomly	O
selected	O
real	Miscellaneous-term
-	Miscellaneous-term
world	Miscellaneous-term
datasets	Miscellaneous-term
the	O
performance	O
of	O
our	O
algorithm	Miscellaneous-term
showed	O
many	O
advantages	O
:	O
no	O
need	O
to	O
set	O
complex	O
parameters	AI/ML/DL-term
faster	O
running	O
speed	O
,	O
and	O
significantly	O
higher	O
accuracy	O
.	O

Compared	O
with	O
the	O
performances	O
of	O
six	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
,	O
MV	O
ZenCrowd	O
PM	O
CATD	O
GLAD	O
and	O
GTIC	O
on	O
12	O
randomly	O
selected	O
real	Miscellaneous-term
-	Miscellaneous-term
world	Miscellaneous-term
datasets	Miscellaneous-term
the	O
performance	O
of	O
our	O
algorithm	Miscellaneous-term
showed	O
many	O
advantages	O
:	O
no	O
need	O
to	O
set	O
complex	O
parameters	AI/ML/DL-term
faster	O
running	O
speed	O
,	O
and	O
significantly	O
higher	O
accuracy	O
.	O

In	O
this	O
article	O
,	O
we	O
introduce	O
DiVA	O
—	O
Diffusion	O
Visualization	O
and	O
Analysis	O
a	O
tool	O
that	O
provides	O
a	O
scalable	O
web	O
interface	O
and	O
extendable	O
APIs	Miscellaneous-term
to	O
analyze	O
various	O
diffusion	O
trends	O
on	O
networks	O
.	O

We	O
noticed	O
that	O
evaluators	O
had	O
a	O
seamless	O
user	O
experience	O
,	O
especially	O
when	O
analyzing	O
diffusion	O
on	O
large	Data/Mining/Information/Retrieval-term
networks	Data/Mining/Information/Retrieval-term
.	O

Specifically	O
,	O
we	O
study	O
Singapore	Miscellaneous-term
MRT	Miscellaneous-term
(	Miscellaneous-term
Mass	Miscellaneous-term
Rapid	Miscellaneous-term
Transit	Miscellaneous-term
)	Miscellaneous-term
as	O
a	O
vehicle	O
and	O
leverage	O
EZ	O
-	O
Link	O
transit	O
card	O
records	O
to	O
estimate	O
the	O
crowd	O
distribution	O
.	O

Guided	O
by	O
a	O
key	O
observation	O
that	O
the	O
passenger	O
inflows	O
and	O
arrival	O
flows	O
at	O
different	O
MRT	O
stations	O
and	O
time	O
are	O
spatio	AI/ML/DL-term
-	AI/ML/DL-term
temporally	AI/ML/DL-term
correlated	AI/ML/DL-term
due	O
to	O
behavioral	O
consistency	O
of	O
MRT	O
riders	O
,	O
we	O
design	O
and	O
implement	O
a	O
machine	O
learning	O
based	O
solution	O
,	O
CrowdAtlas	O
that	O
captures	O
MRT	O
riders	O
’	O
transition	O
probabilities	O
among	O
stations	O
and	O
across	O
time	O
,	O
and	O
based	O
on	O
that	O
accurately	O
estimates	O
the	O
crowd	O
distribution	O
within	O
the	O
MRT	O
system	O
.	O

Some	O
solutions	O
assume	O
that	O
auxiliary	Miscellaneous-term
information	Miscellaneous-term
on	O
known	O
matches	O
or	O
node	O
or	O
edge	O
attributes	O
is	O
available	O
,	O
or	O
utilize	O
arbitrary	O
graph	O
features	O
.	O

We	O
present	O
GRASP	O
a	O
method	O
that	O
first	O
establishes	O
a	O
correspondence	O
between	O
functions	O
derived	O
from	O
Laplacian	O
matrix	O
eigenvectors	O
which	O
capture	O
multiscale	Data/Mining/Information/Retrieval-term
structural	Data/Mining/Information/Retrieval-term
characteristics	Data/Mining/Information/Retrieval-term
and	O
then	O
exploits	O
this	O
correspondence	O
to	O
align	O
nodes	O
.	O

Our	O
experimental	O
study	O
,	O
featuring	O
noise	O
levels	O
higher	O
than	O
anything	O
used	O
in	O
previous	O
studies	O
,	O
shows	O
that	O
the	O
enhanced	O
form	O
of	O
GRASP	O
outperforms	O
scalable	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
for	O
graph	O
alignment	O
across	O
noise	O
levels	O
and	O
graph	O
types	O
,	O
and	O
performs	O
competitively	O
with	O
respect	O
to	O
the	O
best	O
non	O
-	O
scalable	O
ones	O
.	O

To	O
address	O
this	O
challenge	O
,	O
a	O
number	O
of	O
studies	O
have	O
developed	O
algorithms	Miscellaneous-term
that	O
estimate	O
properties	O
of	O
social	O
networks	O
via	O
a	O
simple	O
random	O
walk	O
.	O

However	O
,	O
most	O
existing	O
algorithms	Miscellaneous-term
do	O
not	O
assume	O
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
that	O
do	O
not	O
publish	O
their	O
neighbors	O
’	O
data	O
when	O
they	O
are	O
queried	O
in	O
empirical	O
social	O
networks	O
.	O

However	O
,	O
most	O
existing	O
algorithms	Miscellaneous-term
do	O
not	O
assume	O
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
that	O
do	O
not	O
publish	O
their	O
neighbors	O
’	O
data	O
when	O
they	O
are	O
queried	O
in	O
empirical	O
social	O
networks	O
.	O

Here	O
we	O
propose	O
a	O
practical	Miscellaneous-term
framework	Miscellaneous-term
for	O
estimating	O
properties	O
via	O
random	O
walk	O
-	O
based	O
sampling	O
in	O
social	O
networks	O
involving	O
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
.	O

Here	O
we	O
propose	O
a	O
practical	Miscellaneous-term
framework	Miscellaneous-term
for	O
estimating	O
properties	O
via	O
random	O
walk	O
-	O
based	O
sampling	O
in	O
social	O
networks	O
involving	O
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
.	O

First	O
,	O
we	O
develop	O
a	O
sampling	O
algorithm	O
by	O
extending	O
a	O
simple	O
random	O
walk	O
to	O
the	O
case	O
of	O
social	O
networks	O
involving	O
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
.	O

Then	O
,	O
we	O
propose	O
estimators	O
with	O
reduced	O
biases	O
induced	O
by	O
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
for	O
the	O
network	Data/Mining/Information/Retrieval-term
size	Data/Mining/Information/Retrieval-term
average	Data/Mining/Information/Retrieval-term
degree	Data/Mining/Information/Retrieval-term
and	O
density	O
of	O
the	O
node	O
label	O
.	O

Our	O
results	O
show	O
that	O
the	O
proposed	O
estimators	O
reduce	O
biases	O
induced	O
by	O
private	O
nodes	O
in	O
the	O
existing	O
estimators	O
by	O
up	O
to	O
92	O
.	O
6	O
%	O
on	O
social	O
network	O
datasets	Miscellaneous-term
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
ate	O
nodes	O
.	O

Our	O
results	O
show	O
that	O
the	O
proposed	O
estimators	O
reduce	O
biases	O
induced	O
by	O
private	O
nodes	O
in	O
the	O
existing	O
estimators	O
by	O
up	O
to	O
92	O
.	O
6	O
%	O
on	O
social	O
network	O
datasets	Miscellaneous-term
private	Data/Mining/Information/Retrieval-term
nodes	Data/Mining/Information/Retrieval-term
ate	O
nodes	O
.	O

We	O
propose	O
a	O
novel	O
theoretical	Miscellaneous-term
principled	Miscellaneous-term
framework	Miscellaneous-term
lifelong	O
online	O
learning	O
where	O
the	O
learning	O
process	O
for	O
each	O
task	O
is	O
in	O
an	O
incremental	O
manner	O
.	O

Specifically	O
,	O
our	O
framework	O
is	O
composed	O
of	O
two	O
-	O
level	O
predictions	O
:	O
the	O
prediction	O
information	O
that	O
is	O
solely	O
from	O
the	O
current	O
task	O
;	O
and	O
the	O
prediction	O
from	O
the	O
knowledge	NLP-term
base	NLP-term
by	O
previous	O
tasks	O
.	O

Moreover	O
,	O
this	O
article	O
tackled	O
several	O
fundamental	O
challenges	O
:	O
arbitrary	O
or	O
even	O
non	AI/ML/DL-term
-	AI/ML/DL-term
stationary	AI/ML/DL-term
task	AI/ML/DL-term
generation	AI/ML/DL-term
process	O
,	O
an	O
unknown	O
number	O
of	O
instances	O
in	O
each	O
task	O
,	O
and	O
constructing	O
an	O
efficient	O
accumulated	O
knowledge	NLP-term
base	NLP-term
.	O

Moreover	O
,	O
this	O
article	O
tackled	O
several	O
fundamental	O
challenges	O
:	O
arbitrary	O
or	O
even	O
non	AI/ML/DL-term
-	AI/ML/DL-term
stationary	AI/ML/DL-term
task	AI/ML/DL-term
generation	AI/ML/DL-term
process	O
,	O
an	O
unknown	O
number	O
of	O
instances	O
in	O
each	O
task	O
,	O
and	O
constructing	O
an	O
efficient	O
accumulated	O
knowledge	NLP-term
base	NLP-term
.	O

Notably	O
,	O
we	O
provide	O
a	O
provable	O
bound	O
of	O
the	O
proposed	O
algorithm	Miscellaneous-term
which	O
offers	O
insights	O
on	O
the	O
how	O
the	O
accumulated	O
knowledge	O
improves	O
the	O
predictions	O
.	O

Finally	O
,	O
empirical	Miscellaneous-term
evaluations	Miscellaneous-term
on	O
both	O
synthetic	O
and	O
real	O
datasets	O
validate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
algorithm	Miscellaneous-term
.	O

However	O
,	O
this	O
task	O
is	O
very	O
challenging	O
given	O
the	O
limited	O
training	AI/ML/DL-term
data	AI/ML/DL-term
due	O
to	O
the	O
high	O
cost	O
of	O
sensor	O
installment	O
and	O
maintenance	O
across	O
the	O
entire	O
urban	O
space	O
.	O

A	O
more	O
practical	O
scenario	O
to	O
study	O
the	O
citywide	O
traffic	O
inference	O
is	O
effectively	O
modeling	O
the	O
spatial	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
traffic	O
patterns	O
with	O
limited	O
historical	O
traffic	O
observations	O
.	O

Specifically	O
,	O
for	O
the	O
temporal	AI/ML/DL-term
dimension	AI/ML/DL-term
we	O
propose	O
a	O
temporal	O
self	O
-	O
attention	O
mechanism	O
that	O
is	O
capable	O
of	O
learning	O
the	O
dynamics	O
of	O
traffic	O
data	O
with	O
the	O
time	O
-	O
evolving	O
traffic	O
volume	O
variations	O
.	O

For	O
spatial	AI/ML/DL-term
dimension	AI/ML/DL-term
we	O
build	O
a	O
multi	O
-	O
view	O
graph	O
neural	O
network	O
employing	O
the	O
road	O
-	O
wise	O
message	O
passing	O
scheme	O
to	O
capture	O
the	O
region	O
dependencies	O
.	O

With	O
the	O
designed	O
spatial	AI/ML/DL-term
-	AI/ML/DL-term
temporal	AI/ML/DL-term
learning	AI/ML/DL-term
paradigms	O
,	O
we	O
enable	O
our	O
traffic	O
inference	O
model	O
spatial	AI/ML/DL-term
temporal	AI/ML/DL-term
amism	O
from	O
both	O
spatial	O
and	O
temporal	O
traffic	O
patterns	O
,	O
which	O
is	O
reflective	O
of	O
intra	Miscellaneous-term
-	Miscellaneous-term
and	O
inter	Miscellaneous-term
-	Miscellaneous-term
road	Miscellaneous-term
traffic	Miscellaneous-term
correlations	Miscellaneous-term
.	O

With	O
the	O
designed	O
spatial	AI/ML/DL-term
-	AI/ML/DL-term
temporal	AI/ML/DL-term
learning	AI/ML/DL-term
paradigms	O
,	O
we	O
enable	O
our	O
traffic	O
inference	O
model	O
spatial	AI/ML/DL-term
temporal	AI/ML/DL-term
amism	O
from	O
both	O
spatial	O
and	O
temporal	O
traffic	O
patterns	O
,	O
which	O
is	O
reflective	O
of	O
intra	Miscellaneous-term
-	Miscellaneous-term
and	O
inter	Miscellaneous-term
-	Miscellaneous-term
road	Miscellaneous-term
traffic	Miscellaneous-term
correlations	Miscellaneous-term
.	O

Though	O
various	O
methods	O
have	O
been	O
developed	O
,	O
the	O
core	O
spatio	AI/ML/DL-term
-	AI/ML/DL-term
temporal	AI/ML/DL-term
complexity	AI/ML/DL-term
remains	O
challenging	O
from	O
three	O
perspectives	O
:	O
(	O
1	O
)	O
Compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
.	O

According	O
to	O
our	O
empirical	Miscellaneous-term
analysis	Miscellaneous-term
these	O
relationships	O
widely	O
exist	O
.	O

Previous	O
studies	O
focus	O
on	O
capturing	O
different	O
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
using	O
multi	O
-	O
homogeneous	O
graphs	O
.	O

However	O
,	O
the	O
information	O
flow	O
across	O
various	O
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
is	O
not	O
modeled	O
explicitly	O
.	O

(	O
2	O
)	O
Heterogeneity	Miscellaneous-term
in	O
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
.	O

(	O
2	O
)	O
Heterogeneity	Miscellaneous-term
in	O
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
.	O

(	O
3	O
)	O
Synchronicity	Miscellaneous-term
between	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
.	O

(	O
3	O
)	O
Synchronicity	Miscellaneous-term
between	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
.	O

Previous	O
research	O
considers	O
synchronous	Miscellaneous-term
influences	O
from	O
spatial	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
in	O
a	O
homogeneous	Miscellaneous-term
fashion	O
while	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
are	O
not	O
captured	O
for	O
this	O
synchronicity	Miscellaneous-term
To	O
address	O
the	O
aforementioned	O
perspectives	O
,	O
we	O
propose	O
the	O
Spatio	O
-	O
Temporal	O
Heterogeneous	O
graph	O
Attention	O
Network	O
(	O
STHAN	O
)	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
turing	O
the	O
compound	O
spatial	O
relationships	O
via	O
meta	O
-	O
paths	O
explicitly	O
.	O

Previous	O
research	O
considers	O
synchronous	Miscellaneous-term
influences	O
from	O
spatial	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
in	O
a	O
homogeneous	Miscellaneous-term
fashion	O
while	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
are	O
not	O
captured	O
for	O
this	O
synchronicity	Miscellaneous-term
To	O
address	O
the	O
aforementioned	O
perspectives	O
,	O
we	O
propose	O
the	O
Spatio	O
-	O
Temporal	O
Heterogeneous	O
graph	O
Attention	O
Network	O
(	O
STHAN	O
)	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
turing	O
the	O
compound	O
spatial	O
relationships	O
via	O
meta	O
-	O
paths	O
explicitly	O
.	O

We	O
first	O
construct	O
a	O
spatio	O
-	O
temporal	O
heterogeneous	O
graph	O
including	O
multiple	O
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
and	O
use	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
to	O
depict	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
.	O

We	O
first	O
construct	O
a	O
spatio	O
-	O
temporal	O
heterogeneous	O
graph	O
including	O
multiple	O
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
and	O
use	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
to	O
depict	O
compound	AI/ML/DL-term
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
.	O

To	O
capture	O
the	O
heterogeneity	Miscellaneous-term
we	O
use	O
hierarchical	O
attention	O
which	O
contains	O
node	O
level	O
attention	O
and	O
meta	O
-	O
path	O
level	O
attention	O
.	O

The	O
synchronicity	O
between	O
temporal	AI/ML/DL-term
relationships	AI/ML/DL-term
and	O
spatial	AI/ML/DL-term
relationships	AI/ML/DL-term
including	O
compound	O
ones	O
,	O
is	O
modeled	O
in	O
meta	O
-	O
path	O
-	O
level	O
attention	O
.	O

Our	O
framework	O
outperforms	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
by	O
reducing	O
6	O
.	O
58	O
%	O
4	O
.	O
57	O
%	O
and	O
4	O
.	O
20	O
%	O
of	O
WMAPE	O
in	O
experiments	O
on	O
three	O
real	Miscellaneous-term
-	Miscellaneous-term
world	Miscellaneous-term
datasets	Miscellaneous-term
respectively	O
.	O

Data	O
explosion	O
in	O
the	O
information	Miscellaneous-term
society	Miscellaneous-term
drives	O
people	O
to	O
develop	O
more	O
effective	O
ways	O
to	O
extract	O
meaningful	O
information	O
.	O

Extracting	O
semantic	NLP-term
information	NLP-term
and	O
relational	NLP-term
information	NLP-term
has	O
emerged	O
as	O
a	O
key	O
mining	O
primitive	O
in	O
a	O
wide	O
variety	O
of	O
practical	O
applications	O
.	O

Existing	O
research	O
on	O
relation	O
mining	O
has	O
primarily	O
focused	O
on	O
explicit	O
connections	O
and	O
ignored	O
underlying	O
information	O
,	O
e	O
.	O
g	O
.,	O
the	O
latent	NLP-term
entity	NLP-term
relations	NLP-term
.	O

MIRROR	O
captures	O
rich	O
information	O
in	O
learning	O
node	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
level	Data/Mining/Information/Retrieval-term
representations	Data/Mining/Information/Retrieval-term
by	O
incorporating	O
attributes	O
from	O
heterogeneous	O
neighbors	O
.	O

Furthermore	O
,	O
MIRROR	O
is	O
tolerant	O
of	O
missing	O
n	O
ode	Data/Mining/Information/Retrieval-term
attribute	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
because	O
it	O
is	O
able	O
to	O
utilize	O
network	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
.	O

We	O
empirically	O
evaluate	O
MIRROR	O
on	O
four	O
different	O
genres	O
of	O
networks	O
,	O
achieving	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
for	O
target	O
relations	O
mining	O
.	O

To	O
address	O
this	O
issue	O
,	O
we	O
propose	O
a	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
task	AI/ML/DL-term
learning	AI/ML/DL-term
framework	AI/ML/DL-term
(	AI/ML/DL-term
TAP	AI/ML/DL-term
)	AI/ML/DL-term
based	O
on	O
the	O
Spatio	O
-	O
temporal	O
Variational	O
Graph	O
Auto	O
-	O
Encoders	O
(	O
ST	O
-	O
VGAE	O
)	O
for	O
traffic	O
accident	O
profiling	O
.	O

Then	O
,	O
we	O
use	O
a	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
task	AI/ML/DL-term
learning	AI/ML/DL-term
scheme	O
to	O
combine	O
external	O
factors	O
to	O
generate	O
the	O
traffic	O
accident	O
profiling	O
.	O

Finally	O
,	O
the	O
experimental	O
results	O
on	O
real	O
datasets	O
demonstrate	O
that	O
TAP	AI/ML/DL-term
outperforms	O
other	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
.	O

Finally	O
,	O
the	O
experimental	O
results	O
on	O
real	O
datasets	O
demonstrate	O
that	O
TAP	AI/ML/DL-term
outperforms	O
other	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
baselines	O
.	O

One	O
challenging	O
problem	O
tourists	O
face	O
is	O
identifying	O
attractive	O
Places	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
Interest	Miscellaneous-term
(	Miscellaneous-term
POIs	Miscellaneous-term
)	Miscellaneous-term
and	O
planning	O
the	O
personalized	O
trip	O
with	O
time	O
constraints	O
.	O

Most	O
of	O
the	O
existing	O
trip	O
recommendation	O
methods	O
mainly	O
consider	O
POI	Miscellaneous-term
POI	Miscellaneous-term
POI	Miscellaneous-term
ty	O
and	O
user	O
preferences	O
,	O
and	O
focus	O
on	O
the	O
last	O
visited	O
POI	O
when	O
choosing	O
the	O
next	O
POI	O
.	O

GRM	O
-	O
RTrip	O
learns	O
POI	Data/Mining/Information/Retrieval-term
representations	Data/Mining/Information/Retrieval-term
from	O
incoming	O
and	O
outgoing	O
views	O
to	O
obtain	O
asymmetric	Data/Mining/Information/Retrieval-term
POI	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
POI	Data/Mining/Information/Retrieval-term
transition	Data/Mining/Information/Retrieval-term
probability	Data/Mining/Information/Retrieval-term
via	O
POI	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
POI	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
networks	Data/Mining/Information/Retrieval-term
and	O
then	O
fuses	O
the	O
trained	Data/Mining/Information/Retrieval-term
POI	Data/Mining/Information/Retrieval-term
representation	Data/Mining/Information/Retrieval-term
into	O
a	O
user	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
POI	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
to	O
estimate	O
user	O
preferences	O
.	O

Finally	O
,	O
after	O
formulating	O
the	O
personalized	O
trip	O
recommendation	O
as	O
a	O
Markov	O
Decision	O
Process	O
(	O
MDP	O
)	O
we	O
utilize	O
a	O
reinforcement	O
learning	O
algorithm	Miscellaneous-term
for	O
generating	O
a	O
personalized	O
trip	O
with	O
maximal	O
user	O
travel	O
experience	O
.	O

Extensive	O
experiments	O
are	O
performed	O
on	O
the	O
public	O
datasets	Miscellaneous-term
and	O
the	O
results	O
demonstrate	O
the	O
superiority	O
of	O
GRM	O
-	O
RTrip	O
compared	O
with	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
trip	O
recommendation	O
methods	O
.	O

Graph	O
Convolutional	O
Networks	O
(	O
GCNs	O
)	O
have	O
been	O
widely	O
used	O
for	O
collaborative	O
filtering	O
due	O
to	O
their	O
effectiveness	O
in	O
exploiting	O
high	AI/ML/DL-term
-	AI/ML/DL-term
order	AI/ML/DL-term
collaborative	AI/ML/DL-term
signals	AI/ML/DL-term
.	O

To	O
address	O
these	O
limitations	O
,	O
we	O
propose	O
to	O
mine	O
three	O
kinds	O
of	O
information	O
(	O
user	Miscellaneous-term
preference	Miscellaneous-term
item	Miscellaneous-term
dependency	Miscellaneous-term
and	O
user	O
behavior	O
similarity	O
)	O
and	O
their	O
temporal	O
evolution	O
by	O
constructing	O
multiple	O
discrete	O
dynamic	O
heterogeneous	O
graphs	O
(	O
i	O
.	O
e	O
.,	O
a	O
user	O
-	O
item	O
dynamic	O
graph	O
an	O
item	O
-	O
item	O
dynamic	O
graph	O
and	O
a	O
user	O
-	O
subseq	O
dynamic	O
graph	O
from	O
interaction	O
data	O
.	O

We	O
also	O
design	O
a	O
temporal	O
neighbor	O
aggregation	O
module	O
based	O
on	O
self	O
-	O
attention	O
mechanism	O
to	O
aggregate	O
the	O
features	O
of	O
temporal	Data/Mining/Information/Retrieval-term
neighbors	Data/Mining/Information/Retrieval-term
.	O

While	O
it	O
is	O
a	O
common	O
practice	O
to	O
leverage	O
both	O
attribute	O
and	O
structure	O
information	O
for	O
improved	O
clustering	O
performance	O
,	O
most	O
existing	O
AGC	O
algorithms	Miscellaneous-term
AGC	O
ider	O
only	O
a	O
specific	O
type	O
of	O
relations	O
,	O
which	O
hinders	O
their	O
applicability	O
to	O
integrate	O
various	O
complex	O
relations	O
into	O
node	O
attributes	O
for	O
AGC	O
.	O

The	O
experimental	O
results	O
show	O
that	O
GRACE	O
outperforms	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
AGC	O
methods	O
on	O
the	O
different	O
graph	O
types	O
in	O
terms	O
of	O
clustering	O
quality	O
,	O
time	O
,	O
and	O
memory	O
usage	O
.	O

The	O
experiments	O
show	O
that	O
our	O
method	O
achieves	O
desirable	O
results	O
and	O
generalization	AI/ML/DL-term
ability	AI/ML/DL-term
.	O

In	O
this	O
article	O
,	O
we	O
develop	O
an	O
Individual	AI/ML/DL-technique
-	AI/ML/DL-technique
based	AI/ML/DL-technique
Reinforcement	AI/ML/DL-technique
Learning	AI/ML/DL-technique
Epidemic	AI/ML/DL-technique
Control	AI/ML/DL-technique
Agent	AI/ML/DL-technique
(	AI/ML/DL-technique
IDRLECA	AI/ML/DL-technique
)	AI/ML/DL-technique
to	O
search	O
for	O
smart	O
epidemic	O
control	O
strategies	O
that	O
can	O
simultaneously	O
minimize	O
infections	O
and	O
the	O
cost	O
of	O
mobility	O
intervention	O
.	O

IDRLECA	AI/ML/DL-technique
first	O
hires	O
an	O
infection	O
probability	O
model	O
to	O
calculate	O
the	O
current	O
infection	O
probability	O
of	O
each	O
individual	O
.	O

The	O
estimated	O
risks	O
are	O
used	O
to	O
further	O
support	O
an	O
RL	AI/ML/DL-term
agent	AI/ML/DL-term
to	O
select	O
individual	O
-	O
level	O
epidemic	O
-	O
control	O
actions	O
.	O

The	O
training	O
of	O
IDRLECA	AI/ML/DL-technique
is	O
guided	O
by	O
a	O
specially	O
designed	O
reward	AI/ML/DL-term
function	AI/ML/DL-term
considering	O
both	O
the	O
cost	O
of	O
mobility	O
intervention	O
and	O
the	O
effectiveness	O
of	O
epidemic	O
control	O
.	O

The	O
training	O
of	O
IDRLECA	AI/ML/DL-technique
is	O
guided	O
by	O
a	O
specially	O
designed	O
reward	AI/ML/DL-term
function	AI/ML/DL-term
considering	O
both	O
the	O
cost	O
of	O
mobility	O
intervention	O
and	O
the	O
effectiveness	O
of	O
epidemic	O
control	O
.	O

Extensive	O
experimental	O
results	O
demonstrate	O
that	O
IDRLECA	AI/ML/DL-technique
can	O
suppress	O
infections	O
at	O
a	O
very	O
low	O
level	O
and	O
retain	O
more	O
than	O
95	O
%	O
of	O
human	O
mobility	O
.	O

To	O
solve	O
this	O
problem	O
,	O
this	O
article	O
discovers	O
frequent	O
one	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
off	Data/Mining/Information/Retrieval-term
negative	Data/Mining/Information/Retrieval-term
sequential	Data/Mining/Information/Retrieval-term
patterns	Data/Mining/Information/Retrieval-term
(	Data/Mining/Information/Retrieval-term
ONPs	Data/Mining/Information/Retrieval-term
)	Data/Mining/Information/Retrieval-term
.	O

Experimental	O
results	O
show	O
that	O
ONP	O
-	O
Miner	O
not	O
only	O
improves	O
the	O
mining	O
efficiency	O
but	O
also	O
has	O
better	O
mining	O
performance	O
than	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
algorithms	O
.	O

In	O
general	O
,	O
all	O
centrality	O
metrics	O
aim	O
at	O
measuring	O
the	O
importance	O
of	O
nodes	O
(	O
according	O
to	O
some	O
definition	O
of	O
importance	O
),	O
and	O
such	O
importance	Data/Mining/Information/Retrieval-term
scores	Data/Mining/Information/Retrieval-term
are	O
used	O
to	O
rank	O
the	O
nodes	O
in	O
the	O
network	O
,	O
therefore	O
the	O
rank	O
improvement	O
is	O
a	O
strictly	O
related	O
topic	O
.	O

This	O
problem	O
,	O
also	O
known	O
as	O
link	O
-	O
building	O
has	O
been	O
shown	O
to	O
be	O
NP	O
-	O
hard	O
,	O
and	O
most	O
heuristics	O
developed	O
failed	O
in	O
obtaining	O
good	O
performance	O
with	O
acceptable	O
computational	Miscellaneous-term
complexity	Miscellaneous-term
.	O

To	O
validate	O
our	O
proposal	O
,	O
31	O
real	O
-	O
world	O
networks	O
were	O
considered	O
;	O
tests	O
show	O
that	O
LB	O
–	O
GDM	O
performs	O
significantly	O
better	O
than	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
heuristics	O
,	O
while	O
having	O
a	O
comparable	O
or	O
even	O
lower	O
computational	Miscellaneous-term
complexity	Miscellaneous-term
which	O
allows	O
it	O
to	O
scale	O
well	O
even	O
to	O
large	O
networks	O
.	O

Map	O
matching	O
is	O
a	O
fundamental	O
research	O
topic	O
with	O
the	O
objective	O
of	O
aligning	O
GPS	Miscellaneous-term
trajectories	Miscellaneous-term
to	O
paths	O
on	O
the	O
road	O
network	O
.	O

First	O
,	O
high	O
-	O
quality	O
representations	O
of	O
low	O
-	O
quality	O
trajectories	O
are	O
learned	O
by	O
two	O
representation	O
enhancement	O
methods	O
,	O
i	O
.	O
e	O
.,	O
enhancement	O
with	O
high	Miscellaneous-term
-	Miscellaneous-term
frequency	Miscellaneous-term
trajectories	Miscellaneous-term
and	O
enhancement	O
with	O
the	O
data	AI/ML/DL-term
distribution	AI/ML/DL-term
.	O

First	O
,	O
high	O
-	O
quality	O
representations	O
of	O
low	O
-	O
quality	O
trajectories	O
are	O
learned	O
by	O
two	O
representation	O
enhancement	O
methods	O
,	O
i	O
.	O
e	O
.,	O
enhancement	O
with	O
high	Miscellaneous-term
-	Miscellaneous-term
frequency	Miscellaneous-term
trajectories	Miscellaneous-term
and	O
enhancement	O
with	O
the	O
data	AI/ML/DL-term
distribution	AI/ML/DL-term
.	O

The	O
former	O
employs	O
high	Miscellaneous-term
-	Miscellaneous-term
frequency	Miscellaneous-term
trajectories	Miscellaneous-term
to	O
enhance	O
the	O
expressive	O
capability	O
of	O
representations	O
,	O
while	O
the	O
latter	O
regularizes	O
the	O
representation	O
distribution	O
over	O
the	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
to	O
improve	O
the	O
generalization	O
ability	O
of	O
representations	O
.	O

The	O
former	O
employs	O
high	Miscellaneous-term
-	Miscellaneous-term
frequency	Miscellaneous-term
trajectories	Miscellaneous-term
to	O
enhance	O
the	O
expressive	O
capability	O
of	O
representations	O
,	O
while	O
the	O
latter	O
regularizes	O
the	O
representation	O
distribution	O
over	O
the	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
to	O
improve	O
the	O
generalization	O
ability	O
of	O
representations	O
.	O

Secondly	O
,	O
to	O
embrace	O
more	O
heuristic	O
clues	O
,	O
typical	O
mobility	O
patterns	O
are	O
recognized	O
in	O
the	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
and	O
further	O
incorporated	O
into	O
the	O
map	O
matching	O
task	O
.	O

Dynamic	O
recommender	O
considers	O
not	O
only	O
static	O
user	O
-	O
item	O
interaction	O
data	O
,	O
but	O
the	O
temporal	AI/ML/DL-term
information	AI/ML/DL-term
at	O
the	O
time	O
of	O
recommendation	O
.	O

Previous	O
researches	O
have	O
suggested	O
to	O
incorporate	O
social	O
media	O
as	O
the	O
temporal	O
information	O
in	O
dynamic	O
neural	O
recommenders	O
after	O
transforming	O
them	O
into	O
embeddings	AI/ML/DL-term
.	O

Despite	O
substantial	O
interest	O
in	O
applications	O
of	O
neural	O
networks	O
to	O
information	O
retrieval	O
neural	O
ranking	O
models	O
have	O
mostly	O
been	O
applied	O
to	O
conventional	O
ad	O
-	O
hoc	O
retrieval	O
tasks	O
over	O
web	Miscellaneous-term
pages	Miscellaneous-term
and	O
newswire	Miscellaneous-term
articles	Miscellaneous-term
.	O

This	O
article	O
proposes	O
a	O
concept	O
-	O
enhanced	O
pre	O
-	O
training	O
model	O
for	O
microblog	O
retrieval	O
task	O
leveraging	O
Semantic	O
Matching	O
Model	O
(	O
SMM	O
)	O
objective	AI/ML/DL-term
and	O
Concept	O
Correlation	O
Model	O
(	O
CCM	O
)	O
objective	AI/ML/DL-term
.	O

The	O
proposed	O
model	O
is	O
a	O
novel	O
neural	O
ranking	O
model	O
ranking	Data/Mining/Information/Retrieval-term
ally	O
designed	O
for	O
ranking	O
short	Miscellaneous-term
-	Miscellaneous-term
text	Miscellaneous-term
microblog	Miscellaneous-term
which	O
could	O
merge	O
the	O
advantage	O
of	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
methodology	O
for	O
generating	O
valid	O
contextualized	NLP-term
embedding	NLP-term
with	O
the	O
superiority	O
of	O
the	O
prior	O
lexical	NLP-term
knowledge	NLP-term
(	O
e	O
.	O
g	O
.,	O
concept	O
knowledge	O
)	O
for	O
understanding	O
short	NLP-term
-	NLP-term
text	NLP-term
language	NLP-term
semantic	NLP-term
.	O

The	O
proposed	O
model	O
is	O
a	O
novel	O
neural	O
ranking	O
model	O
ranking	Data/Mining/Information/Retrieval-term
ally	O
designed	O
for	O
ranking	O
short	Miscellaneous-term
-	Miscellaneous-term
text	Miscellaneous-term
microblog	Miscellaneous-term
which	O
could	O
merge	O
the	O
advantage	O
of	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
methodology	O
for	O
generating	O
valid	O
contextualized	NLP-term
embedding	NLP-term
with	O
the	O
superiority	O
of	O
the	O
prior	O
lexical	NLP-term
knowledge	NLP-term
(	O
e	O
.	O
g	O
.,	O
concept	O
knowledge	O
)	O
for	O
understanding	O
short	NLP-term
-	NLP-term
text	NLP-term
language	NLP-term
semantic	NLP-term
.	O

The	O
proposed	O
model	O
is	O
a	O
novel	O
neural	O
ranking	O
model	O
ranking	Data/Mining/Information/Retrieval-term
ally	O
designed	O
for	O
ranking	O
short	Miscellaneous-term
-	Miscellaneous-term
text	Miscellaneous-term
microblog	Miscellaneous-term
which	O
could	O
merge	O
the	O
advantage	O
of	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
methodology	O
for	O
generating	O
valid	O
contextualized	NLP-term
embedding	NLP-term
with	O
the	O
superiority	O
of	O
the	O
prior	O
lexical	NLP-term
knowledge	NLP-term
(	O
e	O
.	O
g	O
.,	O
concept	O
knowledge	O
)	O
for	O
understanding	O
short	NLP-term
-	NLP-term
text	NLP-term
language	NLP-term
semantic	NLP-term
.	O

The	O
proposed	O
model	O
is	O
a	O
novel	O
neural	O
ranking	O
model	O
ranking	Data/Mining/Information/Retrieval-term
ally	O
designed	O
for	O
ranking	O
short	Miscellaneous-term
-	Miscellaneous-term
text	Miscellaneous-term
microblog	Miscellaneous-term
which	O
could	O
merge	O
the	O
advantage	O
of	O
pre	AI/ML/DL-term
-	AI/ML/DL-term
training	AI/ML/DL-term
methodology	O
for	O
generating	O
valid	O
contextualized	NLP-term
embedding	NLP-term
with	O
the	O
superiority	O
of	O
the	O
prior	O
lexical	NLP-term
knowledge	NLP-term
(	O
e	O
.	O
g	O
.,	O
concept	O
knowledge	O
)	O
for	O
understanding	O
short	NLP-term
-	NLP-term
text	NLP-term
language	NLP-term
semantic	NLP-term
.	O

We	O
conduct	O
experiments	O
on	O
widely	O
used	O
real	O
-	O
world	O
datasets	O
,	O
and	O
the	O
experimental	O
results	O
demonstrate	O
the	O
efficiency	O
of	O
the	O
proposed	O
model	O
,	O
even	O
compared	O
with	O
latest	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
neural	O
-	O
based	O
models	O
and	O
pre	O
-	O
training	O
based	O
models	O
.	O

Existing	O
methods	O
mainly	O
focus	O
on	O
some	O
hand	O
-	O
crafted	O
features	O
or	O
graph	O
embedding	O
models	O
based	O
on	O
the	O
user	O
-	O
location	O
bipartite	O
graph	O
,	O
which	O
cannot	O
precisely	O
capture	O
the	O
latent	Data/Mining/Information/Retrieval-term
mobility	Data/Mining/Information/Retrieval-term
similarity	Data/Mining/Information/Retrieval-term
for	O
the	O
majority	O
of	O
users	O
who	O
have	O
no	O
explicit	O
co	O
-	O
visit	O
behaviors	O
and	O
also	O
fail	O
to	O
balance	O
the	O
tradeoff	O
between	O
social	O
features	O
and	O
mobility	O
features	O
for	O
friendship	O
prediction	O
.	O

In	O
this	O
regard	O
,	O
we	O
propose	O
a	O
dual	O
subgraph	O
-	O
based	O
pairwise	O
graph	O
neural	O
network	O
(	O
DSGNN	O
)	O
for	O
friendship	O
prediction	O
in	O
LBSNs	O
which	O
extracts	O
a	O
pairwise	Data/Mining/Information/Retrieval-term
social	Data/Mining/Information/Retrieval-term
subgraph	Data/Mining/Information/Retrieval-term
and	O
a	O
trajectory	Data/Mining/Information/Retrieval-term
subgraph	Data/Mining/Information/Retrieval-term
to	O
model	O
the	O
social	Data/Mining/Information/Retrieval-term
proximity	Data/Mining/Information/Retrieval-term
and	O
mobility	Data/Mining/Information/Retrieval-term
similarity	Data/Mining/Information/Retrieval-term
respectively	O
.	O

Specifically	O
,	O
to	O
overcome	O
the	O
co	O
-	O
visit	O
data	O
sparsity	O
,	O
we	O
design	O
an	O
entropy	O
-	O
based	O
random	O
walk	O
to	O
construct	O
a	O
location	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
that	O
captures	O
the	O
high	O
-	O
level	O
correlation	O
between	O
locations	O
.	O

Based	O
on	O
this	O
,	O
we	O
characterize	O
the	O
pairwise	Data/Mining/Information/Retrieval-term
mobility	Data/Mining/Information/Retrieval-term
similarity	Data/Mining/Information/Retrieval-term
from	O
trajectory	Miscellaneous-term
level	Miscellaneous-term
instead	O
of	O
location	Miscellaneous-term
level	Miscellaneous-term
which	O
is	O
modeled	O
by	O
a	O
graph	O
neural	O
network	O
(	O
GNN	O
)	O
on	O
a	O
labeled	Data/Mining/Information/Retrieval-term
trajectory	Data/Mining/Information/Retrieval-term
subgraph	Data/Mining/Information/Retrieval-term
composed	O
of	O
the	O
two	O
trajectories	O
of	O
the	O
target	O
user	O
pair	O
.	O

Based	O
on	O
this	O
,	O
we	O
characterize	O
the	O
pairwise	Data/Mining/Information/Retrieval-term
mobility	Data/Mining/Information/Retrieval-term
similarity	Data/Mining/Information/Retrieval-term
from	O
trajectory	Miscellaneous-term
level	Miscellaneous-term
instead	O
of	O
location	Miscellaneous-term
level	Miscellaneous-term
which	O
is	O
modeled	O
by	O
a	O
graph	O
neural	O
network	O
(	O
GNN	O
)	O
on	O
a	O
labeled	Data/Mining/Information/Retrieval-term
trajectory	Data/Mining/Information/Retrieval-term
subgraph	Data/Mining/Information/Retrieval-term
composed	O
of	O
the	O
two	O
trajectories	O
of	O
the	O
target	O
user	O
pair	O
.	O

Besides	O
,	O
we	O
also	O
utilize	O
another	O
GNN	O
to	O
extract	O
social	Data/Mining/Information/Retrieval-term
proximity	Data/Mining/Information/Retrieval-term
based	O
on	O
social	Data/Mining/Information/Retrieval-term
subgraph	Data/Mining/Information/Retrieval-term
of	O
the	O
target	O
user	O
pair	O
.	O

We	O
conduct	O
extensive	O
experiments	O
on	O
the	O
real	O
-	O
world	O
datasets	O
and	O
demonstrate	O
the	O
superiority	O
of	O
our	O
approach	O
,	O
which	O
outperforms	O
other	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
.	O

In	O
particular	O
,	O
the	O
comparative	O
experiments	O
on	O
the	O
trajectory	Data/Mining/Information/Retrieval-term
level	Data/Mining/Information/Retrieval-term
mobility	Data/Mining/Information/Retrieval-term
similarity	Data/Mining/Information/Retrieval-term
further	O
validate	O
the	O
effectiveness	O
of	O
the	O
designed	O
trajectory	O
subgraph	O
-	O
based	O
method	O
which	O
can	O
extract	O
predictive	O
mobility	O
features	O
.	O

There	O
exist	O
three	O
major	O
challenges	O
toward	O
solving	O
this	O
problem	O
:	O
temporal	Data/Mining/Information/Retrieval-term
nonlinear	Data/Mining/Information/Retrieval-term
sparsity	Data/Mining/Information/Retrieval-term
weak	Data/Mining/Information/Retrieval-term
serial	Data/Mining/Information/Retrieval-term
correlation	Data/Mining/Information/Retrieval-term
and	O
discontinuous	Data/Mining/Information/Retrieval-term
structural	Data/Mining/Information/Retrieval-term
dynamics	Data/Mining/Information/Retrieval-term
.	O

The	O
structural	O
dynamic	O
evolution	O
is	O
sequenced	O
into	O
consecutive	O
links	O
one	O
by	O
one	O
over	O
time	O
to	O
inhibit	O
temporal	Data/Mining/Information/Retrieval-term
nonlinear	Data/Mining/Information/Retrieval-term
sparsity	Data/Mining/Information/Retrieval-term
.	O

This	O
structural	O
encoding	O
consists	O
of	O
two	O
parts	O
:	O
the	O
node	Data/Mining/Information/Retrieval-term
clustering	Data/Mining/Information/Retrieval-term
encoding	Data/Mining/Information/Retrieval-term
of	O
each	O
link	O
and	O
the	O
link	Data/Mining/Information/Retrieval-term
similarity	Data/Mining/Information/Retrieval-term
encoding	Data/Mining/Information/Retrieval-term
between	O
links	O
.	O

Furthermore	O
,	O
we	O
introduce	O
a	O
measurement	O
of	O
structural	O
similarity	O
in	O
the	O
loss	AI/ML/DL-term
function	AI/ML/DL-term
for	O
the	O
structural	O
differences	O
of	O
link	O
sequences	O
.	O

The	O
experimental	O
results	O
demonstrate	O
that	O
our	O
model	O
outperforms	O
other	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
TLP	O
methods	O
such	O
as	O
Transformer	O
TGAT	O
and	O
EvolveGCN	O
.	O

Multiple	O
imputation	O
is	O
a	O
data	O
recovery	O
method	O
where	O
it	O
produced	O
multiple	Data/Mining/Information/Retrieval-term
imputed	Data/Mining/Information/Retrieval-term
data	Data/Mining/Information/Retrieval-term
.	O

Within	O
a	O
large	O
database	Miscellaneous-term
G	O
containing	O
graphs	O
with	O
labeled	O
nodes	O
and	O
directed	O
,	O
multi	O
-	O
edges	O
;	O
how	O
can	O
we	O
detect	O
the	O
anomalous	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
Most	O
existing	O
work	O
are	O
designed	O
for	O
plain	O
(	O
unlabeled	O
)	O
and	O
/	O
or	O
simple	O
(	O
unweighted	O
)	O
graphs	O
.	O

Within	O
a	O
large	O
database	Miscellaneous-term
G	O
containing	O
graphs	O
with	O
labeled	O
nodes	O
and	O
directed	O
,	O
multi	O
-	O
edges	O
;	O
how	O
can	O
we	O
detect	O
the	O
anomalous	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
Most	O
existing	O
work	O
are	O
designed	O
for	O
plain	O
(	O
unlabeled	O
)	O
and	O
/	O
or	O
simple	O
(	O
unweighted	O
)	O
graphs	O
.	O

We	O
introduce	O
CODEtect	O
the	O
first	O
approach	O
that	O
addresses	O
the	O
anomaly	O
detection	O
task	O
for	O
graph	Miscellaneous-term
databases	Miscellaneous-term
with	O
such	O
complex	O
nature	O
.	O

To	O
this	O
end	O
,	O
it	O
identifies	O
a	O
small	O
representative	O
set	O
P	O
of	O
structural	O
patterns	O
(	O
i	O
.	O
e	O
.,	O
node	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
labeled	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
motifs	Data/Mining/Information/Retrieval-term
that	O
losslessly	O
compress	O
database	Miscellaneous-term
G	O
as	O
concisely	O
as	O
possible	O
.	O

To	O
this	O
end	O
,	O
it	O
identifies	O
a	O
small	O
representative	O
set	O
P	O
of	O
structural	O
patterns	O
(	O
i	O
.	O
e	O
.,	O
node	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
labeled	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
motifs	Data/Mining/Information/Retrieval-term
that	O
losslessly	O
compress	O
database	Miscellaneous-term
G	O
as	O
concisely	O
as	O
possible	O
.	O

How	O
to	O
effectively	O
integrate	O
the	O
anchor	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
on	O
multiple	O
views	O
to	O
achieve	O
enhanced	O
clustering	O
performance	O
still	O
remains	O
a	O
challenging	O
task	O
.	O

Existing	O
fusing	O
strategies	O
ignore	O
the	O
structure	O
diversity	O
among	O
anchor	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
and	O
restrict	O
the	O
anchor	Data/Mining/Information/Retrieval-term
generation	Data/Mining/Information/Retrieval-term
to	O
be	O
same	O
on	O
different	O
views	O
,	O
which	O
degenerates	O
the	O
representation	O
ability	O
of	O
corresponding	O
fused	O
consensus	O
graph	O
.	O

To	O
overcome	O
these	O
drawbacks	O
,	O
we	O
propose	O
a	O
novel	O
structural	O
fusion	O
framework	O
to	O
integrate	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
anchor	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
for	O
clustering	O
.	O

Different	O
from	O
traditional	O
integration	O
strategies	O
,	O
we	O
merge	O
the	O
anchors	Data/Mining/Information/Retrieval-term
and	O
edges	Data/Mining/Information/Retrieval-term
of	O
all	O
the	O
view	O
-	O
specific	O
anchor	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
into	O
a	O
single	O
graph	O
for	O
the	O
structural	O
optimal	O
graph	O
learning	O
.	O

Benefiting	O
from	O
the	O
structural	O
fusion	O
strategy	O
,	O
the	O
anchor	Data/Mining/Information/Retrieval-term
generation	Data/Mining/Information/Retrieval-term
of	O
each	O
view	O
is	O
not	O
forced	O
to	O
be	O
same	O
,	O
which	O
greatly	O
improves	O
the	O
representation	O
capability	O
of	O
the	O
target	O
structural	Data/Mining/Information/Retrieval-term
optimal	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
since	O
the	O
anchors	O
of	O
each	O
view	O
capture	O
the	O
diverse	O
structure	O
of	O
different	O
views	O
.	O

By	O
leveraging	O
the	O
potential	O
structural	O
consistency	O
among	O
each	O
anchor	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
a	O
connectivity	O
constraint	O
is	O
imposed	O
on	O
the	O
target	O
graph	O
to	O
indicate	O
clusters	O
directly	O
without	O
any	O
post	O
-	O
processing	O
such	O
as	O
k	O
-	O
means	O
in	O
classical	O
spectral	O
clustering	O
.	O

Substantial	O
experiments	O
on	O
real	O
-	O
world	O
datasets	O
are	O
conducted	O
to	O
verify	O
the	O
superiority	O
of	O
the	O
proposed	O
method	O
,	O
as	O
compared	O
with	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
arts	Miscellaneous-term
over	O
the	O
clustering	O
performance	O
and	O
time	O
expenditure	O
.	O

It	O
is	O
a	O
more	O
challenging	O
problem	O
for	O
many	O
reasons	O
,	O
such	O
as	O
complex	Data/Mining/Information/Retrieval-term
label	Data/Mining/Information/Retrieval-term
correlation	Data/Mining/Information/Retrieval-term
long	AI/ML/DL-term
-	AI/ML/DL-term
tail	AI/ML/DL-term
label	AI/ML/DL-term
distribution	AI/ML/DL-term
and	O
data	O
shortage	O
.	O

It	O
is	O
a	O
more	O
challenging	O
problem	O
for	O
many	O
reasons	O
,	O
such	O
as	O
complex	Data/Mining/Information/Retrieval-term
label	Data/Mining/Information/Retrieval-term
correlation	Data/Mining/Information/Retrieval-term
long	AI/ML/DL-term
-	AI/ML/DL-term
tail	AI/ML/DL-term
label	AI/ML/DL-term
distribution	AI/ML/DL-term
and	O
data	O
shortage	O
.	O

In	O
general	O
,	O
overcoming	O
these	O
challenges	O
and	O
bettering	O
learning	O
performance	O
could	O
be	O
achieved	O
by	O
utilizing	O
more	O
training	O
samples	O
and	O
including	O
label	Data/Mining/Information/Retrieval-term
correlations	Data/Mining/Information/Retrieval-term
.	O

MUCO	O
explicitly	O
and	O
effectively	O
learns	O
the	O
latent	Data/Mining/Information/Retrieval-term
label	Data/Mining/Information/Retrieval-term
correlations	Data/Mining/Information/Retrieval-term
by	O
updating	O
a	O
label	Data/Mining/Information/Retrieval-term
correlation	Data/Mining/Information/Retrieval-term
tensor	Data/Mining/Information/Retrieval-term
which	O
provides	O
highly	O
accurate	O
and	O
interpretable	O
prediction	O
results	O
.	O

In	O
addition	O
,	O
a	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
label	Data/Mining/Information/Retrieval-term
generative	Data/Mining/Information/Retrieval-term
strategy	Data/Mining/Information/Retrieval-term
is	O
deployed	O
to	O
handle	O
the	O
long	AI/ML/DL-term
-	AI/ML/DL-term
tail	AI/ML/DL-term
label	AI/ML/DL-term
distribution	AI/ML/DL-term
challenge	O
.	O

In	O
addition	O
,	O
a	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
label	Data/Mining/Information/Retrieval-term
generative	Data/Mining/Information/Retrieval-term
strategy	Data/Mining/Information/Retrieval-term
is	O
deployed	O
to	O
handle	O
the	O
long	AI/ML/DL-term
-	AI/ML/DL-term
tail	AI/ML/DL-term
label	AI/ML/DL-term
distribution	AI/ML/DL-term
challenge	O
.	O

However	O
,	O
most	O
of	O
them	O
exhibit	O
high	O
computational	Miscellaneous-term
complexity	Miscellaneous-term
.	O

Specifically	O
,	O
different	O
from	O
existing	O
anchor	O
-	O
based	O
methods	O
where	O
anchors	O
are	O
obtained	O
from	O
key	O
samples	O
by	O
clustering	O
or	O
weighted	O
averaging	O
strategies	O
in	O
this	O
article	O
,	O
the	O
anchors	O
are	O
learned	O
in	O
a	O
principled	O
fashion	O
which	O
aims	O
at	O
constructing	O
a	O
distance	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
preserving	Data/Mining/Information/Retrieval-term
embedding	Data/Mining/Information/Retrieval-term
for	O
each	O
view	O
from	O
samples	O
to	O
their	O
representations	O
,	O
whose	O
elements	O
are	O
the	O
weights	O
of	O
the	O
edges	O
linking	O
corresponding	O
samples	O
and	O
anchors	O
.	O

In	O
addition	O
,	O
the	O
consistency	O
among	O
different	O
views	O
can	O
be	O
explored	O
by	O
imposing	O
a	O
low	O
-	O
rank	O
constraint	O
on	O
the	O
concatenated	AI/ML/DL-term
embedding	AI/ML/DL-term
representations	AI/ML/DL-term
.	O

The	O
objective	AI/ML/DL-term
function	AI/ML/DL-term
is	O
optimized	O
in	O
an	O
alternating	O
optimization	O
fashion	O
.	O

Both	O
theoretical	O
analysis	O
and	O
experimental	O
results	O
on	O
different	O
multi	Miscellaneous-term
-	Miscellaneous-term
label	Miscellaneous-term
image	Miscellaneous-term
datasets	Miscellaneous-term
verify	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
proposed	O
method	O
.	O

In	O
most	O
domains	O
,	O
anomaly	O
detection	O
is	O
typically	O
cast	O
as	O
an	O
unsupervised	AI/ML/DL-term
learning	AI/ML/DL-term
problem	O
because	O
of	O
the	O
infeasibility	O
of	O
labeling	O
large	O
datasets	Miscellaneous-term
.	O

In	O
most	O
domains	O
,	O
anomaly	O
detection	O
is	O
typically	O
cast	O
as	O
an	O
unsupervised	AI/ML/DL-term
learning	AI/ML/DL-term
problem	O
because	O
of	O
the	O
infeasibility	O
of	O
labeling	O
large	O
datasets	Miscellaneous-term
.	O

Although	O
some	O
work	O
has	O
been	O
published	O
in	O
this	O
field	O
,	O
they	O
fail	O
to	O
account	O
that	O
different	O
algorithms	Miscellaneous-term
can	O
detect	O
different	O
kinds	O
of	O
anomalies	O
.	O

More	O
precisely	O
,	O
the	O
literature	O
on	O
this	O
topic	O
has	O
focused	O
on	O
defining	O
criteria	O
to	O
determine	O
which	O
algorithm	Miscellaneous-term
is	O
better	O
,	O
while	O
ignoring	O
the	O
fact	O
that	O
such	O
criteria	O
are	O
meaningful	O
only	O
if	O
the	O
algorithms	Miscellaneous-term
being	O
compared	O
are	O
detecting	O
the	O
same	O
kind	O
of	O
anomalies	O
.	O

Traditional	O
embedding	AI/ML/DL-term
methodologies	O
,	O
also	O
known	O
as	O
dimensionality	O
reduction	O
techniques	O
,	O
assume	O
the	O
availability	O
of	O
exact	O
pairwise	O
distances	O
between	O
the	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
objects	AI/ML/DL-term
that	O
will	O
be	O
embedded	O
in	O
a	O
lower	AI/ML/DL-term
dimensionality	AI/ML/DL-term
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
an	O
embedding	AI/ML/DL-term
that	O
overcomes	O
this	O
limitation	O
and	O
can	O
operate	O
on	O
pairwise	O
distances	O
that	O
are	O
represented	O
as	O
a	O
range	O
of	O
lower	O
and	O
upper	O
bounds	O
.	O

Such	O
bounds	O
are	O
typically	O
estimated	O
when	O
objects	O
are	O
compressed	O
in	O
a	O
lossy	AI/ML/DL-term
manner	AI/ML/DL-term
so	O
our	O
approach	O
is	O
highly	O
applicable	O
in	O
the	O
case	O
of	O
big	O
compressed	O
datasets	O
.	O

Our	O
methodology	O
can	O
preserve	O
multiple	O
aspects	O
of	O
the	O
original	O
data	O
relationships	O
:	O
distances	AI/ML/DL-term
correlations	AI/ML/DL-term
and	O
object	AI/ML/DL-term
scores	AI/ML/DL-term
/	AI/ML/DL-term
ranks	AI/ML/DL-term
whereas	O
existing	O
techniques	O
typically	O
preserve	O
only	O
distances	O
.	O

Structured	NLP-term
text	NLP-term
with	O
plentiful	O
hierarchical	Miscellaneous-term
structure	Miscellaneous-term
information	O
is	O
an	O
important	O
part	O
in	O
real	O
-	O
world	O
complex	O
texts	O
.	O

Structured	NLP-term
text	NLP-term
with	O
plentiful	O
hierarchical	Miscellaneous-term
structure	Miscellaneous-term
information	O
is	O
an	O
important	O
part	O
in	O
real	O
-	O
world	O
complex	O
texts	O
.	O

Most	O
existing	O
methods	O
treat	O
structured	NLP-term
text	NLP-term
from	O
a	O
local	O
hierarchy	O
perspective	O
,	O
focusing	O
on	O
the	O
semantics	NLP-term
dependency	NLP-term
and	O
the	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
structured	NLP-term
text	NLP-term
d	O
text	O
independently	O
.	O

Most	O
existing	O
methods	O
treat	O
structured	NLP-term
text	NLP-term
from	O
a	O
local	O
hierarchy	O
perspective	O
,	O
focusing	O
on	O
the	O
semantics	NLP-term
dependency	NLP-term
and	O
the	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
structured	NLP-term
text	NLP-term
d	O
text	O
independently	O
.	O

However	O
,	O
structured	O
text	O
has	O
global	O
hierarchical	Miscellaneous-term
structures	Miscellaneous-term
with	O
sophisticated	O
dependency	O
when	O
compared	O
to	O
unstructured	NLP-term
text	NLP-term
.	O

However	O
,	O
structured	O
text	O
has	O
global	O
hierarchical	Miscellaneous-term
structures	Miscellaneous-term
with	O
sophisticated	O
dependency	O
when	O
compared	O
to	O
unstructured	NLP-term
text	NLP-term
.	O

According	O
to	O
the	O
variety	O
of	O
structured	NLP-term
texts	NLP-term
it	O
is	O
not	O
appropriate	O
to	O
use	O
the	O
existing	O
methods	O
directly	O
.	O

The	O
function	O
of	O
distinction	O
information	O
within	O
semantics	NLP-term
dependency	NLP-term
and	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
for	O
structured	NLP-term
text	NLP-term
referred	O
to	O
as	O
meta	AI/ML/DL-term
-	AI/ML/DL-term
information	AI/ML/DL-term
should	O
be	O
stated	O
more	O
precisely	O
.	O

The	O
function	O
of	O
distinction	O
information	O
within	O
semantics	NLP-term
dependency	NLP-term
and	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
for	O
structured	NLP-term
text	NLP-term
referred	O
to	O
as	O
meta	AI/ML/DL-term
-	AI/ML/DL-term
information	AI/ML/DL-term
should	O
be	O
stated	O
more	O
precisely	O
.	O

The	O
function	O
of	O
distinction	O
information	O
within	O
semantics	NLP-term
dependency	NLP-term
and	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
for	O
structured	NLP-term
text	NLP-term
referred	O
to	O
as	O
meta	AI/ML/DL-term
-	AI/ML/DL-term
information	AI/ML/DL-term
should	O
be	O
stated	O
more	O
precisely	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
HGMETA	AI/ML/DL-technique
a	O
novel	O
meta	O
-	O
information	O
embedding	O
frame	O
network	O
for	O
structured	O
text	O
classification	O
to	O
obtain	O
the	O
fusion	AI/ML/DL-term
embedding	AI/ML/DL-term
of	O
hierarchical	NLP-term
semantics	NLP-term
dependency	NLP-term
and	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
structured	NLP-term
text	NLP-term
text	O
,	O
and	O
to	O
distill	O
the	O
meta	O
-	O
information	O
from	O
fusion	O
characteristics	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
HGMETA	AI/ML/DL-technique
a	O
novel	O
meta	O
-	O
information	O
embedding	O
frame	O
network	O
for	O
structured	O
text	O
classification	O
to	O
obtain	O
the	O
fusion	AI/ML/DL-term
embedding	AI/ML/DL-term
of	O
hierarchical	NLP-term
semantics	NLP-term
dependency	NLP-term
and	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
structured	NLP-term
text	NLP-term
text	O
,	O
and	O
to	O
distill	O
the	O
meta	O
-	O
information	O
from	O
fusion	O
characteristics	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
HGMETA	AI/ML/DL-technique
a	O
novel	O
meta	O
-	O
information	O
embedding	O
frame	O
network	O
for	O
structured	O
text	O
classification	O
to	O
obtain	O
the	O
fusion	AI/ML/DL-term
embedding	AI/ML/DL-term
of	O
hierarchical	NLP-term
semantics	NLP-term
dependency	NLP-term
and	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
structured	NLP-term
text	NLP-term
text	O
,	O
and	O
to	O
distill	O
the	O
meta	O
-	O
information	O
from	O
fusion	O
characteristics	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
HGMETA	AI/ML/DL-technique
a	O
novel	O
meta	O
-	O
information	O
embedding	O
frame	O
network	O
for	O
structured	O
text	O
classification	O
to	O
obtain	O
the	O
fusion	AI/ML/DL-term
embedding	AI/ML/DL-term
of	O
hierarchical	NLP-term
semantics	NLP-term
dependency	NLP-term
and	O
graph	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
structured	NLP-term
text	NLP-term
text	O
,	O
and	O
to	O
distill	O
the	O
meta	O
-	O
information	O
from	O
fusion	O
characteristics	O
.	O

To	O
integrate	O
the	O
global	O
hierarchical	Miscellaneous-term
features	Miscellaneous-term
with	O
fused	O
structured	O
text	O
information	O
,	O
we	O
design	O
a	O
hierarchical	O
LDA	O
module	O
and	O
a	O
structured	O
text	O
embedding	O
module	O
.	O

Furthermore	O
,	O
using	O
an	O
attention	O
-	O
based	O
network	O
we	O
investigate	O
the	O
complementarity	O
of	O
semantics	NLP-term
dependency	NLP-term
and	O
graph	O
structure	O
based	O
on	O
global	O
hierarchical	Miscellaneous-term
characteristics	Miscellaneous-term
and	O
meta	O
-	O
information	O
.	O

Furthermore	O
,	O
using	O
an	O
attention	O
-	O
based	O
network	O
we	O
investigate	O
the	O
complementarity	O
of	O
semantics	NLP-term
dependency	NLP-term
and	O
graph	O
structure	O
based	O
on	O
global	O
hierarchical	Miscellaneous-term
characteristics	Miscellaneous-term
and	O
meta	O
-	O
information	O
.	O

Finally	O
,	O
the	O
fusion	AI/ML/DL-term
embedding	AI/ML/DL-term
and	O
the	O
meta	O
-	O
information	O
can	O
be	O
straightforwardly	O
incorporated	O
for	O
structured	O
text	O
classification	O
.	O

Experiments	O
conducted	O
on	O
three	O
real	O
-	O
world	O
datasets	O
show	O
the	O
effectiveness	O
of	O
meta	Miscellaneous-term
-	Miscellaneous-term
information	Miscellaneous-term
and	O
demonstrate	O
the	O
superiority	O
of	O
our	O
method	O
.	O

The	O
COVID	Miscellaneous-term
-	Miscellaneous-term
19	Miscellaneous-term
pandemic	Miscellaneous-term
has	O
caused	O
the	O
society	O
lockdowns	O
and	O
a	O
large	O
number	O
of	O
deaths	O
in	O
many	O
countries	O
.	O

In	O
this	O
article	O
,	O
we	O
study	O
the	O
problem	O
of	O
potential	O
transmission	O
cluster	O
discovery	O
based	O
on	O
the	O
spatio	AI/ML/DL-term
-	AI/ML/DL-term
temporal	AI/ML/DL-term
logs	AI/ML/DL-term
.	O

Given	O
a	O
query	Data/Mining/Information/Retrieval-term
of	O
patient	O
user	O
q	O
and	O
a	O
timestamp	O
of	O
confirmed	O
infection	O
tq	O
,	O
the	O
problem	O
is	O
to	O
find	O
all	O
potential	O
infected	O
users	O
who	O
have	O
close	O
social	O
contacts	O
to	O
user	O
q	O
before	O
time	O
tq	O
.	O

We	O
motivate	O
and	O
formulate	O
the	O
potential	O
transmission	O
cluster	O
model	O
equipped	O
with	O
a	O
detailed	O
analysis	O
of	O
transmission	Data/Mining/Information/Retrieval-term
cluster	Data/Mining/Information/Retrieval-term
property	Data/Mining/Information/Retrieval-term
and	O
particular	O
model	O
usability	O
.	O

To	O
identify	O
potential	O
clusters	O
,	O
one	O
straightforward	O
method	O
is	O
to	O
compute	O
all	O
close	O
contacts	O
on	O
-	O
the	O
-	O
fly	O
,	O
which	O
is	O
simple	O
but	O
inefficient	O
caused	O
by	O
scanning	O
spatio	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
temporal	Data/Mining/Information/Retrieval-term
logs	Data/Mining/Information/Retrieval-term
many	O
times	O
.	O

Leveraging	O
two	O
well	O
-	O
designed	O
techniques	O
of	O
spatio	O
-	O
temporal	O
compression	O
and	O
graph	O
partition	O
on	O
bipartite	Data/Mining/Information/Retrieval-term
contact	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
our	O
BCG	O
-	O
index	O
approach	O
achieves	O
a	O
good	O
balance	O
of	O
index	O
construction	O
and	O
online	O
query	O
processing	O
to	O
fast	O
discover	O
potential	O
transmission	O
cluster	O
.	O

We	O
theoretically	O
analyze	O
and	O
compare	O
the	O
algorithm	Miscellaneous-term
complexity	O
of	O
three	O
proposed	O
approaches	O
.	O

Extensive	O
experiments	O
on	O
real	O
-	O
world	O
check	O
-	O
in	O
datasets	Miscellaneous-term
and	O
COVID	O
-	O
19	O
confirmed	O
cases	O
in	O
the	O
United	O
States	O
validate	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
our	O
potential	O
transmission	O
cluster	O
model	O
and	O
algorithms	O
.	O

Background	O
:	O
Looking	O
pattern	O
differences	O
are	O
shown	O
to	O
separate	O
individuals	O
with	O
A	O
utism	Miscellaneous-term
Spectrum	Miscellaneous-term
Disorder	Miscellaneous-term
(	Miscellaneous-term
ASD	Miscellaneous-term
)	Miscellaneous-term
and	O
Typically	Miscellaneous-term
Developing	Miscellaneous-term
(	Miscellaneous-term
TD	Miscellaneous-term
)	Miscellaneous-term
controls	O
.	O

Recent	O
studies	O
have	O
shown	O
that	O
,	O
in	O
children	O
with	O
ASD	Miscellaneous-term
ASD	Miscellaneous-term
se	O
patterns	O
change	O
with	O
intellectual	O
and	O
social	O
impairments	O
,	O
suggesting	O
that	O
patterns	O
of	O
social	O
attention	O
provide	O
indices	O
of	O
clinically	O
meaningful	O
variation	O
in	O
ASD	O
.	O
Method	O
:	O
We	O
conducted	O
a	O
naturalistic	O
study	O
of	O
children	O
with	O
ASD	O
(	O
n	O
=	O
55	O
)	O
and	O
typical	O
development	O
(	O
TD	Miscellaneous-term
n	O
=	O
32	O
).	O

This	O
work	O
reports	O
on	O
the	O
feasibility	O
of	O
spatial	AI/ML/DL-term
and	O
spatiotemporal	Data/Mining/Information/Retrieval-term
scanpaths	Data/Mining/Information/Retrieval-term
generated	O
from	O
eye	O
-	O
gaze	O
patterns	O
of	O
these	O
paradigms	O
in	O
stratifying	O
ASD	Miscellaneous-term
and	O
TD	Miscellaneous-term
groups	O
.	O
Algorithm	Miscellaneous-term
ASD	Miscellaneous-term
TD	Miscellaneous-term
rticle	O
presents	O
an	O
approach	O
for	O
automatically	O
identifying	O
clinically	O
meaningful	O
information	O
contained	O
within	O
the	O
raw	O
eye	O
-	O
tracking	O
data	O
of	O
children	O
with	O
ASD	O
and	O
TD	O
.	O

This	O
work	O
reports	O
on	O
the	O
feasibility	O
of	O
spatial	AI/ML/DL-term
and	O
spatiotemporal	Data/Mining/Information/Retrieval-term
scanpaths	Data/Mining/Information/Retrieval-term
generated	O
from	O
eye	O
-	O
gaze	O
patterns	O
of	O
these	O
paradigms	O
in	O
stratifying	O
ASD	Miscellaneous-term
and	O
TD	Miscellaneous-term
groups	O
.	O
Algorithm	Miscellaneous-term
ASD	Miscellaneous-term
TD	Miscellaneous-term
rticle	O
presents	O
an	O
approach	O
for	O
automatically	O
identifying	O
clinically	O
meaningful	O
information	O
contained	O
within	O
the	O
raw	O
eye	O
-	O
tracking	O
data	O
of	O
children	O
with	O
ASD	O
and	O
TD	O
.	O

This	O
work	O
reports	O
on	O
the	O
feasibility	O
of	O
spatial	AI/ML/DL-term
and	O
spatiotemporal	Data/Mining/Information/Retrieval-term
scanpaths	Data/Mining/Information/Retrieval-term
generated	O
from	O
eye	O
-	O
gaze	O
patterns	O
of	O
these	O
paradigms	O
in	O
stratifying	O
ASD	Miscellaneous-term
and	O
TD	Miscellaneous-term
groups	O
.	O
Algorithm	Miscellaneous-term
ASD	Miscellaneous-term
TD	Miscellaneous-term
rticle	O
presents	O
an	O
approach	O
for	O
automatically	O
identifying	O
clinically	O
meaningful	O
information	O
contained	O
within	O
the	O
raw	O
eye	O
-	O
tracking	O
data	O
of	O
children	O
with	O
ASD	O
and	O
TD	O
.	O

The	O
proposed	O
mechanism	O
utilizes	O
combinations	O
of	O
eye	Miscellaneous-term
-	Miscellaneous-term
gaze	Miscellaneous-term
scan	Miscellaneous-term
-	Miscellaneous-term
paths	Miscellaneous-term
(	O
spatial	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
,	O
fused	O
with	O
temporal	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
and	O
pupil	O
velocity	O
data	O
and	O
Convolutional	O
Neural	O
Network	O
(	O
CNN	O
)	O
for	O
stratification	O
of	O
diagnosis	O
(	O
ASD	Miscellaneous-term
or	O
TD	Miscellaneous-term
ASD	Miscellaneous-term
TD	Miscellaneous-term
ASD	Miscellaneous-term
patial	O
eye	O
-	O
gaze	O
representations	O
in	O
the	O
form	O
of	O
scanpaths	O
in	O
stratifying	O
ASD	O
and	O
TD	O
(	O
ASD	O
vs	O
.	O

The	O
proposed	O
mechanism	O
utilizes	O
combinations	O
of	O
eye	Miscellaneous-term
-	Miscellaneous-term
gaze	Miscellaneous-term
scan	Miscellaneous-term
-	Miscellaneous-term
paths	Miscellaneous-term
(	O
spatial	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
,	O
fused	O
with	O
temporal	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
and	O
pupil	O
velocity	O
data	O
and	O
Convolutional	O
Neural	O
Network	O
(	O
CNN	O
)	O
for	O
stratification	O
of	O
diagnosis	O
(	O
ASD	Miscellaneous-term
or	O
TD	Miscellaneous-term
ASD	Miscellaneous-term
TD	Miscellaneous-term
ASD	Miscellaneous-term
patial	O
eye	O
-	O
gaze	O
representations	O
in	O
the	O
form	O
of	O
scanpaths	O
in	O
stratifying	O
ASD	O
and	O
TD	O
(	O
ASD	O
vs	O
.	O

TD	Miscellaneous-term
DNN	O
74	O
.	O
4	O
%	O
are	O
feasible	O
.	O

These	O
spatial	Data/Mining/Information/Retrieval-term
eye	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
gaze	Data/Mining/Information/Retrieval-term
features	Data/Mining/Information/Retrieval-term
e	O
.	O
g	O
.,	O
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
are	O
shown	O
to	O
be	O
sensitive	O
to	O
factors	O
mediating	O
heterogeneity	O
in	O
ASD	Miscellaneous-term
ASD	Miscellaneous-term
(	O
ASD	O
:	O
2	O
–	O
4	O
y	O
/	O
old	O
vs	O
.	O

These	O
spatial	Data/Mining/Information/Retrieval-term
eye	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
gaze	Data/Mining/Information/Retrieval-term
features	Data/Mining/Information/Retrieval-term
e	O
.	O
g	O
.,	O
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
are	O
shown	O
to	O
be	O
sensitive	O
to	O
factors	O
mediating	O
heterogeneity	O
in	O
ASD	Miscellaneous-term
ASD	Miscellaneous-term
(	O
ASD	O
:	O
2	O
–	O
4	O
y	O
/	O
old	O
vs	O
.	O

5	O
–	O
9	O
y	O
/	O
old	O
Female	O
ASD	Miscellaneous-term
DNN	O
98	O
.	O
8	O
%	O
.	O

Limiting	O
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
path	Data/Mining/Information/Retrieval-term
representations	Data/Mining/Information/Retrieval-term
temporally	O
increased	O
variance	O
in	O
stratification	O
performance	O
,	O
attesting	O
to	O
the	O
importance	O
of	O
the	O
temporal	O
dimension	O
of	O
eye	O
-	O
gaze	O
data	O
.	O

Spatio	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
Temporal	Data/Mining/Information/Retrieval-term
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
that	O
incorporate	O
velocity	O
of	O
eye	O
movement	O
in	O
their	O
images	O
of	O
eye	O
-	O
gaze	O
are	O
shown	O
to	O
outperform	O
other	O
feature	AI/ML/DL-term
representation	AI/ML/DL-term
methods	O
achieving	O
classification	O
accuracy	O
of	O
80	O
.	O
25	O
%	O
Conclusion	O
:	O
The	O
results	O
indicate	O
the	O
feasibility	O
of	O
scan	O
-	O
path	O
images	O
to	O
stratify	O
ASD	Miscellaneous-term
and	O
TD	Miscellaneous-term
diagnosis	O
in	O
children	O
of	O
varying	O
ages	O
and	O
gender	O
.	O

Spatio	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
Temporal	Data/Mining/Information/Retrieval-term
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
that	O
incorporate	O
velocity	O
of	O
eye	O
movement	O
in	O
their	O
images	O
of	O
eye	O
-	O
gaze	O
are	O
shown	O
to	O
outperform	O
other	O
feature	AI/ML/DL-term
representation	AI/ML/DL-term
methods	O
achieving	O
classification	O
accuracy	O
of	O
80	O
.	O
25	O
%	O
Conclusion	O
:	O
The	O
results	O
indicate	O
the	O
feasibility	O
of	O
scan	O
-	O
path	O
images	O
to	O
stratify	O
ASD	Miscellaneous-term
and	O
TD	Miscellaneous-term
diagnosis	O
in	O
children	O
of	O
varying	O
ages	O
and	O
gender	O
.	O

Spatio	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
Temporal	Data/Mining/Information/Retrieval-term
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
that	O
incorporate	O
velocity	O
of	O
eye	O
movement	O
in	O
their	O
images	O
of	O
eye	O
-	O
gaze	O
are	O
shown	O
to	O
outperform	O
other	O
feature	AI/ML/DL-term
representation	AI/ML/DL-term
methods	O
achieving	O
classification	O
accuracy	O
of	O
80	O
.	O
25	O
%	O
Conclusion	O
:	O
The	O
results	O
indicate	O
the	O
feasibility	O
of	O
scan	O
-	O
path	O
images	O
to	O
stratify	O
ASD	Miscellaneous-term
and	O
TD	Miscellaneous-term
diagnosis	O
in	O
children	O
of	O
varying	O
ages	O
and	O
gender	O
.	O

Infusion	O
of	O
temporal	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
and	O
velocity	Data/Mining/Information/Retrieval-term
data	Data/Mining/Information/Retrieval-term
improves	O
the	O
classification	O
performance	O
of	O
our	O
deep	O
learning	O
models	O
.	O

Such	O
novel	O
velocity	Data/Mining/Information/Retrieval-term
fused	Data/Mining/Information/Retrieval-term
spatio	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
temporal	Data/Mining/Information/Retrieval-term
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
path	Data/Mining/Information/Retrieval-term
features	Data/Mining/Information/Retrieval-term
are	O
shown	O
to	O
be	O
able	O
to	O
capture	O
eye	O
gaze	O
patterns	O
that	O
reflect	O
age	O
,	O
gender	O
,	O
and	O
the	O
mixed	O
effect	O
of	O
age	O
and	O
gender	O
,	O
factors	O
that	O
are	O
associated	O
with	O
heterogeneity	O
in	O
ASD	Miscellaneous-term
ASD	Miscellaneous-term
difficulty	O
in	O
identifying	O
robust	O
biomarkers	O
for	O
ASD	O
.	O

Such	O
novel	O
velocity	Data/Mining/Information/Retrieval-term
fused	Data/Mining/Information/Retrieval-term
spatio	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
temporal	Data/Mining/Information/Retrieval-term
scan	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
path	Data/Mining/Information/Retrieval-term
features	Data/Mining/Information/Retrieval-term
are	O
shown	O
to	O
be	O
able	O
to	O
capture	O
eye	O
gaze	O
patterns	O
that	O
reflect	O
age	O
,	O
gender	O
,	O
and	O
the	O
mixed	O
effect	O
of	O
age	O
and	O
gender	O
,	O
factors	O
that	O
are	O
associated	O
with	O
heterogeneity	O
in	O
ASD	Miscellaneous-term
ASD	Miscellaneous-term
difficulty	O
in	O
identifying	O
robust	O
biomarkers	O
for	O
ASD	O
.	O

This	O
corresponds	O
to	O
the	O
two	O
extreme	O
cases	O
where	O
every	O
time	O
-	O
series	O
time	O
-	O
series	O
time	O
-	O
series	O
time	O
-	O
series	O
e	O
-	O
series	O
in	O
the	O
collection	O
or	O
likewise	O
,	O
that	O
every	O
time	O
-	O
series	O
is	O
related	O
to	O
every	O
other	O
time	O
-	O
series	O
resulting	O
in	O
a	O
completely	Data/Mining/Information/Retrieval-term
connected	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
deep	Data/Mining/Information/Retrieval-term
hybrid	Data/Mining/Information/Retrieval-term
probabilistic	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
forecasting	Data/Mining/Information/Retrieval-term
framework	Data/Mining/Information/Retrieval-term
called	O
Graph	O
Deep	O
Factors	O
(	O
GraphDF	O
)	O
that	O
goes	O
beyond	O
these	O
two	O
extremes	O
by	O
allowing	O
nodes	O
and	O
their	O
time	O
-	O
series	O
to	O
be	O
connected	O
to	O
others	O
in	O
an	O
arbitrary	O
fashion	O
.	O

GraphDF	O
is	O
a	O
hybrid	Data/Mining/Information/Retrieval-term
forecasting	Data/Mining/Information/Retrieval-term
framework	Data/Mining/Information/Retrieval-term
that	O
consists	O
of	O
a	O
relational	O
global	O
and	O
relational	O
local	O
model	O
.	O

In	O
particular	O
,	O
a	O
relational	O
global	O
model	O
learns	O
complex	O
non	O
-	O
linear	O
time	O
-	O
series	O
patterns	O
globally	O
using	O
the	O
structure	O
of	O
the	O
graph	Data/Mining/Information/Retrieval-term
to	O
improve	O
both	O
forecasting	O
accuracy	O
and	O
computational	Miscellaneous-term
efficiency	Miscellaneous-term
.	O

In	O
particular	O
,	O
a	O
relational	O
global	O
model	O
learns	O
complex	O
non	O
-	O
linear	O
time	O
-	O
series	O
patterns	O
globally	O
using	O
the	O
structure	O
of	O
the	O
graph	Data/Mining/Information/Retrieval-term
to	O
improve	O
both	O
forecasting	O
accuracy	O
and	O
computational	Miscellaneous-term
efficiency	Miscellaneous-term
.	O

Similarly	O
,	O
instead	O
of	O
modeling	O
every	O
time	O
-	O
series	O
time	O
-	O
series	O
time	O
-	O
series	O
nal	O
local	O
model	O
not	O
only	O
considers	O
its	O
individual	O
time	O
-	O
series	O
but	O
also	O
the	O
time	O
-	O
series	O
of	O
nodes	O
that	O
are	O
connected	O
in	O
the	O
graph	Data/Mining/Information/Retrieval-term
.	O

The	O
experiments	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
deep	O
hybrid	O
graph	O
-	O
based	O
forecasting	O
model	O
compared	O
to	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
in	O
terms	O
of	O
its	O
forecasting	O
accuracy	O
runtime	Miscellaneous-term
and	O
scalability	Miscellaneous-term
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
an	O
online	Data/Mining/Information/Retrieval-term
incremental	Data/Mining/Information/Retrieval-term
learning	Data/Mining/Information/Retrieval-term
framework	Data/Mining/Information/Retrieval-term
for	O
probabilistic	O
forecasting	O
.	O

However	O
,	O
most	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
models	O
are	O
designed	O
to	O
operate	O
with	O
short	O
documents	O
such	O
as	O
tweets	O
,	O
user	O
reviews	O
,	O
comments	O
,	O
and	O
so	O
on	O
.	O

When	O
handling	O
such	O
long	O
documents	O
,	O
there	O
are	O
three	O
primary	O
challenges	O
:	O
(	O
i	O
)	O
the	O
presence	O
of	O
different	O
contexts	NLP-term
for	O
the	O
same	O
word	O
throughout	O
the	O
document	O
,	O
(	O
ii	O
)	O
small	O
sections	O
of	O
contextually	NLP-term
similar	NLP-term
text	NLP-term
between	O
two	O
documents	O
,	O
but	O
dissimilar	O
text	O
in	O
the	O
remaining	O
parts	O
(	O
this	O
defies	O
the	O
basic	O
understanding	O
of	O
“	O
similarity	O
”),	O
and	O
(	O
iii	O
)	O
the	O
coarse	O
nature	O
of	O
a	O
single	O
global	O
similarity	NLP-term
measure	NLP-term
which	O
fails	O
to	O
capture	O
the	O
heterogeneity	Miscellaneous-term
of	O
the	O
document	O
content	O
.	O

When	O
handling	O
such	O
long	O
documents	O
,	O
there	O
are	O
three	O
primary	O
challenges	O
:	O
(	O
i	O
)	O
the	O
presence	O
of	O
different	O
contexts	NLP-term
for	O
the	O
same	O
word	O
throughout	O
the	O
document	O
,	O
(	O
ii	O
)	O
small	O
sections	O
of	O
contextually	NLP-term
similar	NLP-term
text	NLP-term
between	O
two	O
documents	O
,	O
but	O
dissimilar	O
text	O
in	O
the	O
remaining	O
parts	O
(	O
this	O
defies	O
the	O
basic	O
understanding	O
of	O
“	O
similarity	O
”),	O
and	O
(	O
iii	O
)	O
the	O
coarse	O
nature	O
of	O
a	O
single	O
global	O
similarity	NLP-term
measure	NLP-term
which	O
fails	O
to	O
capture	O
the	O
heterogeneity	Miscellaneous-term
of	O
the	O
document	O
content	O
.	O

In	O
this	O
article	O
,	O
we	O
describe	O
CoLDE	O
:	O
Contrastive	O
Long	O
Document	O
Encoder	O
a	O
transformer	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
framework	AI/ML/DL-term
that	O
addresses	O
these	O
challenges	O
and	O
allows	O
for	O
interpretable	NLP-term
comparisons	NLP-term
of	O
long	O
documents	O
.	O

In	O
this	O
article	O
,	O
we	O
describe	O
CoLDE	O
:	O
Contrastive	O
Long	O
Document	O
Encoder	O
a	O
transformer	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
framework	AI/ML/DL-term
that	O
addresses	O
these	O
challenges	O
and	O
allows	O
for	O
interpretable	NLP-term
comparisons	NLP-term
of	O
long	O
documents	O
.	O

CoLDE	O
uses	O
unique	O
positional	NLP-term
embeddings	NLP-term
and	O
a	O
multi	O
-	O
headed	O
chunkwise	O
attention	O
layer	O
in	O
conjunction	O
with	O
a	O
supervised	AI/ML/DL-term
contrastive	AI/ML/DL-term
learning	AI/ML/DL-term
framework	AI/ML/DL-term
to	O
capture	O
similarity	O
at	O
three	O
different	O
levels	O
:	O
(	O
i	O
)	O
high	O
-	O
level	O
similarity	NLP-term
scores	NLP-term
similarity	NLP-term
scores	NLP-term
documents	O
,	O
(	O
ii	O
)	O
similarity	O
scores	O
between	O
different	O
sections	O
within	O
and	O
across	O
documents	O
,	O
and	O
(	O
iii	O
)	O
similarity	O
scores	O
between	O
different	O
chunks	O
in	O
the	O
same	O
document	O
and	O
across	O
other	O
documents	O
.	O

CoLDE	O
uses	O
unique	O
positional	NLP-term
embeddings	NLP-term
and	O
a	O
multi	O
-	O
headed	O
chunkwise	O
attention	O
layer	O
in	O
conjunction	O
with	O
a	O
supervised	AI/ML/DL-term
contrastive	AI/ML/DL-term
learning	AI/ML/DL-term
framework	AI/ML/DL-term
to	O
capture	O
similarity	O
at	O
three	O
different	O
levels	O
:	O
(	O
i	O
)	O
high	O
-	O
level	O
similarity	NLP-term
scores	NLP-term
similarity	NLP-term
scores	NLP-term
documents	O
,	O
(	O
ii	O
)	O
similarity	O
scores	O
between	O
different	O
sections	O
within	O
and	O
across	O
documents	O
,	O
and	O
(	O
iii	O
)	O
similarity	O
scores	O
between	O
different	O
chunks	O
in	O
the	O
same	O
document	O
and	O
across	O
other	O
documents	O
.	O

These	O
fine	NLP-term
-	NLP-term
grained	NLP-term
similarity	NLP-term
scores	NLP-term
aid	O
in	O
better	O
interpretability	O
.	O

We	O
evaluate	O
CoLDE	O
on	O
three	O
long	O
document	O
datasets	O
namely	O
,	O
ACL	NLP-dataset
Anthology	NLP-dataset
publications	O
,	O
Wikipedia	NLP-dataset
articles	NLP-dataset
and	O
USPTO	NLP-dataset
patents	NLP-dataset
.	O

Besides	O
outperforming	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
the	O
document	O
matching	O
task	O
,	O
CoLDE	O
is	O
also	O
robust	O
to	O
changes	O
in	O
document	O
length	O
and	O
text	NLP-term
perturbations	NLP-term
and	O
provides	O
interpretable	O
results	O
.	O

The	O
code	Miscellaneous-term
for	O
the	O
proposed	O
model	O
is	O
publicly	O
available	O
at	O
.	O

We	O
propose	O
a	O
dynamic	Miscellaneous-term
pricing	Miscellaneous-term
mechanism	Miscellaneous-term
named	O
CrowdPricer	O
for	O
incentively	O
delivering	O
bonuses	O
to	O
the	O
crowd	O
workers	O
of	O
completing	O
tasks	O
,	O
in	O
addition	O
to	O
offering	O
a	O
base	O
payment	O
for	O
completing	O
a	O
task	O
.	O

Extensive	O
experiments	O
using	O
both	O
a	O
real	O
crowdsourcing	O
platform	O
and	O
simulations	Miscellaneous-term
demonstrate	O
that	O
CrowdPricer	O
yields	O
the	O
higher	O
utility	O
for	O
the	O
requester	O
.	O

It	O
also	O
obtains	O
more	O
correct	O
crowd	O
answers	O
than	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
pricing	O
methods	O
.	O

Users	O
tend	O
to	O
browse	O
and	O
purchase	O
various	O
items	O
on	O
e	Miscellaneous-term
-	Miscellaneous-term
commerce	Miscellaneous-term
websites	Miscellaneous-term
according	O
to	O
their	O
varied	O
interests	O
and	O
needs	O
,	O
as	O
reflected	O
in	O
their	O
purchasing	O
history	O
.	O

Most	O
existing	O
next	O
-	O
item	O
recommendation	O
methods	O
aim	O
at	O
extracting	O
the	O
main	O
point	Data/Mining/Information/Retrieval-term
of	Data/Mining/Information/Retrieval-term
interest	Data/Mining/Information/Retrieval-term
in	O
each	O
browsing	O
session	O
and	O
encapsulate	O
it	O
in	O
a	O
single	O
representation	O
.	O

However	O
,	O
past	O
behavior	O
sequences	O
reflect	O
the	O
multiple	O
interests	O
of	O
a	O
single	O
user	O
,	O
which	O
cannot	O
be	O
captured	O
by	O
methods	O
that	O
focus	O
on	O
single	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
interest	Data/Mining/Information/Retrieval-term
contexts	Data/Mining/Information/Retrieval-term
.	O

Therefore	O
,	O
we	O
propose	O
a	O
model	O
with	O
a	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
interest	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
for	O
capturing	O
the	O
various	O
interests	O
of	O
users	O
from	O
their	O
behavior	O
sequence	O
.	O

In	O
experiments	O
,	O
the	O
proposed	O
method	O
outperforms	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
session	O
-	O
based	O
recommendation	O
systems	O
on	O
three	O
real	O
-	O
world	O
datasets	O
,	O
achieving	O
4	O
%	O
improvement	O
of	O
Recall	O
over	O
the	O
SOTAs	O
on	O
Jdata	Data/Mining/Information/Retrieval-term
dataset	Data/Mining/Information/Retrieval-term
.	O

In	O
experiments	O
,	O
the	O
proposed	O
method	O
outperforms	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
session	O
-	O
based	O
recommendation	O
systems	O
on	O
three	O
real	O
-	O
world	O
datasets	O
,	O
achieving	O
4	O
%	O
improvement	O
of	O
Recall	O
over	O
the	O
SOTAs	O
on	O
Jdata	Data/Mining/Information/Retrieval-term
dataset	Data/Mining/Information/Retrieval-term
.	O

Textual	NLP-term
reviews	NLP-term
contain	O
rich	O
semantic	NLP-term
information	NLP-term
that	O
is	O
useful	O
for	O
making	O
better	O
recommendation	O
semantic	NLP-term
information	NLP-term
ormation	O
may	O
indicate	O
more	O
fine	O
-	O
grained	O
preferences	O
of	O
users	O
.	O

Recent	O
efforts	O
make	O
considerable	O
improvement	O
on	O
recommendation	O
by	O
integrating	O
textual	NLP-term
reviews	NLP-term
in	O
rating	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
recommendations	Data/Mining/Information/Retrieval-term
.	O

Recent	O
efforts	O
make	O
considerable	O
improvement	O
on	O
recommendation	O
by	O
integrating	O
textual	NLP-term
reviews	NLP-term
in	O
rating	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
recommendations	Data/Mining/Information/Retrieval-term
.	O

However	O
,	O
there	O
still	O
exist	O
major	O
challenges	O
on	O
integrating	O
textual	NLP-term
reviews	NLP-term
for	O
recommendation	O
.	O

On	O
the	O
other	O
hand	O
,	O
these	O
works	O
independently	O
learn	O
latent	AI/ML/DL-term
representations	AI/ML/DL-term
from	O
ratings	O
and	O
reviews	O
while	O
omitting	O
correlations	O
between	O
rating	O
-	O
based	O
features	O
and	O
review	O
-	O
based	O
features	O
,	O
which	O
may	O
harm	O
recommendation	O
performance	O
.	O

In	O
this	O
article	O
,	O
we	O
capture	O
the	O
aspect	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
aware	Data/Mining/Information/Retrieval-term
relations	Data/Mining/Information/Retrieval-term
by	O
constructing	O
heterogeneous	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
from	O
reviews	O
.	O

Furthermore	O
,	O
we	O
propose	O
a	O
new	O
recommendation	Data/Mining/Information/Retrieval-term
model	Data/Mining/Information/Retrieval-term
namely	O
AHOR	O
to	O
jointly	O
distill	O
rating	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
features	Data/Mining/Information/Retrieval-term
and	O
review	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
features	Data/Mining/Information/Retrieval-term
which	O
are	O
derived	O
from	O
ratings	O
and	O
reviews	O
,	O
respectively	O
.	O

To	O
explore	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
hop	Data/Mining/Information/Retrieval-term
connectivity	Data/Mining/Information/Retrieval-term
information	O
between	O
users	O
,	O
items	O
,	O
and	O
aspects	O
,	O
a	O
novel	O
graph	O
neural	O
network	O
is	O
introduced	O
to	O
learn	O
aspect	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
aware	Data/Mining/Information/Retrieval-term
high	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
order	Data/Mining/Information/Retrieval-term
representations	Data/Mining/Information/Retrieval-term
.	O

Experiments	O
based	O
on	O
public	O
datasets	O
show	O
that	O
our	O
approach	O
outperforms	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
.	O

We	O
also	O
provide	O
detailed	O
analysis	O
on	O
the	O
high	O
-	O
order	O
signals	O
and	O
the	O
aspect	O
importance	O
to	O
show	O
the	O
interpretability	AI/ML/DL-term
of	O
our	O
proposed	O
model	O
.	O

Multi	AI/ML/DL-term
-	AI/ML/DL-term
label	AI/ML/DL-term
data	AI/ML/DL-term
is	O
often	O
of	O
high	AI/ML/DL-term
dimensionality	AI/ML/DL-term
and	O
has	O
many	O
noisy	O
,	O
irrelevant	O
,	O
and	O
redundant	O
features	O
.	O

As	O
an	O
important	O
machine	O
learning	O
task	O
,	O
multi	O
-	O
label	O
feature	O
selection	O
has	O
received	O
considerable	O
attention	O
in	O
recent	O
years	O
due	O
to	O
its	O
promising	O
performance	O
in	O
dealing	O
with	O
high	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
multi	AI/ML/DL-term
-	AI/ML/DL-term
label	AI/ML/DL-term
data	AI/ML/DL-term
.	O

Existing	O
multi	O
-	O
label	O
feature	O
selection	O
methods	O
typically	O
select	O
the	O
global	AI/ML/DL-term
features	AI/ML/DL-term
which	O
are	O
shared	O
by	O
all	O
instances	O
in	O
a	O
dataset	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
algorithm	Miscellaneous-term
that	O
integrates	O
Global	O
and	O
Local	O
Feature	O
Selection	O
(	O
GLFS	O
)	O
to	O
exploit	O
both	O
the	O
global	AI/ML/DL-term
features	AI/ML/DL-term
and	O
a	O
subset	O
of	O
discriminative	AI/ML/DL-term
features	AI/ML/DL-term
shared	O
only	O
locally	O
by	O
a	O
subgroup	O
of	O
instances	O
in	O
a	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
label	AI/ML/DL-term
dataset	AI/ML/DL-term
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
algorithm	Miscellaneous-term
that	O
integrates	O
Global	O
and	O
Local	O
Feature	O
Selection	O
(	O
GLFS	O
)	O
to	O
exploit	O
both	O
the	O
global	AI/ML/DL-term
features	AI/ML/DL-term
and	O
a	O
subset	O
of	O
discriminative	AI/ML/DL-term
features	AI/ML/DL-term
shared	O
only	O
locally	O
by	O
a	O
subgroup	O
of	O
instances	O
in	O
a	O
multi	AI/ML/DL-term
-	AI/ML/DL-term
label	AI/ML/DL-term
dataset	AI/ML/DL-term
.	O

Specifically	O
,	O
GLFS	O
employs	O
linear	O
regression	O
and	O
ℓ2	O
,	O
1	O
-	O
norm	O
on	O
the	O
regression	AI/ML/DL-term
parameters	AI/ML/DL-term
to	O
achieve	O
simultaneous	O
global	O
and	O
local	O
feature	O
selection	O
.	O

Moreover	O
,	O
the	O
proposed	O
algorithm	Miscellaneous-term
has	O
an	O
effective	O
mechanism	O
for	O
utilizing	O
label	AI/ML/DL-term
correlations	AI/ML/DL-term
to	O
improve	O
the	O
feature	O
selection	O
.	O

Moreover	O
,	O
the	O
proposed	O
algorithm	Miscellaneous-term
has	O
an	O
effective	O
mechanism	O
for	O
utilizing	O
label	AI/ML/DL-term
correlations	AI/ML/DL-term
to	O
improve	O
the	O
feature	O
selection	O
.	O

Experiments	O
on	O
real	O
-	O
world	O
multi	O
-	O
label	O
datasets	O
show	O
the	O
superiority	O
of	O
GLFS	O
over	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
multi	O
-	O
label	O
feature	O
selection	O
methods	O
.	O

Symbolic	Data/Mining/Information/Retrieval-term
representations	Data/Mining/Information/Retrieval-term
are	O
a	O
useful	O
tool	O
for	O
the	O
dimension	O
reduction	O
of	O
temporal	AI/ML/DL-term
data	AI/ML/DL-term
allowing	O
for	O
the	O
efficient	O
storage	O
of	O
and	O
information	O
retrieval	O
from	O
time	O
series	O
.	O

Symbolic	Data/Mining/Information/Retrieval-term
representations	Data/Mining/Information/Retrieval-term
are	O
a	O
useful	O
tool	O
for	O
the	O
dimension	O
reduction	O
of	O
temporal	AI/ML/DL-term
data	AI/ML/DL-term
allowing	O
for	O
the	O
efficient	O
storage	O
of	O
and	O
information	O
retrieval	O
from	O
time	O
series	O
.	O

They	O
can	O
also	O
enhance	O
the	O
training	O
of	O
machine	O
learning	O
algorithms	Miscellaneous-term
on	O
time	O
series	O
data	O
through	O
noise	O
reduction	O
and	O
reduced	O
sensitivity	O
to	O
hyperparameters	AI/ML/DL-term
.	O

They	O
can	O
also	O
enhance	O
the	O
training	O
of	O
machine	O
learning	O
algorithms	Miscellaneous-term
on	O
time	O
series	O
data	O
through	O
noise	O
reduction	O
and	O
reduced	O
sensitivity	O
to	O
hyperparameters	AI/ML/DL-term
.	O

The	O
adaptive	O
Brownian	O
bridge	O
-	O
based	O
aggregation	O
(	O
ABBA	O
)	O
method	O
is	O
one	O
such	O
effective	O
and	O
robust	O
symbolic	Data/Mining/Information/Retrieval-term
representation	Data/Mining/Information/Retrieval-term
demonstrated	O
to	O
accurately	O
capture	O
important	O
trends	O
and	O
shapes	O
in	O
time	O
series	O
.	O

By	O
replacing	O
the	O
k	O
-	O
means	O
clustering	O
used	O
in	O
ABBA	O
with	O
a	O
sorting	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
aggregation	Data/Mining/Information/Retrieval-term
technique	Data/Mining/Information/Retrieval-term
and	O
thereby	O
avoiding	O
repeated	O
sum	AI/ML/DL-term
-	AI/ML/DL-term
of	AI/ML/DL-term
-	AI/ML/DL-term
squares	AI/ML/DL-term
error	AI/ML/DL-term
computations	AI/ML/DL-term
the	O
computational	Miscellaneous-term
complexity	Miscellaneous-term
is	O
significantly	O
reduced	O
.	O

By	O
replacing	O
the	O
k	O
-	O
means	O
clustering	O
used	O
in	O
ABBA	O
with	O
a	O
sorting	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
aggregation	Data/Mining/Information/Retrieval-term
technique	Data/Mining/Information/Retrieval-term
and	O
thereby	O
avoiding	O
repeated	O
sum	AI/ML/DL-term
-	AI/ML/DL-term
of	AI/ML/DL-term
-	AI/ML/DL-term
squares	AI/ML/DL-term
error	AI/ML/DL-term
computations	AI/ML/DL-term
the	O
computational	Miscellaneous-term
complexity	Miscellaneous-term
is	O
significantly	O
reduced	O
.	O

By	O
replacing	O
the	O
k	O
-	O
means	O
clustering	O
used	O
in	O
ABBA	O
with	O
a	O
sorting	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
based	Data/Mining/Information/Retrieval-term
aggregation	Data/Mining/Information/Retrieval-term
technique	Data/Mining/Information/Retrieval-term
and	O
thereby	O
avoiding	O
repeated	O
sum	AI/ML/DL-term
-	AI/ML/DL-term
of	AI/ML/DL-term
-	AI/ML/DL-term
squares	AI/ML/DL-term
error	AI/ML/DL-term
computations	AI/ML/DL-term
the	O
computational	Miscellaneous-term
complexity	Miscellaneous-term
is	O
significantly	O
reduced	O
.	O

Through	O
extensive	O
tests	O
,	O
we	O
demonstrate	O
that	O
the	O
new	O
method	O
significantly	O
outperforms	O
ABBA	O
with	O
a	O
considerable	O
reduction	O
in	O
runtime	O
while	O
also	O
outperforming	O
the	O
popular	O
SAX	Data/Mining/Information/Retrieval-term
and	O
1d	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
SAX	Data/Mining/Information/Retrieval-term
representations	Data/Mining/Information/Retrieval-term
in	O
terms	O
of	O
reconstruction	O
accuracy	O
.	O

Technically	O
,	O
GPM	O
is	O
to	O
find	O
matched	O
subgraphs	O
that	O
meet	O
the	O
requirements	O
of	O
pattern	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
in	O
big	O
social	O
networks	O
.	O

In	O
the	O
application	O
of	O
expert	O
community	O
location	O
,	O
the	O
nodes	O
in	O
the	O
pattern	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
and	O
data	O
graph	O
represent	O
expert	O
entities	O
,	O
and	O
the	O
edges	O
represent	O
previous	O
cooperations	O
between	O
them	O
.	O

In	O
addition	O
,	O
considering	O
a	O
preferred	Miscellaneous-term
expert	Miscellaneous-term
set	Miscellaneous-term
and	O
a	O
dispreferred	Miscellaneous-term
expert	Miscellaneous-term
set	Miscellaneous-term
together	O
,	O
the	O
DM	O
dispreferred	Miscellaneous-term
expert	Miscellaneous-term
set	Miscellaneous-term
e	O
dispreferred	O
expert	O
set	O
will	O
not	O
appear	O
in	O
final	O
matches	O
,	O
so	O
we	O
have	O
the	O
DsEs	O
-	O
ssGPM	O
+	O
method	O
.	O

Technically	O
,	O
these	O
DsEs	O
-	O
ssGPM	O
methods	O
conduct	O
the	O
matching	O
process	O
from	O
the	O
preferred	Miscellaneous-term
expert	Miscellaneous-term
set	Miscellaneous-term
during	O
dual	Miscellaneous-term
simulation	Miscellaneous-term
-	Miscellaneous-term
based	Miscellaneous-term
edge	O
sequencing	O
and	O
based	O
on	O
the	O
edge	Data/Mining/Information/Retrieval-term
sequence	Data/Mining/Information/Retrieval-term
these	O
edges	O
are	O
searched	O
recursively	O
.	O

Technically	O
,	O
these	O
DsEs	O
-	O
ssGPM	O
methods	O
conduct	O
the	O
matching	O
process	O
from	O
the	O
preferred	Miscellaneous-term
expert	Miscellaneous-term
set	Miscellaneous-term
during	O
dual	Miscellaneous-term
simulation	Miscellaneous-term
-	Miscellaneous-term
based	Miscellaneous-term
edge	O
sequencing	O
and	O
based	O
on	O
the	O
edge	Data/Mining/Information/Retrieval-term
sequence	Data/Mining/Information/Retrieval-term
these	O
edges	O
are	O
searched	O
recursively	O
.	O

Especially	O
,	O
as	O
for	O
the	O
rematching	O
process	O
,	O
when	O
the	O
preferred	O
and	O
/	O
or	O
the	O
dispreferred	Miscellaneous-term
expert	Miscellaneous-term
sets	Miscellaneous-term
change	O
continuously	O
,	O
to	O
process	O
the	O
GPM	O
again	O
is	O
unnecessary	O
and	O
it	O
is	O
possible	O
to	O
revise	O
the	O
previous	O
matched	O
results	O
partially	O
with	O
DsEs	O
-	O
ssGPM	O
methods	O
.	O

Multi	O
-	O
view	O
clustering	O
clustering	O
at	O
boosting	O
the	O
clustering	O
performance	O
by	O
leveraging	O
the	O
individual	O
information	O
and	O
the	O
common	O
information	O
of	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
data	Data/Mining/Information/Retrieval-term
has	O
gained	O
extensive	O
consideration	O
in	O
recent	O
years	O
.	O

However	O
,	O
most	O
existing	O
multi	O
-	O
view	O
clustering	O
algorithms	Miscellaneous-term
either	O
focus	O
on	O
extracting	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
individuality	Data/Mining/Information/Retrieval-term
or	O
emphasize	O
on	O
exploring	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
commonality	Data/Mining/Information/Retrieval-term
neither	O
of	O
which	O
can	O
fully	O
utilize	O
the	O
comprehensive	O
information	O
from	O
multiple	O
views	O
.	O

However	O
,	O
most	O
existing	O
multi	O
-	O
view	O
clustering	O
algorithms	Miscellaneous-term
either	O
focus	O
on	O
extracting	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
individuality	Data/Mining/Information/Retrieval-term
or	O
emphasize	O
on	O
exploring	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
commonality	Data/Mining/Information/Retrieval-term
neither	O
of	O
which	O
can	O
fully	O
utilize	O
the	O
comprehensive	O
information	O
from	O
multiple	O
views	O
.	O

To	O
this	O
end	O
,	O
we	O
propose	O
a	O
novel	O
algorithm	O
named	O
View	O
-	O
specific	O
and	O
Consensus	O
Graph	O
Alignment	O
(	O
VCGA	O
)	O
for	O
multi	O
-	O
view	O
clustering	O
which	O
simultaneously	O
formulates	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
individuality	Data/Mining/Information/Retrieval-term
and	O
the	O
multi	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
view	Data/Mining/Information/Retrieval-term
commonality	Data/Mining/Information/Retrieval-term
into	O
a	O
unified	O
framework	O
to	O
effectively	O
partition	O
data	O
points	O
.	O

To	O
be	O
specific	O
,	O
the	O
VCGA	O
model	O
constructs	O
the	O
view	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
specific	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
and	O
the	O
shared	O
graph	O
from	O
original	O
multi	O
-	O
view	O
data	O
and	O
hidden	AI/ML/DL-term
latent	AI/ML/DL-term
representation	AI/ML/DL-term
respectively	O
.	O

To	O
be	O
specific	O
,	O
the	O
VCGA	O
model	O
constructs	O
the	O
view	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
specific	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
and	O
the	O
shared	O
graph	O
from	O
original	O
multi	O
-	O
view	O
data	O
and	O
hidden	AI/ML/DL-term
latent	AI/ML/DL-term
representation	AI/ML/DL-term
respectively	O
.	O

Furthermore	O
,	O
the	O
view	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
specific	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
of	O
different	O
views	O
and	O
the	O
consensus	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
are	O
aligned	O
into	O
an	O
informative	O
target	O
graph	O
,	O
which	O
is	O
employed	O
as	O
a	O
crucial	O
input	O
to	O
the	O
standard	O
spectral	O
clustering	O
clustering	O
clustering	O
.	O

Extensive	O
experimental	O
results	O
on	O
six	O
benchmark	O
datasets	O
demonstrate	O
the	O
superiority	O
of	O
our	O
method	O
against	O
other	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
clustering	O
algorithms	Miscellaneous-term
.	O

Signed	O
link	O
prediction	O
in	O
graphs	Data/Mining/Information/Retrieval-term
is	O
an	O
important	O
problem	O
that	O
has	O
applications	O
in	O
diverse	O
domains	O
.	O

Inspired	O
by	O
the	O
recent	O
success	O
of	O
Generative	O
Adversarial	O
Network	O
(	O
GAN	O
)	O
GAN	O
d	O
models	O
in	O
several	O
applications	O
,	O
we	O
propose	O
a	O
GAN	O
based	O
model	O
for	O
signed	Data/Mining/Information/Retrieval-term
networks	Data/Mining/Information/Retrieval-term
SigGAN	O
.	O

It	O
considers	O
the	O
inherent	O
characteristics	O
of	O
signed	Data/Mining/Information/Retrieval-term
networks	Data/Mining/Information/Retrieval-term
such	O
as	O
integration	O
of	O
information	O
from	O
negative	O
edges	O
,	O
high	O
imbalance	O
in	O
number	O
of	O
positive	O
and	O
negative	O
edges	O
,	O
and	O
structural	O
balance	O
theory	O
.	O

Comparing	O
the	O
performance	O
with	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
techniques	O
on	O
five	O
real	O
-	O
world	O
datasets	O
validates	O
the	O
effectiveness	O
of	O
SigGAN	O
.	O

Although	O
various	O
methods	O
are	O
proposed	O
for	O
spatio	O
-	O
temporal	O
modeling	O
they	O
ignore	O
the	O
dynamic	O
characteristics	O
of	O
correlations	Data/Mining/Information/Retrieval-term
among	O
locations	O
on	O
road	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
.	O

In	O
DGCRN	O
hyper	O
-	O
networks	O
are	O
designed	O
to	O
leverage	O
and	O
extract	O
dynamic	O
characteristics	O
from	O
node	Data/Mining/Information/Retrieval-term
attributes	Data/Mining/Information/Retrieval-term
while	O
the	O
parameters	O
of	O
dynamic	Data/Mining/Information/Retrieval-term
filters	Data/Mining/Information/Retrieval-term
are	O
generated	O
at	O
each	O
time	O
step	O
.	O

We	O
filter	O
the	O
node	Data/Mining/Information/Retrieval-term
embeddings	Data/Mining/Information/Retrieval-term
and	O
then	O
use	O
them	O
to	O
generate	O
dynamic	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
which	O
is	O
integrated	O
with	O
pre	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
defined	Data/Mining/Information/Retrieval-term
static	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
.	O

As	O
far	O
as	O
we	O
know	O
,	O
we	O
are	O
first	O
to	O
employ	O
a	O
generation	O
method	O
to	O
model	O
fine	Data/Mining/Information/Retrieval-term
topology	Data/Mining/Information/Retrieval-term
of	O
dynamic	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
at	O
each	O
time	O
step	O
.	O

Furthermore	O
,	O
to	O
enhance	O
efficiency	O
and	O
performance	O
,	O
we	O
employ	O
a	O
training	AI/ML/DL-term
strategy	O
for	O
DGCRN	O
by	O
restricting	O
the	O
iteration	O
number	O
of	O
decoder	O
during	O
forward	AI/ML/DL-term
and	O
backward	AI/ML/DL-term
propagation	AI/ML/DL-term
.	O

Extensive	O
experiments	O
on	O
three	O
datasets	Miscellaneous-term
demonstrate	O
that	O
our	O
model	O
outperforms	O
15	O
baselines	Miscellaneous-term
consistently	O
.	O

There	O
is	O
only	O
one	O
algorithm	Miscellaneous-term
proposed	O
for	O
HUSRM	O
which	O
is	O
not	O
efficient	O
enough	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
a	O
faster	O
algorithm	Miscellaneous-term
called	O
US	O
-	O
Rule	O
to	O
efficiently	O
mine	O
high	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
utility	Data/Mining/Information/Retrieval-term
sequential	Data/Mining/Information/Retrieval-term
rules	Data/Mining/Information/Retrieval-term
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
a	O
faster	O
algorithm	Miscellaneous-term
called	O
US	O
-	O
Rule	O
to	O
efficiently	O
mine	O
high	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
utility	Data/Mining/Information/Retrieval-term
sequential	Data/Mining/Information/Retrieval-term
rules	Data/Mining/Information/Retrieval-term
.	O

Moreover	O
,	O
to	O
improve	O
its	O
efficiency	O
on	O
dense	O
and	O
long	O
sequence	O
datasets	O
,	O
four	O
tighter	O
upper	O
bounds	O
(	O
LEEU	Data/Mining/Information/Retrieval-term
REEU	Data/Mining/Information/Retrieval-term
LERSU	Data/Mining/Information/Retrieval-term
and	O
RERSU	Data/Mining/Information/Retrieval-term
and	O
corresponding	O
pruning	O
strategies	O
(	O
LEEUP	O
REEUP	O
LERSUP	O
and	O
RERSUP	O
are	O
designed	O
.	O

Finally	O
,	O
a	O
large	O
number	O
of	O
experiments	O
on	O
different	O
datasets	Miscellaneous-term
compared	O
to	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
algorithm	O
demonstrate	O
that	O
US	O
-	O
Rule	O
can	O
achieve	O
better	O
performance	O
in	O
terms	O
of	O
execution	O
time	O
,	O
memory	Miscellaneous-term
consumption	Miscellaneous-term
and	O
scalability	Miscellaneous-term
.	O

Knowledge	O
Graph	O
Completion	O
(	O
KGC	O
)	O
aims	O
at	O
inferring	O
missing	O
entities	O
or	O
relations	O
by	O
embedding	O
them	O
in	O
a	O
low	AI/ML/DL-term
-	AI/ML/DL-term
dimensional	AI/ML/DL-term
space	AI/ML/DL-term
.	O

However	O
,	O
most	O
existing	O
KGC	O
methods	O
generally	O
fail	O
to	O
handle	O
the	O
complex	O
concepts	O
hidden	O
in	O
triplets	O
,	O
so	O
the	O
learned	AI/ML/DL-term
embeddings	AI/ML/DL-term
of	O
entities	NLP-term
or	O
relations	NLP-term
may	O
deviate	O
from	O
the	O
true	O
situation	O
.	O

However	O
,	O
most	O
existing	O
KGC	O
methods	O
generally	O
fail	O
to	O
handle	O
the	O
complex	O
concepts	O
hidden	O
in	O
triplets	O
,	O
so	O
the	O
learned	AI/ML/DL-term
embeddings	AI/ML/DL-term
of	O
entities	NLP-term
or	O
relations	NLP-term
may	O
deviate	O
from	O
the	O
true	O
situation	O
.	O

Specifically	O
,	O
instead	O
of	O
the	O
single	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
feature	Data/Mining/Information/Retrieval-term
representation	Data/Mining/Information/Retrieval-term
the	O
multi	O
-	O
concept	O
representation	O
module	O
projects	O
each	O
entity	NLP-term
or	O
relation	NLP-term
to	O
multiple	O
vectors	O
to	O
capture	O
the	O
complex	O
conceptual	O
information	O
hidden	O
in	O
them	O
.	O

Specifically	O
,	O
instead	O
of	O
the	O
single	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
feature	Data/Mining/Information/Retrieval-term
representation	Data/Mining/Information/Retrieval-term
the	O
multi	O
-	O
concept	O
representation	O
module	O
projects	O
each	O
entity	NLP-term
or	O
relation	NLP-term
to	O
multiple	O
vectors	O
to	O
capture	O
the	O
complex	O
conceptual	O
information	O
hidden	O
in	O
them	O
.	O

The	O
deep	O
residual	O
attention	O
module	O
simultaneously	O
explores	O
the	O
inter	O
-	O
and	O
intra	O
-	O
connection	O
between	O
entities	NLP-term
and	O
relations	NLP-term
to	O
enhance	O
the	O
entity	NLP-term
and	O
relation	NLP-term
embeddings	NLP-term
corresponding	O
to	O
the	O
current	O
contextual	O
situation	O
.	O

Moreover	O
,	O
the	O
interaction	O
embedding	O
module	O
further	O
weakens	O
the	O
noise	AI/ML/DL-term
and	O
ambiguity	O
to	O
obtain	O
the	O
optimal	O
and	O
robust	AI/ML/DL-term
embeddings	AI/ML/DL-term
.	O

We	O
conduct	O
the	O
link	O
prediction	O
experiment	O
to	O
evaluate	O
the	O
proposed	O
method	O
on	O
several	O
standard	O
datasets	O
,	O
and	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
outperforms	O
existing	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
KGC	O
methods	O
.	O

Entity	O
resolution	O
(	O
ER	O
)	O
is	O
the	O
process	O
of	O
linking	O
records	O
that	O
refer	O
to	O
the	O
same	O
entity	NLP-term
.	O

Traditionally	O
,	O
this	O
process	O
compares	O
attribute	O
values	O
of	O
records	O
to	O
calculate	O
similarities	O
and	O
then	O
classifies	O
pairs	O
of	O
records	O
as	O
referring	O
to	O
the	O
same	O
entity	NLP-term
or	O
not	O
based	O
on	O
these	O
similarities	O
.	O

Recently	O
developed	O
graph	O
-	O
based	O
ER	O
approaches	O
combine	O
relationships	O
between	O
records	O
with	O
attribute	O
similarities	O
to	O
improve	O
linkage	Data/Mining/Information/Retrieval-term
quality	Data/Mining/Information/Retrieval-term
.	Data/Mining/Information/Retrieval-term
.	O

In	O
contrast	O
,	O
temporal	Data/Mining/Information/Retrieval-term
record	Data/Mining/Information/Retrieval-term
linkage	Data/Mining/Information/Retrieval-term
addresses	O
the	O
problem	O
where	O
attribute	O
values	O
of	O
entities	NLP-term
can	O
change	O
over	O
time	O
.	O

In	O
contrast	O
,	O
temporal	Data/Mining/Information/Retrieval-term
record	Data/Mining/Information/Retrieval-term
linkage	Data/Mining/Information/Retrieval-term
addresses	O
the	O
problem	O
where	O
attribute	O
values	O
of	O
entities	NLP-term
can	O
change	O
over	O
time	O
.	O

However	O
,	O
neither	O
existing	O
graph	O
-	O
based	O
ER	O
nor	O
temporal	O
record	O
linkage	O
can	O
achieve	O
high	O
linkage	Data/Mining/Information/Retrieval-term
quality	Data/Mining/Information/Retrieval-term
on	O
databases	Miscellaneous-term
with	O
complex	O
entities	NLP-term
where	O
an	O
entity	NLP-term
entities	NLP-term
a	O
person	O
)	O
can	O
change	O
its	O
attribute	O
values	O
over	O
time	O
while	O
having	O
different	O
relationships	O
with	O
other	O
entities	O
at	O
different	O
points	O
in	O
time	O
.	O

However	O
,	O
neither	O
existing	O
graph	O
-	O
based	O
ER	O
nor	O
temporal	O
record	O
linkage	O
can	O
achieve	O
high	O
linkage	Data/Mining/Information/Retrieval-term
quality	Data/Mining/Information/Retrieval-term
on	O
databases	Miscellaneous-term
with	O
complex	O
entities	NLP-term
where	O
an	O
entity	NLP-term
entities	NLP-term
a	O
person	O
)	O
can	O
change	O
its	O
attribute	O
values	O
over	O
time	O
while	O
having	O
different	O
relationships	O
with	O
other	O
entities	O
at	O
different	O
points	O
in	O
time	O
.	O

However	O
,	O
neither	O
existing	O
graph	O
-	O
based	O
ER	O
nor	O
temporal	O
record	O
linkage	O
can	O
achieve	O
high	O
linkage	Data/Mining/Information/Retrieval-term
quality	Data/Mining/Information/Retrieval-term
on	O
databases	Miscellaneous-term
with	O
complex	O
entities	NLP-term
where	O
an	O
entity	NLP-term
entities	NLP-term
a	O
person	O
)	O
can	O
change	O
its	O
attribute	O
values	O
over	O
time	O
while	O
having	O
different	O
relationships	O
with	O
other	O
entities	O
at	O
different	O
points	O
in	O
time	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
an	O
unsupervised	O
graph	O
-	O
based	O
ER	O
framework	O
that	O
is	O
aimed	O
at	O
linking	O
records	O
of	O
complex	O
entities	NLP-term
.	O

Second	O
,	O
we	O
employ	O
negative	O
evidence	O
by	O
applying	O
temporal	Data/Mining/Information/Retrieval-term
and	O
link	Data/Mining/Information/Retrieval-term
constraints	Data/Mining/Information/Retrieval-term
to	O
restrict	O
which	O
candidate	O
record	O
pairs	O
to	O
consider	O
for	O
linking	Data/Mining/Information/Retrieval-term
.	O

Third	O
,	O
we	O
leverage	O
the	O
ambiguity	O
of	O
attribute	O
values	O
to	O
disambiguate	O
similar	O
records	O
that	O
,	O
however	O
,	O
belong	O
to	O
different	O
entities	NLP-term
.	O

Fifth	O
,	O
using	O
graph	Data/Mining/Information/Retrieval-term
measures	Data/Mining/Information/Retrieval-term
we	O
refine	O
matched	O
clusters	O
of	O
records	O
by	O
removing	O
likely	O
wrong	O
links	O
between	O
records	O
.	O

We	O
conduct	O
extensive	O
experiments	O
on	O
seven	O
real	O
-	O
world	O
datasets	Miscellaneous-term
from	O
different	O
domains	O
showing	O
that	O
on	O
average	O
our	O
unsupervised	O
graph	O
-	O
based	O
ER	O
framework	O
can	O
improve	O
precision	O
by	O
up	O
to	O
25	O
%	O
and	O
recall	O
by	O
up	O
to	O
29	O
%	O
compared	O
to	O
several	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
ER	O
techniques	O
.	O

That	O
is	O
,	O
even	O
if	O
a	O
word	O
that	O
has	O
a	O
critical	O
effect	O
on	O
the	O
classification	O
result	O
is	O
manipulated	O
,	O
it	O
is	O
not	O
considered	O
significant	O
in	O
labeling	O
the	O
augmented	NLP-term
data	NLP-term
.	O

Therefore	O
,	O
in	O
this	O
study	O
,	O
we	O
propose	O
an	O
effective	O
text	O
augmentation	O
technique	O
that	O
explicitly	O
derives	O
the	O
importance	O
of	O
manipulated	O
words	O
and	O
reflects	O
this	O
importance	O
in	O
the	O
labeling	O
of	O
augmented	NLP-term
data	NLP-term
.	O

Most	O
of	O
the	O
existing	O
approaches	O
use	O
heuristic	Miscellaneous-term
models	Miscellaneous-term
or	O
re	O
-	O
weighting	O
strategy	O
on	O
observed	O
ratings	O
to	O
mimic	O
the	O
missing	O
-	O
at	O
-	O
random	O
setting	O
.	O

In	O
general	O
,	O
DENC	O
provides	O
a	O
causal	O
analysis	O
on	O
MNAR	O
from	O
both	O
the	O
inherent	O
factors	O
(	O
e	O
.	O
g	O
.,	O
latent	O
user	O
or	O
item	O
factors	O
)	O
and	O
auxiliary	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
’	Data/Mining/Information/Retrieval-term
s	Data/Mining/Information/Retrieval-term
perspective	O
.	O

Meanwhile	O
,	O
we	O
present	O
some	O
commonly	O
used	O
public	O
datasets	Miscellaneous-term
and	O
the	O
scheme	O
to	O
measure	O
the	O
performance	O
of	O
deep	O
hashing	O
algorithms	Miscellaneous-term
.	O

To	O
predict	O
rainfall	O
,	O
our	O
proposed	O
model	O
architecture	O
combines	O
the	O
Convolutional	O
Neural	O
Network	O
(	O
CNN	O
)	O
which	O
uses	O
the	O
ResNet	O
-	O
152	O
pre	O
-	O
training	O
model	O
with	O
the	O
Recurrent	O
Neural	O
Network	O
(	O
RNN	O
)	O
which	O
uses	O
the	O
Long	O
Short	O
-	O
term	O
Memory	O
Network	O
(	O
LSTM	O
)	O
layer	O
,	O
for	O
model	AI/ML/DL-term
training	AI/ML/DL-term
.	O

By	O
encoding	O
the	O
cloud	O
images	O
through	O
CNN	O
we	O
extract	O
the	O
image	Computer/vision-term
feature	Computer/vision-term
vectors	Computer/vision-term
in	O
the	O
training	AI/ML/DL-term
process	O
and	O
train	O
the	O
vectors	O
and	O
meteorological	O
data	O
as	O
the	O
input	O
of	O
RNN	O
.	O

By	O
encoding	O
the	O
cloud	O
images	O
through	O
CNN	O
we	O
extract	O
the	O
image	Computer/vision-term
feature	Computer/vision-term
vectors	Computer/vision-term
in	O
the	O
training	AI/ML/DL-term
process	O
and	O
train	O
the	O
vectors	O
and	O
meteorological	O
data	O
as	O
the	O
input	O
of	O
RNN	O
.	O

After	O
training	AI/ML/DL-term
the	O
accuracy	O
of	O
the	O
prediction	O
model	O
can	O
reach	O
up	O
to	O
82	O
%	O
.	O

This	O
solution	O
was	O
evaluated	O
on	O
four	O
benchmark	O
human	O
activity	O
recognition	O
datasets	Miscellaneous-term
collected	O
from	O
mobile	O
sensing	O
devices	O
.	O

The	O
results	O
demonstrate	O
an	O
up	O
to	O
4	O
%	O
performance	O
improvement	O
in	O
catastrophic	O
forgetting	O
compared	O
to	O
the	O
use	O
of	O
loss	O
functions	O
in	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
solutions	O
while	O
demonstrating	O
minimal	O
losses	O
compared	O
to	O
upper	O
bound	O
methods	O
of	O
traditional	O
fine	O
-	O
tuning	O
(	O
FT	O
)	O
and	O
multi	O
-	O
task	O
learning	O
(	O
MTL	O
).	O

The	O
task	O
of	O
next	O
Point	O
-	O
of	O
-	O
Interest	O
(	O
POI	O
)	O
recommendation	O
aims	O
at	O
recommending	O
a	O
list	O
of	O
POIs	Data/Mining/Information/Retrieval-term
for	O
a	O
user	O
to	O
visit	O
at	O
the	O
next	O
timestamp	O
based	O
on	O
his	O
/	O
her	O
previous	O
interactions	O
,	O
which	O
is	O
valuable	O
for	O
both	O
location	O
-	O
based	O
service	O
providers	O
and	O
users	O
.	O

Finally	O
,	O
we	O
evaluate	O
the	O
proposed	O
model	O
using	O
three	O
real	O
-	O
world	O
datasets	Miscellaneous-term
.	O

Extensive	O
experiments	O
demonstrate	O
the	O
effectiveness	O
of	O
GSD	O
in	O
capturing	O
various	O
geographical	O
influences	O
and	O
the	O
improvement	O
of	O
GSTN	O
over	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
.	O

Multivariate	O
time	O
-	O
series	O
data	O
are	O
frequently	O
observed	O
in	O
critical	O
care	O
settings	O
and	O
are	O
typically	O
characterized	O
by	O
sparsity	AI/ML/DL-term
(	O
missing	O
information	O
)	O
and	O
irregular	O
time	O
intervals	O
.	O

Recently	O
,	O
learning	O
and	O
mining	O
from	O
data	O
streams	O
with	O
incremental	O
feature	O
spaces	O
have	O
attracted	O
extensive	O
attention	O
,	O
where	O
data	O
may	O
dynamically	O
expand	O
over	O
time	O
in	O
both	O
volume	O
and	O
feature	AI/ML/DL-term
dimensions	AI/ML/DL-term
.	O

After	O
receiving	O
the	O
labels	O
,	O
we	O
combine	O
the	O
online	AI/ML/DL-term
passive	AI/ML/DL-term
-	AI/ML/DL-term
aggressive	AI/ML/DL-term
update	AI/ML/DL-term
rule	AI/ML/DL-term
and	O
margin	AI/ML/DL-term
-	AI/ML/DL-term
maximum	AI/ML/DL-term
principle	AI/ML/DL-term
to	O
jointly	O
update	O
the	O
dynamic	O
classifier	O
in	O
the	O
shared	O
and	O
augmented	O
feature	O
space	O
.	O

We	O
theoretically	O
analyze	O
the	O
error	AI/ML/DL-term
bounds	AI/ML/DL-term
of	O
FLLS	O
and	O
its	O
two	O
variants	O
.	O

Also	O
,	O
we	O
conduct	O
experiments	O
on	O
synthetic	O
data	O
and	O
real	O
-	O
world	O
applications	O
to	O
further	O
validate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
algorithms	Miscellaneous-term
.	O

The	O
task	O
of	O
semi	O
-	O
supervised	O
outlier	O
detection	O
is	O
first	O
decomposed	O
into	O
the	O
detection	O
of	O
discrete	AI/ML/DL-term
anomalies	AI/ML/DL-term
and	O
that	O
of	O
partially	O
identified	O
group	AI/ML/DL-term
anomalies	AI/ML/DL-term
and	O
a	O
distribution	O
construction	O
sub	O
-	O
module	O
and	O
a	O
data	O
augmentation	O
sub	O
-	O
module	O
are	O
then	O
proposed	O
to	O
identify	O
them	O
,	O
respectively	O
.	O

In	O
this	O
way	O
,	O
the	O
dual	AI/ML/DL-technique
multiple	AI/ML/DL-technique
generative	AI/ML/DL-technique
adversarial	AI/ML/DL-technique
networks	AI/ML/DL-technique
(	AI/ML/DL-technique
Dual	AI/ML/DL-technique
-	AI/ML/DL-technique
MGAN	AI/ML/DL-technique
)	AI/ML/DL-technique
that	O
combine	O
the	O
two	O
sub	O
-	O
modules	O
can	O
identify	O
discrete	O
as	O
well	O
as	O
partially	O
identified	O
group	O
anomalies	O
.	O

Extensive	O
experiments	O
on	O
synthetic	O
and	O
real	O
-	O
world	O
data	O
show	O
that	O
the	O
proposed	O
Dual	AI/ML/DL-technique
-	AI/ML/DL-technique
MGAN	AI/ML/DL-technique
can	O
significantly	O
improve	O
the	O
accuracy	O
of	O
outlier	O
detection	O
and	O
the	O
proposed	O
evaluation	O
indicators	O
can	O
reflect	O
the	O
training	O
status	O
of	O
the	O
sub	O
-	O
GANs	O
.	O

Although	O
existing	O
neural	O
-	O
based	O
NER	O
approaches	O
achieve	O
great	O
success	O
in	O
many	O
language	O
domains	O
,	O
most	O
of	O
them	O
normally	O
ignore	O
the	O
nested	O
nature	O
of	O
named	NLP-term
entities	NLP-term
.	O

Recently	O
,	O
diverse	O
studies	O
focus	O
on	O
the	O
nested	O
NER	O
problem	O
and	O
yield	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
performance	O
.	O

This	O
survey	O
attempts	O
to	O
provide	O
a	O
comprehensive	O
review	O
on	O
existing	O
approaches	O
for	O
nested	O
NER	O
from	O
the	O
perspectives	O
of	O
the	O
model	AI/ML/DL-term
architecture	AI/ML/DL-term
and	O
the	O
model	O
property	O
,	O
which	O
may	O
help	O
readers	O
have	O
a	O
better	O
understanding	O
of	O
the	O
current	O
research	O
status	O
and	O
ideas	O
.	O

We	O
then	O
review	O
the	O
existing	O
nested	O
NER	O
approaches	O
from	O
2002	O
to	O
2020	O
and	O
mainly	O
classify	O
them	O
into	O
five	O
categories	O
according	O
to	O
the	O
model	AI/ML/DL-term
architecture	AI/ML/DL-term
including	O
early	O
rule	O
-	O
based	O
layered	O
-	O
based	O
region	O
-	O
based	O
hypergraph	O
-	O
based	O
and	O
transition	O
-	O
based	O
approaches	O
.	O

We	O
also	O
explore	O
in	O
greater	O
depth	O
the	O
impact	O
of	O
key	O
properties	O
unique	O
to	O
nested	O
NER	O
approaches	O
from	O
the	O
model	O
property	O
perspective	O
,	O
namely	O
entity	O
dependency	O
stage	AI/ML/DL-term
framework	AI/ML/DL-term
error	AI/ML/DL-term
propagation	AI/ML/DL-term
and	O
tag	NLP-term
scheme	NLP-term
.	O

We	O
also	O
explore	O
in	O
greater	O
depth	O
the	O
impact	O
of	O
key	O
properties	O
unique	O
to	O
nested	O
NER	O
approaches	O
from	O
the	O
model	O
property	O
perspective	O
,	O
namely	O
entity	O
dependency	O
stage	AI/ML/DL-term
framework	AI/ML/DL-term
error	AI/ML/DL-term
propagation	AI/ML/DL-term
and	O
tag	NLP-term
scheme	NLP-term
.	O

Under	O
such	O
an	O
environment	O
,	O
many	O
machine	O
learning	O
problems	O
can	O
be	O
reformulated	O
as	O
a	O
consensus	O
optimization	AI/ML/DL-term
problem	O
,	O
which	O
consists	O
of	O
one	O
objective	O
and	O
constraint	O
terms	O
splitting	O
into	O
N	O
parts	O
(	O
each	O
corresponds	O
to	O
a	O
node	O
).	O

However	O
,	O
existing	O
consensus	O
optimization	O
frameworks	O
assume	O
that	O
every	O
node	O
has	O
the	O
same	O
quality	Data/Mining/Information/Retrieval-term
of	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
(	Data/Mining/Information/Retrieval-term
QoI	Data/Mining/Information/Retrieval-term
)	Data/Mining/Information/Retrieval-term
i	O
.	O
e	O
.,	O
the	O
data	O
from	O
all	O
the	O
nodes	O
are	O
equally	O
informative	O
for	O
the	O
estimation	O
of	O
global	AI/ML/DL-term
model	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

However	O
,	O
existing	O
consensus	O
optimization	O
frameworks	O
assume	O
that	O
every	O
node	O
has	O
the	O
same	O
quality	Data/Mining/Information/Retrieval-term
of	Data/Mining/Information/Retrieval-term
information	Data/Mining/Information/Retrieval-term
(	Data/Mining/Information/Retrieval-term
QoI	Data/Mining/Information/Retrieval-term
)	Data/Mining/Information/Retrieval-term
i	O
.	O
e	O
.,	O
the	O
data	O
from	O
all	O
the	O
nodes	O
are	O
equally	O
informative	O
for	O
the	O
estimation	O
of	O
global	AI/ML/DL-term
model	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

As	O
a	O
consequence	O
,	O
they	O
may	O
lead	O
to	O
inaccurate	O
estimates	O
in	O
the	O
presence	O
of	O
nodes	O
with	O
low	O
QoI	Data/Mining/Information/Retrieval-term
.	O

To	O
overcome	O
this	O
challenge	O
,	O
in	O
this	O
article	O
,	O
we	O
propose	O
a	O
novel	O
consensus	O
optimization	O
framework	O
for	O
distributed	O
machine	O
-	O
learning	O
that	O
incorporates	O
the	O
crucial	O
metric	O
,	O
QoI	Data/Mining/Information/Retrieval-term
.	O

Then	O
the	O
reduced	O
dataset	Miscellaneous-term
is	O
formed	O
by	O
collecting	O
the	O
representations	O
of	O
each	O
region	O
.	O

The	O
performance	O
of	O
ARIS	O
is	O
verified	O
by	O
experiments	O
on	O
artificial	O
and	O
real	O
datasets	Miscellaneous-term
.	O

Contextual	Data/Mining/Information/Retrieval-term
bandit	Data/Mining/Information/Retrieval-term
serves	O
as	O
an	O
invaluable	O
tool	O
to	O
balance	O
the	O
exploration	O
vs	O
.	O

In	O
many	O
applications	O
,	O
heterogeneous	O
information	O
networks	O
(	O
HINs	O
)	O
provide	O
rich	O
side	O
information	O
for	O
contextual	Data/Mining/Information/Retrieval-term
bandits	Data/Mining/Information/Retrieval-term
such	O
as	O
different	O
types	O
of	O
attributes	O
and	O
relationships	O
among	O
users	O
and	O
items	O
.	O

The	O
proposed	O
framework	O
uses	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
in	O
HIN	O
to	O
extract	O
rich	O
relations	O
among	O
users	O
and	O
items	O
for	O
the	O
contextual	Data/Mining/Information/Retrieval-term
bandit	Data/Mining/Information/Retrieval-term
.	O

The	O
main	O
challenge	O
is	O
how	O
to	O
leverage	O
these	O
relations	O
,	O
since	O
users	O
’	O
preference	O
over	O
items	O
,	O
the	O
target	O
of	O
our	O
online	O
learning	O
are	O
closely	O
related	O
to	O
users	O
’	O
preference	O
over	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
.	O

We	O
propose	O
the	O
HIN	O
-	O
assisted	O
upper	O
confidence	O
bound	O
(	O
HUCB	O
)	O
algorithm	Miscellaneous-term
to	O
address	O
such	O
a	O
challenge	O
.	O

For	O
each	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
path	Data/Mining/Information/Retrieval-term
the	O
HUCB	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
path	Data/Mining/Information/Retrieval-term
employs	O
an	O
independent	O
base	O
bandit	O
algorithm	O
to	O
handle	O
online	O
item	O
recommendations	O
by	O
leveraging	O
the	O
relationship	O
captured	O
in	O
this	O
meta	O
-	O
path	O
.	O

We	O
theoretically	O
prove	O
that	O
the	O
HUCB	O
algorithm	Miscellaneous-term
algorithm	Miscellaneous-term
e	O
similar	O
performance	O
compared	O
with	O
the	O
optimal	O
algorithm	O
where	O
each	O
user	O
is	O
served	O
according	O
to	O
his	O
true	O
preference	O
over	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
algorithm	Miscellaneous-term
the	O
optimal	O
algorithm	O
knows	O
the	O
preference	O
).	O

We	O
theoretically	O
prove	O
that	O
the	O
HUCB	O
algorithm	Miscellaneous-term
algorithm	Miscellaneous-term
e	O
similar	O
performance	O
compared	O
with	O
the	O
optimal	O
algorithm	O
where	O
each	O
user	O
is	O
served	O
according	O
to	O
his	O
true	O
preference	O
over	O
meta	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
paths	Data/Mining/Information/Retrieval-term
algorithm	Miscellaneous-term
the	O
optimal	O
algorithm	O
knows	O
the	O
preference	O
).	O

Moreover	O
,	O
we	O
prove	O
that	O
the	O
HUCB	O
algorithm	Miscellaneous-term
benefits	O
from	O
leveraging	O
HIN	O
in	O
achieving	O
a	O
smaller	O
regret	O
upper	Miscellaneous-term
bound	Miscellaneous-term
algorithm	Miscellaneous-term
HIN	O
ine	O
algorithm	O
without	O
leveraging	O
HIN	O
.	O

Experimental	O
results	O
on	O
a	O
synthetic	O
dataset	Miscellaneous-term
as	O
well	O
as	O
real	O
datasets	Miscellaneous-term
from	O
LastFM	Miscellaneous-term
and	O
Yelp	Miscellaneous-term
demonstrate	O
the	O
fast	O
learning	O
speed	O
of	O
the	O
HUCB	O
algorithm	Miscellaneous-term
.	O

Representing	O
a	O
matrix	O
as	O
a	O
mixture	O
of	O
a	O
small	O
collection	O
of	O
latent	AI/ML/DL-term
vectors	AI/ML/DL-term
via	O
low	O
-	O
rank	O
decomposition	O
is	O
often	O
seen	O
as	O
an	O
advantageous	O
method	O
to	O
interpret	O
and	O
analyze	O
data	O
.	O

We	O
introduce	O
a	O
method	O
for	O
robust	O
Boolean	O
model	O
selection	O
called	O
BMFk	O
BMFk	O
show	O
on	O
numerical	O
examples	O
that	O
BMFk	O
not	O
only	O
accurately	O
determines	O
the	O
correct	O
number	O
of	O
Boolean	AI/ML/DL-term
latent	AI/ML/DL-term
features	AI/ML/DL-term
but	O
reconstruct	O
the	O
pre	O
-	O
determined	O
factors	O
accurately	O
.	O

By	O
allowing	O
VAR	AI/ML/DL-term
parameters	AI/ML/DL-term
to	O
change	O
segment	O
-	O
wisely	O
over	O
time	O
,	O
the	O
time	O
-	O
varying	O
dynamics	O
of	O
the	O
network	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
can	O
be	O
described	O
.	O

By	O
allowing	O
VAR	AI/ML/DL-term
parameters	AI/ML/DL-term
to	O
change	O
segment	O
-	O
wisely	O
over	O
time	O
,	O
the	O
time	O
-	O
varying	O
dynamics	O
of	O
the	O
network	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
can	O
be	O
described	O
.	O

Graph	Data/Mining/Information/Retrieval-term
Laplacian	Data/Mining/Information/Retrieval-term
is	O
further	O
imposed	O
to	O
regularize	O
similar	O
nodes	O
to	O
have	O
similar	O
network	O
structures	O
.	O

The	O
regularized	O
maximum	O
a	O
posterior	O
estimation	O
in	O
the	O
Bayesian	O
inference	O
framework	O
is	O
used	O
as	O
a	O
score	O
function	O
for	O
TVDBN	Data/Mining/Information/Retrieval-term
structure	Data/Mining/Information/Retrieval-term
evaluation	Data/Mining/Information/Retrieval-term
and	O
the	O
alternating	O
direction	O
method	O
of	O
multipliers	O
(	O
ADMM	O
)	O
with	O
L	O
-	O
BFGS	O
-	O
B	O
algorithm	O
is	O
used	O
for	O
optimal	O
structure	O
learning	O
.	O

Thorough	O
simulation	Miscellaneous-term
studies	O
and	O
a	O
real	O
case	O
study	O
are	O
carried	O
out	O
to	O
verify	O
our	O
proposed	O
method	O
’	O
s	O
efficacy	O
and	O
efficiency	O
.	O

Diagram	Miscellaneous-term
is	O
a	O
special	O
form	O
of	O
visual	O
expression	O
for	O
representing	O
complex	O
concepts	O
,	O
logic	O
,	O
and	O
knowledge	O
,	O
which	O
widely	O
appears	O
in	O
educational	O
scenes	O
such	O
as	O
textbooks	O
,	O
blogs	O
,	O
and	O
encyclopedias	O
.	O

Current	O
research	O
on	O
diagrams	Miscellaneous-term
preliminarily	O
focuses	O
on	O
natural	O
disciplines	O
such	O
as	O
Biology	O
and	O
Geography	O
whose	O
expressions	O
are	O
still	O
similar	O
to	O
natural	O
images	O
.	O

In	O
this	O
article	O
,	O
we	O
construct	O
the	O
first	O
novel	O
geometric	O
type	O
of	O
diagrams	Miscellaneous-term
dataset	Miscellaneous-term
in	O
Computer	O
Science	O
field	O
,	O
which	O
has	O
more	O
abstract	Miscellaneous-term
expressions	Miscellaneous-term
and	O
complex	O
logical	O
relations	O
.	O

The	O
dataset	Miscellaneous-term
has	O
exhaustive	O
annotations	O
of	O
objects	O
and	O
relations	O
for	O
about	O
1	O
,	O
300	O
diagrams	O
and	O
3	O
,	O
500	O
question	O
-	O
answer	O
pairs	O
.	O

We	O
introduce	O
the	O
tasks	O
of	O
diagram	O
classification	O
(	O
DC	O
)	O
and	O
diagram	O
question	O
answering	O
(	O
DQA	O
)	O
based	O
on	O
the	O
new	O
dataset	O
,	O
and	O
propose	O
the	O
Diagram	Computer/Vision-technique
Paring	Computer/Vision-technique
Net	Computer/Vision-technique
(	Computer/Vision-technique
DPN	Computer/Vision-technique
)	Computer/Vision-technique
that	O
focuses	O
on	O
analyzing	O
the	O
topological	O
structure	O
and	O
text	O
information	O
of	O
diagrams	Miscellaneous-term
.	O

We	O
introduce	O
the	O
tasks	O
of	O
diagram	O
classification	O
(	O
DC	O
)	O
and	O
diagram	O
question	O
answering	O
(	O
DQA	O
)	O
based	O
on	O
the	O
new	O
dataset	O
,	O
and	O
propose	O
the	O
Diagram	Computer/Vision-technique
Paring	Computer/Vision-technique
Net	Computer/Vision-technique
(	Computer/Vision-technique
DPN	Computer/Vision-technique
)	Computer/Vision-technique
that	O
focuses	O
on	O
analyzing	O
the	O
topological	O
structure	O
and	O
text	O
information	O
of	O
diagrams	Miscellaneous-term
.	O

We	O
use	O
DPN	Computer/Vision-technique
based	O
models	O
to	O
solve	O
DC	O
and	O
DQA	O
tasks	O
,	O
and	O
compare	O
the	O
performances	O
to	O
well	O
-	O
known	O
natural	O
images	O
classification	O
models	O
and	O
visual	O
question	O
answering	O
models	O
.	O

Our	O
experiments	O
show	O
the	O
effectiveness	O
of	O
the	O
proposed	O
DPN	Computer/Vision-technique
based	O
models	O
on	O
diagram	O
understanding	O
tasks	O
,	O
also	O
indicate	O
that	O
our	O
dataset	Miscellaneous-term
is	O
more	O
complex	O
compared	O
to	O
previous	O
natural	O
image	O
understanding	O
datasets	O
.	O

Our	O
experiments	O
show	O
the	O
effectiveness	O
of	O
the	O
proposed	O
DPN	Computer/Vision-technique
based	O
models	O
on	O
diagram	O
understanding	O
tasks	O
,	O
also	O
indicate	O
that	O
our	O
dataset	Miscellaneous-term
is	O
more	O
complex	O
compared	O
to	O
previous	O
natural	O
image	O
understanding	O
datasets	O
.	O

The	O
presented	O
dataset	Miscellaneous-term
opens	O
new	O
challenges	O
for	O
research	O
in	O
diagram	O
understanding	O
and	O
the	O
DPN	Computer/Vision-technique
method	O
provides	O
a	O
novel	O
perspective	O
for	O
studying	O
such	O
data	O
.	O

The	O
presented	O
dataset	Miscellaneous-term
opens	O
new	O
challenges	O
for	O
research	O
in	O
diagram	O
understanding	O
and	O
the	O
DPN	Computer/Vision-technique
method	O
provides	O
a	O
novel	O
perspective	O
for	O
studying	O
such	O
data	O
.	O

Our	O
dataset	Miscellaneous-term
can	O
be	O
available	O
from	O
https	O
://	O
github	O
.	O
com	O
/	O
WayneWong97	O
/	O
CSDia	O
.	O

What	O
are	O
the	O
key	O
structures	O
existing	O
in	O
a	O
large	O
real	O
-	O
world	O
MMORPG	O
(	O
Massively	O
Multiplayer	O
Online	O
Role	O
-	O
Playing	O
Game	O
)	O
graph	O
How	O
can	O
we	O
compactly	O
summarize	O
an	O
MMORPG	O
graph	O
with	O
hierarchical	Data/Mining/Information/Retrieval-term
node	Data/Mining/Information/Retrieval-term
labels	Data/Mining/Information/Retrieval-term
considering	O
substructures	O
at	O
different	O
levels	O
of	O
hierarchy	O
?	O
Recent	O
MMORPGs	O
generate	O
complex	O
interactions	O
between	O
entities	O
inducing	O
a	O
heterogeneous	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
where	O
each	O
entity	O
has	O
hierarchical	AI/ML/DL-term
labels	AI/ML/DL-term
.	O

What	O
are	O
the	O
key	O
structures	O
existing	O
in	O
a	O
large	O
real	O
-	O
world	O
MMORPG	O
(	O
Massively	O
Multiplayer	O
Online	O
Role	O
-	O
Playing	O
Game	O
)	O
graph	O
How	O
can	O
we	O
compactly	O
summarize	O
an	O
MMORPG	O
graph	O
with	O
hierarchical	Data/Mining/Information/Retrieval-term
node	Data/Mining/Information/Retrieval-term
labels	Data/Mining/Information/Retrieval-term
considering	O
substructures	O
at	O
different	O
levels	O
of	O
hierarchy	O
?	O
Recent	O
MMORPGs	O
generate	O
complex	O
interactions	O
between	O
entities	O
inducing	O
a	O
heterogeneous	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
where	O
each	O
entity	O
has	O
hierarchical	AI/ML/DL-term
labels	AI/ML/DL-term
.	O

Succinctly	O
summarizing	O
a	O
heterogeneous	O
MMORPG	O
graph	O
is	O
crucial	O
to	O
better	O
understand	O
its	O
structure	O
;	O
however	O
it	O
is	O
a	O
challenging	O
task	O
since	O
it	O
needs	O
to	O
handle	O
complex	O
interactions	O
and	O
hierarchical	AI/ML/DL-term
labels	AI/ML/DL-term
efficiently	O
.	O

Although	O
there	O
exist	O
few	O
methods	O
to	O
summarize	O
a	O
large	O
-	O
scale	O
graph	O
,	O
they	O
do	O
not	O
deal	O
with	O
heterogeneous	Data/Mining/Information/Retrieval-term
graphs	Data/Mining/Information/Retrieval-term
with	O
hierarchical	Data/Mining/Information/Retrieval-term
node	Data/Mining/Information/Retrieval-term
labels	Data/Mining/Information/Retrieval-term
We	O
propose	O
GSHL	O
heterogeneous	Data/Mining/Information/Retrieval-term
graph	Data/Mining/Information/Retrieval-term
summarizes	O
a	O
heterogeneous	O
graph	O
with	O
hierarchical	O
labels	O
.	O

We	O
formulate	O
the	O
encoding	O
cost	O
of	O
hierarchical	AI/ML/DL-term
labels	AI/ML/DL-term
using	O
MDL	AI/ML/DL-term
(	AI/ML/DL-term
Minimum	AI/ML/DL-term
Description	AI/ML/DL-term
Length	AI/ML/DL-term
)	AI/ML/DL-term
.	O

GSHL	O
exploits	O
the	O
formulation	O
to	O
identify	O
and	O
segment	Data/Mining/Information/Retrieval-term
subgraphs	Data/Mining/Information/Retrieval-term
and	O
discovers	O
compact	O
and	O
consistent	O
structures	O
in	O
the	O
graph	O
.	O

The	O
understanding	O
of	O
people	O
’	O
s	O
inter	O
-	O
regional	O
mobility	O
behaviors	O
,	O
such	O
as	O
predicting	O
the	O
next	O
activity	Data/Mining/Information/Retrieval-term
region	Data/Mining/Information/Retrieval-term
(	Data/Mining/Information/Retrieval-term
AR	Data/Mining/Information/Retrieval-term
)	Data/Mining/Information/Retrieval-term
or	O
uncovering	O
the	O
intentions	O
for	O
regional	O
mobility	O
,	O
is	O
of	O
great	O
value	O
to	O
public	O
administration	O
or	O
business	O
interests	O
.	O

To	O
this	O
end	O
,	O
in	O
this	O
article	O
,	O
we	O
propose	O
a	O
dynamic	O
region	O
-	O
relation	O
-	O
aware	O
graph	O
neural	O
network	O
(	O
DRRGNN	O
)	O
for	O
exploring	O
individual	O
mobility	O
behaviors	O
over	O
ARs	Data/Mining/Information/Retrieval-term
.	O

Specifically	O
,	O
we	O
aim	O
at	O
developing	O
models	O
that	O
can	O
answer	O
three	O
questions	O
:	O
(	O
1	O
)	O
Which	O
regions	O
are	O
the	O
ARs	Data/Mining/Information/Retrieval-term
AR	Data/Mining/Information/Retrieval-term
ARs	Data/Mining/Information/Retrieval-term
ich	O
region	O
will	O
be	O
the	O
next	O
AR	O
,	O
and	O
(	O
3	O
)	O
Why	O
do	O
people	O
make	O
this	O
regional	O
mobility	O
?	O
To	O
achieve	O
these	O
tasks	O
,	O
we	O
first	O
propose	O
a	O
method	O
to	O
find	O
out	O
people	O
’	O
s	O
ARs	O
.	O

Then	O
,	O
the	O
designed	O
model	O
integrates	O
a	O
dynamic	O
graph	O
convolution	O
network	O
(	O
DGCN	O
)	O
and	O
a	O
recurrent	O
neural	O
network	O
(	O
RNN	O
)	O
to	O
depict	O
the	O
evolution	O
of	O
relations	O
between	O
ARs	Data/Mining/Information/Retrieval-term
and	O
mine	O
the	O
regional	O
mobility	O
patterns	O
.	O

In	O
the	O
learning	O
process	O
,	O
the	O
model	O
further	O
considers	O
peoples	O
’	O
profiles	O
and	O
visited	O
point	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
of	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
interest	Data/Mining/Information/Retrieval-term
(	Data/Mining/Information/Retrieval-term
POIs	Data/Mining/Information/Retrieval-term
)	Data/Mining/Information/Retrieval-term
.	O

Regularization	O
that	O
incorporates	O
the	O
linear	O
combination	O
of	O
empirical	AI/ML/DL-term
loss	AI/ML/DL-term
and	O
explicit	O
regularization	AI/ML/DL-term
terms	AI/ML/DL-term
as	O
the	O
loss	O
function	O
has	O
been	O
frequently	O
used	O
for	O
many	O
machine	O
learning	O
tasks	O
.	O

To	O
deal	O
with	O
such	O
issues	O
in	O
this	O
work	O
,	O
we	O
propose	O
a	O
novel	O
strategy	O
,	O
namely	O
Gradients	AI/ML/DL-technique
Orthogonal	AI/ML/DL-technique
Decomposition	AI/ML/DL-technique
(	AI/ML/DL-technique
GrOD	AI/ML/DL-technique
)	AI/ML/DL-technique
that	O
improves	O
the	O
training	O
procedure	O
of	O
regularized	O
deep	O
learning	O
.	O

Instead	O
of	O
linearly	O
combining	O
gradients	O
of	O
the	O
two	O
terms	O
,	O
GrOD	AI/ML/DL-technique
re	O
-	O
estimates	O
a	O
new	O
direction	O
for	O
iteration	O
that	O
does	O
not	O
hurt	O
the	O
empirical	O
loss	O
minimization	O
while	O
preserving	O
the	O
regularization	O
affects	O
,	O
through	O
orthogonal	O
decomposition	O
.	O

We	O
have	O
performed	O
extensive	O
experiments	O
to	O
use	O
GrOD	AI/ML/DL-technique
improving	O
the	O
commonly	O
used	O
algorithms	Miscellaneous-term
of	O
transfer	O
learning	O
nbsp	O
;[	O
2	O
],	O
knowledge	O
distillation	O
nbsp	O
;[	O
3	O
],	O
and	O
adversarial	O
learning	O
nbsp	O
;[	O
4	O
].	O

We	O
have	O
performed	O
extensive	O
experiments	O
to	O
use	O
GrOD	AI/ML/DL-technique
improving	O
the	O
commonly	O
used	O
algorithms	Miscellaneous-term
of	O
transfer	O
learning	O
nbsp	O
;[	O
2	O
],	O
knowledge	O
distillation	O
nbsp	O
;[	O
3	O
],	O
and	O
adversarial	O
learning	O
nbsp	O
;[	O
4	O
].	O

The	O
experiment	O
results	O
based	O
on	O
large	O
datasets	O
,	O
including	O
Caltech	O
256	O
nbsp	O
;[	O
5	O
],	O
MIT	O
indoor	O
67	O
nbsp	O
;[	O
6	O
],	O
CIFAR	O
-	O
10	O
nbsp	O
;[	O
7	O
],	O
and	O
ImageNet	O
nbsp	O
;[	O
8	O
],	O
show	O
significant	O
improvement	O
made	O
by	O
GrOD	AI/ML/DL-technique
for	O
all	O
three	O
algorithms	Miscellaneous-term
in	O
all	O
cases	O
.	O

The	O
experiment	O
results	O
based	O
on	O
large	O
datasets	O
,	O
including	O
Caltech	O
256	O
nbsp	O
;[	O
5	O
],	O
MIT	O
indoor	O
67	O
nbsp	O
;[	O
6	O
],	O
CIFAR	O
-	O
10	O
nbsp	O
;[	O
7	O
],	O
and	O
ImageNet	O
nbsp	O
;[	O
8	O
],	O
show	O
significant	O
improvement	O
made	O
by	O
GrOD	AI/ML/DL-technique
for	O
all	O
three	O
algorithms	Miscellaneous-term
in	O
all	O
cases	O
.	O

Synthetic	Miscellaneous-term
data	Miscellaneous-term
have	O
been	O
used	O
to	O
generate	O
representative	O
location	O
sequences	O
yet	O
to	O
maintain	O
the	O
users	O
’	O
privacy	O
.	O

Nonetheless	O
,	O
the	O
privacy	AI/ML/DL-term
-	AI/ML/DL-term
accuracy	AI/ML/DL-term
tradeoff	AI/ML/DL-term
between	O
these	O
two	O
measures	O
has	O
not	O
been	O
addressed	O
systematically	O
.	O

In	O
this	O
article	O
,	O
we	O
analyze	O
the	O
use	O
of	O
different	O
synthetic	O
data	O
generation	O
models	O
for	O
long	Data/Mining/Information/Retrieval-term
location	Data/Mining/Information/Retrieval-term
sequences	Data/Mining/Information/Retrieval-term
including	O
extended	O
short	O
-	O
term	O
memory	O
networks	O
(	O
LSTMs	O
)	O
Markov	O
Chains	O
(	O
MC	O
)	O
and	O
variable	O
-	O
order	O
Markov	O
models	O
(	O
VMMs	O
)	O
.	O

We	O
employ	O
different	O
performance	O
measures	O
,	O
such	O
as	O
data	O
similarity	O
and	O
privacy	O
,	O
and	O
discuss	O
the	O
inherent	O
tradeoff	Miscellaneous-term
.	O

We	O
present	O
a	O
novel	O
and	O
practical	O
deep	O
fully	O
convolutional	O
neural	O
network	O
architecture	O
for	O
semantic	O
pixel	O
-	O
wise	O
segmentation	O
termed	O
SegNet	Computer/Vision-technique
.	O

The	O
architecture	O
of	O
the	O
encoder	O
network	O
is	O
topologically	O
identical	O
to	O
the	O
13	O
convolutional	Computer/vision-term
layers	Computer/vision-term
in	O
the	O
VGG16	O
network	O
[	O
1	O
]	O
.	O

The	O
role	O
of	O
the	O
decoder	O
network	O
is	O
to	O
map	O
the	O
low	Computer/vision-term
resolution	Computer/vision-term
encoder	Computer/vision-term
feature	Computer/vision-term
maps	Computer/vision-term
to	O
full	Computer/vision-term
input	Computer/vision-term
resolution	Computer/vision-term
feature	Computer/vision-term
maps	Computer/vision-term
for	O
pixel	O
-	O
wise	O
classification	O
.	O

The	O
novelty	O
of	O
SegNet	Computer/Vision-technique
lies	O
is	O
in	O
the	O
manner	O
in	O
which	O
the	O
decoder	O
upsamples	O
its	O
lower	Computer/vision-term
resolution	Computer/vision-term
input	Computer/vision-term
feature	Computer/vision-term
map	Computer/vision-term
(	Computer/vision-term
s	Computer/vision-term
)	Computer/vision-term
.	O

The	O
novelty	O
of	O
SegNet	Computer/Vision-technique
lies	O
is	O
in	O
the	O
manner	O
in	O
which	O
the	O
decoder	O
upsamples	O
its	O
lower	Computer/vision-term
resolution	Computer/vision-term
input	Computer/vision-term
feature	Computer/vision-term
map	Computer/vision-term
(	Computer/vision-term
s	Computer/vision-term
)	Computer/vision-term
.	O

Specifically	O
,	O
the	O
decoder	O
uses	O
pooling	AI/ML/DL-term
indices	AI/ML/DL-term
computed	O
in	O
the	O
max	O
-	O
pooling	O
step	O
of	O
the	O
corresponding	O
encoder	O
to	O
perform	O
non	O
-	O
linear	O
upsampling	O
.	O

The	O
upsampled	Computer/vision-term
maps	Computer/vision-term
are	O
sparse	O
and	O
are	O
then	O
convolved	O
with	O
trainable	Computer/vision-term
filters	Computer/vision-term
to	O
produce	O
dense	Computer/vision-term
feature	Computer/vision-term
maps	Computer/vision-term
.	O

SegNet	Computer/Vision-technique
was	O
primarily	O
motivated	O
by	O
scene	O
understanding	O
applications	O
.	O

Hence	O
,	O
it	O
is	O
designed	O
to	O
be	O
efficient	O
both	O
in	O
terms	O
of	O
memory	O
and	O
computational	Miscellaneous-term
time	Miscellaneous-term
during	O
inference	AI/ML/DL-term
.	O

Hence	O
,	O
it	O
is	O
designed	O
to	O
be	O
efficient	O
both	O
in	O
terms	O
of	O
memory	O
and	O
computational	Miscellaneous-term
time	Miscellaneous-term
during	O
inference	AI/ML/DL-term
.	O

It	O
is	O
also	O
significantly	O
smaller	O
in	O
the	O
number	O
of	O
trainable	AI/ML/DL-term
parameters	AI/ML/DL-term
than	O
other	O
competing	O
architectures	O
and	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
using	O
stochastic	O
gradient	O
descent	O
.	O

We	O
also	O
performed	O
a	O
controlled	O
benchmark	O
of	O
SegNet	Computer/Vision-technique
and	O
other	O
architectures	O
on	O
both	O
road	O
scenes	O
and	O
SUN	O
RGB	O
-	O
D	O
indoor	O
scene	O
segmentation	O
tasks	O
.	O

These	O
quantitative	O
assessments	O
show	O
that	O
SegNet	Computer/Vision-technique
provides	O
good	O
performance	O
with	O
competitive	O
inference	O
time	O
and	O
most	O
efficient	O
inference	O
memory	O
-	O
wise	O
as	O
compared	O
to	O
other	O
architectures	O
.	O

We	O
also	O
provide	O
a	O
Caffe	O
implementation	O
of	O
SegNet	Computer/Vision-technique
and	O
a	O
web	O
demo	O
at	O
http	O
://	O
mi	O
.	O
eng	O
.	O
cam	O
.	O
ac	O
.	O
uk	O
/	O
projects	O
/	O
segnet	O
/.	O
.	O

In	O
a	O
variety	O
of	O
visual	O
benchmarks	O
,	O
transformer	O
-	O
based	O
models	O
perform	O
similar	O
to	O
or	O
better	O
than	O
other	O
types	O
of	O
networks	O
such	O
as	O
convolutional	AI/ML/DL-term
and	O
recurrent	O
neural	O
networks	O
.	O

Given	O
its	O
high	O
performance	O
and	O
less	O
need	O
for	O
vision	Computer/vision-term
-	Computer/vision-term
specific	Computer/vision-term
inductive	Computer/vision-term
bias	Computer/vision-term
transformer	O
is	O
receiving	O
more	O
and	O
more	O
attention	O
from	O
the	O
computer	O
vision	O
community	O
.	O

The	O
main	O
categories	O
we	O
explore	O
include	O
the	O
backbone	AI/ML/DL-term
network	AI/ML/DL-term
high	O
/	O
mid	O
-	O
level	O
vision	O
,	O
low	O
-	O
level	O
vision	O
,	O
and	O
video	O
processing	O
.	O

Image	O
segmentation	O
is	O
a	O
key	O
task	O
in	O
computer	O
vision	O
and	O
image	O
processing	O
with	O
important	O
applications	O
such	O
as	O
scene	O
understanding	O
medical	O
image	O
analysis	O
robotic	O
perception	O
video	O
surveillance	O
augmented	O
reality	O
and	O
image	O
compression	O
segmentation	O
,	O
and	O
numerous	O
segmentation	O
algorithms	Miscellaneous-term
are	O
found	O
in	O
the	O
literature	O
.	O

We	O
provide	O
a	O
comprehensive	O
review	O
of	O
this	O
recent	O
literature	O
,	O
covering	O
the	O
spectrum	O
of	O
pioneering	O
efforts	O
in	O
semantic	Computer/vision-term
and	O
instance	Computer/vision-term
segmentation	Computer/vision-term
including	O
convolutional	O
pixel	O
-	O
labeling	O
networks	O
encoder	O
-	O
decoder	O
architectures	O
multiscale	Computer/vision-term
and	O
pyramid	O
-	O
based	O
approaches	O
recurrent	O
networks	O
visual	O
attention	O
models	O
and	O
generative	O
models	O
in	O
adversarial	AI/ML/DL-term
settings	AI/ML/DL-term
.	O

We	O
provide	O
a	O
comprehensive	O
review	O
of	O
this	O
recent	O
literature	O
,	O
covering	O
the	O
spectrum	O
of	O
pioneering	O
efforts	O
in	O
semantic	Computer/vision-term
and	O
instance	Computer/vision-term
segmentation	Computer/vision-term
including	O
convolutional	O
pixel	O
-	O
labeling	O
networks	O
encoder	O
-	O
decoder	O
architectures	O
multiscale	Computer/vision-term
and	O
pyramid	O
-	O
based	O
approaches	O
recurrent	O
networks	O
visual	O
attention	O
models	O
and	O
generative	O
models	O
in	O
adversarial	AI/ML/DL-term
settings	AI/ML/DL-term
.	O

Contrary	O
to	O
conventional	O
approaches	O
to	O
AI	O
where	O
tasks	O
are	O
solved	O
from	O
scratch	O
using	O
a	O
fixed	O
learning	O
algorithm	O
meta	O
-	O
learning	O
learning	O
algorithm	O
learning	O
algorithm	O
itself	O
,	O
given	O
the	O
experience	O
of	O
multiple	AI/ML/DL-term
learning	AI/ML/DL-term
episodes	AI/ML/DL-term
.	O

This	O
paradigm	O
provides	O
an	O
opportunity	O
to	O
tackle	O
many	O
conventional	O
challenges	O
of	O
deep	O
learning	O
including	O
data	O
and	O
computation	O
bottlenecks	O
,	O
as	O
well	O
as	O
generalization	AI/ML/DL-term
.	O

We	O
present	O
SR3	Computer/Vision-technique
an	O
approach	O
to	O
image	O
Super	O
-	O
Resolution	O
via	O
Repeated	O
Refinement	O
.	O

SR3	Computer/Vision-technique
adapts	O
denoising	O
diffusion	O
probabilistic	O
models	O
(	O
Ho	O
et	O
al	O
.	O

Output	O
images	O
are	O
initialized	O
with	O
pure	O
Gaussian	O
noise	O
and	O
iteratively	O
refined	O
using	O
a	O
U	AI/ML/DL-term
-	AI/ML/DL-term
Net	AI/ML/DL-term
architecture	AI/ML/DL-term
that	O
is	O
trained	O
on	O
denoising	O
at	O
various	O
noise	O
levels	O
,	O
conditioned	O
on	O
a	O
low	Computer/vision-term
-	Computer/vision-term
resolution	Computer/vision-term
input	Computer/vision-term
image	Computer/vision-term
.	O

Output	O
images	O
are	O
initialized	O
with	O
pure	O
Gaussian	O
noise	O
and	O
iteratively	O
refined	O
using	O
a	O
U	AI/ML/DL-term
-	AI/ML/DL-term
Net	AI/ML/DL-term
architecture	AI/ML/DL-term
that	O
is	O
trained	O
on	O
denoising	O
at	O
various	O
noise	O
levels	O
,	O
conditioned	O
on	O
a	O
low	Computer/vision-term
-	Computer/vision-term
resolution	Computer/vision-term
input	Computer/vision-term
image	Computer/vision-term
.	O

SR3	Computer/Vision-technique
exhibits	O
strong	O
performance	O
on	O
super	O
-	O
resolution	O
tasks	O
at	O
different	O
magnification	O
factors	O
,	O
on	O
faces	O
and	O
natural	O
images	O
.	O

We	O
conduct	O
human	O
evaluation	O
on	O
a	O
standard	O
8	O
×	O
face	O
super	O
-	O
resolution	O
task	O
on	O
CelebA	O
-	O
HQ	O
for	O
which	O
SR3	Computer/Vision-technique
achieves	O
a	O
fool	O
rate	O
close	O
to	O
50	O
%,	O
suggesting	O
photo	O
-	O
realistic	O
outputs	O
,	O
while	O
GAN	O
baselines	O
do	O
not	O
exceed	O
a	O
fool	O
rate	O
of	O
34	O
%	O
.	O

We	O
evaluate	O
SR3	Computer/Vision-technique
on	O
a	O
4	O
×	O
super	O
-	O
resolution	O
task	O
on	O
ImageNet	O
SR3	Computer/Vision-technique
re	O
SR3	O
outperforms	O
baselines	O
in	O
human	O
evaluation	O
and	O
classification	O
accuracy	O
of	O
a	O
ResNet	O
-	O
50	O
classifier	O
trained	O
on	O
high	O
-	O
resolution	O
images	O
.	O

We	O
further	O
show	O
the	O
effectiveness	O
of	O
SR3	Computer/Vision-technique
in	O
cascaded	O
image	O
generation	O
where	O
a	O
generative	O
model	O
is	O
chained	O
with	O
super	O
-	O
resolution	O
models	O
to	O
synthesize	O
high	O
-	O
resolution	O
images	O
with	O
competitive	O
FID	O
scores	O
on	O
the	O
class	AI/ML/DL-term
-	AI/ML/DL-term
conditional	AI/ML/DL-term
256	O
×	O
256	O
ImageNet	O
generation	O
challenge	O
.	O

We	O
further	O
show	O
the	O
effectiveness	O
of	O
SR3	Computer/Vision-technique
in	O
cascaded	O
image	O
generation	O
where	O
a	O
generative	O
model	O
is	O
chained	O
with	O
super	O
-	O
resolution	O
models	O
to	O
synthesize	O
high	O
-	O
resolution	O
images	O
with	O
competitive	O
FID	O
scores	O
on	O
the	O
class	AI/ML/DL-term
-	AI/ML/DL-term
conditional	AI/ML/DL-term
256	O
×	O
256	O
ImageNet	O
generation	O
challenge	O
.	O

The	O
protein	AI/ML/DL-technique
LMs	AI/ML/DL-technique
(	AI/ML/DL-technique
pLMs	AI/ML/DL-technique
)	AI/ML/DL-technique
were	O
trained	O
on	O
the	O
Summit	O
supercomputer	O
using	O
5616	O
GPUs	O
and	O
TPU	O
Pod	O
up	O
-	O
to	O
1024	O
cores	O
.	O

Dimensionality	O
reduction	O
revealed	O
that	O
the	O
raw	AI/ML/DL-term
pLM	AI/ML/DL-term
-	AI/ML/DL-term
embeddings	AI/ML/DL-term
from	O
unlabeled	O
data	O
captured	O
some	O
biophysical	O
features	O
of	O
protein	O
sequences	O
.	O

For	O
secondary	O
structure	O
,	O
the	O
most	O
informative	O
embeddings	O
(	O
ProtT5	AI/ML/DL-term
for	O
the	O
first	O
time	O
outperformed	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
without	O
multiple	AI/ML/DL-term
sequence	AI/ML/DL-term
alignments	AI/ML/DL-term
(	AI/ML/DL-term
MSAs	AI/ML/DL-term
)	AI/ML/DL-term
or	O
evolutionary	O
information	O
thereby	O
bypassing	O
expensive	O
database	O
searches	O
.	O

For	O
secondary	O
structure	O
,	O
the	O
most	O
informative	O
embeddings	O
(	O
ProtT5	AI/ML/DL-term
for	O
the	O
first	O
time	O
outperformed	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
without	O
multiple	AI/ML/DL-term
sequence	AI/ML/DL-term
alignments	AI/ML/DL-term
(	AI/ML/DL-term
MSAs	AI/ML/DL-term
)	AI/ML/DL-term
or	O
evolutionary	O
information	O
thereby	O
bypassing	O
expensive	O
database	O
searches	O
.	O

Taken	O
together	O
,	O
the	O
results	O
implied	O
that	O
pLMs	AI/ML/DL-technique
learned	O
some	O
of	O
the	O
grammar	O
of	O
the	O
language	O
of	O
life	O
.	O

State	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
object	O
detection	O
networks	O
depend	O
on	O
region	O
proposal	O
algorithms	O
to	O
hypothesize	O
object	Computer/vision-term
locations	Computer/vision-term
.	O

State	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
object	O
detection	O
networks	O
depend	O
on	O
region	O
proposal	O
algorithms	O
to	O
hypothesize	O
object	Computer/vision-term
locations	Computer/vision-term
.	O

In	O
this	O
work	O
,	O
we	O
introduce	O
a	O
Region	O
Proposal	O
Network	O
(	O
RPN	O
)	O
that	O
shares	O
full	Computer/vision-term
-	Computer/vision-term
image	Computer/vision-term
convolutional	Computer/vision-term
features	Computer/vision-term
with	O
the	O
detection	O
network	O
thus	O
enabling	O
nearly	O
cost	O
-	O
free	O
region	O
proposals	O
.	O

The	O
RPN	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
to	O
generate	O
high	Computer/vision-term
-	Computer/vision-term
quality	Computer/vision-term
region	Computer/vision-term
proposals	Computer/vision-term
which	O
are	O
used	O
by	O
Fast	O
R	O
-	O
CNN	O
for	O
detection	O
.	O

We	O
further	O
merge	O
RPN	O
and	O
Fast	O
R	O
-	O
CNN	O
into	O
a	O
single	O
network	O
by	O
sharing	O
their	O
convolutional	Computer/vision-term
features	Computer/vision-term
using	O
the	O
recently	O
popular	O
terminology	O
of	O
neural	O
networks	O
with	O
'	O
attention	O
RPN	O
hanisms	O
,	O
the	O
RPN	O
component	O
tells	O
the	O
unified	O
network	O
where	O
to	O
look	O
.	O

For	O
the	O
very	O
deep	O
VGG	O
-	O
16	O
model	O
[	O
3	O
],	O
our	O
detection	O
system	O
has	O
a	O
frame	O
rate	O
of	O
5	O
fps	O
(	O
including	O
all	O
steps	O
)	O
on	O
a	O
GPU	O
,	O
while	O
achieving	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
object	O
detection	O
accuracy	O
on	O
PASCAL	O
VOC	O
2007	O
,	O
2012	O
and	O
MS	O
COCO	O
datasets	O
with	O
only	O
300	O
proposals	O
per	O
image	O
.	O

It	O
covers	O
several	O
novel	O
and	O
insightful	O
components	O
:	O
1	O
)	O
besides	O
supervision	AI/ML/DL-term
with	O
binary	AI/ML/DL-term
label	AI/ML/DL-term
(	O
e	O
.	O
g	O
.,	O
‘	O
0	O
’	O
for	O
bonafide	O
versus	O
‘	O
1	O
’	O
for	O
PAs	O
,	O
we	O
also	O
investigate	O
recent	O
methods	O
with	O
pixel	Computer/vision-term
-	Computer/vision-term
wise	Computer/vision-term
supervision	Computer/vision-term
(	O
e	O
.	O
g	O
.,	O
pseudo	Computer/vision-term
depth	Computer/vision-term
map	Computer/vision-term
;	O
2	O
)	O
in	O
addition	O
to	O
traditional	O
intra	O
-	O
dataset	O
evaluation	O
,	O
we	O
collect	O
and	O
analyze	O
the	O
latest	O
methods	O
specially	O
designed	O
for	O
domain	O
generalization	O
and	O
open	O
-	O
set	O
FAS	O
;	O
and	O
3	O
)	O
besides	O
commercial	O
RGB	O
camera	O
,	O
we	O
summarize	O
the	O
deep	O
learning	O
applications	O
under	O
multi	Computer/vision-term
-	Computer/vision-term
modal	Computer/vision-term
(	O
e	O
.	O
g	O
.,	O
depth	O
and	O
infrared	O
)	O
or	O
specialized	O
(	O
e	O
.	O
g	O
.,	O
light	O
field	O
and	O
flash	O
)	O
sensors	O
.	O

It	O
covers	O
several	O
novel	O
and	O
insightful	O
components	O
:	O
1	O
)	O
besides	O
supervision	AI/ML/DL-term
with	O
binary	AI/ML/DL-term
label	AI/ML/DL-term
(	O
e	O
.	O
g	O
.,	O
‘	O
0	O
’	O
for	O
bonafide	O
versus	O
‘	O
1	O
’	O
for	O
PAs	O
,	O
we	O
also	O
investigate	O
recent	O
methods	O
with	O
pixel	Computer/vision-term
-	Computer/vision-term
wise	Computer/vision-term
supervision	Computer/vision-term
(	O
e	O
.	O
g	O
.,	O
pseudo	Computer/vision-term
depth	Computer/vision-term
map	Computer/vision-term
;	O
2	O
)	O
in	O
addition	O
to	O
traditional	O
intra	O
-	O
dataset	O
evaluation	O
,	O
we	O
collect	O
and	O
analyze	O
the	O
latest	O
methods	O
specially	O
designed	O
for	O
domain	O
generalization	O
and	O
open	O
-	O
set	O
FAS	O
;	O
and	O
3	O
)	O
besides	O
commercial	O
RGB	O
camera	O
,	O
we	O
summarize	O
the	O
deep	O
learning	O
applications	O
under	O
multi	Computer/vision-term
-	Computer/vision-term
modal	Computer/vision-term
(	O
e	O
.	O
g	O
.,	O
depth	O
and	O
infrared	O
)	O
or	O
specialized	O
(	O
e	O
.	O
g	O
.,	O
light	O
field	O
and	O
flash	O
)	O
sensors	O
.	O

A	O
diffusion	O
model	O
is	O
a	O
deep	O
generative	O
model	O
that	O
is	O
based	O
on	O
two	O
stages	O
,	O
a	O
forward	Computer/vision-term
diffusion	Computer/vision-term
stage	Computer/vision-term
and	O
a	O
reverse	Computer/vision-term
diffusion	Computer/vision-term
stage	Computer/vision-term
.	O

In	O
the	O
forward	O
diffusion	O
stage	O
,	O
the	O
input	O
data	O
is	O
gradually	O
perturbed	O
over	O
several	O
steps	O
by	O
adding	O
Gaussian	AI/ML/DL-term
noise	AI/ML/DL-term
.	O

Following	O
the	O
rapid	O
evolution	O
of	O
visual	O
object	O
tracking	O
in	O
the	O
last	O
decade	O
,	O
this	O
survey	O
presents	O
a	O
systematic	O
and	O
thorough	O
review	O
of	O
more	O
than	O
90	Computer/vision-term
DCFs	Computer/vision-term
and	O
Siamese	O
trackers	O
based	O
on	O
results	O
in	O
nine	O
tracking	O
benchmarks	O
.	O

Furthermore	O
,	O
we	O
thoroughly	O
analyze	O
the	O
performance	O
of	O
DCF	O
and	O
Siamese	O
trackers	O
on	O
nine	O
benchmarks	O
,	O
covering	O
different	O
experimental	O
aspects	O
of	O
visual	O
tracking	O
datasets	Miscellaneous-term
evaluation	O
metrics	O
,	O
performance	O
,	O
and	O
speed	O
comparisons	O
.	O

Despite	O
its	O
prevalence	O
,	O
the	O
algorithm	Miscellaneous-term
has	O
a	O
major	O
drawback	O
that	O
remains	O
unsolved	O
:	O
It	O
unnaturally	O
deforms	O
the	O
different	O
parts	O
of	O
a	O
shape	O
,	O
e	O
.	O
g	O
.,	O
human	O
legs	O
,	O
when	O
they	O
are	O
neighboring	O
each	O
other	O
.	O

The	O
inappropriate	O
deformations	O
originate	O
from	O
a	O
proximity	Computer/vision-term
-	Computer/vision-term
based	Computer/vision-term
deformation	Computer/vision-term
constraint	Computer/vision-term
called	O
motion	O
coherence	O
.	O

We	O
also	O
propose	O
the	O
accelerated	AI/ML/DL-term
variant	AI/ML/DL-term
of	O
the	O
registration	O
method	O
.	O

In	O
numerical	O
studies	O
,	O
we	O
demonstrate	O
that	O
the	O
algorithms	Miscellaneous-term
can	O
circumvent	O
the	O
drawback	O
of	O
coherent	O
point	O
drift	O
.	O

However	O
,	O
this	O
combined	O
OFIP	Computer/vision-term
pipeline	O
exacerbates	O
the	O
ill	O
-	O
posedness	O
inherent	O
to	O
each	O
technique	O
,	O
propagating	O
errors	O
and	O
preventing	O
uncertainty	O
quantification	O
.	O

As	O
we	O
illustrate	O
with	O
traction	O
force	O
microscopy	O
,	O
our	O
approach	O
offers	O
several	O
advantages	O
:	O
more	O
accurate	O
reconstructions	O
;	O
unprecedented	O
flexibility	O
in	O
experiment	O
design	O
(	O
e	O
.	O
g	O
.,	O
arbitrary	O
boundary	O
conditions	O
);	O
and	O
the	O
exclusivity	O
of	O
measurement	O
error	O
,	O
central	O
to	O
empirical	O
science	O
,	O
yet	O
still	O
unavailable	O
under	O
the	O
OFIP	Computer/vision-term
strategy	O
.	O

Event	O
cameras	O
offer	O
attractive	O
properties	O
compared	O
to	O
traditional	O
cameras	O
:	O
high	Computer/vision-term
temporal	Computer/vision-term
resolution	Computer/vision-term
(	O
in	O
the	O
order	O
of	O
$\	O
mu	O
$	O
μs	O
),	O
very	O
high	O
dynamic	O
range	O
(	O
140	O
dB	O
versus	O
60	O
dB	O
),	O
low	O
power	O
consumption	O
,	O
and	O
high	O
pixel	Computer/vision-term
bandwidth	Computer/vision-term
(	O
on	O
the	O
order	O
of	O
kHz	O
)	O
resulting	O
in	O
reduced	O
motion	O
blur	O
.	O

Hence	O
,	O
event	O
cameras	O
have	O
a	O
large	O
potential	O
for	O
robotics	O
and	O
computer	O
vision	O
in	O
challenging	O
scenarios	O
for	O
traditional	O
cameras	O
,	O
such	O
as	O
low	Computer/vision-term
-	Computer/vision-term
latency	Computer/vision-term
high	O
speed	O
,	O
and	O
high	O
dynamic	O
range	O
.	O

We	O
show	O
that	O
the	O
application	O
of	O
these	O
strategies	O
leads	O
to	O
remarkable	O
improvements	O
;	O
indeed	O
,	O
the	O
resulting	O
method	O
–	O
termed	O
eXtended	Computer/Vision-technique
-	Computer/Vision-technique
DER	Computer/Vision-technique
(	Computer/Vision-technique
X	Computer/Vision-technique
-	Computer/Vision-technique
DER	Computer/Vision-technique
)	Computer/Vision-technique
–	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
on	O
both	O
standard	O
benchmarks	O
(	O
such	O
as	O
CIFAR	O
-	O
100	O
and	O
miniImageNet	O
and	O
a	O
novel	O
one	O
here	O
introduced	O
.	O

We	O
make	O
our	O
results	O
fully	O
reproducible	O
;	O
the	O
codebase	Miscellaneous-term
is	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
aimagelab	O
/	O
mammoth	O
.	O

This	O
paper	O
establishes	O
parameterized	AI/ML/DL-technique
Hamiltonian	AI/ML/DL-technique
learning	AI/ML/DL-technique
(	AI/ML/DL-technique
PHL	AI/ML/DL-technique
)	AI/ML/DL-technique
and	O
explores	O
its	O
application	O
and	O
implementation	O
on	O
quantum	Miscellaneous-term
computers	Miscellaneous-term
.	O

This	O
paper	O
establishes	O
parameterized	AI/ML/DL-technique
Hamiltonian	AI/ML/DL-technique
learning	AI/ML/DL-technique
(	AI/ML/DL-technique
PHL	AI/ML/DL-technique
)	AI/ML/DL-technique
and	O
explores	O
its	O
application	O
and	O
implementation	O
on	O
quantum	Miscellaneous-term
computers	Miscellaneous-term
.	O

Then	O
,	O
a	O
PHL	AI/ML/DL-technique
algorithm	O
is	O
developed	O
to	O
prepare	O
a	O
specific	O
Hamiltonian	O
system	O
by	O
iteratively	O
updating	O
the	O
gradient	O
of	O
the	O
loss	O
function	O
about	O
circuit	O
parameters	O
.	O

Finally	O
,	O
the	O
experiments	O
are	O
conducted	O
on	O
Origin	O
Pilot	O
and	O
it	O
demonstrates	O
that	O
the	O
PHL	AI/ML/DL-technique
algorithm	Miscellaneous-term
can	O
deal	O
with	O
the	O
image	O
segmentation	O
problem	O
and	O
provide	O
a	O
segmentation	O
solution	O
accurately	O
.	O

Finally	O
,	O
the	O
experiments	O
are	O
conducted	O
on	O
Origin	O
Pilot	O
and	O
it	O
demonstrates	O
that	O
the	O
PHL	AI/ML/DL-technique
algorithm	Miscellaneous-term
can	O
deal	O
with	O
the	O
image	O
segmentation	O
problem	O
and	O
provide	O
a	O
segmentation	O
solution	O
accurately	O
.	O

Compared	O
with	O
the	O
classical	O
Grabcut	O
algorithm	Miscellaneous-term
the	O
PHL	AI/ML/DL-technique
algorithm	O
eliminates	O
the	O
requirement	O
of	O
early	O
manual	O
intervention	O
.	O

Compared	O
with	O
the	O
classical	O
Grabcut	O
algorithm	Miscellaneous-term
the	O
PHL	AI/ML/DL-technique
algorithm	O
eliminates	O
the	O
requirement	O
of	O
early	O
manual	O
intervention	O
.	O

Finally	O
,	O
we	O
show	O
that	O
the	O
resulting	O
gradient	O
-	O
based	O
algorithms	O
are	O
more	O
stable	O
,	O
for	O
both	O
prediction	O
and	O
control	O
,	O
with	O
less	O
sensitivity	O
to	O
meta	AI/ML/DL-term
-	AI/ML/DL-term
parameters	AI/ML/DL-term
.	O

It	O
also	O
presents	O
comparative	O
results	O
on	O
several	O
publicly	O
available	O
datasets	Miscellaneous-term
together	O
with	O
insightful	O
observations	O
and	O
inspiring	O
future	O
research	O
directions	O
.	O

Second	O
,	O
we	O
propose	O
atrous	Computer/Vision-technique
spatial	Computer/Vision-technique
pyramid	Computer/Vision-technique
pooling	Computer/Vision-technique
(	Computer/Vision-technique
ASPP	Computer/Vision-technique
)	Computer/Vision-technique
to	O
robustly	O
segment	O
objects	O
at	O
multiple	O
scales	O
.	O

ASPP	Computer/Vision-technique
probes	O
an	O
incoming	O
convolutional	O
feature	O
layer	O
with	O
filters	O
at	O
multiple	O
sampling	O
rates	O
and	O
effective	O
fields	O
-	O
of	O
-	O
views	O
,	O
thus	O
capturing	O
objects	O
as	O
well	O
as	O
image	O
context	O
at	O
multiple	O
scales	O
.	O

Our	O
proposed	O
“	O
DeepLab	O
”	O
system	O
sets	O
the	O
new	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
at	O
the	O
PASCAL	O
VOC	O
-	O
2012	O
semantic	O
image	O
segmentation	O
task	O
,	O
reaching	O
79	O
.	O
7	O
percent	O
mIOU	O
in	O
the	O
test	O
set	O
,	O
and	O
advances	O
the	O
results	O
on	O
three	O
other	O
datasets	Miscellaneous-term
PASCAL	O
-	O
Context	O
PASCAL	O
-	O
Person	O
-	O
Part	O
and	O
Cityscapes	O
.	O

All	O
of	O
our	O
code	Miscellaneous-term
is	O
made	O
publicly	O
available	O
online	O
.	O

In	O
addition	O
,	O
we	O
discuss	O
the	O
available	O
benchmark	O
data	Miscellaneous-term
sets	Miscellaneous-term
and	O
applications	O
of	O
GZSL	O
along	O
with	O
a	O
discussion	O
on	O
the	O
research	O
gaps	O
and	O
directions	O
for	O
future	O
investigations	O
.	O

Our	O
experience	O
of	O
the	O
world	O
is	O
multimodal	AI/ML/DL-term
-	O
we	O
see	O
objects	O
,	O
hear	O
sounds	O
,	O
feel	O
texture	O
,	O
smell	O
odors	O
,	O
and	O
taste	O
flavors	O
.	O

Modality	O
refers	O
to	O
the	O
way	O
in	O
which	O
something	O
happens	O
or	O
is	O
experienced	O
and	O
a	O
research	O
problem	O
is	O
characterized	O
as	O
multimodal	AI/ML/DL-term
when	O
it	O
includes	O
multiple	O
such	O
modalities	O
.	O

In	O
order	O
for	O
Artificial	O
Intelligence	O
to	O
make	O
progress	O
in	O
understanding	O
the	O
world	O
around	O
us	O
,	O
it	O
needs	O
to	O
be	O
able	O
to	O
interpret	O
such	O
multimodal	AI/ML/DL-term
signals	AI/ML/DL-term
together	O
.	O

Instead	O
of	O
focusing	O
on	O
specific	O
multimodal	Computer/vision-term
applications	O
,	O
this	O
paper	O
surveys	O
the	O
recent	O
advances	O
in	O
multimodal	O
machine	O
learning	O
itself	O
and	O
presents	O
them	O
in	O
a	O
common	O
taxonomy	O
.	O

The	O
success	O
of	O
machine	O
learning	O
algorithms	Miscellaneous-term
generally	O
depends	O
on	O
data	O
representation	O
,	O
and	O
we	O
hypothesize	O
that	O
this	O
is	O
because	O
different	O
representations	O
can	O
entangle	O
and	O
hide	O
more	O
or	O
less	O
the	O
different	O
explanatory	O
factors	O
of	O
variation	O
behind	O
the	O
data	O
.	O

Although	O
specific	O
domain	O
knowledge	O
can	O
be	O
used	O
to	O
help	O
design	O
representations	O
,	O
learning	O
with	O
generic	O
priors	O
can	O
also	O
be	O
used	O
,	O
and	O
the	O
quest	O
for	O
AI	O
is	O
motivating	O
the	O
design	O
of	O
more	O
powerful	O
representation	O
-	O
learning	O
algorithms	Miscellaneous-term
implementing	O
such	O
priors	O
.	O

Generalization	AI/ML/DL-term
to	AI/ML/DL-term
out	AI/ML/DL-term
-	AI/ML/DL-term
of	AI/ML/DL-term
-	AI/ML/DL-term
distribution	AI/ML/DL-term
(	AI/ML/DL-term
OOD	AI/ML/DL-term
)	AI/ML/DL-term
data	AI/ML/DL-term
is	O
a	O
capability	O
natural	O
to	O
humans	O
yet	O
challenging	O
for	O
machines	O
to	O
reproduce	O
.	O

This	O
is	O
because	O
most	O
learning	O
algorithms	Miscellaneous-term
strongly	O
rely	O
on	O
the	O
i	O
.	O
i	O
.	O
d	O
.	O

Domain	O
generalization	O
(	O
DG	O
)	O
aims	O
to	O
achieve	O
OOD	AI/ML/DL-term
generalization	AI/ML/DL-term
by	O
using	O
only	O
source	O
data	O
for	O
model	O
learning	O
.	O

This	O
paper	O
presents	O
a	O
comprehensive	O
survey	O
of	O
Transformer	O
techniques	O
oriented	O
at	O
multimodal	Computer/vision-term
data	Computer/vision-term
.	O

We	O
propose	O
a	O
deep	O
learning	O
method	O
for	O
single	Computer/vision-term
image	Computer/vision-term
super	Computer/vision-term
-	Computer/vision-term
resolution	Computer/vision-term
(	Computer/vision-term
SR	Computer/vision-term
)	Computer/vision-term
.	O

Our	O
method	O
directly	O
learns	O
an	O
end	Miscellaneous-term
-	Miscellaneous-term
to	Miscellaneous-term
-	Miscellaneous-term
end	Miscellaneous-term
mapping	Miscellaneous-term
between	O
the	O
low	Computer/vision-term
/	Computer/vision-term
high	Computer/vision-term
-	Computer/vision-term
resolution	Computer/vision-term
images	Computer/vision-term
.	O

Our	O
method	O
directly	O
learns	O
an	O
end	Miscellaneous-term
-	Miscellaneous-term
to	Miscellaneous-term
-	Miscellaneous-term
end	Miscellaneous-term
mapping	Miscellaneous-term
between	O
the	O
low	Computer/vision-term
/	Computer/vision-term
high	Computer/vision-term
-	Computer/vision-term
resolution	Computer/vision-term
images	Computer/vision-term
.	O

The	O
mapping	O
is	O
represented	O
as	O
a	O
deep	O
convolutional	O
neural	O
network	O
(	O
CNN	O
)	O
that	O
takes	O
the	O
low	Computer/vision-term
-	Computer/vision-term
resolution	Computer/vision-term
image	Computer/vision-term
as	O
the	O
input	O
and	O
outputs	O
the	O
high	Computer/vision-term
-	Computer/vision-term
resolution	Computer/vision-term
one	O
.	O

Our	O
deep	O
CNN	O
has	O
a	O
lightweight	O
structure	O
,	O
yet	O
demonstrates	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
restoration	O
quality	O
,	O
and	O
achieves	O
fast	O
speed	O
for	O
practical	O
on	O
-	O
line	O
usage	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
simple	O
but	O
effective	O
image	Computer/vision-term
prior	Computer/vision-term
-	Computer/vision-term
dark	Computer/vision-term
channel	Computer/vision-term
prior	Computer/vision-term
to	O
remove	O
haze	O
from	O
a	O
single	O
input	O
image	O
.	O

The	O
dark	Computer/vision-term
channel	Computer/vision-term
prior	Computer/vision-term
is	O
a	O
kind	O
of	O
statistics	O
of	O
outdoor	O
haze	O
-	O
free	O
images	O
.	O

Human	O
actions	O
can	O
be	O
represented	O
using	O
various	O
data	AI/ML/DL-term
modalities	AI/ML/DL-term
such	O
as	O
RGB	Computer/vision-term
skeleton	Computer/vision-term
depth	Computer/vision-term
infrared	Computer/vision-term
point	Computer/vision-term
cloud	Computer/vision-term
event	O
stream	O
,	O
audio	O
,	O
acceleration	O
,	O
radar	O
,	O
and	O
WiFi	O
signal	O
,	O
which	O
encode	O
different	O
sources	O
of	O
useful	O
yet	O
distinct	O
information	O
and	O
have	O
various	O
advantages	O
depending	O
on	O
the	O
application	O
scenarios	O
.	O

Human	O
actions	O
can	O
be	O
represented	O
using	O
various	O
data	AI/ML/DL-term
modalities	AI/ML/DL-term
such	O
as	O
RGB	Computer/vision-term
skeleton	Computer/vision-term
depth	Computer/vision-term
infrared	Computer/vision-term
point	Computer/vision-term
cloud	Computer/vision-term
event	O
stream	O
,	O
audio	O
,	O
acceleration	O
,	O
radar	O
,	O
and	O
WiFi	O
signal	O
,	O
which	O
encode	O
different	O
sources	O
of	O
useful	O
yet	O
distinct	O
information	O
and	O
have	O
various	O
advantages	O
depending	O
on	O
the	O
application	O
scenarios	O
.	O

Specifically	O
,	O
we	O
review	O
the	O
current	O
mainstream	O
deep	O
learning	O
methods	O
for	O
single	O
data	O
modalities	O
and	O
multiple	Computer/vision-term
data	Computer/vision-term
modalities	Computer/vision-term
including	O
the	O
fusion	O
-	O
based	O
and	O
the	O
co	O
-	O
learning	O
-	O
based	O
frameworks	O
.	O

The	O
new	O
network	O
structure	O
,	O
called	O
SPP	Computer/Vision-technique
-	Computer/Vision-technique
net	Computer/Vision-technique
can	O
generate	O
a	O
fixed	O
-	O
length	O
representation	O
regardless	O
of	O
image	O
size	O
/	O
scale	O
.	O

With	O
these	O
advantages	O
,	O
SPP	Computer/Vision-technique
-	Computer/Vision-technique
net	Computer/Vision-technique
should	O
in	O
general	O
improve	O
all	O
CNN	O
based	O
image	O
classification	O
methods	O
.	O

On	O
the	O
ImageNet	O
2012	O
dataset	O
,	O
we	O
demonstrate	O
that	O
SPP	Computer/Vision-technique
-	Computer/Vision-technique
net	Computer/Vision-technique
boosts	O
the	O
accuracy	O
of	O
a	O
variety	O
of	O
CNN	O
architectures	O
despite	O
their	O
different	O
designs	O
.	O

On	O
the	O
Pascal	O
VOC	O
2007	O
and	O
Caltech101	O
datasets	O
,	O
SPP	Computer/Vision-technique
-	Computer/Vision-technique
net	Computer/Vision-technique
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
classification	O
results	O
using	O
a	O
single	O
full	O
-	O
image	O
representation	O
and	O
no	O
fine	O
-	O
tuning	O
.	O

On	O
the	O
Pascal	O
VOC	O
2007	O
and	O
Caltech101	O
datasets	O
,	O
SPP	Computer/Vision-technique
-	Computer/Vision-technique
net	Computer/Vision-technique
achieves	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
classification	O
results	O
using	O
a	O
single	O
full	O
-	O
image	O
representation	O
and	O
no	O
fine	O
-	O
tuning	O
.	O

The	O
power	O
of	O
SPP	Computer/Vision-technique
-	Computer/Vision-technique
net	Computer/Vision-technique
is	O
also	O
significant	O
in	O
object	O
detection	O
.	O

Using	O
SPP	Computer/Vision-technique
-	Computer/Vision-technique
net	Computer/Vision-technique
we	O
compute	O
the	O
feature	O
maps	O
from	O
the	O
entire	O
image	O
only	O
once	O
,	O
and	O
then	O
pool	O
features	O
in	O
arbitrary	O
regions	O
(	O
sub	O
-	O
images	O
)	O
to	O
generate	O
fixed	O
-	O
length	O
representations	O
for	O
training	O
the	O
detectors	O
.	O

Deep	O
generative	O
models	O
are	O
a	O
class	O
of	O
techniques	O
that	O
train	O
deep	O
neural	O
networks	O
to	O
model	O
the	O
distribution	O
of	O
training	AI/ML/DL-term
samples	AI/ML/DL-term
.	O

These	O
techniques	O
are	O
compared	O
and	O
contrasted	O
,	O
explaining	O
the	O
premises	O
behind	O
each	O
and	O
how	O
they	O
are	O
interrelated	O
,	O
while	O
reviewing	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
advances	O
and	O
implementations	O
.	O

In	O
addition	O
,	O
we	O
also	O
cover	O
some	O
other	O
important	O
issues	O
,	O
such	O
as	O
publicly	O
available	O
benchmark	O
datasets	Miscellaneous-term
and	O
performance	O
evaluation	O
metrics	O
.	O

This	O
increases	O
the	O
risk	O
of	O
overfitting	AI/ML/DL-term
during	O
training	AI/ML/DL-term
.	O

In	O
this	O
paper	O
,	O
we	O
address	O
this	O
issue	O
by	O
introducing	O
a	O
multitask	O
learning	O
scheme	O
that	O
employs	O
related	O
tasks	O
as	O
well	O
as	O
related	O
datasets	Miscellaneous-term
in	O
the	O
training	O
process	O
.	O

Still	O
,	O
the	O
training	O
data	O
is	O
limited	O
to	O
a	O
single	O
dataset	Miscellaneous-term
because	O
the	O
set	O
of	O
action	O
labels	O
usually	O
differs	O
across	O
datasets	Miscellaneous-term
.	O

To	O
mitigate	O
this	O
issue	O
,	O
we	O
extend	O
the	O
multitask	O
paradigm	O
to	O
include	O
datasets	Miscellaneous-term
with	O
different	O
label	O
sets	O
.	O

Our	O
experiments	O
on	O
egocentric	O
action	O
recognition	O
in	O
the	O
EPIC	O
-	O
Kitchens	O
EGTEA	O
Gaze	O
+	O
ADL	O
and	O
Charades	O
-	O
EGO	O
datasets	Miscellaneous-term
demonstrate	O
the	O
improvements	O
of	O
our	O
approach	O
over	O
single	O
-	O
dataset	O
baselines	O
.	O

On	O
EGTEA	O
we	O
surpass	O
the	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
by	O
2	O
.	O
47	O
percent	O
.	O

We	O
further	O
illustrate	O
the	O
cross	O
-	O
dataset	O
task	O
correlations	O
that	O
emerge	O
automatically	O
with	O
our	O
novel	O
training	AI/ML/DL-term
scheme	O
.	O

It	O
combines	O
a	O
fully	O
direct	O
probabilistic	O
model	O
(	O
minimizing	O
a	O
photometric	O
error	O
)	O
with	O
consistent	O
,	O
joint	O
optimization	O
of	O
all	O
model	AI/ML/DL-term
parameters	AI/ML/DL-term
including	O
geometry	O
-	O
represented	O
as	O
inverse	O
depth	O
in	O
a	O
reference	O
frame	O
-	O
and	O
camera	O
motion	O
.	O

The	O
proposed	O
model	O
integrates	O
a	O
full	O
photometric	O
calibration	O
accounting	O
for	O
exposure	Computer/vision-term
time	Computer/vision-term
lens	Computer/vision-term
vignetting	Computer/vision-term
and	O
non	O
-	O
linear	O
response	O
functions	O
.	O

We	O
thoroughly	O
evaluate	O
our	O
method	O
on	O
three	O
different	O
datasets	Miscellaneous-term
comprising	O
several	O
hours	O
of	O
video	O
.	O

The	O
experiments	O
show	O
that	O
the	O
presented	O
approach	O
significantly	O
outperforms	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
direct	O
and	O
indirect	O
methods	O
in	O
a	O
variety	O
of	O
real	O
-	O
world	O
settings	O
,	O
both	O
in	O
terms	O
of	O
tracking	O
accuracy	O
and	O
robustness	O
.	O

We	O
then	O
define	O
a	O
skip	AI/ML/DL-term
architecture	AI/ML/DL-term
that	O
combines	O
semantic	AI/ML/DL-term
information	AI/ML/DL-term
from	O
a	O
deep	O
,	O
coarse	O
layer	O
with	O
appearance	O
information	O
from	O
a	O
shallow	O
,	O
fine	O
layer	O
to	O
produce	O
accurate	O
and	O
detailed	O
segmentations	O
.	O

Artificial	O
neural	O
networks	O
thrive	O
in	O
solving	O
the	O
classification	O
problem	O
for	O
a	O
particular	O
rigid	O
task	O
,	O
acquiring	O
knowledge	O
through	O
generalized	O
learning	O
behaviour	O
from	O
a	O
distinct	O
training	AI/ML/DL-term
phase	O
.	O

Our	O
main	O
contributions	O
concern	O
:	O
(	O
1	O
)	O
a	O
taxonomy	O
and	O
extensive	O
overview	O
of	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
ework	O
to	O
continually	O
determine	O
the	O
stability	O
-	O
plasticity	O
trade	O
-	O
off	O
of	O
the	O
continual	O
learner	O
;	O
(	O
3	O
)	O
a	O
comprehensive	O
experimental	O
comparison	O
of	O
11	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
continual	O
learning	O
methods	O
;	O
and	O
(	O
4	O
)	O
baselines	O
.	O

We	O
empirically	O
scrutinize	O
method	O
strengths	O
and	O
weaknesses	O
on	O
three	O
benchmarks	O
,	O
considering	O
Tiny	O
Imagenet	O
and	O
large	O
-	O
scale	O
unbalanced	AI/ML/DL-term
iNaturalist	O
and	O
a	O
sequence	O
of	O
recognition	O
datasets	O
.	O

We	O
study	O
the	O
influence	O
of	O
model	O
capacity	O
,	O
weight	AI/ML/DL-term
decay	AI/ML/DL-term
and	O
dropout	AI/ML/DL-term
regularization	AI/ML/DL-term
and	O
the	O
order	O
in	O
which	O
the	O
tasks	O
are	O
presented	O
,	O
and	O
qualitatively	O
compare	O
methods	O
in	O
terms	O
of	O
required	O
memory	O
,	O
computation	O
time	O
,	O
and	O
storage	O
.	O

This	O
model	O
extracts	O
features	O
from	O
both	O
the	O
spatial	Computer/vision-term
and	O
the	O
temporal	Computer/vision-term
dimensions	Computer/vision-term
by	O
performing	O
3D	O
convolutions	O
thereby	O
capturing	O
the	O
motion	O
information	O
encoded	O
in	O
multiple	O
adjacent	O
frames	O
.	O

To	O
facilitate	O
evaluations	O
,	O
we	O
provide	O
a	O
testbed	O
for	O
GNN	O
explainability	O
including	O
datasets	Miscellaneous-term
common	O
algorithms	Miscellaneous-term
and	O
evaluation	O
metrics	O
.	O

The	O
existing	O
approaches	O
usually	O
utilize	O
two	O
independent	O
branches	O
to	O
recognize	O
egocentric	Computer/vision-term
actions	Computer/vision-term
i	O
.	O
e	O
.,	O
a	O
verb	O
branch	O
and	O
a	O
noun	O
branch	O
.	O

We	O
design	O
a	O
Symbiotic	Computer/Vision-technique
Attention	Computer/Vision-technique
with	Computer/Vision-technique
Object	Computer/Vision-technique
-	Computer/Vision-technique
centric	Computer/Vision-technique
feature	Computer/Vision-technique
Alignment	Computer/Vision-technique
framework	Computer/Vision-technique
(	Computer/Vision-technique
SAOA	Computer/Vision-technique
)	Computer/Vision-technique
to	O
provide	O
meticulous	O
reasoning	O
between	O
the	O
actor	O
and	O
the	O
environment	O
.	O

Notably	O
,	O
our	O
framework	O
achieves	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
on	O
the	O
largest	O
egocentric	Computer/vision-term
video	Computer/vision-term
dataset	Miscellaneous-term
.	O

Notably	O
,	O
our	O
framework	O
achieves	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
on	O
the	O
largest	O
egocentric	Computer/vision-term
video	Computer/vision-term
dataset	Miscellaneous-term
.	O

Computer	O
vision	O
applications	O
have	O
come	O
to	O
rely	O
increasingly	O
on	O
superpixels	Computer/vision-term
superpixel	Computer/vision-term
ears	O
,	O
but	O
it	O
is	O
not	O
always	O
clear	O
what	O
constitutes	O
a	O
good	O
superpixel	O
algorithm	Miscellaneous-term
.	O

Computer	O
vision	O
applications	O
have	O
come	O
to	O
rely	O
increasingly	O
on	O
superpixels	Computer/vision-term
superpixel	Computer/vision-term
ears	O
,	O
but	O
it	O
is	O
not	O
always	O
clear	O
what	O
constitutes	O
a	O
good	O
superpixel	O
algorithm	Miscellaneous-term
.	O

In	O
an	O
effort	O
to	O
understand	O
the	O
benefits	O
and	O
drawbacks	O
of	O
existing	O
methods	O
,	O
we	O
empirically	O
compare	O
five	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
superpixel	Computer/vision-term
algorithms	Miscellaneous-term
for	O
their	O
ability	O
to	O
adhere	O
to	O
image	O
boundaries	O
,	O
speed	O
,	O
memory	O
efficiency	O
,	O
and	O
their	O
impact	O
on	O
segmentation	O
performance	O
.	O

In	O
an	O
effort	O
to	O
understand	O
the	O
benefits	O
and	O
drawbacks	O
of	O
existing	O
methods	O
,	O
we	O
empirically	O
compare	O
five	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
superpixel	Computer/vision-term
algorithms	Miscellaneous-term
for	O
their	O
ability	O
to	O
adhere	O
to	O
image	O
boundaries	O
,	O
speed	O
,	O
memory	O
efficiency	O
,	O
and	O
their	O
impact	O
on	O
segmentation	O
performance	O
.	O

We	O
then	O
introduce	O
a	O
new	O
superpixel	Computer/vision-term
algorithm	Miscellaneous-term
simple	Computer/Vision-technique
linear	Computer/Vision-technique
iterative	Computer/Vision-technique
clustering	Computer/Vision-technique
(	Computer/Vision-technique
SLIC	Computer/Vision-technique
)	Computer/Vision-technique
which	O
adapts	O
a	O
k	O
-	O
means	O
clustering	O
approach	O
to	O
efficiently	O
generate	O
superpixels	Computer/vision-term
.	O

We	O
then	O
introduce	O
a	O
new	O
superpixel	Computer/vision-term
algorithm	Miscellaneous-term
simple	Computer/Vision-technique
linear	Computer/Vision-technique
iterative	Computer/Vision-technique
clustering	Computer/Vision-technique
(	Computer/Vision-technique
SLIC	Computer/Vision-technique
)	Computer/Vision-technique
which	O
adapts	O
a	O
k	O
-	O
means	O
clustering	O
approach	O
to	O
efficiently	O
generate	O
superpixels	Computer/vision-term
.	O

We	O
then	O
introduce	O
a	O
new	O
superpixel	Computer/vision-term
algorithm	Miscellaneous-term
simple	Computer/Vision-technique
linear	Computer/Vision-technique
iterative	Computer/Vision-technique
clustering	Computer/Vision-technique
(	Computer/Vision-technique
SLIC	Computer/Vision-technique
)	Computer/Vision-technique
which	O
adapts	O
a	O
k	O
-	O
means	O
clustering	O
approach	O
to	O
efficiently	O
generate	O
superpixels	Computer/vision-term
.	O

Despite	O
its	O
simplicity	O
,	O
SLIC	Computer/Vision-technique
adheres	O
to	O
boundaries	O
as	O
well	O
as	O
or	O
better	O
than	O
previous	O
methods	O
.	O

Large	O
-	O
scale	O
labeled	Miscellaneous-term
data	Miscellaneous-term
are	O
generally	O
required	O
to	O
train	O
deep	O
neural	O
networks	O
in	O
order	O
to	O
obtain	O
better	O
performance	O
in	O
visual	O
feature	O
learning	O
from	O
images	O
or	O
videos	O
for	O
computer	O
vision	O
applications	O
.	O

To	O
avoid	O
extensive	O
cost	O
of	O
collecting	O
and	O
annotating	O
large	O
-	O
scale	O
datasets	Miscellaneous-term
as	O
a	O
subset	O
of	O
unsupervised	O
learning	O
methods	O
,	O
self	O
-	O
supervised	O
learning	O
methods	O
are	O
proposed	O
to	O
learn	O
general	O
image	O
and	O
video	O
features	O
from	O
large	O
-	O
scale	O
unlabeled	O
data	O
without	O
using	O
any	O
human	Miscellaneous-term
-	Miscellaneous-term
annotated	Miscellaneous-term
labels	Miscellaneous-term
.	O

Next	O
,	O
the	O
schema	O
and	O
evaluation	O
metrics	O
of	O
self	O
-	O
supervised	O
learning	O
methods	O
are	O
reviewed	O
followed	O
by	O
the	O
commonly	O
used	O
datasets	Miscellaneous-term
for	O
images	O
,	O
videos	O
,	O
audios	O
,	O
and	O
3D	O
data	O
,	O
as	O
well	O
as	O
the	O
existing	O
self	O
-	O
supervised	O
visual	O
feature	O
learning	O
methods	O
.	O

This	O
study	O
proposes	O
a	O
novel	O
unified	O
and	O
unsupervised	O
end	O
-	O
to	O
-	O
end	O
image	O
fusion	O
network	O
termed	O
as	O
U2Fusion	Computer/Vision-technique
which	O
is	O
capable	O
of	O
solving	O
different	O
fusion	O
problems	O
,	O
including	O
multi	Computer/vision-term
-	Computer/vision-term
modal	Computer/vision-term
multi	Computer/vision-term
-	Computer/vision-term
exposure	Computer/vision-term
and	O
multi	Computer/vision-term
-	Computer/vision-term
focus	Computer/vision-term
cases	O
.	O

This	O
study	O
proposes	O
a	O
novel	O
unified	O
and	O
unsupervised	O
end	O
-	O
to	O
-	O
end	O
image	O
fusion	O
network	O
termed	O
as	O
U2Fusion	Computer/Vision-technique
which	O
is	O
capable	O
of	O
solving	O
different	O
fusion	O
problems	O
,	O
including	O
multi	Computer/vision-term
-	Computer/vision-term
modal	Computer/vision-term
multi	Computer/vision-term
-	Computer/vision-term
exposure	Computer/vision-term
and	O
multi	Computer/vision-term
-	Computer/vision-term
focus	Computer/vision-term
cases	O
.	O

Using	O
feature	O
extraction	O
and	O
information	O
measurement	O
,	O
U2Fusion	Computer/Vision-technique
automatically	O
estimates	O
the	O
importance	O
of	O
corresponding	O
source	O
images	O
and	O
comes	O
up	O
with	O
adaptive	O
information	O
preservation	O
degrees	O
.	O

Moreover	O
,	O
a	O
new	O
aligned	O
infrared	O
and	O
visible	Computer/vision-term
image	Computer/vision-term
dataset	Miscellaneous-term
RoadScene	O
(	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
hanna	O
-	O
xu	O
/	O
RoadScene	O
,	O
is	O
released	O
to	O
provide	O
a	O
new	O
option	O
for	O
benchmark	O
evaluation	O
.	O

Moreover	O
,	O
a	O
new	O
aligned	O
infrared	O
and	O
visible	Computer/vision-term
image	Computer/vision-term
dataset	Miscellaneous-term
RoadScene	O
(	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
hanna	O
-	O
xu	O
/	O
RoadScene	O
,	O
is	O
released	O
to	O
provide	O
a	O
new	O
option	O
for	O
benchmark	O
evaluation	O
.	O

Qualitative	O
and	O
quantitative	O
experimental	O
results	O
on	O
three	O
typical	O
image	O
fusion	O
tasks	O
validate	O
the	O
effectiveness	O
and	O
universality	O
of	O
U2Fusion	Computer/Vision-technique
.	O

Our	O
code	Miscellaneous-term
is	O
publicly	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
hanna	O
-	O
xu	O
/	O
U2Fusion	O
.	O

This	O
work	O
has	O
culminated	O
in	O
the	O
release	O
of	O
OpenPose	Computer/Vision-technique
the	O
first	O
open	O
-	O
source	O
realtime	O
system	O
for	O
multi	O
-	O
person	O
2D	O
pose	O
detection	O
including	O
body	O
,	O
foot	O
,	O
hand	O
,	O
and	O
facial	O
keypoints	O
.	O

We	O
propose	O
to	O
address	O
this	O
class	O
imbalance	O
by	O
reshaping	O
the	O
standard	O
cross	AI/ML/DL-term
entropy	AI/ML/DL-term
loss	AI/ML/DL-term
such	O
that	O
it	O
down	O
-	O
weights	O
the	O
loss	O
assigned	O
to	O
well	O
-	O
classified	O
examples	O
.	O

Our	O
novel	O
Focal	O
Loss	O
focuses	O
training	AI/ML/DL-term
on	O
a	O
sparse	O
set	O
of	O
hard	O
examples	O
and	O
prevents	O
the	O
vast	O
number	O
of	O
easy	O
negatives	O
from	O
overwhelming	O
the	O
detector	O
during	O
training	O
.	O

To	O
evaluate	O
the	O
effectiveness	O
of	O
our	O
loss	O
,	O
we	O
design	O
and	O
train	O
a	O
simple	O
dense	O
detector	O
we	O
call	O
RetinaNet	Computer/Vision-technique
.	O

Our	O
results	O
show	O
that	O
when	O
trained	O
with	O
the	O
focal	O
loss	O
,	O
RetinaNet	Computer/Vision-technique
is	O
able	O
to	O
match	O
the	O
speed	O
of	O
previous	O
one	O
-	O
stage	O
detectors	O
while	O
surpassing	O
the	O
accuracy	O
of	O
all	O
existing	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
two	O
-	O
stage	O
detectors	O
.	O

Our	O
results	O
show	O
that	O
when	O
trained	O
with	O
the	O
focal	O
loss	O
,	O
RetinaNet	Computer/Vision-technique
is	O
able	O
to	O
match	O
the	O
speed	O
of	O
previous	O
one	O
-	O
stage	O
detectors	O
while	O
surpassing	O
the	O
accuracy	O
of	O
all	O
existing	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
two	O
-	O
stage	O
detectors	O
.	O

We	O
study	O
how	O
to	O
select	O
good	O
features	Computer/vision-term
according	O
to	O
the	O
maximal	O
statistical	O
dependency	O
criterion	O
based	O
on	O
mutual	O
information	O
.	O

Because	O
of	O
the	O
difficulty	O
in	O
directly	O
implementing	O
the	O
maximal	O
dependency	O
condition	O
,	O
we	O
first	O
derive	O
an	O
equivalent	O
form	O
,	O
called	O
minimal	Computer/Vision-technique
-	Computer/Vision-technique
redundancy	Computer/Vision-technique
-	Computer/Vision-technique
maximal	Computer/Vision-technique
-	Computer/Vision-technique
relevance	Computer/Vision-technique
criterion	Computer/Vision-technique
(	Computer/Vision-technique
mRMR	Computer/Vision-technique
)	Computer/Vision-technique
for	O
first	O
-	O
order	O
incremental	O
feature	O
selection	O
.	O

Then	O
,	O
we	O
present	O
a	O
two	O
-	O
stage	O
feature	O
selection	O
algorithm	Miscellaneous-term
by	O
combining	O
mRMR	Computer/Vision-technique
and	O
other	O
more	O
sophisticated	O
feature	O
selectors	O
(	O
e	O
.	O
g	O
.,	O
wrappers	O
).	O

Then	O
,	O
we	O
present	O
a	O
two	O
-	O
stage	O
feature	O
selection	O
algorithm	Miscellaneous-term
by	O
combining	O
mRMR	Computer/Vision-technique
and	O
other	O
more	O
sophisticated	O
feature	O
selectors	O
(	O
e	O
.	O
g	O
.,	O
wrappers	O
).	O

We	O
perform	O
extensive	O
experimental	O
comparison	O
of	O
our	O
algorithm	Miscellaneous-term
and	O
other	O
methods	O
using	O
three	O
different	O
classifiers	O
(	O
naive	O
Bayes	O
support	O
vector	O
machine	O
and	O
linear	O
discriminate	O
analysis	O
and	O
four	O
different	O
data	Miscellaneous-term
sets	Miscellaneous-term
(	O
handwritten	O
digits	O
,	O
arrhythmia	O
,	O
NCI	O
cancer	O
cell	O
lines	O
,	O
and	O
lymphoma	O
tissues	O
).	O

The	O
results	O
confirm	O
that	O
mRMR	Computer/Vision-technique
leads	O
to	O
promising	O
improvement	O
on	O
feature	O
selection	O
and	O
classification	O
accuracy	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
knowledge	O
distillation	O
technique	O
named	O
self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
to	O
address	O
this	O
problem	O
.	O

Self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
attaches	O
several	O
attention	O
modules	O
and	O
shallow	O
classifiers	O
at	O
different	O
depths	O
of	O
neural	O
networks	O
and	O
distills	O
knowledge	O
from	O
the	O
deepest	O
classifier	O
to	O
the	O
shallower	O
classifiers	O
.	O

Different	O
from	O
the	O
conventional	O
knowledge	O
distillation	O
methods	O
where	O
the	O
knowledge	O
of	O
the	O
teacher	AI/ML/DL-term
model	AI/ML/DL-term
is	O
transferred	O
to	O
another	O
student	AI/ML/DL-term
model	AI/ML/DL-term
self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
can	O
be	O
considered	O
as	O
knowledge	O
transfer	O
in	O
the	O
same	O
model	O
-	O
from	O
the	O
deeper	O
layers	O
to	O
the	O
shallow	O
layers	O
.	O

Different	O
from	O
the	O
conventional	O
knowledge	O
distillation	O
methods	O
where	O
the	O
knowledge	O
of	O
the	O
teacher	AI/ML/DL-term
model	AI/ML/DL-term
is	O
transferred	O
to	O
another	O
student	AI/ML/DL-term
model	AI/ML/DL-term
self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
can	O
be	O
considered	O
as	O
knowledge	O
transfer	O
in	O
the	O
same	O
model	O
-	O
from	O
the	O
deeper	O
layers	O
to	O
the	O
shallow	O
layers	O
.	O

Moreover	O
,	O
the	O
additional	O
classifiers	O
in	O
self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
allow	O
the	O
neural	O
network	O
to	O
work	O
in	O
a	O
dynamic	O
manner	O
,	O
which	O
leads	O
to	O
a	O
much	O
higher	O
acceleration	O
.	O

Experiments	O
demonstrate	O
that	O
self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
has	O
consistent	O
and	O
significant	O
effectiveness	O
on	O
various	O
neural	O
networks	O
and	O
datasets	Miscellaneous-term
.	O

Experiments	O
demonstrate	O
that	O
self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
has	O
consistent	O
and	O
significant	O
effectiveness	O
on	O
various	O
neural	O
networks	O
and	O
datasets	Miscellaneous-term
.	O

Besides	O
,	O
experiments	O
show	O
that	O
self	AI/ML/DL-technique
-	AI/ML/DL-technique
distillation	AI/ML/DL-technique
can	O
be	O
combined	O
with	O
other	O
model	O
compression	O
methods	O
,	O
including	O
knowledge	O
distillation	O
pruning	O
and	O
lightweight	O
model	O
design	O
.	O

The	O
widely	O
studied	O
closed	O
-	O
world	O
setting	O
is	O
usually	O
applied	O
under	O
various	O
research	O
-	O
oriented	O
assumptions	O
,	O
and	O
has	O
achieved	O
inspiring	O
success	O
using	O
deep	O
learning	O
techniques	O
on	O
a	O
number	O
of	O
datasets	Miscellaneous-term
.	O

By	O
analyzing	O
the	O
advantages	O
of	O
existing	O
methods	O
,	O
we	O
design	O
a	O
powerful	O
AGW	O
baseline	O
,	O
achieving	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
or	O
at	O
least	O
comparable	O
performance	O
on	O
twelve	O
datasets	Miscellaneous-term
for	O
four	O
different	O
Re	O
-	O
ID	O
tasks	O
.	O

This	O
work	O
aims	O
at	O
providing	O
a	O
comprehensive	O
overview	O
of	O
image	O
captioning	O
approaches	O
,	O
from	O
visual	O
encoding	O
and	O
text	O
generation	O
to	O
training	O
strategies	O
,	O
datasets	Miscellaneous-term
and	O
evaluation	O
metrics	O
.	O

In	O
this	O
respect	O
,	O
we	O
quantitatively	O
compare	O
many	O
relevant	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
approaches	O
to	O
identify	O
the	O
most	O
impactful	O
technical	O
innovations	O
in	O
architectures	O
and	O
training	O
strategies	O
.	O

Existing	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
frameworks	O
first	O
encode	O
the	O
input	O
image	O
as	O
a	O
low	O
-	O
resolution	O
representation	O
through	O
a	O
subnetwork	O
that	O
is	O
formed	O
by	O
connecting	O
high	O
-	O
to	O
-	O
low	O
resolution	O
convolutions	O
in	O
series	O
(	O
e	O
.	O
g	O
.,	O
ResNet	O
VGGNet	O
,	O
and	O
then	O
recover	O
the	O
high	O
-	O
resolution	O
representation	O
from	O
the	O
encoded	O
low	O
-	O
resolution	O
representation	O
.	O

Instead	O
,	O
our	O
proposed	O
network	O
,	O
named	O
as	O
High	Computer/Vision-technique
-	Computer/Vision-technique
Resolution	Computer/Vision-technique
Network	Computer/Vision-technique
(	Computer/Vision-technique
HRNet	Computer/Vision-technique
)	Computer/Vision-technique
maintains	O
high	O
-	O
resolution	O
representations	O
through	O
the	O
whole	O
process	O
.	O

There	O
are	O
two	O
key	O
characteristics	O
:	O
(	O
i	O
)	O
Connect	O
the	O
high	Computer/vision-term
-	Computer/vision-term
to	Computer/vision-term
-	Computer/vision-term
low	Computer/vision-term
resolution	Computer/vision-term
convolution	Computer/vision-term
streams	Computer/vision-term
in	O
parallel	O
and	O
(	O
ii	O
)	O
repeatedly	O
exchange	O
the	O
information	O
across	O
resolutions	O
.	O

We	O
show	O
the	O
superiority	O
of	O
the	O
proposed	O
HRNet	Computer/Vision-technique
in	O
a	O
wide	O
range	O
of	O
applications	O
,	O
including	O
human	O
pose	O
estimation	O
semantic	O
segmentation	O
and	O
object	O
detection	O
HRNet	Computer/Vision-technique
sting	O
that	O
the	O
HRNet	O
is	O
a	O
stronger	O
backbone	O
for	O
computer	O
vision	O
problems	O
.	O

However	O
,	O
these	O
models	O
are	O
huge	O
in	O
size	O
with	O
millions	O
(	O
and	O
even	O
billions	O
)	O
of	O
parameters	AI/ML/DL-term
demanding	O
heavy	O
computation	O
power	O
and	O
failing	O
to	O
be	O
deployed	O
on	O
edge	O
devices	O
.	O

We	O
use	O
the	O
criteria	O
in	O
numerical	O
optimization	O
to	O
derive	O
detectors	O
for	O
several	O
common	O
image	Computer/vision-term
features	Computer/vision-term
including	O
step	O
edges	O
.	O

The	O
optimal	O
detector	O
has	O
a	O
simple	O
approximate	O
implementation	O
in	O
which	O
edges	O
are	O
marked	O
at	O
maxima	O
in	O
gradient	O
magnitude	O
of	O
a	O
Gaussian	Computer/vision-term
-	Computer/vision-term
smoothed	Computer/vision-term
image	Computer/vision-term
.	O

We	O
present	O
a	O
general	O
method	O
,	O
called	O
feature	Computer/Vision-technique
synthesis	Computer/Vision-technique
for	O
the	O
fine	O
-	O
to	O
-	O
coarse	O
integration	O
of	O
information	O
from	O
operators	O
at	O
different	O
scales	O
.	O

Many	O
previous	O
performance	O
capture	O
approaches	O
either	O
required	O
expensive	O
multi	O
-	O
view	O
setups	O
or	O
did	O
not	O
recover	O
dense	AI/ML/DL-term
space	AI/ML/DL-term
-	AI/ML/DL-term
time	AI/ML/DL-term
coherent	AI/ML/DL-term
geometry	AI/ML/DL-term
with	O
frame	O
-	O
to	O
-	O
frame	O
correspondences	O
.	O

Extensive	O
qualitative	O
and	O
quantitative	O
evaluations	O
show	O
that	O
our	O
approach	O
outperforms	O
the	O
state	Miscellaneous-term
of	Miscellaneous-term
the	Miscellaneous-term
art	Miscellaneous-term
in	O
terms	O
of	O
quality	O
and	O
robustness	O
.	O

As	O
a	O
remedy	O
,	O
we	O
develop	O
a	O
computationally	O
affordable	O
deterministic	O
scheme	O
which	O
accurately	O
approximates	O
the	O
transition	AI/ML/DL-term
kernel	AI/ML/DL-term
when	O
dynamics	O
is	O
governed	O
by	O
a	O
NSDE	O
.	O

Our	O
method	O
introduces	O
a	O
bidimensional	O
moment	O
matching	O
algorithm	Miscellaneous-term
vertical	O
along	O
the	O
neural	AI/ML/DL-term
net	AI/ML/DL-term
layers	AI/ML/DL-term
and	O
horizontal	O
along	O
the	O
time	O
direction	O
,	O
which	O
benefits	O
from	O
an	O
original	O
combination	O
of	O
effective	O
approximations	O
.	O

Our	O
method	O
introduces	O
a	O
bidimensional	O
moment	O
matching	O
algorithm	Miscellaneous-term
vertical	O
along	O
the	O
neural	AI/ML/DL-term
net	AI/ML/DL-term
layers	AI/ML/DL-term
and	O
horizontal	O
along	O
the	O
time	O
direction	O
,	O
which	O
benefits	O
from	O
an	O
original	O
combination	O
of	O
effective	O
approximations	O
.	O

Our	O
deterministic	O
approximation	O
of	O
the	O
transition	AI/ML/DL-term
kernel	AI/ML/DL-term
is	O
applicable	O
to	O
both	O
training	O
and	O
prediction	O
.	O

Traditional	O
search	O
-	O
based	O
algorithms	O
tend	O
to	O
require	O
extensive	O
configuration	O
evaluations	O
for	O
each	O
round	O
to	O
select	O
the	O
desirable	O
hyperparameters	AI/ML/DL-term
during	O
the	O
process	O
,	O
and	O
they	O
are	O
often	O
very	O
inefficient	O
for	O
the	O
implementations	O
on	O
large	O
-	O
scale	O
tasks	O
.	O

Our	O
proposed	O
approach	O
predicts	O
the	O
performance	O
for	O
hyperparameters	AI/ML/DL-term
hyperparameters	AI/ML/DL-term
based	O
on	O
their	O
previous	O
performance	O
so	O
that	O
the	O
underlying	O
suitable	O
hyperparameters	O
with	O
better	O
efficiency	O
can	O
be	O
attained	O
.	O

Different	O
from	O
existing	O
approaches	O
,	O
the	O
hyperparameter	AI/ML/DL-term
performance	O
space	O
is	O
instantiated	O
under	O
tensor	O
framework	O
that	O
can	O
preserve	O
the	O
spatial	O
structure	O
and	O
reflect	O
the	O
correlations	O
among	O
the	O
adjacent	O
hyperparameters	AI/ML/DL-term
.	O

Toward	O
the	O
completion	O
purpose	O
,	O
we	O
develop	O
an	O
LRTC	O
algorithm	Miscellaneous-term
utilizing	O
the	O
sum	O
of	O
nuclear	O
norm	O
(	O
SNN	O
)	O
model	O
.	O

In	O
addition	O
,	O
a	O
corresponding	O
coupled	O
matrix	O
factorization	O
(	O
CMF	O
)	O
algorithm	Miscellaneous-term
is	O
established	O
to	O
render	O
the	O
predictions	O
solely	O
depend	O
on	O
the	O
meta	AI/ML/DL-term
-	AI/ML/DL-term
features	AI/ML/DL-term
to	O
avoid	O
additional	O
hyperparameter	AI/ML/DL-term
evaluations	O
.	O

In	O
addition	O
,	O
a	O
corresponding	O
coupled	O
matrix	O
factorization	O
(	O
CMF	O
)	O
algorithm	Miscellaneous-term
is	O
established	O
to	O
render	O
the	O
predictions	O
solely	O
depend	O
on	O
the	O
meta	AI/ML/DL-term
-	AI/ML/DL-term
features	AI/ML/DL-term
to	O
avoid	O
additional	O
hyperparameter	AI/ML/DL-term
evaluations	O
.	O

We	O
test	O
recommendation	O
performance	O
with	O
our	O
proposed	O
methods	O
for	O
classical	O
SVM	O
and	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
deep	O
neural	O
networks	O
such	O
as	O
vision	O
transformer	O
(	O
ViT	O
)	O
and	O
residual	O
network	O
(	O
ResNet	O
)	O
and	O
the	O
obtained	O
results	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
approaches	O
under	O
various	O
evaluation	O
metrics	O
by	O
comparing	O
with	O
the	O
baselines	O
commonly	O
used	O
for	O
MtL	O
.	O

Combining	O
few	AI/ML/DL-term
-	AI/ML/DL-term
shot	AI/ML/DL-term
and	O
self	O
-	O
supervised	O
object	O
detection	O
is	O
a	O
promising	O
research	O
direction	O
.	O

In	O
this	O
survey	O
,	O
we	O
review	O
and	O
characterize	O
the	O
most	O
recent	O
approaches	O
on	O
few	AI/ML/DL-term
-	AI/ML/DL-term
shot	AI/ML/DL-term
and	O
self	O
-	O
supervised	O
object	O
detection	O
.	O

However	O
,	O
little	O
attention	O
has	O
been	O
paid	O
to	O
the	O
security	O
issue	O
of	O
such	O
algorithms	Miscellaneous-term
in	O
contrast	O
to	O
numerous	O
research	O
work	O
on	O
the	O
computational	O
and	O
statistical	O
characteristics	O
.	O

Driven	O
by	O
huge	O
profit	O
,	O
the	O
potential	O
adversary	O
has	O
strong	O
motivation	O
and	O
incentives	O
to	O
manipulate	O
the	O
ranking	Data/Mining/Information/Retrieval-term
list	Data/Mining/Information/Retrieval-term
.	O

From	O
the	O
perspective	O
of	O
the	O
dynamical	Miscellaneous-term
system	Miscellaneous-term
the	O
attack	O
behavior	O
with	O
a	O
target	O
ranking	Data/Mining/Information/Retrieval-term
list	Data/Mining/Information/Retrieval-term
is	O
a	O
fixed	O
point	O
belonging	O
to	O
the	O
composition	O
of	O
the	O
adversary	O
and	O
the	O
victim	O
.	O

From	O
the	O
perspective	O
of	O
the	O
dynamical	Miscellaneous-term
system	Miscellaneous-term
the	O
attack	O
behavior	O
with	O
a	O
target	O
ranking	Data/Mining/Information/Retrieval-term
list	Data/Mining/Information/Retrieval-term
is	O
a	O
fixed	O
point	O
belonging	O
to	O
the	O
composition	O
of	O
the	O
adversary	O
and	O
the	O
victim	O
.	O

Furthermore	O
,	O
we	O
prove	O
that	O
the	O
victims	O
will	O
produce	O
the	O
target	O
ranking	Data/Mining/Information/Retrieval-term
list	Data/Mining/Information/Retrieval-term
once	O
the	O
adversary	O
masters	O
the	O
complete	O
information	O
.	O

The	O
effectiveness	O
of	O
the	O
suggested	O
target	O
attack	O
strategies	O
is	O
demonstrated	O
by	O
a	O
series	O
of	O
toy	Miscellaneous-term
simulations	Miscellaneous-term
and	O
several	O
real	O
-	O
world	O
data	O
experiments	O
.	O

These	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
methods	O
could	O
achieve	O
the	O
attacker	O
'	O
s	O
goal	O
in	O
the	O
sense	O
that	O
the	O
leading	O
candidate	O
of	O
the	O
perturbed	O
ranking	Data/Mining/Information/Retrieval-term
list	Data/Mining/Information/Retrieval-term
is	O
the	O
designated	O
one	O
by	O
the	O
adversary	O
.	O

To	O
alleviate	O
these	O
issues	O
,	O
we	O
introduce	O
a	O
deep	O
sensing	O
solution	O
to	O
directly	O
recognize	O
human	O
actions	O
from	O
coded	Computer/vision-term
exposure	Computer/vision-term
images	Computer/vision-term
.	O

Our	O
deep	O
sensing	O
solution	O
consists	O
of	O
a	O
binary	O
CNN	O
-	O
based	O
encoder	O
network	O
that	O
emulates	O
the	O
capturing	O
of	O
a	O
coded	Computer/vision-term
exposure	Computer/vision-term
image	Computer/vision-term
of	O
a	O
dynamic	O
scene	O
using	O
a	O
coded	Miscellaneous-term
exposure	Miscellaneous-term
camera	Miscellaneous-term
followed	O
by	O
a	O
2D	O
CNN	O
coded	Computer/vision-term
exposure	Computer/vision-term
image	Computer/vision-term
action	O
in	O
the	O
captured	O
coded	O
exposure	O
image	O
.	O

Our	O
deep	O
sensing	O
solution	O
consists	O
of	O
a	O
binary	O
CNN	O
-	O
based	O
encoder	O
network	O
that	O
emulates	O
the	O
capturing	O
of	O
a	O
coded	Computer/vision-term
exposure	Computer/vision-term
image	Computer/vision-term
of	O
a	O
dynamic	O
scene	O
using	O
a	O
coded	Miscellaneous-term
exposure	Miscellaneous-term
camera	Miscellaneous-term
followed	O
by	O
a	O
2D	O
CNN	O
coded	Computer/vision-term
exposure	Computer/vision-term
image	Computer/vision-term
action	O
in	O
the	O
captured	O
coded	O
exposure	O
image	O
.	O

Furthermore	O
,	O
we	O
propose	O
a	O
novel	O
knowledge	O
distillation	O
framework	O
to	O
jointly	O
train	O
the	O
encoder	O
and	O
the	O
action	O
recognition	O
model	O
action	O
recognition	O
roposed	O
training	O
approach	O
improves	O
the	O
action	O
recognition	O
accuracy	O
by	O
an	O
absolute	O
margin	O
of	O
6	O
.	O
2	O
%	O
2	O
.	O
9	O
%	O
and	O
7	O
.	O
9	O
%	O
on	O
Something	O
$^{	O
2	O
}$	O
2	O
-	O
v2	O
Kinetics	O
-	O
400	O
and	O
UCF	O
-	O
101	O
datasets	Miscellaneous-term
respectively	O
,	O
in	O
comparison	O
to	O
our	O
previous	O
approach	O
.	O

Finally	O
,	O
we	O
built	O
a	O
prototype	Miscellaneous-term
coded	Miscellaneous-term
exposure	Miscellaneous-term
camera	Miscellaneous-term
using	O
LCoS	Miscellaneous-term
to	O
validate	O
the	O
feasibility	O
of	O
our	O
deep	O
sensing	O
solution	O
.	O

Our	O
evaluation	O
of	O
the	O
prototype	O
camera	O
show	O
results	O
that	O
are	O
consistent	O
with	O
the	O
simulation	Miscellaneous-term
results	O
.	O

This	O
article	O
proposes	O
a	O
unified	O
framework	O
dubbed	O
Multi	AI/ML/DL-technique
-	AI/ML/DL-technique
view	AI/ML/DL-technique
and	AI/ML/DL-technique
Temporal	AI/ML/DL-technique
Fusing	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
(	AI/ML/DL-technique
MTF	AI/ML/DL-technique
-	AI/ML/DL-technique
Transformer	AI/ML/DL-technique
)	AI/ML/DL-technique
to	O
adaptively	O
handle	O
varying	O
view	O
numbers	O
and	O
video	O
length	O
without	O
camera	O
calibration	O
in	O
3D	O
Human	O
Pose	O
Estimation	O
(	O
HPE	O
)	O
.	O

Feature	O
Extractor	O
estimates	O
2D	Computer/vision-term
pose	Computer/vision-term
from	O
each	O
image	O
and	O
fuses	O
the	O
prediction	O
according	O
to	O
the	O
confidence	O
.	O

MFT	O
fuses	O
the	O
features	O
of	O
a	O
varying	O
number	O
of	O
views	O
with	O
a	O
novel	O
Relative	AI/ML/DL-term
-	AI/ML/DL-term
Attention	AI/ML/DL-term
block	O
.	O

TFT	O
aggregates	O
the	O
features	O
of	O
the	O
whole	O
sequence	O
and	O
predicts	O
3D	Computer/vision-term
pose	Computer/vision-term
via	O
a	O
transformer	O
.	O

The	O
migration	O
of	O
transformers	O
enables	O
our	O
model	O
to	O
learn	O
spatial	AI/ML/DL-term
geometry	AI/ML/DL-term
better	O
and	O
preserve	O
robustness	O
for	O
varying	O
application	O
scenarios	O
.	O

Compared	O
with	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
with	O
camera	O
parameters	O
,	O
MTF	Computer/Vision-technique
-	Computer/Vision-technique
Transformer	Computer/Vision-technique
obtains	O
competitive	O
results	O
and	O
generalizes	O
well	O
to	O
dynamic	O
capture	O
with	O
an	O
arbitrary	O
number	O
of	O
unseen	O
views	O
.	O

Compared	O
with	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
with	O
camera	O
parameters	O
,	O
MTF	Computer/Vision-technique
-	Computer/Vision-technique
Transformer	Computer/Vision-technique
obtains	O
competitive	O
results	O
and	O
generalizes	O
well	O
to	O
dynamic	O
capture	O
with	O
an	O
arbitrary	O
number	O
of	O
unseen	O
views	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
an	O
adaptive	Computer/Vision-technique
two	Computer/Vision-technique
-	Computer/Vision-technique
stream	Computer/Vision-technique
consensus	Computer/Vision-technique
network	Computer/Vision-technique
(	Computer/Vision-technique
A	Computer/Vision-technique
-	Computer/Vision-technique
TSCN	Computer/Vision-technique
)	Computer/Vision-technique
to	O
address	O
this	O
problem	O
.	O

Our	O
A	Computer/Vision-technique
-	Computer/Vision-technique
TSCN	Computer/Vision-technique
features	O
an	O
iterative	O
refinement	O
training	O
scheme	O
:	O
a	O
frame	O
-	O
level	O
pseudo	O
ground	O
truth	O
is	O
generated	O
and	O
iteratively	O
updated	O
from	O
a	O
late	O
-	O
fusion	O
activation	O
sequence	O
,	O
and	O
used	O
to	O
provide	O
frame	O
-	O
level	O
supervision	O
for	O
improved	O
model	AI/ML/DL-term
training	AI/ML/DL-term
.	O

Our	O
A	Computer/Vision-technique
-	Computer/Vision-technique
TSCN	Computer/Vision-technique
features	O
an	O
iterative	O
refinement	O
training	O
scheme	O
:	O
a	O
frame	O
-	O
level	O
pseudo	O
ground	O
truth	O
is	O
generated	O
and	O
iteratively	O
updated	O
from	O
a	O
late	O
-	O
fusion	O
activation	O
sequence	O
,	O
and	O
used	O
to	O
provide	O
frame	O
-	O
level	O
supervision	O
for	O
improved	O
model	AI/ML/DL-term
training	AI/ML/DL-term
.	O

Besides	O
,	O
we	O
introduce	O
an	O
adaptive	AI/ML/DL-technique
attention	AI/ML/DL-technique
normalization	AI/ML/DL-technique
loss	AI/ML/DL-technique
which	O
adaptively	O
selects	O
action	O
and	O
background	O
snippets	O
according	O
to	O
video	O
attention	O
distribution	O
.	O

By	O
differentiating	O
the	O
attention	O
values	O
of	O
the	O
selected	O
action	O
snippets	O
and	O
background	O
snippets	O
,	O
it	O
forces	O
the	O
predicted	O
attention	O
to	O
act	O
as	O
a	O
binary	O
selection	O
and	O
promotes	O
the	O
precise	O
localization	O
of	O
action	Computer/vision-term
boundaries	Computer/vision-term
.	O

Experiments	O
conducted	O
on	O
the	O
THUMOS14	O
ActivityNet	O
v1	O
.	O
2	O
ActivityNet	O
v1	O
.	O
3	O
and	O
HACS	O
datasets	Miscellaneous-term
show	O
that	O
our	O
A	Computer/Vision-technique
-	Computer/Vision-technique
TSCN	Computer/Vision-technique
outperforms	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
,	O
and	O
even	O
achieves	O
comparable	O
performance	O
with	O
several	O
fully	O
-	O
supervised	O
methods	O
.	O

Experiments	O
conducted	O
on	O
the	O
THUMOS14	O
ActivityNet	O
v1	O
.	O
2	O
ActivityNet	O
v1	O
.	O
3	O
and	O
HACS	O
datasets	Miscellaneous-term
show	O
that	O
our	O
A	Computer/Vision-technique
-	Computer/Vision-technique
TSCN	Computer/Vision-technique
outperforms	O
current	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
,	O
and	O
even	O
achieves	O
comparable	O
performance	O
with	O
several	O
fully	O
-	O
supervised	O
methods	O
.	O

However	O
,	O
it	O
often	O
suffers	O
from	O
training	O
inefficiency	O
as	O
the	O
action	O
space	O
of	O
the	O
high	O
-	O
level	O
,	O
i	O
.	O
e	O
.,	O
the	O
goal	AI/ML/DL-term
space	AI/ML/DL-term
is	O
large	O
.	O

Searching	O
in	O
a	O
large	O
goal	O
space	O
poses	O
difficulty	O
for	O
both	O
high	AI/ML/DL-term
-	AI/ML/DL-term
level	AI/ML/DL-term
subgoal	AI/ML/DL-term
generation	AI/ML/DL-term
and	O
low	O
-	O
level	O
policy	O
learning	O
.	O

In	O
this	O
article	O
,	O
we	O
show	O
that	O
this	O
problem	O
can	O
be	O
effectively	O
alleviated	O
by	O
restricting	O
the	O
high	O
-	O
level	O
action	O
space	O
from	O
the	O
whole	O
goal	AI/ML/DL-term
space	AI/ML/DL-term
to	O
a	O
$	O
k	O
$	O
k	O
-	O
step	O
adjacent	O
region	O
of	O
the	O
current	O
state	O
using	O
an	O
adjacency	AI/ML/DL-term
constraint	AI/ML/DL-term
.	O

We	O
theoretically	O
prove	O
that	O
in	O
a	O
deterministic	O
Markov	O
Decision	O
Process	O
(	O
MDP	O
)	O
the	O
proposed	O
adjacency	AI/ML/DL-term
constraint	AI/ML/DL-term
preserves	O
the	O
optimal	O
hierarchical	O
policy	O
,	O
while	O
in	O
a	O
stochastic	O
MDP	O
the	O
adjacency	O
constraint	O
induces	O
a	O
bounded	O
state	O
-	O
value	O
suboptimality	O
determined	O
by	O
the	O
MDP	O
'	O
s	O
transition	O
structure	O
.	O

We	O
further	O
show	O
that	O
this	O
constraint	O
can	O
be	O
practically	O
implemented	O
by	O
training	AI/ML/DL-term
an	O
adjacency	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
that	O
can	O
discriminate	O
between	O
adjacent	O
and	O
non	O
-	O
adjacent	O
subgoals	O
.	O

We	O
further	O
show	O
that	O
this	O
constraint	O
can	O
be	O
practically	O
implemented	O
by	O
training	AI/ML/DL-term
an	O
adjacency	Data/Mining/Information/Retrieval-term
network	Data/Mining/Information/Retrieval-term
that	O
can	O
discriminate	O
between	O
adjacent	O
and	O
non	O
-	O
adjacent	O
subgoals	O
.	O

Experimental	O
results	O
on	O
discrete	O
and	O
continuous	O
control	O
tasks	O
including	O
challenging	O
simulated	O
robot	O
locomotion	O
and	O
manipulation	O
tasks	O
show	O
that	O
incorporating	O
the	O
adjacency	O
constraint	O
significantly	O
boosts	O
the	O
performance	O
of	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
goal	O
-	O
conditioned	O
HRL	O
approaches	O
.	O

To	O
this	O
end	O
,	O
we	O
propose	O
a	O
defense	O
strategy	O
that	O
manipulates	O
the	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
of	O
novelty	O
detectors	O
to	O
improve	O
the	O
robustness	O
against	O
adversarial	O
examples	O
.	O

The	O
proposed	O
method	O
,	O
referred	O
to	O
as	O
Principal	AI/ML/DL-technique
Latent	AI/ML/DL-technique
Space	AI/ML/DL-technique
(	AI/ML/DL-technique
PrincipaLS	AI/ML/DL-technique
)	AI/ML/DL-technique
learns	O
the	O
incrementally	O
-	O
trained	O
cascade	AI/ML/DL-term
principal	AI/ML/DL-term
components	AI/ML/DL-term
in	O
the	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
to	O
robustify	O
novelty	O
detectors	O
.	O

The	O
proposed	O
method	O
,	O
referred	O
to	O
as	O
Principal	AI/ML/DL-technique
Latent	AI/ML/DL-technique
Space	AI/ML/DL-technique
(	AI/ML/DL-technique
PrincipaLS	AI/ML/DL-technique
)	AI/ML/DL-technique
learns	O
the	O
incrementally	O
-	O
trained	O
cascade	AI/ML/DL-term
principal	AI/ML/DL-term
components	AI/ML/DL-term
in	O
the	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
to	O
robustify	O
novelty	O
detectors	O
.	O

PrincipaLS	AI/ML/DL-technique
can	O
purify	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
latent	AI/ML/DL-term
space	AI/ML/DL-term
sarial	O
examples	O
and	O
constrain	O
latent	O
space	O
to	O
exclusively	O
model	O
the	O
known	O
class	AI/ML/DL-term
distribution	AI/ML/DL-term
.	O

PrincipaLS	AI/ML/DL-technique
can	O
purify	O
latent	AI/ML/DL-term
space	AI/ML/DL-term
latent	AI/ML/DL-term
space	AI/ML/DL-term
sarial	O
examples	O
and	O
constrain	O
latent	O
space	O
to	O
exclusively	O
model	O
the	O
known	O
class	AI/ML/DL-term
distribution	AI/ML/DL-term
.	O

We	O
conduct	O
extensive	O
experiments	O
on	O
eight	O
attacks	O
,	O
five	O
datasets	Miscellaneous-term
and	O
seven	O
novelty	O
detectors	O
showing	O
that	O
PrincipaLS	AI/ML/DL-technique
consistently	O
enhances	O
the	O
adversarial	O
robustness	O
of	O
novelty	O
detection	O
models	O
.	O

We	O
conduct	O
extensive	O
experiments	O
on	O
eight	O
attacks	O
,	O
five	O
datasets	Miscellaneous-term
and	O
seven	O
novelty	O
detectors	O
showing	O
that	O
PrincipaLS	AI/ML/DL-technique
consistently	O
enhances	O
the	O
adversarial	O
robustness	O
of	O
novelty	O
detection	O
models	O
.	O

However	O
,	O
two	O
major	O
challenges	O
limit	O
the	O
reconstruction	O
performance	O
,	O
i	O
.	O
e	O
.,	O
the	O
low	O
photon	Computer/vision-term
counts	Computer/vision-term
accompanied	O
by	O
low	O
signal	O
-	O
to	O
-	O
background	O
ratio	O
(	O
SBR	O
)	O
and	O
the	O
multiple	O
returns	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
unified	O
deep	O
neural	O
network	O
that	O
,	O
for	O
the	O
first	O
time	O
,	O
explicitly	O
addresses	O
these	O
two	O
challenges	O
,	O
and	O
simultaneously	O
recovers	O
depth	Computer/vision-term
maps	Computer/vision-term
and	O
intensity	Computer/vision-term
images	Computer/vision-term
from	O
photon	O
-	O
efficient	O
measurements	O
.	O

Starting	O
from	O
a	O
general	O
image	O
formation	O
model	O
our	O
network	O
is	O
constituted	O
of	O
one	O
encoder	O
where	O
a	O
non	O
-	O
local	O
block	O
is	O
utilized	O
to	O
exploit	O
the	O
long	O
-	O
range	O
correlations	O
in	O
both	O
spatial	AI/ML/DL-term
and	O
temporal	AI/ML/DL-term
dimensions	AI/ML/DL-term
of	O
the	O
raw	O
measurement	O
,	O
and	O
two	O
decoders	O
which	O
are	O
designed	O
to	O
recover	O
depth	O
and	O
intensity	O
,	O
respectively	O
.	O

Meanwhile	O
,	O
we	O
investigate	O
the	O
statistics	O
of	O
the	O
background	O
noise	O
photons	O
and	O
propose	O
a	O
noise	AI/ML/DL-term
prior	AI/ML/DL-term
block	O
to	O
further	O
improve	O
the	O
reconstruction	O
performance	O
.	O

The	O
proposed	O
network	O
achieves	O
decent	O
reconstruction	O
fidelity	O
even	O
under	O
extremely	O
low	O
photon	Computer/vision-term
counts	Computer/vision-term
/	O
SBR	O
and	O
heavy	O
blur	O
caused	O
by	O
the	O
multiple	O
-	O
return	O
effect	O
,	O
which	O
significantly	O
surpasses	O
the	O
existing	O
methods	O
.	O

Moreover	O
,	O
our	O
network	O
trained	O
on	O
simulated	Miscellaneous-term
data	Miscellaneous-term
generalizes	O
well	O
to	O
real	O
-	O
world	O
imaging	O
systems	O
,	O
which	O
greatly	O
extends	O
the	O
application	O
scope	O
of	O
photon	O
-	O
efficient	O
imaging	O
in	O
challenging	O
scenarios	O
with	O
a	O
strict	O
limit	O
on	O
optical	O
flux	O
.	O

Code	Miscellaneous-term
is	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
JiayongO	O
-	O
O	O
/	O
PENonLocal	O
.	O

In	O
this	O
article	O
,	O
we	O
design	O
the	O
Conditional	AI/ML/DL-technique
Kernel	AI/ML/DL-technique
Bures	AI/ML/DL-technique
(	AI/ML/DL-technique
CKB	AI/ML/DL-technique
)	AI/ML/DL-technique
metric	O
for	O
characterizing	O
conditional	O
distribution	O
discrepancy	O
and	O
derive	O
an	O
empirical	O
estimation	O
with	O
convergence	O
guarantee	O
.	O

CKB	AI/ML/DL-technique
provides	O
a	O
statistical	O
and	O
interpretable	O
approach	O
,	O
under	O
the	O
optimal	O
transportation	O
framework	O
,	O
to	O
understand	O
the	O
knowledge	O
transfer	O
mechanism	O
.	O

CKB	AI/ML/DL-technique
can	O
be	O
used	O
as	O
a	O
plug	O
-	O
and	O
-	O
play	O
module	O
and	O
placed	O
onto	O
the	O
loss	O
layer	O
in	O
deep	O
networks	O
thus	O
,	O
it	O
plays	O
the	O
bottleneck	O
role	O
in	O
representation	O
learning	O
.	O

From	O
this	O
perspective	O
,	O
the	O
new	O
method	O
with	O
network	O
architecture	O
is	O
abbreviated	O
as	O
BuresNet	AI/ML/DL-technique
and	O
it	O
can	O
be	O
used	O
extract	O
conditional	O
invariant	O
features	O
for	O
both	O
UDA	O
and	O
FSL	O
tasks	O
.	O

BuresNet	AI/ML/DL-technique
can	O
be	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O

Extensive	O
experiment	O
results	O
on	O
several	O
benchmark	O
datasets	Miscellaneous-term
validate	O
the	O
effectiveness	O
of	O
BuresNet	AI/ML/DL-technique
.	O

Extensive	O
experiment	O
results	O
on	O
several	O
benchmark	O
datasets	Miscellaneous-term
validate	O
the	O
effectiveness	O
of	O
BuresNet	AI/ML/DL-technique
.	O

In	O
this	O
study	O
,	O
we	O
propose	O
a	O
novel	O
method	O
,	O
called	O
Class	AI/ML/DL-technique
-	AI/ML/DL-technique
Specific	AI/ML/DL-technique
Semantic	AI/ML/DL-technique
Reconstruction	AI/ML/DL-technique
(	AI/ML/DL-technique
CSSR	AI/ML/DL-technique
)	AI/ML/DL-technique
that	O
integrates	O
the	O
power	O
of	O
AE	O
and	O
prototype	O
learning	O
.	O

Specifically	O
,	O
CSSR	AI/ML/DL-technique
replaces	O
prototype	O
points	O
with	O
manifolds	O
represented	O
by	O
class	O
-	O
specific	O
AEs	O
.	O

Unlike	O
conventional	O
prototype	O
-	O
based	O
methods	O
,	O
CSSR	AI/ML/DL-technique
models	O
each	O
known	O
class	O
on	O
an	O
individual	O
AE	AI/ML/DL-term
manifold	AI/ML/DL-term
and	O
measures	O
class	O
belongingness	O
through	O
AE	O
'	O
s	O
reconstruction	O
error	O
.	O

Unlike	O
conventional	O
prototype	O
-	O
based	O
methods	O
,	O
CSSR	AI/ML/DL-technique
models	O
each	O
known	O
class	O
on	O
an	O
individual	O
AE	AI/ML/DL-term
manifold	AI/ML/DL-term
and	O
measures	O
class	O
belongingness	O
through	O
AE	O
'	O
s	O
reconstruction	O
error	O
.	O

The	O
results	O
of	O
experiments	O
conducted	O
on	O
multiple	O
datasets	Miscellaneous-term
show	O
that	O
the	O
proposed	O
method	O
achieves	O
outstanding	O
performance	O
in	O
both	O
close	O
and	O
open	O
set	O
recognition	O
and	O
is	O
sufficiently	O
simple	O
and	O
flexible	O
to	O
incorporate	O
into	O
existing	O
frameworks	O
.	O

To	O
overcome	O
the	O
above	O
limitation	O
,	O
in	O
consideration	O
of	O
the	O
fact	O
that	O
a	O
network	O
can	O
be	O
regarded	O
as	O
a	O
pattern	O
composed	O
of	O
communities	O
,	O
we	O
introduce	O
Turing	AI/ML/DL-term
pattern	AI/ML/DL-term
dynamic	AI/ML/DL-term
as	O
theory	O
support	O
to	O
construct	O
the	O
network	O
evolution	O
model	O
.	O

Specifically	O
,	O
we	O
develop	O
a	O
Reaction	O
-	O
Diffusion	O
model	O
according	O
to	O
Q	O
-	O
Learning	O
technology	O
(	O
RDQL	AI/ML/DL-technique
,	O
in	O
which	O
each	O
node	O
regarded	O
as	O
an	O
intelligent	O
agent	O
makes	O
a	O
behavior	O
choice	O
to	O
update	O
its	O
relationships	O
,	O
based	O
on	O
the	O
utility	O
and	O
behavioral	O
strategy	O
at	O
every	O
time	O
step	O
.	O

The	O
effectiveness	O
of	O
the	O
RDQL	AI/ML/DL-technique
model	AI/ML/DL-technique
has	O
also	O
been	O
verified	O
by	O
its	O
application	O
in	O
real	O
networks	O
.	O

Furthermore	O
,	O
the	O
depth	O
analysis	O
of	O
the	O
RDQL	AI/ML/DL-technique
model	AI/ML/DL-technique
provides	O
a	O
conclusion	O
that	O
the	O
proportion	O
of	O
exploration	O
and	O
exploitation	O
behaviors	O
of	O
nodes	O
is	O
the	O
only	O
factor	O
affecting	O
the	O
formation	O
of	O
communities	O
.	O

The	O
proposed	O
RDQL	AI/ML/DL-technique
model	AI/ML/DL-technique
has	O
potential	O
to	O
be	O
the	O
basic	O
theoretical	O
tool	O
for	O
studying	O
network	O
stability	O
and	O
dynamics	O
.	O

In	O
this	O
work	O
,	O
we	O
systematically	O
construct	O
the	O
perturbed	O
lens	O
system	O
model	O
to	O
illustrate	O
the	O
relationship	O
between	O
the	O
deviated	O
system	O
parameters	O
and	O
the	O
spatial	Computer/vision-term
frequency	Computer/vision-term
response	Computer/vision-term
(	Computer/vision-term
SFR	Computer/vision-term
)	Computer/vision-term
measured	O
from	O
photographs	O
.	O

To	O
further	O
address	O
this	O
issue	O
,	O
an	O
optimization	O
framework	O
is	O
proposed	O
based	O
on	O
this	O
model	O
to	O
build	O
proxy	O
cameras	O
from	O
the	O
machining	O
samples	O
’	O
SFRs	Computer/vision-term
.	O

Engaging	O
with	O
the	O
proxy	O
cameras	O
,	O
we	O
synthetic	O
data	O
pairs	O
,	O
which	O
encode	O
the	O
optical	O
aberrations	O
and	O
the	O
random	O
manufacturing	O
biases	O
,	O
for	O
training	O
the	O
learning	O
-	O
based	O
algorithms	Miscellaneous-term
.	O

Therefore	O
,	O
we	O
propose	O
a	O
dilated	Computer/Vision-technique
Omni	Computer/Vision-technique
-	Computer/Vision-technique
dimensional	Computer/Vision-technique
dynamic	Computer/Vision-technique
convolution	Computer/Vision-technique
(	Computer/Vision-technique
DOConv	Computer/Vision-technique
)	Computer/Vision-technique
and	O
implement	O
it	O
in	O
post	O
-	O
processing	O
to	O
account	O
for	O
the	O
manufacturing	O
degradation	O
.	O

Active	O
learning	O
(	O
AL	O
)	O
has	O
been	O
successful	O
based	O
on	O
the	O
premise	O
that	O
labeled	O
and	O
unlabeled	O
data	O
come	O
from	O
the	O
same	O
class	AI/ML/DL-term
distribution	AI/ML/DL-term
.	O

However	O
,	O
its	O
performance	O
undergoes	O
a	O
severe	O
deterioration	O
under	O
class	O
distribution	O
mismatch	O
class	AI/ML/DL-term
distribution	AI/ML/DL-term
led	O
data	O
contain	O
numerous	O
instances	O
out	O
of	O
the	O
class	O
distribution	O
of	O
labeled	O
data	O
.	O

In	O
this	O
article	O
,	O
we	O
solve	O
this	O
practical	O
yet	O
rarely	O
studied	O
problem	O
by	O
minimizing	O
the	O
AL	AI/ML/DL-term
error	AI/ML/DL-term
which	O
is	O
formally	O
defined	O
and	O
decomposed	O
as	O
the	O
valid	O
query	O
error	O
and	O
invalid	O
query	O
error	O
.	O

In	O
light	O
of	O
this	O
discovery	O
,	O
we	O
propose	O
a	O
contrastive	O
AL	O
framework	O
,	O
named	O
ConAL	AI/ML/DL-technique
to	O
simultaneously	O
learn	O
the	O
semantics	O
and	O
distinctiveness	O
of	O
the	O
instances	O
by	O
contrastive	O
techniques	O
,	O
thereby	O
reducing	O
the	O
invalid	O
query	O
error	O
and	O
valid	O
query	O
error	O
,	O
respectively	O
.	O

Theoretically	O
,	O
we	O
prove	O
that	O
the	O
AL	AI/ML/DL-term
error	AI/ML/DL-term
of	O
ConAL	AI/ML/DL-technique
has	O
a	O
tight	O
upper	O
bound	O
.	O

Theoretically	O
,	O
we	O
prove	O
that	O
the	O
AL	AI/ML/DL-term
error	AI/ML/DL-term
of	O
ConAL	AI/ML/DL-technique
has	O
a	O
tight	O
upper	O
bound	O
.	O

Experimentally	O
,	O
ConAL	AI/ML/DL-technique
achieves	O
superior	O
performance	O
on	O
two	O
benchmark	O
datasets	Miscellaneous-term
CIFAR10	O
and	O
CIFAR100	O
and	O
a	O
cross	O
-	O
dataset	O
with	O
class	AI/ML/DL-term
distribution	AI/ML/DL-term
across	O
multi	Miscellaneous-term
-	Miscellaneous-term
datasets	Miscellaneous-term
.	O

Experimentally	O
,	O
ConAL	AI/ML/DL-technique
achieves	O
superior	O
performance	O
on	O
two	O
benchmark	O
datasets	Miscellaneous-term
CIFAR10	O
and	O
CIFAR100	O
and	O
a	O
cross	O
-	O
dataset	O
with	O
class	AI/ML/DL-term
distribution	AI/ML/DL-term
across	O
multi	Miscellaneous-term
-	Miscellaneous-term
datasets	Miscellaneous-term
.	O

Experimentally	O
,	O
ConAL	AI/ML/DL-technique
achieves	O
superior	O
performance	O
on	O
two	O
benchmark	O
datasets	Miscellaneous-term
CIFAR10	O
and	O
CIFAR100	O
and	O
a	O
cross	O
-	O
dataset	O
with	O
class	AI/ML/DL-term
distribution	AI/ML/DL-term
across	O
multi	Miscellaneous-term
-	Miscellaneous-term
datasets	Miscellaneous-term
.	O

Furthermore	O
,	O
we	O
validate	O
that	O
the	O
ConAL	AI/ML/DL-technique
technique	O
performs	O
admirably	O
even	O
on	O
the	O
realistic	O
dataset	Miscellaneous-term
.	O

Furthermore	O
,	O
we	O
validate	O
that	O
the	O
ConAL	AI/ML/DL-technique
technique	O
performs	O
admirably	O
even	O
on	O
the	O
realistic	O
dataset	Miscellaneous-term
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
ConAL	AI/ML/DL-technique
AL	O
the	O
first	O
AL	O
work	O
for	O
class	O
distribution	O
mismatch	O
.	O

In	O
practice	O
,	O
the	O
SGG	O
datasets	Miscellaneous-term
are	O
often	O
dual	AI/ML/DL-term
imbalanced	AI/ML/DL-term
presented	O
as	O
a	O
large	O
number	O
of	O
backgrounds	O
and	O
rarely	O
few	O
foregrounds	O
,	O
and	O
highly	O
skewed	O
foreground	O
relationships	O
categories	O
(	O
i	O
.	O
e	O
.,	O
the	O
long	O
-	O
tailed	O
distribution	O
.	O

In	O
practice	O
,	O
the	O
SGG	O
datasets	Miscellaneous-term
are	O
often	O
dual	AI/ML/DL-term
imbalanced	AI/ML/DL-term
presented	O
as	O
a	O
large	O
number	O
of	O
backgrounds	O
and	O
rarely	O
few	O
foregrounds	O
,	O
and	O
highly	O
skewed	O
foreground	O
relationships	O
categories	O
(	O
i	O
.	O
e	O
.,	O
the	O
long	O
-	O
tailed	O
distribution	O
.	O

Meanwhile	O
,	O
a	O
causal	O
graph	O
of	O
content	O
and	O
context	O
is	O
designed	O
to	O
remove	O
the	O
context	AI/ML/DL-term
bias	AI/ML/DL-term
and	O
learn	O
unbiased	O
relationship	O
features	O
via	O
casual	O
intervention	O
tree	O
.	O

Extensive	O
experimental	O
results	O
on	O
two	O
extremely	O
imbalanced	O
datasets	Miscellaneous-term
VG150	O
and	O
VrR	O
-	O
VG	O
demonstrate	O
our	O
DSDI	O
outperforms	O
other	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
.	O

Federated	O
averaging	O
(	O
FedAvg	O
)	O
is	O
a	O
communication	O
-	O
efficient	O
algorithm	Miscellaneous-term
for	O
distributed	O
training	O
with	O
an	O
enormous	O
number	O
of	O
clients	O
.	O

This	O
central	O
server	O
distributes	O
the	O
parameters	AI/ML/DL-term
parameters	AI/ML/DL-term
ent	O
and	O
collects	O
the	O
updated	O
parameters	O
from	O
clients	O
.	O

To	O
this	O
end	O
,	O
in	O
this	O
paper	O
,	O
we	O
study	O
the	O
decentralized	AI/ML/DL-technique
FedAvg	AI/ML/DL-technique
with	AI/ML/DL-technique
momentum	AI/ML/DL-technique
(	AI/ML/DL-technique
DFedAvgM	AI/ML/DL-technique
)	AI/ML/DL-technique
implemented	O
on	O
clients	O
that	O
are	O
connected	O
by	O
an	O
undirected	Miscellaneous-term
graph	Miscellaneous-term
.	O

To	O
this	O
end	O
,	O
in	O
this	O
paper	O
,	O
we	O
study	O
the	O
decentralized	AI/ML/DL-technique
FedAvg	AI/ML/DL-technique
with	AI/ML/DL-technique
momentum	AI/ML/DL-technique
(	AI/ML/DL-technique
DFedAvgM	AI/ML/DL-technique
)	AI/ML/DL-technique
implemented	O
on	O
clients	O
that	O
are	O
connected	O
by	O
an	O
undirected	Miscellaneous-term
graph	Miscellaneous-term
.	O

In	O
DFedAvgM	AI/ML/DL-technique
all	O
clients	O
perform	O
stochastic	O
gradient	O
descent	O
with	O
momentum	O
and	O
communicate	O
with	O
their	O
neighbors	O
only	O
.	O

To	O
further	O
reduce	O
the	O
communication	O
cost	O
,	O
we	O
also	O
consider	O
the	O
quantized	O
DFedAvgM	AI/ML/DL-technique
.	O

We	O
prove	O
convergence	O
of	O
the	O
(	O
quantized	O
)	O
DFedAvgM	AI/ML/DL-technique
under	O
trivial	O
assumptions	O
;	O
the	O
convergence	O
rate	O
can	O
be	O
improved	O
to	O
sublinear	O
when	O
the	O
loss	O
function	O
satisfies	O
the	O
PŁ	O
property	O
.	O

Numerically	O
,	O
we	O
find	O
that	O
the	O
proposed	O
algorithm	Miscellaneous-term
outperforms	O
FedAvg	O
in	O
both	O
convergence	O
speed	O
and	O
communication	O
cost	O
.	O

Despite	O
the	O
progress	O
of	O
action	O
recognition	O
algorithms	Miscellaneous-term
in	O
trimmed	Computer/vision-term
videos	Computer/vision-term
the	O
majority	O
of	O
real	O
-	O
world	O
videos	O
are	O
lengthy	O
and	O
untrimmed	O
with	O
sparse	O
segments	O
of	O
interest	O
.	O

Despite	O
the	O
progress	O
of	O
action	O
recognition	O
algorithms	Miscellaneous-term
in	O
trimmed	Computer/vision-term
videos	Computer/vision-term
the	O
majority	O
of	O
real	O
-	O
world	O
videos	O
are	O
lengthy	O
and	O
untrimmed	O
with	O
sparse	O
segments	O
of	O
interest	O
.	O

This	O
article	O
provides	O
an	O
extensive	O
overview	O
of	O
deep	O
learning	O
based	O
algorithms	Miscellaneous-term
to	O
tackle	O
temporal	O
action	O
detection	O
in	O
untrimmed	O
videos	O
with	O
different	O
supervision	O
levels	O
including	O
fully	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
weakly	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
unsupervised	AI/ML/DL-term
self	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
and	O
semi	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
.	O

This	O
article	O
provides	O
an	O
extensive	O
overview	O
of	O
deep	O
learning	O
based	O
algorithms	Miscellaneous-term
to	O
tackle	O
temporal	O
action	O
detection	O
in	O
untrimmed	O
videos	O
with	O
different	O
supervision	O
levels	O
including	O
fully	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
weakly	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
unsupervised	AI/ML/DL-term
self	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
and	O
semi	AI/ML/DL-term
-	AI/ML/DL-term
supervised	AI/ML/DL-term
.	O

In	O
addition	O
,	O
this	O
article	O
reviews	O
advances	O
in	O
spatio	O
-	O
temporal	O
action	O
detection	O
temporal	Computer/vision-term
ions	O
are	O
localized	O
in	O
both	O
temporal	O
and	O
spatial	Computer/vision-term
dimensions	Computer/vision-term
.	O

Moreover	O
,	O
the	O
commonly	O
used	O
action	O
detection	O
benchmark	O
datasets	Miscellaneous-term
and	O
evaluation	O
metrics	O
are	O
described	O
,	O
and	O
the	O
performance	O
of	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
methods	O
are	O
compared	O
.	O

To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
DeepLogic	AI/ML/DL-technique
a	O
framework	O
with	O
joint	O
learning	O
of	O
neural	O
perception	O
and	O
logical	O
reasoning	O
such	O
that	O
these	O
two	O
components	O
are	O
jointly	O
optimized	O
through	O
mutual	O
supervision	O
signals	O
.	O

In	O
particular	O
,	O
the	O
proposed	O
DeepLogic	AI/ML/DL-technique
framework	O
contains	O
a	O
deep	O
-	O
logic	O
module	O
that	O
is	O
capable	O
of	O
representing	O
complex	O
first	O
-	O
order	O
-	O
logic	O
formulas	O
in	O
a	O
tree	O
structure	O
with	O
basic	O
logic	O
operators	O
.	O

We	O
then	O
theoretically	O
quantify	O
the	O
mutual	O
supervision	O
signals	O
and	O
propose	O
the	O
deep	O
&	O
logic	O
optimization	O
algorithm	Miscellaneous-term
for	O
joint	O
optimization	O
.	O

We	O
further	O
prove	O
the	O
convergence	O
of	O
DeepLogic	AI/ML/DL-technique
and	O
conduct	O
extensive	O
experiments	O
on	O
model	O
performance	O
,	O
convergence	O
,	O
and	O
generalization	O
,	O
as	O
well	O
as	O
its	O
extension	O
to	O
the	O
continuous	O
domain	O
.	O

The	O
experimental	O
results	O
show	O
that	O
through	O
jointly	O
learning	O
both	O
perceptual	O
ability	O
and	O
logic	O
formulas	O
in	O
a	O
weakly	AI/ML/DL-term
supervised	AI/ML/DL-term
manner	O
,	O
our	O
proposed	O
DeepLogic	AI/ML/DL-technique
framework	O
can	O
significantly	O
outperform	O
DNN	O
based	O
baselines	Miscellaneous-term
by	O
a	O
great	O
margin	O
and	O
beat	O
other	O
strong	O
baselines	O
without	O
out	O
-	O
of	O
-	O
box	O
tools	O
.	O

The	O
experimental	O
results	O
show	O
that	O
through	O
jointly	O
learning	O
both	O
perceptual	O
ability	O
and	O
logic	O
formulas	O
in	O
a	O
weakly	AI/ML/DL-term
supervised	AI/ML/DL-term
manner	O
,	O
our	O
proposed	O
DeepLogic	AI/ML/DL-technique
framework	O
can	O
significantly	O
outperform	O
DNN	O
based	O
baselines	Miscellaneous-term
by	O
a	O
great	O
margin	O
and	O
beat	O
other	O
strong	O
baselines	O
without	O
out	O
-	O
of	O
-	O
box	O
tools	O
.	O

The	O
experimental	O
results	O
show	O
that	O
through	O
jointly	O
learning	O
both	O
perceptual	O
ability	O
and	O
logic	O
formulas	O
in	O
a	O
weakly	AI/ML/DL-term
supervised	AI/ML/DL-term
manner	O
,	O
our	O
proposed	O
DeepLogic	AI/ML/DL-technique
framework	O
can	O
significantly	O
outperform	O
DNN	O
based	O
baselines	Miscellaneous-term
by	O
a	O
great	O
margin	O
and	O
beat	O
other	O
strong	O
baselines	O
without	O
out	O
-	O
of	O
-	O
box	O
tools	O
.	O

We	O
argue	O
that	O
such	O
a	O
mechanism	O
has	O
fundamental	O
limitations	O
in	O
building	O
an	O
effective	O
regression	AI/ML/DL-term
loss	AI/ML/DL-term
for	O
rotation	O
detection	O
,	O
especially	O
for	O
high	O
-	O
precision	O
detection	O
with	O
high	O
IoU	O
(	O
e	O
.	O
g	O
.,	O
0	O
.	O
75	O
.	O

A	O
direct	O
advantage	O
is	O
that	O
our	O
new	O
regression	AI/ML/DL-term
loss	AI/ML/DL-term
regarding	O
the	O
distance	O
between	O
two	O
Gaussians	O
e	O
.	O
g	O
.,	O
Kullback	O
-	O
Leibler	O
Divergence	O
(	O
KLD	O
)	O
can	O
well	O
align	O
the	O
actual	O
detection	O
performance	O
metric	O
,	O
which	O
is	O
not	O
well	O
addressed	O
in	O
existing	O
methods	O
.	O

Interestingly	O
,	O
by	O
analyzing	O
the	O
BBox	Computer/vision-term
parameters	Computer/vision-term
’	Computer/vision-term
gradients	Computer/vision-term
under	O
our	O
Gaussian	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
KLD	AI/ML/DL-term
loss	AI/ML/DL-term
we	O
show	O
that	O
these	O
parameters	O
are	O
dynamically	O
updated	O
with	O
interpretable	O
physical	O
meaning	O
,	O
which	O
help	O
explain	O
the	O
effectiveness	O
of	O
our	O
approach	O
,	O
especially	O
for	O
high	O
-	O
precision	O
detection	O
.	O

Interestingly	O
,	O
by	O
analyzing	O
the	O
BBox	Computer/vision-term
parameters	Computer/vision-term
’	Computer/vision-term
gradients	Computer/vision-term
under	O
our	O
Gaussian	AI/ML/DL-term
-	AI/ML/DL-term
based	AI/ML/DL-term
KLD	AI/ML/DL-term
loss	AI/ML/DL-term
we	O
show	O
that	O
these	O
parameters	O
are	O
dynamically	O
updated	O
with	O
interpretable	O
physical	O
meaning	O
,	O
which	O
help	O
explain	O
the	O
effectiveness	O
of	O
our	O
approach	O
,	O
especially	O
for	O
high	O
-	O
precision	O
detection	O
.	O

We	O
extend	O
our	O
approach	O
from	O
2	O
-	O
D	O
to	O
3	O
-	O
D	O
with	O
a	O
tailored	O
algorithm	Miscellaneous-term
design	O
to	O
handle	O
the	O
heading	O
estimation	O
,	O
and	O
experimental	O
results	O
on	O
twelve	O
public	O
datasets	Miscellaneous-term
(	O
2	O
-	O
D	O
/	O
3	O
-	O
D	O
,	O
aerial	O
/	O
text	O
/	O
face	O
images	O
)	O
with	O
various	O
base	O
detectors	O
show	O
its	O
superiority	O
.	O

We	O
discuss	O
two	O
variants	O
of	O
our	O
discrete	Computer/Vision-technique
search	Computer/Vision-technique
photometric	Computer/Vision-technique
stereo	Computer/Vision-technique
(	Computer/Vision-technique
DSPS	Computer/Vision-technique
)	Computer/Vision-technique
one	O
working	O
with	O
continuous	O
linear	O
combinations	O
of	O
BRDF	O
bases	O
and	O
the	O
other	O
working	O
with	O
discrete	O
BRDFs	O
BRDF	O
ed	O
from	O
a	O
BRDF	O
space	O
.	O

Experiments	O
show	O
that	O
DSPS	Computer/Vision-technique
has	O
comparable	O
accuracy	O
to	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
exemplar	O
-	O
based	O
photometric	O
stereo	O
methods	O
while	O
achieving	O
10	O
–	O
100x	O
acceleration	O
.	O

Experiments	O
show	O
that	O
DSPS	Computer/Vision-technique
has	O
comparable	O
accuracy	O
to	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
exemplar	O
-	O
based	O
photometric	O
stereo	O
methods	O
while	O
achieving	O
10	O
–	O
100x	O
acceleration	O
.	O

Wikipedia	Miscellaneous-term
combines	O
the	O
power	O
of	O
AI	O
solutions	O
and	O
human	O
reviewers	O
to	O
safeguard	O
article	O
quality	O
.	O

We	O
present	O
a	O
method	O
that	O
(	O
1	O
)	O
gathers	O
the	O
semantic	O
information	O
surrounding	O
the	O
context	O
of	O
each	O
mathematical	O
formulae	O
,	O
(	O
2	O
)	O
provides	O
access	O
to	O
the	O
information	O
in	O
a	O
graph	Data/Mining/Information/Retrieval-term
-	Data/Mining/Information/Retrieval-term
structured	Data/Mining/Information/Retrieval-term
dependency	Data/Mining/Information/Retrieval-term
hierarchy	O
,	O
and	O
(	O
3	O
)	O
performs	O
automatic	O
plausibility	O
checks	O
on	O
equations	O
.	O

Our	O
system	O
,	O
$\	O
text	O
{	O
L	O
}{	O
A	O
}\	O
text	O
{	O
C	O
}{\	O
scriptsize	O
{\	O
text	O
{	O
AS	O
}}}\	O
text	O
{	O
T	O
}$	O
LACAST	AI/ML/DL-technique
verified	O
358	O
out	O
of	O
1	O
,	O
516	O
equations	O
as	O
error	O
-	O
free	O
.	O

$\	O
text	O
{	O
L	O
}{	O
A	O
}\	O
text	O
{	O
C	O
}{\	O
scriptsize	O
\	O
text	O
{	O
AS	O
}}\	O
text	O
{	O
T	O
}$	O
LACAST	AI/ML/DL-technique
successfully	O
translated	O
27	O
%	O
of	O
the	O
mathematical	O
expressions	O
and	O
outperformed	O
existing	O
translation	O
approaches	O
by	O
16	O
%.	O

Additionally	O
,	O
$\	O
text	O
{	O
L	O
}{	O
A	O
}\	O
text	O
{	O
C	O
}{\	O
scriptsize	O
\	O
text	O
{	O
AS	O
}}\	O
text	O
{	O
T	O
}$	O
LACAST	AI/ML/DL-technique
achieved	O
an	O
F1	O
score	O
of	O
.	O
495	O
for	O
annotating	O
mathematical	O
expressions	O
with	O
relevant	O
textual	O
descriptions	O
,	O
which	O
is	O
a	O
significant	O
step	O
towards	O
advancing	O
searchability	O
,	O
readability	O
,	O
and	O
accessibility	O
of	O
mathematical	O
formulae	O
in	O
Wikipedia	O
.	O

A	O
prototype	O
of	O
$\	O
text	O
{	O
L	O
}{	O
A	O
}\	O
text	O
{	O
C	O
}{\	O
scriptsize	O
\	O
text	O
{	O
AS	O
}}\	O
text	O
{	O
T	O
}$	O
LACAST	AI/ML/DL-technique
and	O
the	O
semantically	O
enhanced	O
Wikipedia	O
articles	O
are	O
available	O
at	O
:	O
https	O
://	O
tpami	O
.	O
wmflabs	O
.	O
org	O
.	O

Camera	O
-	O
based	O
3D	O
object	O
detectors	O
are	O
welcome	O
due	O
to	O
their	O
wider	O
deployment	O
and	O
lower	O
price	O
than	O
LiDAR	Computer/vision-term
sensors	Computer/vision-term
.	O

We	O
polish	O
the	O
stereo	O
modeling	O
and	O
propose	O
the	O
advanced	O
version	O
,	O
DSGN	Computer/Vision-technique
++	Computer/Vision-technique
aiming	O
to	O
enhance	O
effective	O
information	O
flow	O
throughout	O
the	O
2D	O
-	O
to	O
-	O
3D	O
pipeline	O
in	O
three	O
main	O
aspects	O
.	O

Second	O
,	O
for	O
grasping	O
differently	O
spaced	O
features	O
,	O
we	O
present	O
a	O
novel	O
stereo	O
volume	O
–	O
Dual	Computer/Vision-technique
-	Computer/Vision-technique
view	Computer/Vision-technique
Stereo	Computer/Vision-technique
Volume	Computer/Vision-technique
(	Computer/Vision-technique
DSV	Computer/Vision-technique
)	Computer/Vision-technique
that	O
integrates	O
front	O
-	O
view	O
and	O
top	O
-	O
view	O
features	O
and	O
reconstructs	O
sub	Computer/vision-term
-	Computer/vision-term
voxel	Computer/vision-term
depth	Computer/vision-term
in	O
the	O
camera	O
frustum	O
.	O

Second	O
,	O
for	O
grasping	O
differently	O
spaced	O
features	O
,	O
we	O
present	O
a	O
novel	O
stereo	O
volume	O
–	O
Dual	Computer/Vision-technique
-	Computer/Vision-technique
view	Computer/Vision-technique
Stereo	Computer/Vision-technique
Volume	Computer/Vision-technique
(	Computer/Vision-technique
DSV	Computer/Vision-technique
)	Computer/Vision-technique
that	O
integrates	O
front	O
-	O
view	O
and	O
top	O
-	O
view	O
features	O
and	O
reconstructs	O
sub	Computer/vision-term
-	Computer/vision-term
voxel	Computer/vision-term
depth	Computer/vision-term
in	O
the	O
camera	O
frustum	O
.	O

Code	Miscellaneous-term
is	O
available	O
at	O
https	O
://	O
github	O
.	O
com	O
/	O
chenyilun95	O
/	O
DSGN2	O
.	O

Dynamic	O
networks	O
have	O
shown	O
their	O
promising	O
capability	O
in	O
reducing	O
theoretical	O
computation	Miscellaneous-term
complexity	Miscellaneous-term
by	O
adapting	O
their	O
architectures	O
to	O
the	O
input	O
during	O
inference	AI/ML/DL-term
.	O

Dynamic	O
networks	O
have	O
shown	O
their	O
promising	O
capability	O
in	O
reducing	O
theoretical	O
computation	Miscellaneous-term
complexity	Miscellaneous-term
by	O
adapting	O
their	O
architectures	O
to	O
the	O
input	O
during	O
inference	AI/ML/DL-term
.	O

However	O
,	O
their	O
practical	O
runtime	O
usually	O
lags	O
behind	O
the	O
theoretical	AI/ML/DL-term
acceleration	AI/ML/DL-term
due	O
to	O
inefficient	O
sparsity	Miscellaneous-term
.	O

However	O
,	O
their	O
practical	O
runtime	O
usually	O
lags	O
behind	O
the	O
theoretical	AI/ML/DL-term
acceleration	AI/ML/DL-term
due	O
to	O
inefficient	O
sparsity	Miscellaneous-term
.	O

In	O
this	O
paper	O
,	O
we	O
explore	O
a	O
hardware	O
-	O
efficient	O
dynamic	AI/ML/DL-term
inference	AI/ML/DL-term
regime	O
,	O
named	O
dynamic	O
weight	O
slicing	O
that	O
can	O
generalized	O
well	O
on	O
multiple	O
dimensions	O
in	O
both	O
CNNs	O
and	O
transformers	O
(	O
e	O
.	O
g	O
.	O
kernel	AI/ML/DL-term
size	AI/ML/DL-term
embedding	AI/ML/DL-term
dimension	AI/ML/DL-term
number	O
of	O
heads	O
,	O
etc	O
.).	O

During	O
inference	AI/ML/DL-term
weights	O
are	O
progressively	O
sliced	O
beginning	O
with	O
the	O
most	O
important	O
elements	O
to	O
less	O
important	O
ones	O
to	O
achieve	O
different	O
model	O
capacity	O
for	O
inputs	O
with	O
diverse	O
difficulty	O
levels	O
.	O

Based	O
on	O
this	O
conception	O
,	O
we	O
present	O
DS	Computer/Vision-technique
-	Computer/Vision-technique
CNN	Computer/Vision-technique
++	Computer/Vision-technique
and	O
DS	Computer/Vision-technique
-	Computer/Vision-technique
ViT	Computer/Vision-technique
++	Computer/Vision-technique
by	O
carefully	O
designing	O
the	O
double	O
headed	O
dynamic	O
gate	O
and	O
the	O
overall	O
network	O
architecture	O
.	O

We	O
further	O
propose	O
dynamic	O
idle	O
slicing	O
to	O
address	O
the	O
drastic	O
reduction	O
of	O
embedding	O
dimension	O
in	O
DS	Computer/Vision-technique
-	Computer/Vision-technique
ViT	Computer/Vision-technique
++	Computer/Vision-technique
.	O

In	O
Stage	O
I	O
,	O
in	O
-	O
place	O
bootstrapping	O
(	O
IB	O
)	O
and	O
multi	O
-	O
view	O
consistency	O
(	O
MvCo	O
)	O
are	O
proposed	O
to	O
stablize	O
and	O
improve	O
the	O
training	O
of	O
DS	Computer/Vision-technique
-	Computer/Vision-technique
CNN	Computer/Vision-technique
++	Computer/Vision-technique
and	O
DS	Computer/Vision-technique
-	Computer/Vision-technique
ViT	Computer/Vision-technique
++	Computer/Vision-technique
supernet	O
,	O
respectively	O
.	O

Extensive	O
experiments	O
on	O
4	O
datasets	Miscellaneous-term
and	O
3	O
different	O
network	O
architectures	O
demonstrate	O
our	O
methods	O
consistently	O
outperform	O
the	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
static	O
and	O
dynamic	O
model	O
compression	O
methods	O
by	O
a	O
large	O
margin	O
(	O
up	O
to	O
6	O
.	O
6	O
%).	O

With	O
the	O
theoretical	O
framework	O
,	O
we	O
propose	O
a	O
novel	O
objective	AI/ML/DL-term
function	AI/ML/DL-term
which	O
jointly	O
solves	O
the	O
aforementioned	O
two	O
problems	O
and	O
achieves	O
a	O
provable	O
sufficient	O
and	O
minimal	O
representation	O
.	O

In	O
detail	O
,	O
the	O
consistency	O
learning	O
is	O
performed	O
by	O
maximizing	O
the	O
mutual	O
information	O
of	O
different	O
views	O
through	O
contrastive	O
learning	O
and	O
the	O
missing	O
views	O
are	O
recovered	O
by	O
minimizing	O
the	O
conditional	AI/ML/DL-term
entropy	AI/ML/DL-term
through	O
dual	O
prediction	O
.	O

Extensive	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
remarkably	O
outperforms	O
20	O
competitive	O
multi	O
-	O
view	O
learning	O
methods	O
on	O
six	O
datasets	Miscellaneous-term
in	O
terms	O
of	O
clustering	O
classification	O
and	O
human	O
action	O
recognition	O
.	O

At	O
the	O
theoretical	O
level	O
,	O
we	O
propose	O
a	O
new	O
representation	O
framework	O
for	O
forensics	O
,	O
called	O
dense	Computer/Vision-technique
invariant	Computer/Vision-technique
representation	Computer/Vision-technique
(	Computer/Vision-technique
DIR	Computer/Vision-technique
)	Computer/Vision-technique
which	O
is	O
characterized	O
by	O
stable	O
description	O
with	O
mathematical	O
guarantees	O
.	O

At	O
the	O
implementation	O
level	O
,	O
the	O
discrete	O
calculation	O
problems	O
of	O
DIR	Computer/Vision-technique
are	O
discussed	O
,	O
and	O
the	O
corresponding	O
accurate	O
and	O
fast	O
solutions	O
are	O
designed	O
with	O
generic	O
nature	O
and	O
constant	O
complexity	O
.	O

We	O
demonstrate	O
the	O
above	O
arguments	O
on	O
the	O
dense	O
-	O
domain	O
pattern	O
detection	O
and	O
matching	O
experiments	O
,	O
providing	O
comparison	O
results	O
with	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
descriptors	O
.	O

Also	O
,	O
at	O
the	O
application	O
level	O
,	O
the	O
proposed	O
DIR	Computer/Vision-technique
is	O
initially	O
explored	O
in	O
passive	O
and	O
active	O
forensics	O
,	O
namely	O
copy	O
-	O
move	O
forgery	O
detection	O
and	O
perceptual	O
hashing	O
exhibiting	O
the	O
benefits	O
in	O
fulfilling	O
the	O
requirements	O
of	O
such	O
forensic	O
tasks	O
.	O

The	O
main	O
contributions	O
of	O
the	O
present	O
work	O
include	O
:	O
(	O
i	O
)	O
a	O
new	O
descent	O
direction	O
for	O
the	O
rank	O
-	O
one	O
SNMF	O
is	O
derived	O
and	O
a	O
strategy	O
for	O
choosing	O
the	O
step	Data/Mining/Information/Retrieval-term
size	Data/Mining/Information/Retrieval-term
along	O
this	O
descent	O
direction	O
is	O
established	O
;	O
(	O
ii	O
)	O
a	O
progressive	O
hierarchical	O
alternating	O
least	O
squares	O
(	O
PHALS	O
)	O
SNMF	O
d	O
for	O
SNMF	O
is	O
developed	O
,	O
which	O
is	O
parameter	O
-	O
free	O
and	O
updates	O
the	O
variables	O
column	O
by	O
column	O
.	O

Our	O
PHALS	O
provides	O
better	O
performance	O
in	O
terms	O
of	O
the	O
computational	O
accuracy	O
the	O
optimality	O
gap	O
,	O
and	O
the	O
CPU	O
time	O
,	O
compared	O
with	O
a	O
number	O
of	O
state	Miscellaneous-term
-	Miscellaneous-term
of	Miscellaneous-term
-	Miscellaneous-term
the	Miscellaneous-term
-	Miscellaneous-term
art	Miscellaneous-term
SNMF	O
methods	O
.	O

