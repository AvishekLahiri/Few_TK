We	O
start	O
with	O
decomposing	O
the	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
layer	AI/ML/DL-focus
problem	AI/ML/DL-focus
into	O
a	O
series	O
of	O
two	O
-	O
layer	O
problems	O
.	O

Although	O
various	O
distributed	AI/ML/DL-focus
machine	AI/ML/DL-focus
learning	AI/ML/DL-focus
schemes	O
have	O
been	O
proposed	O
recently	O
for	O
purely	O
linear	O
models	O
and	O
fully	O
nonparametric	O
models	O
little	O
attention	O
has	O
been	O
paid	O
to	O
distributed	O
optimization	O
for	O
semi	O
-	O
parametric	O
models	O
with	O
multiple	O
structures	O
(	O
e	O
.	O
g	O
.	O
sparsity	O
linearity	O
and	O
nonlinearity	O
.	O

We	O
propose	O
algorithms	O
for	O
approximate	AI/ML/DL-focus
filtering	AI/ML/DL-focus
and	O
smoothing	AI/ML/DL-focus
in	O
high	O
-	O
dimensional	O
Factorial	O
hidden	O
Markov	O
models	O
.	O

This	O
allows	O
the	O
exponential	O
-	O
in	O
-	O
dimension	O
cost	O
of	O
exact	AI/ML/DL-focus
filtering	AI/ML/DL-focus
and	O
smoothing	AI/ML/DL-focus
to	O
be	O
avoided	O
.	O

We	O
prove	O
that	O
the	O
approximation	O
accuracy	Classification-metrics
measured	O
in	O
a	O
local	O
total	O
variation	O
norm	O
is	O
"	O
dimension	O
-	O
free	O
dimension	O
nse	O
that	O
as	O
the	O
overall	O
dimension	O
of	O
the	O
model	O
increases	O
the	O
error	O
bounds	O
we	O
derive	O
do	O
not	O
necessarily	O
degrade	O
.	O

We	O
demonstrate	O
the	O
new	O
algorithms	O
on	O
synthetic	O
examples	O
and	O
a	O
London	AI/ML/DL-focus
Underground	AI/ML/DL-focus
passenger	AI/ML/DL-focus
flow	AI/ML/DL-focus
problem	AI/ML/DL-focus
where	O
the	O
factor	O
graph	O
is	O
effectively	O
given	O
by	O
the	O
train	O
network	O
.	O

We	O
consider	O
the	O
classic	AI/ML/DL-focus
supervised	AI/ML/DL-focus
learning	AI/ML/DL-focus
problem	AI/ML/DL-focus
where	O
a	O
continuous	O
non	O
-	O
negative	O
random	O
label	O
$	O
Y	O
$	O
(	O
e	O
.	O
g	O
.	O
a	O
random	O
duration	O
)	O
is	O
to	O
be	O
predicted	O
based	O
upon	O
observing	O
a	O
random	O
vector	O
$	O
X	O
$	O
valued	O
in	O
$\	O
mathbb	O
{	O
R	O
}^	O
d	O
$	O
with	O
$	O
d	O
\	O
geq	O
1	O
$	O
by	O
means	O
of	O
a	O
regression	O
rule	O
with	O
minimum	O
least	O
square	O
error	O
.	O

In	O
various	O
applications	O
,	O
ranging	O
from	O
industrial	O
quality	O
control	O
to	O
public	O
health	O
through	O
credit	AI/ML/DL-focus
risk	AI/ML/DL-focus
analysis	AI/ML/DL-focus
for	O
instance	O
,	O
training	O
observations	O
can	O
be	O
right	O
censored	O
,	O
meaning	O
that	O
,	O
rather	O
than	O
on	O
independent	O
copies	O
of	O
$(	O
X	O
,	O
Y	O
)$,	O
statistical	O
learning	O
relies	O
on	O
a	O
collection	O
of	O
$	O
n	O
\	O
geq	O
1	O
$	O
independent	O
realizations	O
of	O
the	O
triplet	O
$(	O
X	O
,	O
\;	O
\	O
min	O
\{	O
Y	O
,\;	O
C	O
\},\;	O
\	O
delta	O
)$,	O
where	O
$	O
C	O
$	O
is	O
a	O
nonnegative	O
random	O
variable	O
with	O
unknown	O
distribution	O
modelling	O
censoring	O
and	O
$\	O
delta	O
=\	O
mathbb	O
{	O
I	O
}\{	O
Y	O
\	O
leq	O
C	O
\}$	O
indicates	O
whether	O
the	O
duration	O
is	O
right	O
censored	O
or	O
not	O
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
two	O
challenging	O
problems	O
in	O
explainable	O
AI	O
(	O
XAI	O
)	O
and	O
data	AI/ML/DL-focus
clustering	AI/ML/DL-focus
.	O

The	O
second	O
is	O
implementing	O
discrete	O
$	O
k	O
$-	O
means	O
with	O
a	O
differentiable	O
neural	O
network	O
that	O
embraces	O
the	O
advantages	O
of	O
parallel	Miscellaneous-focus
computing	Miscellaneous-focus
online	AI/ML/DL-focus
clustering	AI/ML/DL-focus
and	O
clustering	NLP-focus
-	NLP-focus
favorable	NLP-focus
representation	NLP-focus
learning	NLP-focus
.	O

This	O
work	O
is	O
one	O
of	O
the	O
few	O
XAI	O
studies	O
on	O
unsupervised	O
learning	O
in	O
particular	O
,	O
data	AI/ML/DL-focus
clustering	AI/ML/DL-focus
.	O

Third	O
,	O
from	O
the	O
view	O
of	O
data	AI/ML/DL-focus
clustering	AI/ML/DL-focus
TELL	O
possesses	O
many	O
properties	O
highly	O
desired	O
by	O
$	O
k	O
$-	O
means	O
including	O
but	O
not	O
limited	O
to	O
online	AI/ML/DL-focus
clustering	AI/ML/DL-focus
plug	Miscellaneous-focus
-	Miscellaneous-focus
and	Miscellaneous-focus
-	Miscellaneous-focus
play	Miscellaneous-focus
module	Miscellaneous-focus
parallel	Miscellaneous-focus
computing	Miscellaneous-focus
and	O
provable	Miscellaneous-focus
convergence	Miscellaneous-focus
.	O

Extensive	O
experiments	O
show	O
that	O
our	O
method	O
achieves	O
superior	O
performance	O
comparing	O
with	O
14	O
clustering	AI/ML/DL-focus
approaches	O
on	O
three	O
challenging	O
data	O
sets	O
.	O

It	O
is	O
argued	O
that	O
using	O
targets	O
for	O
training	O
addresses	O
the	O
problem	O
of	O
exploding	AI/ML/DL-focus
gradients	AI/ML/DL-focus
by	O
a	O
process	O
which	O
we	O
call	O
cascade	O
untangling	O
and	O
makes	O
the	O
loss	O
-	O
function	O
surface	O
training	O
to	O
traverse	O
,	O
and	O
so	O
leads	O
to	O
easier	O
,	O
faster	O
training	O
,	O
and	O
also	O
potentially	O
better	O
generalisation	O
,	O
of	O
the	O
neural	O
network	O
.	O

In	O
the	O
theory	O
of	O
Partially	O
Observed	O
Markov	O
Decision	O
Processes	O
(	O
POMDPs	O
)	O
existence	O
of	O
optimal	O
policies	O
have	O
in	O
general	O
been	O
established	O
via	O
converting	O
the	O
original	O
partially	AI/ML/DL-focus
observed	AI/ML/DL-focus
stochastic	AI/ML/DL-focus
control	AI/ML/DL-focus
problem	AI/ML/DL-focus
to	O
a	O
fully	O
observed	O
one	O
on	O
the	O
belief	O
space	O
leading	O
to	O
a	O
belief	O
-	O
MDP	O
.	O

We	O
propose	O
a	O
theoretical	O
framework	O
for	O
approximate	AI/ML/DL-focus
planning	AI/ML/DL-focus
and	O
learning	AI/ML/DL-focus
in	O
partially	O
observed	O
systems	O
.	O

Sparse	AI/ML/DL-focus
principal	AI/ML/DL-focus
component	AI/ML/DL-focus
analysis	AI/ML/DL-focus
(	AI/ML/DL-focus
PCA	AI/ML/DL-focus
)	AI/ML/DL-focus
is	O
a	O
popular	O
dimensionality	AI/ML/DL-focus
reduction	AI/ML/DL-focus
technique	O
for	O
obtaining	O
principal	O
components	O
which	O
are	O
linear	O
combinations	O
of	O
a	O
small	O
subset	O
of	O
the	O
original	O
features	O
.	O

By	O
reformulating	O
sparse	AI/ML/DL-focus
PCA	AI/ML/DL-focus
as	O
a	O
convex	AI/ML/DL-focus
mixed	AI/ML/DL-focus
-	AI/ML/DL-focus
integer	AI/ML/DL-focus
semidefinite	AI/ML/DL-focus
optimization	AI/ML/DL-focus
problem	AI/ML/DL-focus
we	O
design	O
a	O
cutting	O
-	O
plane	O
method	O
which	O
solves	O
the	O
problem	O
to	O
certifiable	O
optimality	O
at	O
the	O
scale	O
of	O
selecting	O
$	O
k	O
=	O
5	O
$	O
covariates	O
from	O
$	O
p	O
=	O
300	O
$	O
variables	O
and	O
provides	O
small	O
bound	O
gaps	O
at	O
a	O
larger	O
scale	O
.	O

Plug	O
-	O
and	O
-	O
Play	O
(	O
PnP	O
)	O
is	O
a	O
non	AI/ML/DL-focus
-	AI/ML/DL-focus
convex	AI/ML/DL-focus
optimization	AI/ML/DL-focus
framework	AI/ML/DL-focus
that	O
combines	O
proximal	O
algorithms	O
for	O
example	O
,	O
the	O
alternating	O
direction	O
method	O
of	O
multipliers	O
(	O
ADMM	O
)	O
with	O
advanced	O
denoising	O
priors	O
.	O

A	O
core	O
part	O
of	O
our	O
approach	O
is	O
a	O
policy	O
network	O
for	O
automated	AI/ML/DL-focus
parameter	AI/ML/DL-focus
search	AI/ML/DL-focus
which	O
can	O
be	O
effectively	O
learned	O
via	O
a	O
mixture	O
of	O
model	O
-	O
free	O
and	O
model	O
-	O
based	O
deep	O
reinforcement	O
learning	O
strategies	O
.	O

This	O
advanced	O
performance	O
is	O
prevalent	O
on	O
both	O
linear	O
and	O
nonlinear	O
exemplar	O
inverse	Computer/vision-focus
imaging	Computer/vision-focus
problems	O
,	O
and	O
in	O
particular	O
shows	O
promising	O
results	O
on	O
compressed	O
sensing	O
MRI	O
sparse	O
-	O
view	O
CT	O
single	O
-	O
photon	O
imaging	O
and	O
phase	O
retrieval	O
.	O

Graph	AI/ML/DL-focus
representation	AI/ML/DL-focus
learning	AI/ML/DL-focus
has	O
many	O
real	O
-	O
world	O
applications	O
,	O
from	O
self	O
-	O
driving	O
LiDAR	O
3D	O
computer	O
vision	O
to	O
drug	O
repurposing	O
protein	O
classification	O
social	O
networks	O
analysis	O
.	O

From	O
this	O
,	O
we	O
give	O
a	O
fast	O
algorithm	O
for	O
the	O
decimated	O
G	O
-	O
framelet	O
transforms	O
or	O
FGT	O
that	O
has	O
linear	O
computational	Miscellaneous-metrics
complexity	Miscellaneous-metrics
O	O
(	O
N	O
)	O
for	O
a	O
graph	O
of	O
size	O
N	O
.	O

The	O
effectiveness	O
for	O
constructing	O
the	O
decimated	O
framelet	O
system	O
and	O
the	O
FGT	O
is	O
demonstrated	O
by	O
a	O
simulated	O
example	O
of	O
random	O
graphs	O
and	O
real	O
-	O
world	O
applications	O
,	O
including	O
multiresolution	O
analysis	O
for	O
traffic	O
network	O
and	O
representation	O
learning	O
of	O
graph	O
neural	O
networks	O
for	O
graph	AI/ML/DL-focus
classification	AI/ML/DL-focus
tasks	O
.	O

As	O
such	O
,	O
CE	O
incorporates	O
label	O
information	O
and	O
performs	O
a	O
supervised	AI/ML/DL-focus
data	AI/ML/DL-focus
visualization	AI/ML/DL-focus
CE	O
.	O

We	O
combine	O
two	O
popular	O
optimization	AI/ML/DL-focus
approaches	O
to	O
derive	O
learning	O
algorithms	O
for	O
generative	O
models	O
variational	O
optimization	O
and	O
evolutionary	O
algorithms	O
.	O

To	O
demonstrate	O
effectiveness	O
and	O
efficiency	O
of	O
the	O
novel	O
variational	O
approach	O
,	O
we	O
use	O
the	O
standard	O
competitive	O
benchmarks	O
of	O
image	Computer/vision-focus
denoising	Computer/vision-focus
and	O
inpainting	O
benchmarks	O
.	O

We	O
show	O
that	O
the	O
accuracy	Classification-metrics
of	O
approximations	O
lies	O
within	O
$(	O
1	O
+\	O
mathcal	O
{	O
O	O
}({\	O
varepsilon	O
}))$	O
of	O
the	O
true	O
leverage	O
scores	O
with	O
high	O
probability	O
.	O

In	O
rank	AI/ML/DL-focus
aggregation	AI/ML/DL-focus
(	AI/ML/DL-focus
RA	AI/ML/DL-focus
)	AI/ML/DL-focus
a	O
collection	O
of	O
preferences	O
from	O
different	O
users	O
are	O
summarized	O
into	O
a	O
total	O
order	O
under	O
the	O
assumption	O
of	O
homogeneity	O
of	O
users	O
.	O

Model	O
misspecification	O
in	O
RA	AI/ML/DL-focus
arises	O
since	O
the	O
homogeneity	O
assumption	O
fails	O
to	O
be	O
satisfied	O
in	O
the	O
complex	O
real	O
-	O
world	O
situation	O
.	O
RAs	AI/ML/DL-focus
.	O

Since	O
the	O
majority	O
of	O
robust	O
RAs	AI/ML/DL-focus
rely	O
on	O
certain	O
perturbation	O
assumptions	O
,	O
they	O
cannot	O
generalize	O
well	O
to	O
agnostic	O
noise	O
-	O
corrupted	O
preferences	O
in	O
the	O
real	O
world	O
.	O

(	O
2	O
)	O
CoarsenRank	O
then	O
performs	O
regular	O
RAs	AI/ML/DL-focus
over	O
a	O
neighborhood	O
of	O
the	O
preferences	O
instead	O
of	O
the	O
original	O
data	O
set	O
CoarsenRank	O
.	O

We	O
support	O
our	O
theory	O
with	O
numerical	O
illustrations	O
.	O
Decision	AI/ML/DL-focus
tree	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

Heuristic	O
methods	O
are	O
traditionally	O
used	O
to	O
quickly	O
produce	O
models	O
with	O
reasonably	O
high	O
accuracy	Classification-metrics
.	O

A	O
commonly	O
criticised	O
point	O
,	O
however	O
,	O
is	O
that	O
the	O
resulting	O
trees	O
may	O
not	O
necessarily	O
be	O
the	O
best	O
representation	O
of	O
the	O
data	O
in	O
terms	O
of	O
accuracy	Classification-metrics
and	O
size	O
.	O

Whereas	O
algorithms	O
for	O
optimal	O
classification	O
trees	O
have	O
traditionally	O
been	O
plagued	O
by	O
high	O
runtimes	Miscellaneous-metrics
and	O
limited	O
scalability	Miscellaneous-metrics
we	O
show	O
in	O
a	O
detailed	O
experimental	O
study	O
that	O
our	O
approach	O
uses	O
only	O
a	O
fraction	O
of	O
the	O
time	O
required	O
by	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
and	O
can	O
handle	O
datasets	O
with	O
tens	O
of	O
thousands	O
of	O
instances	O
,	O
providing	O
several	O
orders	O
of	O
magnitude	O
improvements	O
and	O
notably	O
contributing	O
towards	O
the	O
practical	O
use	O
of	O
optimal	O
decision	O
trees	O
.	O

We	O
explore	O
this	O
framework	O
by	O
studying	O
rich	O
model	O
classes	O
that	O
may	O
only	O
admit	O
pointwise	O
consistency	O
guarantees	O
,	O
yet	O
enough	O
information	O
about	O
the	O
unknown	O
model	O
driving	O
the	O
observations	O
needed	O
to	O
gauge	O
estimator	Classification-metrics
accuracy	Classification-metrics
can	O
be	O
inferred	O
from	O
the	O
sample	O
at	O
hand	O
.	O

In	O
this	O
paper	O
we	O
obtain	O
a	O
novel	O
characterization	O
of	O
lossless	AI/ML/DL-focus
compression	AI/ML/DL-focus
problems	O
over	O
a	O
countable	O
alphabet	O
in	O
the	O
data	O
-	O
derived	O
framework	O
in	O
terms	O
of	O
what	O
we	O
term	O
deceptive	O
distributions	O
.	O

We	O
expect	O
that	O
the	O
methodology	O
underlying	O
such	O
characterizations	O
in	O
a	O
data	O
-	O
derived	O
estimation	O
framework	O
will	O
be	O
broadly	O
applicable	O
to	O
a	O
wide	O
range	O
of	O
estimation	AI/ML/DL-focus
problems	AI/ML/DL-focus
enabling	O
a	O
more	O
systematic	O
approach	O
to	O
data	O
-	O
derived	O
guarantees	O
.	O

In	O
this	O
article	O
,	O
we	O
dwell	O
into	O
the	O
class	O
of	O
so	O
-	O
called	O
ill	O
-	O
posed	O
Linear	AI/ML/DL-focus
Inverse	AI/ML/DL-focus
Problems	AI/ML/DL-focus
(	AI/ML/DL-focus
LIP	AI/ML/DL-focus
)	AI/ML/DL-focus
which	O
simply	O
refer	O
to	O
the	O
task	O
of	O
recovering	O
the	O
entire	O
signal	O
from	O
its	O
relatively	O
few	O
random	O
linear	O
measurements	O
.	O

We	O
propose	O
a	O
slightly	O
generalized	O
version	O
of	O
the	O
error	AI/ML/DL-focus
constrained	AI/ML/DL-focus
linear	AI/ML/DL-focus
inverse	AI/ML/DL-focus
problem	AI/ML/DL-focus
and	O
obtain	O
a	O
novel	O
and	O
equivalent	O
convex	O
-	O
concave	O
min	O
-	O
max	O
reformulation	O
by	O
providing	O
an	O
exposition	O
to	O
its	O
convex	O
geometry	O
Saddle	O
points	O
.	O

Saddle	O
points	O
of	O
the	O
min	O
-	O
max	O
problem	O
are	O
completely	O
characterized	O
in	O
terms	O
of	O
a	O
solution	O
to	O
the	O
LIP	AI/ML/DL-focus
and	O
vice	O
versa	O
.	O

Applying	O
simple	O
saddle	O
point	O
seeking	O
ascend	O
-	O
descent	O
type	O
algorithms	O
to	O
solve	O
the	O
min	O
-	O
max	O
problems	O
provides	O
novel	O
and	O
simple	O
algorithms	O
to	O
find	O
a	O
solution	O
to	O
the	O
LIP	AI/ML/DL-focus
.	O

Moreover	O
,	O
the	O
reformulation	O
of	O
an	O
LIP	AI/ML/DL-focus
as	O
the	O
min	O
-	O
max	O
problem	O
provided	O
in	O
this	O
article	O
is	O
crucial	O
in	O
developing	O
methods	O
to	O
solve	O
the	O
dictionary	AI/ML/DL-focus
learning	AI/ML/DL-focus
problem	AI/ML/DL-focus
with	O
almost	O
sure	O
recovery	O
constraints	O
.	O
meta	O
-	O
learning	O
.	O

For	O
both	O
cases	O
,	O
we	O
characterize	O
the	O
convergence	O
rate	O
and	O
the	O
computational	Miscellaneous-metrics
complexity	Miscellaneous-metrics
to	O
attain	O
an	O
$\	O
epsilon	O
$-	O
accurate	O
solution	O
for	O
multi	O
-	O
step	O
MAML	O
in	O
the	O
general	O
nonconvex	O
setting	O
.	O

This	O
is	O
due	O
to	O
the	O
apparent	O
absence	O
of	O
a	O
tractable	O
class	O
of	O
conjugate	O
priors	O
that	O
may	O
facilitate	O
posterior	AI/ML/DL-focus
inference	AI/ML/DL-focus
on	O
the	O
multinomial	O
probit	O
coefficients	O
.	O

Leveraging	O
this	O
result	O
and	O
the	O
SUN	O
properties	O
,	O
we	O
improve	O
upon	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
solutions	O
for	O
posterior	AI/ML/DL-focus
inference	AI/ML/DL-focus
and	O
classification	AI/ML/DL-focus
both	O
in	O
terms	O
of	O
closed	O
-	O
form	O
results	O
for	O
several	O
functionals	O
of	O
interest	O
,	O
and	O
also	O
by	O
developing	O
novel	O
computational	O
methods	O
relying	O
either	O
on	O
independent	O
and	O
identically	O
distributed	O
samples	O
from	O
the	O
exact	O
posterior	O
or	O
on	O
scalable	O
and	O
accurate	O
variational	O
approximations	O
based	O
on	O
blocked	O
partially	O
-	O
factorized	O
representations	O
.	O

We	O
introduce	O
a	O
procedure	O
for	O
conditional	AI/ML/DL-focus
density	AI/ML/DL-focus
estimation	AI/ML/DL-focus
under	O
logarithmic	O
loss	O
which	O
we	O
call	O
SMP	O
(	O
Sample	O
Minmax	O
Predictor	O
)	O
.	O

While	O
the	O
identification	O
of	O
nonlinear	AI/ML/DL-focus
dynamical	AI/ML/DL-focus
systems	AI/ML/DL-focus
is	O
a	O
fundamental	O
building	O
block	O
of	O
model	O
-	O
based	O
reinforcement	O
learning	O
and	O
feedback	O
control	O
,	O
its	O
sample	O
complexity	O
is	O
only	O
understood	O
for	O
systems	O
that	O
either	O
have	O
discrete	O
states	O
and	O
actions	O
or	O
for	O
systems	O
that	O
can	O
be	O
identified	O
from	O
data	O
generated	O
by	O
i	O
.	O
i	O
.	O
d	O
.	O

Motivated	O
by	O
practical	O
settings	O
,	O
we	O
study	O
a	O
class	O
of	O
nonlinear	AI/ML/DL-focus
dynamical	AI/ML/DL-focus
systems	AI/ML/DL-focus
whose	O
state	O
transitions	O
depend	O
linearly	O
on	O
a	O
known	O
feature	O
embedding	O
of	O
state	O
-	O
action	O
pairs	O
.	O

We	O
show	O
that	O
our	O
method	O
estimates	O
nonlinear	AI/ML/DL-focus
dynamical	AI/ML/DL-focus
systems	AI/ML/DL-focus
at	O
a	O
parametric	O
rate	O
,	O
similar	O
to	O
the	O
statistical	O
rate	O
of	O
standard	O
linear	O
regression	O
.	O

We	O
have	O
focused	O
our	O
attention	O
on	O
the	O
regression	AI/ML/DL-focus
context	O
since	O
that	O
is	O
wheremodel	O
averaging	O
techniques	O
differ	O
most	O
often	O
from	O
current	O
practice	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
flexible	O
model	O
for	O
survival	AI/ML/DL-focus
analysis	AI/ML/DL-focus
using	O
neural	O
networks	O
along	O
with	O
scalable	O
optimization	O
algorithms	O
.	O

To	O
address	O
this	O
challenge	O
,	O
we	O
recognize	O
from	O
a	O
novel	O
perspective	O
that	O
the	O
MLE	O
for	O
censored	O
data	O
can	O
be	O
viewed	O
as	O
a	O
differential	AI/ML/DL-focus
-	AI/ML/DL-focus
equation	AI/ML/DL-focus
constrained	AI/ML/DL-focus
optimization	AI/ML/DL-focus
problem	O
.	O

Convergence	O
to	O
a	O
saddle	O
point	O
for	O
convex	O
-	O
concave	O
functions	O
has	O
been	O
studied	O
for	O
decades	O
,	O
while	O
recent	O
years	O
has	O
seen	O
a	O
surge	O
of	O
interest	O
in	O
non	AI/ML/DL-focus
-	AI/ML/DL-focus
convex	AI/ML/DL-focus
(	AI/ML/DL-focus
zero	AI/ML/DL-focus
-	AI/ML/DL-focus
sum	AI/ML/DL-focus
)	AI/ML/DL-focus
smooth	AI/ML/DL-focus
games	AI/ML/DL-focus
motivated	O
by	O
their	O
recent	O
wide	O
applications	O
.	O

We	O
find	O
that	O
local	O
saddle	O
points	O
can	O
be	O
regarded	O
as	O
a	O
special	O
type	O
of	O
local	O
minimax	O
points	O
local	O
minimax	O
points	O
al	O
minimax	O
points	O
,	O
under	O
mild	O
continuity	O
assumptions	O
.	O
non	AI/ML/DL-focus
-	AI/ML/DL-focus
convex	AI/ML/DL-focus
)	AI/ML/DL-focus
quadratic	AI/ML/DL-focus
games	AI/ML/DL-focus
.	O

In	O
the	O
paper	O
,	O
we	O
propose	O
a	O
class	O
of	O
accelerated	O
zeroth	O
-	O
order	O
and	O
first	O
-	O
order	O
momentum	O
methods	O
for	O
both	O
nonconvex	AI/ML/DL-focus
mini	AI/ML/DL-focus
-	AI/ML/DL-focus
optimization	AI/ML/DL-focus
and	O
minimax	AI/ML/DL-focus
-	AI/ML/DL-focus
optimization	AI/ML/DL-focus
.	O

Specifically	O
,	O
we	O
propose	O
a	O
new	O
accelerated	O
zeroth	O
-	O
order	O
momentum	O
(	O
Acc	O
-	O
ZOM	O
)	O
method	O
for	O
black	AI/ML/DL-focus
-	AI/ML/DL-focus
box	AI/ML/DL-focus
mini	AI/ML/DL-focus
-	AI/ML/DL-focus
optimization	AI/ML/DL-focus
where	O
only	O
function	O
values	O
Acc	O
-	O
ZOM	O
btained	O
.	O

Moreover	O
,	O
we	O
prove	O
that	O
our	O
Acc	O
-	O
ZOM	O
method	O
achieves	O
a	O
lower	O
query	Miscellaneous-metrics
complexity	Miscellaneous-metrics
of	O
$\	O
tilde	O
{	O
O	O
}(	O
d	O
^{	O
3	O
/	O
4	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
for	O
finding	O
an	O
$\	O
epsilon	O
$-	O
stationary	O
point	O
which	O
improves	O
the	O
best	O
known	O
result	O
by	O
a	O
factor	O
of	O
$	O
O	O
(	O
d	O
^{	O
1	O
/	O
4	O
})$	O
where	O
$	O
d	O
$	O
denotes	O
the	O
variable	O
dimension	O
Acc	O
-	O
ZOM	O
.	O

Meanwhile	O
,	O
we	O
propose	O
an	O
accelerated	O
zeroth	O
-	O
order	O
momentum	O
descent	O
ascent	O
(	O
Acc	O
-	O
ZOMDA	O
)	O
method	O
for	O
black	AI/ML/DL-focus
-	AI/ML/DL-focus
box	AI/ML/DL-focus
minimax	AI/ML/DL-focus
optimization	AI/ML/DL-focus
Acc	O
-	O
ZOMDA	O
y	O
function	O
values	O
can	O
be	O
obtained	O
.	O

Our	O
Acc	O
-	O
ZOMDA	O
obtains	O
a	O
low	O
query	Miscellaneous-metrics
complexity	Miscellaneous-metrics
of	O
$\	O
tilde	O
{	O
O	O
}((	O
d_1	O
+	O
d_2	O
)^{	O
3	O
/	O
4	O
}\	O
kappa_y	O
^{	O
4	O
.	O
5	O
}\	O
epsilon	O
^{-	O
3	O
})$	O
without	O
requiring	O
large	O
batches	O
for	O
finding	O
an	O
$\	O
epsilon	O
$-	O
stationary	O
point	O
where	O
$	O
d_1	O
$	O
and	O
$	O
d_2	O
$	O
denote	O
variable	O
dimensions	O
and	O
$\	O
kappa_y	O
$	O
is	O
condition	O
number	O
.	O

Moreover	O
,	O
we	O
propose	O
an	O
accelerated	O
first	O
-	O
order	O
momentum	O
descent	O
ascent	O
(	O
Acc	O
-	O
MDA	O
)	O
method	O
for	O
minimax	AI/ML/DL-focus
optimization	AI/ML/DL-focus
whose	O
explicit	O
gradients	O
Acc	O
-	O
MDA	O
ssible	O
.	O

We	O
present	O
a	O
novel	O
class	O
of	O
projected	O
methods	O
to	O
perform	O
statistical	O
analysis	O
on	O
a	O
data	O
set	O
of	O
probability	O
distributions	O
on	O
the	O
real	O
line	O
,	O
with	O
the	O
2	Statistical/Mathematical-metrics
-	Statistical/Mathematical-metrics
Wasserstein	Statistical/Mathematical-metrics
metric	O
.	O

Bayesian	AI/ML/DL-focus
Likelihood	AI/ML/DL-focus
-	AI/ML/DL-focus
Free	AI/ML/DL-focus
Inference	AI/ML/DL-focus
(	AI/ML/DL-focus
LFI	AI/ML/DL-focus
)	AI/ML/DL-focus
approaches	O
allow	O
to	O
obtain	O
posterior	O
distributions	O
for	O
stochastic	O
models	O
with	O
intractable	O
likelihood	O
by	O
relying	O
on	O
model	O
simulations	O
.	O

In	O
Approximate	O
Bayesian	O
Computation	O
(	O
ABC	O
)	O
a	O
popular	O
LFI	AI/ML/DL-focus
method	O
,	O
summary	O
statistics	O
are	O
used	O
to	O
reduce	O
data	O
dimensionality	O
ABC	O
algorithms	O
.	O

We	O
develop	O
a	O
rigorous	O
and	O
general	O
framework	O
for	O
constructing	O
information	O
-	O
theoretic	O
divergences	O
divergences	O
both	O
$	O
f	O
$-	O
divergences	O
and	O
integral	Statistical/Mathematical-metrics
probability	Statistical/Mathematical-metrics
metrics	Statistical/Mathematical-metrics
(	Statistical/Mathematical-metrics
IPMs	Statistical/Mathematical-metrics
)	Statistical/Mathematical-metrics
such	O
as	O
the	O
$	Statistical/Mathematical-metrics
1	Statistical/Mathematical-metrics
$-	Statistical/Mathematical-metrics
Wasserstein	Statistical/Mathematical-metrics
distance	Statistical/Mathematical-metrics
.	O

We	O
prove	O
under	O
which	O
assumptions	O
these	O
divergences	O
divergences	O
eferred	O
to	O
as	O
$(	O
f	O
,\	O
Gamma	O
)$-	O
divergences	O
,	O
provide	O
a	O
notion	O
of	O
`	O
distance	O
'	O
between	O
probability	O
measures	O
and	O
show	O
that	O
they	O
can	O
be	O
expressed	O
as	O
a	O
two	O
-	O
stage	O
mass	AI/ML/DL-focus
-	AI/ML/DL-focus
redistribution	AI/ML/DL-focus
/	AI/ML/DL-focus
mass	AI/ML/DL-focus
-	AI/ML/DL-focus
transport	AI/ML/DL-focus
divergences	O
.	O

The	O
$(	O
f	O
,\	O
Gamma	O
)$-	O
divergences	O
inherit	O
features	O
from	O
IPMs	Statistical/Mathematical-metrics
such	O
as	O
the	O
ability	O
to	O
compare	O
distributions	O
which	O
are	O
not	O
absolutely	O
continuous	O
,	O
as	O
well	O
as	O
from	O
$	O
f	O
$-	O
divergences	O
,	O
namely	O
the	O
strict	O
concavity	O
of	O
their	O
variational	O
representations	O
and	O
the	O
ability	O
to	O
control	O
heavy	O
-	O
tailed	O
distributions	O
for	O
particular	O
choices	O
of	O
$	O
f	O
$.	O

When	O
combined	O
,	O
these	O
features	O
establish	O
a	O
divergence	O
with	O
improved	O
properties	O
for	O
estimation	AI/ML/DL-focus
statistical	O
learning	O
and	O
uncertainty	AI/ML/DL-focus
quantification	AI/ML/DL-focus
statistical	O
learning	O
.	O

We	O
also	O
show	O
improved	O
performance	O
and	O
stability	O
over	O
gradient	O
-	O
penalized	O
Wasserstein	O
GAN	O
in	O
image	Computer/vision-focus
generation	Computer/vision-focus
.	O

We	O
consider	O
a	O
problem	O
of	O
manifold	AI/ML/DL-focus
estimation	AI/ML/DL-focus
from	O
noisy	O
observations	O
manifold	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

In	O
our	O
theoretical	O
study	O
,	O
we	O
establish	O
tight	O
lower	O
and	O
upper	O
bounds	O
proving	O
asymptotic	O
optimality	O
of	O
the	O
method	O
for	O
manifold	AI/ML/DL-focus
estimation	AI/ML/DL-focus
under	O
the	O
Hausdorff	O
loss	O
provided	O
that	O
the	O
noise	O
degrades	O
to	O
zero	O
fast	O
enough	O
.	O

We	O
introduce	O
a	O
novel	O
approach	O
to	O
estimation	AI/ML/DL-focus
problems	AI/ML/DL-focus
in	O
settings	O
with	O
missing	O
data	O
.	O

Our	O
proposal	O
--	O
the	O
Correlation	O
-	O
Assisted	O
Missing	O
data	O
(	O
CAM	O
)	O
estimator	O
--	O
works	O
by	O
exploiting	O
the	O
relationship	O
between	O
the	O
observations	O
with	O
missing	O
features	O
and	O
those	O
without	O
missing	O
features	O
in	O
order	O
to	O
obtain	O
improved	O
prediction	Classification-metrics
accuracy	Classification-metrics
.	O

In	O
particular	O
,	O
our	O
theoretical	O
results	O
elucidate	O
general	O
conditions	O
under	O
which	O
the	O
proposed	O
CAM	O
estimator	O
has	O
lower	O
mean	O
squared	O
error	O
than	O
the	O
widely	O
used	O
complete	O
-	O
case	O
approach	O
in	O
a	O
range	O
of	O
estimation	AI/ML/DL-focus
problems	O
.	O

Further	O
,	O
in	O
nonparametric	AI/ML/DL-focus
density	AI/ML/DL-focus
estimation	AI/ML/DL-focus
and	O
regression	AI/ML/DL-focus
problems	O
,	O
we	O
construct	O
our	O
CAM	O
estimator	O
using	O
kernel	O
functions	O
and	O
show	O
it	O
has	O
lower	O
asymptotic	O
mean	O
squared	O
error	O
than	O
the	O
corresponding	O
complete	O
-	O
case	O
kernel	O
estimator	O
.	O

Experiments	O
show	O
the	O
above	O
techniques	O
provide	O
significant	O
improvements	O
for	O
Shapley	O
value	O
estimates	O
over	O
existing	O
methods	O
,	O
converging	O
to	O
a	O
smaller	O
RMSE	O
in	O
the	O
same	O
number	O
of	O
model	O
evaluations	O
.	O
Open	AI/ML/DL-focus
category	AI/ML/DL-focus
detection	AI/ML/DL-focus
.	O

Further	O
,	O
while	O
there	O
are	O
algorithms	O
for	O
open	AI/ML/DL-focus
category	AI/ML/DL-focus
detection	AI/ML/DL-focus
there	O
are	O
few	O
empirical	O
results	O
that	O
directly	O
report	O
alien	O
detection	O
rates	O
.	O

Thus	O
,	O
there	O
are	O
significant	O
theoretical	O
and	O
empirical	O
gaps	O
in	O
our	O
understanding	O
of	O
open	AI/ML/DL-focus
category	AI/ML/DL-focus
detection	AI/ML/DL-focus
.	O

In	O
this	O
paper	O
,	O
we	O
take	O
a	O
step	O
toward	O
addressing	O
this	O
gap	O
by	O
studying	O
a	O
simple	O
,	O
but	O
practically	O
-	O
relevant	O
variant	O
of	O
open	AI/ML/DL-focus
category	AI/ML/DL-focus
detection	AI/ML/DL-focus
.	O

In	O
addition	O
,	O
for	O
the	O
situation	O
when	O
an	O
upper	O
bound	O
for	O
$\	O
alpha	O
$	O
is	O
not	O
available	O
,	O
we	O
employ	O
nine	O
different	O
anomaly	O
proportion	O
estimators	O
and	O
run	O
experiments	O
on	O
both	O
synthetic	O
and	O
standard	O
benchmark	O
data	O
sets	O
to	O
compare	O
their	O
performance	O
.	O
optimal	AI/ML/DL-focus
transport	AI/ML/DL-focus
problem	AI/ML/DL-focus
.	O

We	O
study	O
the	O
optimal	O
transport	O
problem	O
for	O
pairs	O
of	O
stationary	O
finite	O
-	O
state	O
Markov	O
chains	O
with	O
an	O
emphasis	O
on	O
the	O
computation	O
of	O
optimal	AI/ML/DL-focus
transition	AI/ML/DL-focus
couplings	AI/ML/DL-focus
Transition	O
couplings	O
.	O

Solutions	O
of	O
the	O
optimal	AI/ML/DL-focus
transition	AI/ML/DL-focus
coupling	AI/ML/DL-focus
(	AI/ML/DL-focus
OTC	AI/ML/DL-focus
)	AI/ML/DL-focus
OTC	AI/ML/DL-focus
lem	O
correspond	O
to	O
alignments	O
of	O
the	O
two	O
chains	O
that	O
minimize	O
long	O
-	O
term	O
average	O
cost	O
.	O

We	O
establish	O
a	O
connection	O
between	O
the	O
OTC	O
problem	O
and	O
Markov	O
decision	O
processes	O
OTC	AI/ML/DL-focus
show	O
that	O
solutions	O
of	O
the	O
OTC	O
problem	O
can	O
be	O
obtained	O
via	O
an	O
adaptation	O
of	O
policy	O
iteration	O
.	O
state	O
spaces	O
.	O

For	O
settings	O
with	O
large	O
state	O
spaces	O
,	O
we	O
develop	O
a	O
fast	O
approximate	O
algorithm	O
based	O
on	O
an	O
entropy	O
-	O
regularized	O
version	O
of	O
the	O
OTC	AI/ML/DL-focus
problem	O
,	O
and	O
provide	O
bounds	O
on	O
its	O
per	O
-	O
iteration	O
complexity	O
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
the	O
concentration	O
property	O
of	O
stochastic	O
gradient	O
descent	O
(	O
SGD	O
)	O
solutions	O
.	O
concentration	AI/ML/DL-focus
analyses	AI/ML/DL-focus
.	O

We	O
also	O
show	O
that	O
the	O
Nagaev	O
type	O
upper	O
bound	O
is	O
almost	O
tight	O
through	O
an	O
example	O
,	O
where	O
the	O
exact	O
asymptotic	O
form	O
of	O
the	O
tail	O
probability	O
can	O
be	O
derived	O
.	O
concentration	AI/ML/DL-focus
analysis	AI/ML/DL-focus
.	O

Our	O
experiments	O
show	O
that	O
conditioning	O
augmentation	O
prevents	O
compounding	O
error	O
during	O
sampling	O
in	O
a	O
cascaded	O
model	O
,	O
helping	O
us	O
to	O
train	O
cascading	O
pipelines	O
achieving	O
FID	Statistical/Mathematical-metrics
scores	O
of	O
1	O
.	O
48	O
at	O
64x64	O
3	O
.	O
52	O
at	O
128x128	O
and	O
4	O
.	O
88	O
at	O
256x256	O
resolutions	O
,	O
outperforming	O
BigGAN	O
-	O
deep	O
and	O
classification	Classification-metrics
accuracy	Classification-metrics
scores	O
of	O
63	O
.	O
02	O
%	O
(	O
top	O
-	O
1	O
)	O
and	O
84	O
.	O
06	O
%	O
(	O
top	O
-	O
5	O
)	O
at	O
256x256	O
outperforming	O
VQ	O
-	O
VAE	O
-	O
2	O
.	O
parameters	O
.	O

Finding	O
parameters	O
in	O
a	O
deep	O
neural	O
network	O
(	O
NN	O
)	O
that	O
fit	O
training	O
data	O
is	O
a	O
nonconvex	AI/ML/DL-focus
optimization	AI/ML/DL-focus
problem	AI/ML/DL-focus
but	O
a	O
basic	O
first	O
-	O
order	O
optimization	O
method	O
(	O
gradient	O
descent	O
finds	O
a	O
global	O
optimizer	O
with	O
perfect	O
fit	O
(	O
zero	O
-	O
loss	O
in	O
many	O
practical	O
situations	O
.	O

An	O
application	O
of	O
IAE	O
to	O
the	O
one	AI/ML/DL-focus
-	AI/ML/DL-focus
class	AI/ML/DL-focus
anomalous	AI/ML/DL-focus
sequence	AI/ML/DL-focus
detection	AI/ML/DL-focus
problem	O
with	O
unknown	O
anomaly	O
and	O
anomaly	O
-	O
free	O
models	O
is	O
also	O
presented	O
.	O
neural	O
networks	O
.	O

One	O
novel	O
aspect	O
is	O
that	O
it	O
allows	O
inferring	O
hidden	O
states	O
through	O
the	O
imposition	O
of	O
constraints	O
designed	O
to	O
achieve	O
specific	O
objectives	O
,	O
as	O
illustrated	O
through	O
three	O
examples	O
:	O
(	O
1	O
)	O
the	O
generation	O
of	O
adversarial	O
-	O
attack	O
examples	O
(	O
2	O
)	O
the	O
usage	O
of	O
a	O
neural	O
network	O
as	O
a	O
black	AI/ML/DL-focus
-	AI/ML/DL-focus
box	AI/ML/DL-focus
optimization	AI/ML/DL-focus
method	O
,	O
and	O
(	O
3	O
)	O
the	O
application	O
of	O
inference	O
on	O
continuous	O
-	O
action	O
reinforcement	O
learning	O
.	O

These	O
applications	O
showcase	O
how	O
tasks	O
that	O
were	O
previously	O
reserved	O
to	O
gradient	AI/ML/DL-focus
-	AI/ML/DL-focus
based	AI/ML/DL-focus
optimization	AI/ML/DL-focus
approaches	O
can	O
now	O
be	O
approached	O
with	O
analytically	O
tractable	O
inference	O
.	O
scikit	O
-	O
multimodallearn	O
Python	O
library	O
.	O

scikit	O
-	O
multimodallearn	O
is	O
a	O
Python	O
library	O
for	O
multimodal	AI/ML/DL-focus
supervised	AI/ML/DL-focus
learning	AI/ML/DL-focus
licensed	O
under	O
Free	O
BSD	O
and	O
compatible	O
with	O
the	O
well	O
-	O
known	O
scikit	O
-	O
learn	O
toolbox	O
(	O
Fabian	O
Pedregosa	O
,	O
2011	O
).	O

This	O
paper	O
details	O
the	O
content	O
of	O
the	O
library	O
,	O
including	O
a	O
specific	O
multimodal	O
data	O
formatting	O
and	O
classification	AI/ML/DL-focus
and	O
regression	AI/ML/DL-focus
algorithms	O
.	O

Use	O
cases	O
and	O
examples	O
are	O
also	O
provided	O
.	O
Conditional	Miscellaneous-focus
density	Miscellaneous-focus
estimation	Miscellaneous-focus
.	O

Furthermore	O
,	O
like	O
boosted	O
regression	O
trees	O
,	O
LinCDE	O
does	O
automatic	AI/ML/DL-focus
feature	AI/ML/DL-focus
selection	AI/ML/DL-focus
LinCDE	O
'	O
s	O
.	O

To	O
support	O
users	O
in	O
determining	O
well	O
-	O
performing	O
hyperparameter	O
configurations	O
for	O
their	O
algorithms	O
datasets	O
and	O
applications	O
at	O
hand	O
,	O
SMAC3	O
offers	O
a	O
robust	O
and	O
flexible	O
framework	O
for	O
Bayesian	AI/ML/DL-focus
Optimization	AI/ML/DL-focus
which	O
can	O
improve	O
performance	O
within	O
a	O
few	O
evaluations	O
.	O

It	O
offers	O
several	O
facades	O
and	O
pre	O
-	O
sets	O
for	O
typical	O
use	O
cases	O
,	O
such	O
as	O
optimizing	O
hyperparameters	O
solving	O
low	AI/ML/DL-focus
dimensional	AI/ML/DL-focus
continuous	AI/ML/DL-focus
(	AI/ML/DL-focus
artificial	AI/ML/DL-focus
)	AI/ML/DL-focus
global	AI/ML/DL-focus
optimization	AI/ML/DL-focus
problems	O
and	O
configuring	O
algorithms	O
to	O
perform	O
well	O
across	O
multiple	O
problem	O
instances	O
.	O
SMAC3	O
.	O

We	O
propose	O
a	O
Bayesian	O
pseudo	O
posterior	O
mechanism	O
to	O
generate	O
record	O
-	O
level	O
synthetic	O
databases	O
equipped	O
with	O
an	O
$(\	O
epsilon	O
,\	O
pi	O
)-$	O
probabilistic	AI/ML/DL-focus
differential	AI/ML/DL-focus
privacy	AI/ML/DL-focus
(	AI/ML/DL-focus
pDP	AI/ML/DL-focus
)	AI/ML/DL-focus
guarantee	O
,	O
where	O
$\	O
pi	O
$	O
denotes	O
the	O
probability	O
database	O
pseudo	O
posterior	O
mechanism	O
\	O
epsilon	O
$.	O

However	O
,	O
the	O
exact	O
tradeoff	O
between	O
fairness	O
and	O
accuracy	Classification-metrics
is	O
not	O
entirely	O
clear	O
,	O
even	O
for	O
the	O
basic	O
paradigm	O
of	O
classification	AI/ML/DL-focus
problems	O
.	O

However	O
,	O
the	O
exact	O
tradeoff	O
between	O
fairness	O
and	O
accuracy	Classification-metrics
is	O
not	O
entirely	O
clear	O
,	O
even	O
for	O
the	O
basic	O
paradigm	O
of	O
classification	AI/ML/DL-focus
problems	O
.	O

In	O
this	O
paper	O
,	O
we	O
characterize	O
an	O
inherent	O
tradeoff	O
between	O
statistical	Statistical/Mathematical-metrics
parity	Statistical/Mathematical-metrics
and	O
accuracy	Classification-metrics
in	O
the	O
classification	AI/ML/DL-focus
setting	O
by	O
providing	O
a	O
lower	O
bound	O
on	O
the	O
sum	O
of	O
group	O
-	O
wise	O
errors	O
of	O
any	O
fair	O
classifiers	O
.	O

In	O
this	O
paper	O
,	O
we	O
characterize	O
an	O
inherent	O
tradeoff	O
between	O
statistical	Statistical/Mathematical-metrics
parity	Statistical/Mathematical-metrics
and	O
accuracy	Classification-metrics
in	O
the	O
classification	AI/ML/DL-focus
setting	O
by	O
providing	O
a	O
lower	O
bound	O
on	O
the	O
sum	O
of	O
group	O
-	O
wise	O
errors	O
of	O
any	O
fair	O
classifiers	O
.	O

Our	O
impossibility	O
theorem	O
could	O
be	O
interpreted	O
as	O
a	O
certain	O
uncertainty	O
principle	O
in	O
fairness	O
:	O
if	O
the	O
base	O
rates	O
differ	O
among	O
groups	O
,	O
then	O
any	O
fair	O
classifier	O
satisfying	O
statistical	Statistical/Mathematical-metrics
parity	Statistical/Mathematical-metrics
has	O
to	O
incur	O
a	O
large	O
error	O
on	O
at	O
least	O
one	O
of	O
the	O
groups	O
.	O
lower	O
bound	O
.	O

To	O
show	O
that	O
our	O
lower	O
bound	O
is	O
tight	O
,	O
assuming	O
oracle	O
access	O
to	O
Bayes	O
(	O
potentially	O
unfair	O
)	O
classifiers	O
we	O
also	O
construct	O
an	O
algorithm	O
that	O
returns	O
a	O
randomized	O
classifier	O
which	O
is	O
both	O
optimal	O
(	O
in	O
terms	O
of	O
accuracy	Classification-metrics
and	O
fair	O
.	O

Nevertheless	O
,	O
in	O
this	O
case	O
,	O
we	O
show	O
that	O
the	O
lower	O
bound	O
can	O
be	O
efficiently	O
computed	O
by	O
solving	O
a	O
linear	O
program	O
,	O
which	O
we	O
term	O
as	O
the	O
TV	AI/ML/DL-focus
-	AI/ML/DL-focus
Barycenter	AI/ML/DL-focus
problem	AI/ML/DL-focus
a	O
barycenter	O
problem	O
under	O
the	O
TV	Miscellaneous-metrics
-	Miscellaneous-metrics
distance	Miscellaneous-metrics
.	O

Nevertheless	O
,	O
in	O
this	O
case	O
,	O
we	O
show	O
that	O
the	O
lower	O
bound	O
can	O
be	O
efficiently	O
computed	O
by	O
solving	O
a	O
linear	O
program	O
,	O
which	O
we	O
term	O
as	O
the	O
TV	AI/ML/DL-focus
-	AI/ML/DL-focus
Barycenter	AI/ML/DL-focus
problem	AI/ML/DL-focus
a	O
barycenter	O
problem	O
under	O
the	O
TV	Miscellaneous-metrics
-	Miscellaneous-metrics
distance	Miscellaneous-metrics
.	O

On	O
the	O
upside	O
,	O
we	O
prove	O
that	O
if	O
the	O
group	O
-	O
wise	O
Bayes	O
optimal	O
classifiers	O
are	O
close	O
,	O
then	O
learning	O
fair	O
representations	O
leads	O
to	O
an	O
alternative	O
notion	O
of	O
fairness	O
,	O
known	O
as	O
the	O
accuracy	Classification-metrics
parity	Classification-metrics
which	O
states	O
that	O
the	O
error	O
rates	O
are	O
close	O
between	O
groups	O
.	O

We	O
further	O
validate	O
the	O
method	O
through	O
a	O
simulation	O
study	O
confirming	O
the	O
superiority	O
of	O
our	O
approach	O
compared	O
to	O
other	O
standard	O
heuristic	O
metrics	O
like	O
the	O
perplexity	NLP-metrics
index	NLP-metrics
.	O
causal	AI/ML/DL-focus
classification	AI/ML/DL-focus
.	O

We	O
further	O
validate	O
the	O
method	O
through	O
a	O
simulation	O
study	O
confirming	O
the	O
superiority	O
of	O
our	O
approach	O
compared	O
to	O
other	O
standard	O
heuristic	O
metrics	O
like	O
the	O
perplexity	NLP-metrics
index	NLP-metrics
.	O
causal	AI/ML/DL-focus
classification	AI/ML/DL-focus
.	O

Examples	O
include	O
targeting	O
advertisements	O
and	O
targeting	O
retention	O
incentives	O
to	O
reduce	O
churn	O
.	O
Causal	AI/ML/DL-focus
classification	AI/ML/DL-focus
.	O

Curiously	O
,	O
we	O
often	O
see	O
practitioners	O
using	O
simple	O
outcome	AI/ML/DL-focus
prediction	AI/ML/DL-focus
instead	O
,	O
for	O
example	O
,	O
predicting	O
if	O
someone	O
will	O
purchase	O
if	O
shown	O
the	O
ad	O
.	O

Rather	O
than	O
disregarding	O
this	O
as	O
naive	O
behavior	O
,	O
we	O
present	O
a	O
theoretical	O
analysis	O
comparing	O
treatment	AI/ML/DL-focus
effect	AI/ML/DL-focus
estimation	AI/ML/DL-focus
and	O
outcome	AI/ML/DL-focus
prediction	AI/ML/DL-focus
when	O
addressing	O
causal	AI/ML/DL-focus
classification	AI/ML/DL-focus
.	O

We	O
focus	O
on	O
the	O
key	O
question	O
:	O
"	O
When	O
(	O
if	O
ever	O
)	O
is	O
simple	O
outcome	AI/ML/DL-focus
prediction	AI/ML/DL-focus
preferable	O
to	O
treatment	AI/ML/DL-focus
effect	AI/ML/DL-focus
estimation	AI/ML/DL-focus
for	O
causal	AI/ML/DL-focus
classification	AI/ML/DL-focus
"	O
The	O
analysis	O
reveals	O
a	O
causal	O
bias	O
--	O
variance	O
tradeoff	O
treatment	AI/ML/DL-focus
effect	AI/ML/DL-focus
estimation	AI/ML/DL-focus
.	O

First	O
,	O
when	O
the	O
treatment	O
effect	O
estimation	O
depends	O
on	O
two	O
outcome	AI/ML/DL-focus
predictions	AI/ML/DL-focus
larger	O
sampling	O
variance	O
may	O
lead	O
to	O
more	O
errors	O
than	O
the	O
(	O
biased	O
outcome	AI/ML/DL-focus
prediction	AI/ML/DL-focus
approach	O
.	O
signal	O
-	O
to	O
-	O
noise	O
ratio	O
.	O

Second	O
,	O
a	O
stronger	O
signal	O
-	O
to	O
-	O
noise	O
ratio	O
in	O
outcome	AI/ML/DL-focus
prediction	AI/ML/DL-focus
implies	O
that	O
the	O
bias	O
can	O
help	O
with	O
intervention	O
decisions	O
when	O
outcomes	O
are	O
informative	O
of	O
effects	O
.	O

The	O
theoretical	O
results	O
,	O
as	O
well	O
as	O
simulations	O
,	O
illustrate	O
settings	O
where	O
outcome	AI/ML/DL-focus
prediction	AI/ML/DL-focus
should	O
actually	O
be	O
better	O
,	O
including	O
cases	O
where	O
(	O
1	O
)	O
the	O
bias	O
may	O
be	O
partially	O
corrected	O
by	O
choosing	O
a	O
different	O
threshold	O
(	O
2	O
)	O
outcomes	O
and	O
treatment	O
effects	O
are	O
correlated	O
,	O
and	O
(	O
3	O
)	O
data	O
to	O
estimate	O
counterfactuals	O
are	O
limited	O
.	O

Finally	O
,	O
we	O
show	O
that	O
for	O
a	O
real	O
online	O
advertising	O
application	O
,	O
outcome	O
prediction	O
models	O
indeed	O
excel	O
at	O
causal	AI/ML/DL-focus
classification	AI/ML/DL-focus
.	O
monotone	AI/ML/DL-focus
inclusion	AI/ML/DL-focus
.	O

This	O
framework	O
includes	O
a	O
number	O
of	O
existing	O
deterministic	O
and	O
variance	O
-	O
reduced	O
algorithms	O
for	O
function	O
minimization	O
as	O
special	O
cases	O
,	O
and	O
it	O
is	O
also	O
applicable	O
to	O
more	O
general	O
problems	O
such	O
as	O
saddle	AI/ML/DL-focus
-	AI/ML/DL-focus
point	AI/ML/DL-focus
problems	AI/ML/DL-focus
and	O
variational	O
inequalities	O
Lyapunov	O
function	O
.	O

With	O
a	O
carefully	O
constructed	O
Lyapunov	O
function	O
,	O
we	O
show	O
that	O
the	O
algorithms	AI/ML/DL-focus
covered	O
by	O
our	O
framework	O
enjoy	O
a	O
linear	O
convergence	O
rate	O
in	O
expectation	O
under	O
mild	O
assumptions	O
.	O
Catalyst	O
acceleration	O
asynchronous	O
.	O

In	O
this	O
paper	O
we	O
introduce	O
a	O
novel	O
model	O
for	O
Gaussian	AI/ML/DL-focus
process	AI/ML/DL-focus
(	AI/ML/DL-focus
GP	AI/ML/DL-focus
)	AI/ML/DL-focus
regression	AI/ML/DL-focus
in	O
the	O
fully	O
Bayesian	O
setting	O
sparsification	O
localization	O
.	O

We	O
demonstrate	O
the	O
practical	O
usability	O
of	O
the	O
AIM	O
algorithm	O
by	O
prototype	O
implementations	O
for	O
parameter	AI/ML/DL-focus
learning	AI/ML/DL-focus
from	O
continuous	O
Gaussian	O
data	O
and	O
from	O
discrete	O
Bayesian	O
network	O
data	O
.	O

We	O
propose	O
a	O
method	O
for	O
simultaneous	O
estimation	O
and	O
variable	O
selection	O
of	O
an	O
additive	O
quantile	O
regression	O
model	O
that	O
can	O
be	O
used	O
with	O
high	O
dimensional	O
data	O
Quantile	AI/ML/DL-focus
regression	AI/ML/DL-focus
.	O

The	O
additive	O
nonlinear	O
model	O
is	O
fit	O
using	O
B	O
-	O
splines	O
and	O
a	O
nonconvex	O
group	O
penalty	O
is	O
used	O
for	O
simultaneous	O
estimation	AI/ML/DL-focus
and	O
variable	AI/ML/DL-focus
selection	AI/ML/DL-focus
asymptotic	O
.	O

In	O
addition	O
,	O
we	O
propose	O
a	O
coordinate	O
descent	O
algorithm	O
that	O
reduces	O
the	O
computational	O
cost	O
compared	O
to	O
the	O
linear	O
programming	O
approach	O
typically	O
used	O
for	O
solving	O
quantile	AI/ML/DL-focus
regression	AI/ML/DL-focus
problems	O
.	O

Stochastic	O
zeroth	O
-	O
order	O
optimization	O
algorithms	O
have	O
been	O
predominantly	O
analyzed	O
under	O
the	O
assumption	O
that	O
the	O
objective	O
function	O
being	O
optimized	O
is	O
time	O
-	O
invariant	O
dynamic	AI/ML/DL-focus
matrix	AI/ML/DL-focus
sensing	AI/ML/DL-focus
completion	AI/ML/DL-focus
.	O

Motivated	O
by	O
dynamic	O
matrix	O
sensing	O
and	O
completion	O
problems	O
,	O
and	O
online	AI/ML/DL-focus
reinforcement	AI/ML/DL-focus
learning	AI/ML/DL-focus
problems	O
,	O
in	O
this	O
work	O
,	O
we	O
propose	O
and	O
analyze	O
stochastic	O
zeroth	O
-	O
order	O
optimization	O
algorithms	O
when	O
the	O
objective	O
being	O
optimized	O
changes	O
with	O
time	O
.	O
nonconvex	O
functions	O
.	O

We	O
study	O
the	O
complexity	O
of	O
approximating	O
the	O
multimarginal	AI/ML/DL-focus
optimal	AI/ML/DL-focus
transport	AI/ML/DL-focus
(	AI/ML/DL-focus
MOT	AI/ML/DL-focus
)	AI/ML/DL-focus
distance	AI/ML/DL-focus
a	O
generalization	O
of	O
the	O
classical	O
optimal	AI/ML/DL-focus
transport	AI/ML/DL-focus
distance	AI/ML/DL-focus
considered	O
here	O
between	O
$	O
m	O
$	O
discrete	O
probability	O
distributions	O
supported	O
each	O
on	O
$	O
n	O
$	O
support	O
points	O
.	O
standard	O
linear	O
programming	O
(	O
LP	O
)	O
.	O

First	O
,	O
we	O
show	O
that	O
the	O
standard	O
linear	O
programming	O
(	O
LP	O
)	O
representation	O
of	O
the	O
MOT	AI/ML/DL-focus
problem	O
is	O
not	O
a	O
minimum	AI/ML/DL-focus
-	AI/ML/DL-focus
cost	AI/ML/DL-focus
flow	AI/ML/DL-focus
problem	AI/ML/DL-focus
when	O
$	O
m	O
\	O
geq	O
3	O
$.	O
combinatorial	O
algorithms	O
.	O

This	O
negative	O
result	O
implies	O
that	O
some	O
combinatorial	O
algorithms	O
,	O
e	O
.	O
g	O
.,	O
network	O
simplex	O
method	O
,	O
are	O
not	O
suitable	O
for	O
approximating	O
the	O
MOT	AI/ML/DL-focus
problem	O
,	O
while	O
the	O
worst	O
-	O
case	O
complexity	O
bound	O
for	O
the	O
deterministic	O
interior	O
-	O
point	O
algorithm	O
remains	O
a	O
quantity	O
of	O
$\	O
tilde	O
{\	O
mathcal	O
{	O
O	O
}}(	O
n	O
^{	O
3m	O
})$.	O
deterministic	O
algorithms	O
.	O

We	O
then	O
propose	O
two	O
simple	O
and	O
deterministic	O
algorithms	O
for	O
approximating	O
the	O
MOT	AI/ML/DL-focus
algorithm	O
.	O

This	O
provides	O
a	O
first	O
near	O
-	O
linear	O
time	O
complexity	O
bound	O
guarantee	O
for	O
approximating	O
the	O
MOT	AI/ML/DL-focus
complexity	O
bound	O
es	O
the	O
best	O
known	O
complexity	O
bound	O
for	O
the	O
Sinkhorn	O
algorithm	O
algorithm	O
ssical	O
OT	O
setting	O
when	O
$	O
m	O
=	O
2	O
$.	O

Preliminary	O
results	O
on	O
synthetic	O
data	O
and	O
real	O
images	O
demonstrate	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
our	O
algorithms	O
.	O
multivariate	AI/ML/DL-focus
square	AI/ML/DL-focus
-	AI/ML/DL-focus
root	AI/ML/DL-focus
lasso	AI/ML/DL-focus
.	O

Unlike	O
existing	O
methods	O
that	O
require	O
explicit	O
estimates	O
of	O
the	O
error	O
precision	O
(	O
inverse	O
covariance	O
)	O
matrix	O
the	O
multivariate	AI/ML/DL-focus
square	AI/ML/DL-focus
-	AI/ML/DL-focus
root	AI/ML/DL-focus
lasso	AI/ML/DL-focus
implicitly	O
accounts	O
for	O
error	O
dependence	O
and	O
is	O
the	O
solution	O
to	O
a	O
convex	AI/ML/DL-focus
optimization	AI/ML/DL-focus
problem	O
.	O

We	O
establish	O
error	O
bounds	O
which	O
reveal	O
that	O
like	O
the	O
univariate	AI/ML/DL-focus
square	AI/ML/DL-focus
-	AI/ML/DL-focus
root	AI/ML/DL-focus
lasso	AI/ML/DL-focus
the	O
multivariate	AI/ML/DL-focus
square	AI/ML/DL-focus
-	AI/ML/DL-focus
root	AI/ML/DL-focus
lasso	AI/ML/DL-focus
is	O
pivotal	O
with	O
respect	O
to	O
the	O
unknown	O
error	O
covariance	O
matrix	O
.	O

In	O
both	O
simulation	O
studies	O
and	O
a	O
genomic	O
data	O
application	O
,	O
we	O
show	O
that	O
the	O
multivariate	AI/ML/DL-focus
square	AI/ML/DL-focus
-	AI/ML/DL-focus
root	AI/ML/DL-focus
lasso	AI/ML/DL-focus
can	O
outperform	O
more	O
computationally	O
intensive	O
methods	O
that	O
require	O
explicit	O
estimation	O
of	O
the	O
error	O
precision	O
matrix	O
.	O
deep	O
neural	O
networks	O
.	O

Numerical	O
experiments	O
demonstrate	O
that	O
the	O
proposed	O
scaling	O
-	O
translation	O
-	O
equivariant	O
network	O
with	O
decomposed	O
convolutional	O
filters	O
(	O
ScDCFNet	O
)	O
achieves	O
significantly	O
improved	O
performance	O
in	O
multiscale	Computer/vision-focus
image	Computer/vision-focus
classification	Computer/vision-focus
and	O
better	O
interpretability	O
than	O
regular	O
CNNs	O
at	O
a	O
reduced	O
model	O
size	O
.	O
distributed	O
subgradient	O
methods	O
.	O

We	O
also	O
show	O
that	O
the	O
same	O
method	O
can	O
fail	O
to	O
have	O
this	O
“	O
asymptotic	O
network	O
independence	O
property	O
under	O
the	O
optimally	O
decaying	O
step	O
-	O
size	O
$	O
1	O
/\	O
sqrt	O
{	O
t	O
}$	O
and	O
,	O
as	O
a	O
consequence	O
,	O
can	O
fail	O
to	O
provide	O
a	O
linear	O
speedup	O
step	O
-	O
size	O
o	O
a	O
single	O
node	O
with	O
$	O
1	O
/\	O
sqrt	O
{	O
t	O
}$	O
step	O
-	O
size	O
.	O
estimation	AI/ML/DL-focus
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
method	O
called	O
Batch	O
Normalization	O
Preconditioning	O
(	O
BNP	O
)	O
normalization	AI/ML/DL-focus
.	O

We	O
consider	O
this	O
work	O
a	O
considerable	O
step	O
in	O
the	O
direction	O
of	O
making	O
the	O
long	O
-	O
standing	O
challenge	O
of	O
carrying	O
out	O
a	O
fully	O
Bayesian	O
treatment	O
of	O
neural	O
networks	O
including	O
convolutional	O
neural	O
networks	O
a	O
concrete	O
possibility	O
.	O
Posterior	AI/ML/DL-focus
collapse	AI/ML/DL-focus
density	O
models	O
.	O

Posterior	O
collapse	O
is	O
a	O
common	O
failure	O
mode	O
of	O
density	O
models	O
trained	O
as	O
variational	O
autoencoders	O
wherein	O
they	O
model	O
the	O
data	O
without	O
relying	O
on	O
their	O
latent	O
variables	O
rendering	O
these	O
variables	O
useless	O
.	O
posterior	AI/ML/DL-focus
collapse	AI/ML/DL-focus
.	O

First	O
,	O
the	O
underspecification	O
of	O
the	O
model	O
,	O
which	O
in	O
an	O
extreme	O
but	O
common	O
case	O
allows	O
posterior	AI/ML/DL-focus
collapse	AI/ML/DL-focus
to	O
be	O
the	O
theoretical	O
optimium	O
variational	O
lower	O
bound	O
.	O

While	O
alleviated	O
,	O
the	O
tradeoff	O
between	O
modelling	O
the	O
data	O
and	O
using	O
the	O
latents	O
still	O
remains	O
,	O
and	O
we	O
urge	O
for	O
evaluating	O
inference	O
methods	O
across	O
a	O
range	O
of	O
mutual	O
information	O
values	O
.	O
Inferring	Data/Mining/Information/Retrieval-focus
graph	Data/Mining/Information/Retrieval-focus
structure	Data/Mining/Information/Retrieval-focus
.	O

Departing	O
from	O
the	O
more	O
common	O
inference	O
of	O
a	O
single	O
graph	O
,	O
we	O
study	O
the	O
problem	O
of	O
jointly	O
inferring	O
multiple	O
graphs	O
from	O
the	O
observation	O
of	O
signals	O
at	O
their	O
nodes	O
(	O
graph	O
signals	O
),	O
which	O
are	O
assumed	O
to	O
be	O
stationary	O
in	O
the	O
sought	O
graphs	O
.	O
Graph	Data/Mining/Information/Retrieval-focus
stationarity	Data/Mining/Information/Retrieval-focus
.	O

In	O
this	O
paper	O
,	O
we	O
provide	O
a	O
general	O
framework	O
for	O
studying	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
agent	AI/ML/DL-focus
online	AI/ML/DL-focus
learning	AI/ML/DL-focus
problems	O
in	O
the	O
presence	O
of	O
delays	O
and	O
asynchronicities	O
.	O
adaptive	AI/ML/DL-focus
dual	AI/ML/DL-focus
averaging	AI/ML/DL-focus
.	O

Under	O
ordinary	O
smoothness	O
assumptions	O
more	O
caution	O
is	O
needed	O
as	O
a	O
polynomial	O
deviation	O
in	O
the	O
sample	O
sizes	O
could	O
drastically	O
deteriorate	O
the	O
convergence	O
to	O
the	O
truth	O
.	O
Clustering	AI/ML/DL-focus
unsupervised	O
learning	O
.	O

There	O
is	O
an	O
increased	O
emphasis	O
on	O
fairness	O
in	O
machine	O
learning	O
and	O
AI	O
;	O
one	O
representative	O
notion	O
of	O
fairness	O
is	O
that	O
no	O
single	O
group	O
should	O
be	O
over	O
-	O
represented	O
among	O
the	O
cluster	O
-	O
centers	O
clustering	AI/ML/DL-focus
.	O

Motivated	O
by	O
analyzing	O
long	O
-	O
term	O
physiological	O
time	O
series	O
,	O
we	O
design	O
a	O
robust	O
and	O
scalable	Data/Mining/Information/Retrieval-focus
spectral	Data/Mining/Information/Retrieval-focus
embedding	Data/Mining/Information/Retrieval-focus
algorithm	O
that	O
we	O
refer	O
to	O
as	O
RObust	O
and	O
Scalable	O
Embedding	O
via	O
LANdmark	O
Diffusion	O
(	O
Roseland	O
)	O
.	O

To	O
demonstrate	O
the	O
potential	O
of	O
Roseland	O
,	O
we	O
apply	O
it	O
to	O
{	O
three	O
}	O
datasets	O
and	O
compare	O
it	O
with	O
several	O
other	O
existing	O
algorithms	O
Roseland	O
spectral	Data/Mining/Information/Retrieval-focus
clustering	Data/Mining/Information/Retrieval-focus
MNIST	O
.	O

First	O
,	O
we	O
apply	O
Roseland	O
to	O
the	O
task	O
of	O
spectral	O
clustering	O
using	O
the	O
MNIST	O
dataset	O
(	O
70	O
,	O
000	O
images	O
,	O
achieving	O
85	O
\%	O
accuracy	Classification-metrics
when	O
the	O
dataset	O
is	O
clean	O
and	O
78	O
\%	O
accuracy	Classification-metrics
when	O
the	O
dataset	O
is	O
noisy	O
.	O
subsampling	O
.	O

Compared	O
with	O
other	O
subsampling	O
schemes	O
,	O
overall	O
Roseland	O
achieves	O
a	O
better	O
performance	O
.	O
image	Computer/vision-focus
segmentation	Computer/vision-focus
COCO	O
.	O

In	O
a	O
wide	O
variety	O
of	O
our	O
simulations	O
,	O
CD	O
-	O
split	O
and	O
HPD	O
-	O
split	O
have	O
better	O
conditional	O
coverage	O
and	O
yield	O
smaller	O
prediction	O
regions	O
than	O
other	O
methods	O
.	O
Error	AI/ML/DL-focus
decomposition	AI/ML/DL-focus
analysis	AI/ML/DL-focus
ensemble	O
learning	O
.	O

Error	O
decomposition	O
analysis	O
is	O
a	O
key	O
problem	O
for	O
ensemble	O
learning	O
which	O
indicates	O
that	O
proper	O
combination	O
of	O
multiple	O
models	O
can	O
achieve	O
better	O
performance	O
than	O
any	O
individual	O
one	O
.	O
regression	AI/ML/DL-focus
.	O

Existing	O
theoretical	O
research	O
of	O
ensemble	O
learning	O
focuses	O
on	O
regression	O
or	O
classification	AI/ML/DL-focus
tasks	O
.	O
ranking	AI/ML/DL-focus
ensemble	AI/ML/DL-focus
.	O

In	O
this	O
paper	O
,	O
we	O
first	O
generalize	O
the	O
ambiguity	O
decomposition	O
theory	O
from	O
regression	O
ensemble	O
to	O
ranking	AI/ML/DL-focus
ensemble	AI/ML/DL-focus
which	O
proves	O
the	O
effectiveness	O
of	O
ranking	O
ensemble	O
with	O
consideration	O
of	O
list	O
-	O
wise	O
ranking	O
information	O
.	O

According	O
to	O
the	O
generalized	O
theory	O
,	O
we	O
propose	O
an	O
explicit	O
diversity	O
measure	O
for	O
ranking	AI/ML/DL-focus
ensemble	AI/ML/DL-focus
which	O
can	O
be	O
used	O
to	O
enhance	O
the	O
diversity	O
of	O
ensemble	O
and	O
improve	O
the	O
performance	O
of	O
ensemble	O
model	O
query	O
-	O
dependent	O
.	O

Extensive	O
experiments	O
on	O
recommendation	O
and	O
information	O
retrieval	O
tasks	O
demonstrate	O
the	O
effectiveness	O
and	O
theoretical	O
advantages	O
of	O
the	O
proposed	O
method	O
compared	O
with	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
graph	Data/Mining/Information/Retrieval-focus
representation	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
GRL	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
GRL	Data/Mining/Information/Retrieval-focus
.	O

Here	O
,	O
we	O
aim	O
to	O
bridge	O
the	O
gap	O
between	O
network	O
embedding	O
,	O
graph	O
regularization	O
and	O
graph	O
neural	O
networks	O
GRL	Data/Mining/Information/Retrieval-focus
.	O

In	O
this	O
paper	O
,	O
we	O
consider	O
an	O
unconstrained	O
optimization	O
model	O
where	O
the	O
objective	O
is	O
a	O
sum	O
of	O
a	O
large	O
number	O
of	O
possibly	O
nonconvex	O
functions	O
though	O
overall	O
the	O
objective	O
is	O
assumed	O
to	O
be	O
smooth	O
and	O
convex	O
.	O
cubic	AI/ML/DL-focus
regularization	AI/ML/DL-focus
.	O

Our	O
bid	O
to	O
solving	O
such	O
model	O
uses	O
the	O
framework	O
of	O
cubic	AI/ML/DL-focus
regularization	AI/ML/DL-focus
of	O
Newton	O
'	O
s	O
method	O
.	O
Hessian	O
.	O

In	O
particular	O
,	O
we	O
propose	O
to	O
compute	O
an	O
approximated	O
Hessian	O
matrix	O
by	O
either	O
uniformly	O
or	O
non	O
-	O
uniformly	O
sub	O
-	O
sampling	O
the	O
components	O
of	O
the	O
objective	O
.	O
cubic	AI/ML/DL-focus
regularization	AI/ML/DL-focus
.	O

Based	O
upon	O
such	O
sampling	O
strategy	O
,	O
we	O
develop	O
accelerated	O
adaptive	O
cubic	O
regularization	O
approaches	O
and	O
provide	O
theoretical	O
guarantees	O
on	O
global	O
iteration	O
complexity	O
of	O
$\	O
O	O
(\	O
epsilon	O
^{-	O
1	O
/	O
3	O
})$	O
with	O
high	O
probability	O
cubic	AI/ML/DL-focus
regularization	AI/ML/DL-focus
f	O
the	O
original	O
accelerated	O
cubic	O
regularization	O
methods	O
Jiang	O
et	O
al	O
.	O
Hessian	O
.	O

This	O
allows	O
us	O
to	O
obtain	O
new	O
results	O
on	O
hardness	O
of	O
approximation	O
and	O
learnability	O
of	O
parity	O
functions	O
DNF	O
formulas	O
and	O
$	O
AC	O
^	O
0	O
$	O
circuits	O
.	O
Gaussian	O
processes	O
probabilistic	AI/ML/DL-focus
kernel	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

We	O
utilize	O
the	O
structure	O
of	O
the	O
low	O
rank	O
approximation	O
to	O
achieve	O
effective	O
hyperparameter	AI/ML/DL-focus
learning	AI/ML/DL-focus
training	O
and	O
prediction	O
.	O
random	O
Fourier	O
features	O
.	O

Furthermore	O
,	O
the	O
structure	O
of	O
the	O
low	O
-	O
rank	O
approximation	O
that	O
our	O
method	O
builds	O
is	O
subtly	O
different	O
from	O
the	O
one	O
generated	O
by	O
random	O
Fourier	O
features	O
,	O
and	O
this	O
enables	O
much	O
more	O
efficient	O
hyperparameter	AI/ML/DL-focus
learning	AI/ML/DL-focus
datasets	O
.	O

We	O
adopt	O
a	O
Bayesian	O
perspective	O
and	O
demonstrate	O
that	O
,	O
for	O
a	O
suitable	O
choice	O
of	O
prior	O
constructed	O
with	O
sufficiently	O
many	O
unlabeled	O
data	O
,	O
the	O
posterior	O
contracts	O
around	O
the	O
truth	O
at	O
a	O
rate	O
that	O
is	O
minimax	O
optimal	O
up	O
to	O
a	O
logarithmic	O
factor	O
regression	AI/ML/DL-focus
classification	AI/ML/DL-focus
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
the	O
Prediction	O
for	O
Enormous	O
and	O
Correlated	O
Output	O
Spaces	O
(	O
PECOS	O
)	O
framework	O
,	O
a	O
versatile	O
and	O
modular	O
machine	O
learning	O
framework	O
for	O
solving	O
prediction	O
problems	O
for	O
very	O
large	O
output	O
spaces	O
,	O
and	O
apply	O
it	O
to	O
the	O
eXtreme	AI/ML/DL-focus
Multilabel	AI/ML/DL-focus
Ranking	AI/ML/DL-focus
(	AI/ML/DL-focus
XMR	AI/ML/DL-focus
)	AI/ML/DL-focus
PECOS	O
PECOS	O
en	O
an	O
input	O
instance	O
,	O
find	O
and	O
rank	O
the	O
most	O
relevant	O
items	O
from	O
an	O
enormous	O
but	O
fixed	O
and	O
finite	O
output	O
space	O
.	O

For	O
the	O
critical	O
matching	O
phase	O
,	O
we	O
develop	O
a	O
recursive	O
machine	O
learned	O
matching	O
strategy	O
with	O
both	O
linear	O
and	O
neural	O
matchers	O
eXtreme	AI/ML/DL-focus
Multilabel	AI/ML/DL-focus
Ranking	AI/ML/DL-focus
.	O

When	O
applied	O
to	O
eXtreme	O
Multilabel	O
Ranking	O
where	O
the	O
input	O
instances	O
are	O
in	O
textual	O
form	O
,	O
we	O
find	O
that	O
the	O
recursive	O
Transformer	O
matcher	O
gives	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	Classification-metrics
results	O
,	O
at	O
the	O
cost	O
of	O
two	O
orders	O
of	O
magnitude	O
increased	O
training	O
time	O
compared	O
to	O
the	O
recursive	O
linear	O
matcher	O
dataset	O
.	O

For	O
example	O
,	O
on	O
a	O
dataset	O
where	O
the	O
output	O
space	O
is	O
of	O
size	O
2	O
.	O
8	O
million	O
,	O
the	O
recursive	O
Transformer	O
matcher	O
results	O
in	O
a	O
6	O
%	O
increase	O
in	O
precision	Classification-metrics
@	Classification-metrics
1	Classification-metrics
(	O
from	O
48	O
.	O
6	O
%	O
to	O
54	O
.	O
2	O
%)	O
over	O
the	O
recursive	O
linear	O
matcher	O
but	O
takes	O
100x	O
more	O
time	O
to	O
train	O
.	O

Thus	O
it	O
is	O
up	O
to	O
the	O
practitioner	O
to	O
evaluate	O
the	O
trade	O
-	O
offs	O
and	O
decide	O
whether	O
the	O
increased	O
training	O
time	O
and	O
infrastructure	O
cost	O
is	O
warranted	O
for	O
their	O
application	O
;	O
indeed	O
,	O
the	O
flexibility	O
of	O
the	O
PECOS	O
framework	O
seamlessly	O
allows	O
different	O
strategies	O
to	O
be	O
used	O
.	O
XMR	AI/ML/DL-focus
.	O

Retrieval	O
Augment	O
Generation	O
(	O
RAG	O
)	O
is	O
a	O
recent	O
advancement	O
in	O
Open	NLP-focus
-	NLP-focus
Domain	NLP-focus
Question	NLP-focus
Answering	NLP-focus
(	NLP-focus
ODQA	NLP-focus
)	NLP-focus
.	O

In	O
this	O
paper	O
,	O
we	O
evaluate	O
the	O
impact	O
of	O
joint	O
training	O
of	O
the	O
retriever	O
and	O
generator	O
components	O
of	O
RAG	O
for	O
the	O
task	O
of	O
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
in	O
ODQA	NLP-focus
.	O

Our	O
novel	O
contribution	O
is	O
that	O
,	O
unlike	O
RAG	O
RAG	O
-	O
end2end	O
does	O
joint	O
training	O
of	O
the	O
retriever	O
and	O
generator	O
for	O
the	O
end	NLP-focus
QA	NLP-focus
task	NLP-focus
and	O
domain	NLP-focus
adaptation	NLP-focus
.	O

Many	O
studies	O
have	O
shown	O
that	O
transformers	O
are	O
able	O
to	O
predict	O
subject	NLP-focus
-	NLP-focus
verb	NLP-focus
agreement	NLP-focus
demonstrating	O
their	O
ability	O
to	O
uncover	O
an	O
abstract	NLP-focus
representation	NLP-focus
of	O
the	O
sentence	O
in	O
an	O
unsupervised	O
way	O
.	O

(	O
2021	O
)	O
found	O
that	O
transformers	O
were	O
also	O
able	O
to	O
predict	O
the	O
object	NLP-focus
-	NLP-focus
past	NLP-focus
participle	NLP-focus
agreement	NLP-focus
in	O
French	O
the	O
modeling	O
of	O
which	O
in	O
formal	O
grammar	O
is	O
fundamentally	O
different	O
from	O
that	O
of	O
subject	NLP-focus
-	NLP-focus
verb	NLP-focus
agreement	NLP-focus
and	O
relies	O
on	O
a	O
movement	O
and	O
an	O
anaphora	O
resolution	O
transformers	O
erstand	O
transformers	O
’	O
internal	O
working	O
,	O
we	O
propose	O
to	O
contrast	O
how	O
they	O
handle	O
these	O
two	O
kinds	O
of	O
agreement	O
.	O

Using	O
probing	O
and	O
counterfactual	O
analysis	O
methods	O
,	O
our	O
experiments	O
on	O
French	O
agreements	O
show	O
that	O
(	O
i	O
)	O
the	O
agreement	O
task	O
suffers	O
from	O
several	O
confounders	O
that	O
partially	O
question	O
the	O
conclusions	O
drawn	O
so	O
far	O
and	O
(	O
ii	O
)	O
transformers	O
handle	O
subject	NLP-focus
-	NLP-focus
verb	NLP-focus
and	O
object	NLP-focus
-	NLP-focus
past	NLP-focus
participle	NLP-focus
agreements	NLP-focus
in	O
a	O
way	O
that	O
is	O
consistent	O
with	O
their	O
modeling	O
in	O
theoretical	O
linguistics	O
.	O

In	O
contrast	O
,	O
we	O
turn	O
our	O
focus	O
to	O
negative	O
outcomes	O
here	O
,	O
and	O
introduce	O
a	O
new	O
task	O
of	O
negative	NLP-focus
outcome	NLP-focus
prediction	NLP-focus
.	O

Where	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
outcome	O
prediction	O
model	O
we	O
used	O
predicts	O
positive	O
outcomes	O
at	O
75	O
.	O
06	O
F1	Classification-metrics
it	O
predicts	O
negative	O
outcomes	O
at	O
only	O
10	O
.	O
09	O
F1	Classification-metrics
worse	O
than	O
a	O
random	O
baseline	O
.	O

Our	O
first	O
model	O
significantly	O
improves	O
positive	NLP-focus
outcome	NLP-focus
prediction	NLP-focus
score	O
to	O
77	O
.	O
15	O
F1	Classification-metrics
and	O
our	O
second	O
model	O
more	O
than	O
doubles	O
the	O
negative	NLP-focus
outcome	NLP-focus
prediction	NLP-focus
performance	O
to	O
24	O
.	O
01	O
F1	Classification-metrics
.	O

Our	O
first	O
model	O
significantly	O
improves	O
positive	NLP-focus
outcome	NLP-focus
prediction	NLP-focus
score	O
to	O
77	O
.	O
15	O
F1	Classification-metrics
and	O
our	O
second	O
model	O
more	O
than	O
doubles	O
the	O
negative	NLP-focus
outcome	NLP-focus
prediction	NLP-focus
performance	O
to	O
24	O
.	O
01	O
F1	Classification-metrics
.	O

Despite	O
this	O
improvement	O
,	O
shifting	O
focus	O
to	O
negative	O
outcomes	O
reveals	O
that	O
there	O
is	O
still	O
much	O
room	O
for	O
improvement	O
for	O
outcome	NLP-focus
prediction	NLP-focus
models	NLP-focus
https	O
://	O
github	O
.	O
com	O
/	O
valvoda	O
/	O
Negative	O
-	O
Precedent	O
-	O
in	O
-	O
Legal	O
-	O
Outcome	O
-	O
Prediction	O
.	O

Localizing	O
a	O
semantic	O
parser	O
to	O
support	O
new	O
languages	O
requires	O
effective	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
generalization	NLP-focus
.	O

Recent	O
work	O
has	O
found	O
success	O
with	O
machine	NLP-focus
-	NLP-focus
translation	NLP-focus
or	O
zero	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
methods	AI/ML/DL-focus
although	O
these	O
approaches	O
can	O
struggle	O
to	O
model	O
how	O
native	O
speakers	O
ask	O
questions	O
.	O

We	O
consider	O
how	O
to	O
effectively	O
leverage	O
minimal	O
annotated	O
examples	O
in	O
new	O
languages	O
for	O
few	NLP-focus
-	NLP-focus
shot	NLP-focus
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
semantic	NLP-focus
parsing	NLP-focus
.	O

We	O
introduce	O
a	O
first	O
-	O
order	O
meta	O
-	O
learning	O
algorithm	O
to	O
train	O
a	O
semantic	O
parser	O
with	O
maximal	O
sample	O
efficiency	O
during	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
transfer	NLP-focus
.	O

Our	O
algorithm	O
uses	O
high	O
-	O
resource	O
languages	O
to	O
train	O
the	O
parser	O
and	O
simultaneously	O
optimizes	O
for	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
generalization	NLP-focus
to	O
lower	O
-	O
resource	O
languages	O
.	O

This	O
paper	O
presents	O
an	O
ontology	O
-	O
aware	O
pretrained	O
language	O
model	O
(	O
OPAL	O
)	O
for	O
end	O
-	O
to	O
-	O
end	O
task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialogue	NLP-focus
(	NLP-focus
TOD	NLP-focus
)	NLP-focus
.	O

The	O
large	O
-	O
scale	O
task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialogue	NLP-focus
data	NLP-focus
with	O
the	O
annotated	O
structured	O
dialogue	O
state	O
usually	O
are	O
inaccessible	O
.	O

It	O
prevents	O
the	O
development	O
of	O
the	O
pretrained	O
language	O
model	O
for	O
the	O
task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialogue	NLP-focus
.	O

To	O
bridge	O
the	O
gap	O
between	O
the	O
pretraining	O
method	O
and	O
downstream	O
tasks	O
,	O
we	O
design	O
two	O
pretraining	O
tasks	O
:	O
ontology	NLP-focus
-	NLP-focus
like	NLP-focus
triple	NLP-focus
recovery	NLP-focus
and	O
next	NLP-focus
-	NLP-focus
text	NLP-focus
generation	NLP-focus
which	O
simulates	O
the	O
DST	O
and	O
RG	O
respectively	O
.	O

The	O
second	O
phase	O
is	O
to	O
fine	O
-	O
tune	O
the	O
pretrained	O
model	O
on	O
the	O
TOD	NLP-focus
data	O
.	O

Applied	O
to	O
Japanese	O
place	O
names	O
we	O
demonstrate	O
the	O
utility	O
of	O
the	O
model	O
to	O
finding	O
and	O
proposing	O
corrections	O
for	O
errors	O
in	O
Google	O
Maps	O
.	O
To	O
demonstrate	O
the	O
utility	O
of	O
this	O
approach	O
to	O
structurally	O
similar	O
problems	O
,	O
we	O
also	O
report	O
on	O
an	O
application	O
to	O
a	O
totally	O
different	O
task	O
:	O
Cognate	NLP-focus
reflex	NLP-focus
prediction	NLP-focus
in	O
comparative	O
historical	O
linguistics	O
.	O

Today	O
’	O
s	O
probabilistic	O
language	O
generators	O
fall	O
short	O
when	O
it	O
comes	O
to	O
producing	O
coherent	O
and	O
fluent	O
text	O
despite	O
the	O
fact	O
that	O
the	O
underlying	O
models	O
perform	O
well	O
under	O
standard	O
metrics	O
(	O
e	O
.	O
g	O
.,	O
perplexity	NLP-metrics
.	O

This	O
discrepancy	O
has	O
puzzled	O
the	O
language	NLP-focus
generation	NLP-focus
community	O
for	O
the	O
last	O
few	O
years	O
.	O

In	O
this	O
work	O
,	O
we	O
posit	O
that	O
the	O
abstraction	O
of	O
natural	NLP-focus
language	NLP-focus
generation	NLP-focus
as	O
a	O
discrete	O
stochastic	O
process	O
which	O
allows	O
for	O
an	O
information	O
-	O
theoretic	O
analysis	O
can	O
provide	O
new	O
insights	O
into	O
the	O
behavior	O
of	O
probabilistic	O
language	O
generators	O
for	O
example	O
,	O
why	O
high	O
-	O
probability	O
texts	O
can	O
be	O
dull	O
or	O
repetitive	O
.	O

We	O
formally	O
define	O
the	O
set	O
of	O
strings	O
that	O
meet	O
this	O
criterion	O
:	O
Those	O
for	O
which	O
each	O
word	O
has	O
an	O
information	O
content	O
close	O
to	O
the	O
expected	O
information	O
content	O
namely	O
,	O
the	O
conditional	Statistical/Mathematical-metrics
entropy	Statistical/Mathematical-metrics
of	O
our	O
model	O
.	O

Automatic	O
and	O
human	O
evaluations	O
show	O
that	O
,	O
in	O
comparison	O
to	O
nucleus	O
and	O
top	O
-	O
k	O
sampling	O
,	O
locally	O
typical	O
sampling	O
offers	O
competitive	O
performance	O
(	O
in	O
both	O
abstractive	NLP-focus
summarization	NLP-focus
and	O
story	NLP-focus
generation	NLP-focus
in	O
terms	O
of	O
quality	O
while	O
consistently	O
reducing	O
degenerate	O
repetitions	O
.	O

Multilingual	NLP-focus
task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialogue	NLP-focus
(	NLP-focus
ToD	NLP-focus
)	NLP-focus
facilitates	O
access	O
to	O
services	O
and	O
information	O
for	O
many	O
(	O
communities	O
of	O
)	O
speakers	O
.	O

In	O
this	O
work	O
,	O
to	O
tackle	O
these	O
limitations	O
we	O
propose	O
a	O
novel	O
outline	O
-	O
based	O
annotation	O
process	O
for	O
multilingual	NLP-focus
ToD	NLP-focus
datasets	O
,	O
where	O
domain	O
-	O
specific	O
abstract	O
schemata	O
of	O
dialogue	O
are	O
mapped	O
into	O
natural	O
language	O
outlines	O
.	O

Finally	O
,	O
we	O
benchmark	O
a	O
series	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
for	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
ToD	NLP-focus
setting	O
reference	O
scores	O
for	O
future	O
work	O
and	O
demonstrating	O
that	O
cod	O
prevents	O
over	O
-	O
inflated	O
performance	O
,	O
typically	O
met	O
with	O
prior	O
translation	O
-	O
based	O
ToD	O
datasets	O
.	O

Most	O
previous	O
work	O
in	O
music	NLP-focus
emotion	NLP-focus
recognition	NLP-focus
assumes	O
a	O
single	O
or	O
a	O
few	O
song	O
-	O
level	O
labels	O
for	O
the	O
whole	O
song	O
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
method	O
to	O
predict	NLP-focus
emotion	NLP-focus
dynamics	NLP-focus
in	O
song	O
lyrics	O
without	O
song	O
-	O
level	O
supervision	O
.	O

Drawing	O
on	O
studies	O
of	O
word	NLP-focus
acquisition	NLP-focus
in	O
children	O
,	O
we	O
evaluate	O
multiple	O
predictors	O
for	O
words	O
’	O
ages	O
of	O
acquisition	O
in	O
LSTMs	O
BERT	O
and	O
GPT	O
-	O
2	O
.	O

We	O
find	O
that	O
the	O
effects	O
of	O
concreteness	O
,	O
word	O
length	O
and	O
lexical	O
class	O
are	O
pointedly	O
different	O
in	O
children	O
and	O
language	O
models	O
reinforcing	O
the	O
importance	O
of	O
interaction	O
and	O
sensorimotor	O
experience	O
in	O
child	NLP-focus
language	NLP-focus
acquisition	NLP-focus
.	O

We	O
present	O
an	O
event	NLP-focus
structure	NLP-focus
classification	NLP-focus
empirically	O
derived	O
from	O
inferential	O
properties	O
annotated	O
on	O
sentence	O
-	O
and	O
document	O
-	O
level	O
Universal	O
Decompositional	O
Semantics	O
(	O
UDS	O
)	O
graphs	O
.	O

We	O
induce	O
this	O
classification	AI/ML/DL-focus
jointly	O
with	O
semantic	O
role	O
entity	O
and	O
event	O
-	O
event	O
relation	O
classifications	AI/ML/DL-focus
using	O
a	O
document	O
-	O
level	O
generative	O
model	O
structured	O
by	O
these	O
graphs	O
.	O

Existing	O
table	O
question	NLP-focus
answering	NLP-focus
datasets	O
contain	O
abundant	O
factual	O
questions	O
that	O
primarily	O
evaluate	O
a	O
QA	NLP-focus
system	NLP-focus
s	O
comprehension	O
of	O
query	O
and	O
tabular	O
data	O
.	O

To	O
complement	O
the	O
existing	O
datasets	O
and	O
to	O
reveal	O
the	O
challenging	O
nature	O
of	O
the	O
table	NLP-focus
-	NLP-focus
based	NLP-focus
question	NLP-focus
answering	NLP-focus
task	NLP-focus
we	O
introduce	O
FeTaQA	O
dataset	O
ataset	O
with	O
10K	O
Wikipedia	O
-	O
based	O
table	O
question	O
ion	O
,	O
free	O
-	O
form	O
answer	O
supporting	O
table	O
cells	O
\}	O
pairs	O
.	O

FeTaQA	O
is	O
collected	O
from	O
noteworthy	O
descriptions	O
of	O
Wikipedia	O
tables	O
that	O
contain	O
information	O
people	O
tend	O
to	O
seek	O
;	O
generation	O
of	O
these	O
descriptions	O
requires	O
advanced	O
processing	O
that	O
humans	O
perform	O
on	O
a	O
daily	O
basis	O
:	O
Understand	O
the	O
question	O
and	O
table	O
,	O
retrieve	O
,	O
integrate	O
,	O
infer	O
,	O
and	O
conduct	O
text	NLP-focus
planning	NLP-focus
and	O
surface	O
realization	O
to	O
generate	O
an	O
answer	O
.	O

We	O
provide	O
two	O
benchmark	O
methods	O
for	O
the	O
proposed	O
task	O
:	O
a	O
pipeline	O
method	O
based	O
on	O
semantic	O
parsing	O
based	O
QA	NLP-focus
systems	NLP-focus
and	O
an	O
end	O
-	O
to	O
-	O
end	O
method	O
based	O
on	O
large	O
pretrained	O
text	O
generation	O
models	O
and	O
show	O
that	O
FeTaQA	O
poses	O
a	O
challenge	O
for	O
both	O
methods	O
.	O

Canine	O
outperforms	O
a	O
comparable	O
mBert	O
model	O
by	O
5	O
.	O
7	O
F1	Classification-metrics
on	O
TyDi	O
QA	O
a	O
challenging	O
multilingual	O
benchmark	O
despite	O
having	O
fewer	O
model	O
parameters	O
.	O

However	O
,	O
annotators	O
may	O
systematically	O
disagree	O
with	O
one	O
another	O
,	O
often	O
reflecting	O
their	O
individual	O
biases	O
and	O
values	O
,	O
especially	O
in	O
the	O
case	O
of	O
subjective	O
tasks	O
such	O
as	O
detecting	NLP-focus
affect	O
aggression	O
and	O
hate	O
speech	O
.	O

We	O
show	O
that	O
this	O
approach	O
yields	O
same	O
or	O
better	O
performance	O
than	O
aggregating	AI/ML/DL-focus
labels	AI/ML/DL-focus
in	O
the	O
data	O
prior	O
to	O
training	O
across	O
seven	O
different	O
binary	AI/ML/DL-focus
classification	AI/ML/DL-focus
tasks	AI/ML/DL-focus
.	O

Our	O
approach	O
also	O
provides	O
a	O
way	O
to	O
estimate	NLP-focus
uncertainty	NLP-focus
in	O
predictions	O
,	O
which	O
we	O
demonstrate	O
better	O
correlate	O
with	O
annotation	O
disagreements	O
than	O
traditional	O
methods	O
.	O

In	O
this	O
work	O
,	O
we	O
introduce	O
the	O
“	O
Break	O
,	O
Perturb	O
,	O
Build	O
”	O
(	O
BPB	O
)	O
framework	O
for	O
automatic	NLP-focus
reasoning	NLP-focus
-	NLP-focus
oriented	NLP-focus
perturbation	NLP-focus
of	O
question	O
-	O
answer	O
pairs	O
.	O

We	O
demonstrate	O
the	O
effectiveness	O
of	O
BPB	O
by	O
creating	O
evaluation	O
sets	O
for	O
three	O
reading	NLP-focus
comprehension	NLP-focus
(	NLP-focus
RC	NLP-focus
)	NLP-focus
benchmarks	O
,	O
generating	O
thousands	O
of	O
high	O
-	O
quality	O
examples	O
without	O
human	O
intervention	O
.	O

Discourse	NLP-focus
parsing	NLP-focus
has	O
been	O
studied	O
for	O
decades	O
.	O

Specifically	O
,	O
we	O
investigate	O
self	O
-	O
training	O
co	O
-	O
training	O
tri	O
-	O
training	O
and	O
asymmetric	O
tri	O
-	O
training	O
of	O
graph	O
-	O
based	O
and	O
transition	O
-	O
based	O
discourse	O
dependency	O
parsing	O
models	O
,	O
as	O
well	O
as	O
confidence	O
measures	O
and	O
sample	O
selection	O
criteria	O
in	O
two	O
adaptation	O
scenarios	O
:	O
monologue	NLP-focus
adaptation	NLP-focus
between	O
scientific	O
disciplines	O
and	O
dialogue	NLP-focus
genre	NLP-focus
adaptation	NLP-focus
.	O

We	O
also	O
release	O
COVID	O
-	O
19	O
Discourse	O
Dependency	O
Treebank	O
(	O
COVID19	O
-	O
DTB	O
)	O
a	O
new	O
manually	O
annotated	O
resource	O
for	O
discourse	NLP-focus
dependency	NLP-focus
parsing	NLP-focus
of	O
biomedical	O
paper	O
abstracts	O
.	O

The	O
experimental	O
results	O
show	O
that	O
bootstrapping	O
is	O
significantly	O
and	O
consistently	O
effective	O
for	O
unsupervised	AI/ML/DL-focus
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
of	O
discourse	NLP-focus
dependency	NLP-focus
parsing	NLP-focus
but	O
the	O
low	O
coverage	O
of	O
accurately	O
predicted	O
pseudo	O
labels	O
is	O
a	O
bottleneck	O
for	O
further	O
improvement	O
.	O

We	O
mine	O
the	O
parallel	O
sentences	O
from	O
the	O
Web	O
by	O
combining	O
many	O
corpora	O
,	O
tools	O
,	O
and	O
methods	O
:	O
(	O
a	O
)	O
Web	O
-	O
crawled	O
monolingual	O
corpora	O
(	O
b	O
)	O
document	O
OCR	O
for	O
extracting	Miscellaneous-focus
sentences	Miscellaneous-focus
from	O
scanned	O
documents	O
,	O
(	O
c	O
)	O
multilingual	O
representation	O
models	O
for	O
aligning	NLP-focus
sentences	NLP-focus
and	O
(	O
d	O
)	O
approximate	O
nearest	O
neighbor	O
search	O
for	O
searching	O
in	O
a	O
large	O
collection	O
of	O
sentences	O
.	O

In	O
the	O
summarization	NLP-focus
domain	O
,	O
a	O
key	O
requirement	O
for	O
summaries	O
is	O
to	O
be	O
factually	O
consistent	O
with	O
the	O
input	O
document	O
.	O

In	O
this	O
work	O
,	O
we	O
revisit	O
the	O
use	O
of	O
NLI	O
for	O
inconsistency	O
detection	O
,	O
finding	O
that	O
past	O
work	O
suffered	O
from	O
a	O
mismatch	O
in	O
input	NLP-focus
granularity	NLP-focus
between	O
NLI	O
datasets	O
(	O
sentence	O
-	O
level	O
inconsistency	NLP-focus
detection	NLP-focus
ction	O
(	O
document	O
level	O
.	O

We	O
provide	O
a	O
highly	O
effective	O
and	O
light	O
-	O
weight	O
method	O
called	O
SummaCConv	O
that	O
enables	O
NLI	O
models	O
to	O
be	O
successfully	O
used	O
for	O
this	O
task	O
by	O
segmenting	NLP-focus
documents	NLP-focus
into	O
sentence	O
units	O
and	O
aggregating	Miscellaneous-focus
scores	Miscellaneous-focus
between	O
pairs	O
of	O
sentences	O
.	O

On	O
this	O
dataset	O
,	O
SummaCConv	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
with	O
a	O
balanced	O
accuracy	Classification-metrics
of	O
74	O
.	O
4	O
\\%	O
a	O
5	O
\\%	O
improvement	O
compared	O
with	O
prior	O
work	O
.	O

Fact	NLP-focus
-	NLP-focus
checking	NLP-focus
has	O
become	O
increasingly	O
important	O
due	O
to	O
the	O
speed	O
with	O
which	O
both	O
information	O
and	O
misinformation	O
can	O
spread	O
in	O
the	O
modern	O
media	O
ecosystem	O
.	O

Therefore	O
,	O
researchers	O
have	O
been	O
exploring	O
how	O
fact	O
-	O
checking	O
can	O
be	O
automated	O
,	O
using	O
techniques	O
based	O
on	O
natural	O
language	O
processing	O
machine	O
learning	O
knowledge	NLP-focus
representation	NLP-focus
and	O
databases	O
to	O
automatically	O
predict	O
the	O
veracity	O
of	O
claims	O
.	O

In	O
this	O
paper	O
,	O
we	O
survey	O
automated	NLP-focus
fact	NLP-focus
-	NLP-focus
checking	NLP-focus
stemming	NLP-focus
from	O
natural	O
language	O
processing	O
and	O
discuss	O
its	O
connections	O
to	O
related	O
tasks	O
and	O
disciplines	O
.	O

This	O
paper	O
presents	O
a	O
new	O
task	O
of	O
predicting	O
the	O
coverage	O
of	O
a	O
text	O
document	O
for	O
relation	NLP-focus
extraction	NLP-focus
(	NLP-focus
RE	NLP-focus
)	NLP-focus
Does	O
the	O
document	O
contain	O
many	O
relational	O
tuples	O
for	O
a	O
given	O
entity	O
?	O
Coverage	O
predictions	O
are	O
useful	O
in	O
selecting	O
the	O
best	O
documents	O
for	O
knowledge	NLP-focus
base	NLP-focus
construction	NLP-focus
with	O
large	O
input	O
corpora	O
.	O

The	O
model	O
combining	O
features	O
and	O
BERT	O
HERB	O
achieves	O
an	O
F1	Classification-metrics
score	Classification-metrics
of	O
up	O
to	O
46	O
\\%	O
.	O

We	O
demonstrate	O
the	O
utility	O
of	O
coverage	O
predictions	O
on	O
two	O
use	O
cases	O
:	O
KB	NLP-focus
construction	NLP-focus
and	O
claim	NLP-focus
refutation	NLP-focus
.	O

Pretrained	O
contextualized	O
language	O
models	O
such	O
as	O
BERT	O
and	O
T5	O
have	O
established	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
ad	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
hoc	Data/Mining/Information/Retrieval-focus
search	Data/Mining/Information/Retrieval-focus
.	O

We	O
present	O
a	O
new	O
comprehensive	O
framework	O
for	O
Analyzing	Data/Mining/Information/Retrieval-focus
the	Data/Mining/Information/Retrieval-focus
Behavior	Data/Mining/Information/Retrieval-focus
of	Data/Mining/Information/Retrieval-focus
Neural	Data/Mining/Information/Retrieval-focus
IR	Data/Mining/Information/Retrieval-focus
ModeLs	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
ABNIRML	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
which	O
includes	O
new	O
types	O
of	O
diagnostic	O
probes	O
that	O
allow	O
us	O
to	O
test	O
several	O
characteristics	O
—	O
such	O
as	O
writing	NLP-focus
styles	NLP-focus
factuality	NLP-focus
sensitivity	NLP-focus
to	NLP-focus
paraphrasing	NLP-focus
and	O
word	NLP-focus
order	NLP-focus
that	O
are	O
not	O
addressed	O
by	O
previous	O
techniques	O
.	O

The	O
model	O
samples	O
and	O
rewards	O
specific	O
reasoning	O
paths	O
through	O
policy	O
gradient	O
in	O
which	O
the	O
introspective	O
revision	O
algorithm	O
modifies	O
intermediate	O
symbolic	O
reasoning	O
steps	O
to	O
discover	O
reward	O
-	O
earning	O
operations	O
as	O
well	O
as	O
leverages	O
external	O
knowledge	O
to	O
alleviate	O
spurious	AI/ML/DL-focus
reasoning	AI/ML/DL-focus
and	O
training	AI/ML/DL-focus
inefficiency	AI/ML/DL-focus
.	O

The	O
proposed	O
model	O
has	O
built	O
-	O
in	O
interpretability	O
and	O
shows	O
superior	O
capability	O
in	O
monotonicity	AI/ML/DL-focus
inference	AI/ML/DL-focus
systematic	AI/ML/DL-focus
generalization	AI/ML/DL-focus
interpretability	AI/ML/DL-focus
lity	O
,	O
compared	O
with	O
previous	O
models	O
on	O
the	O
existing	O
datasets	O
.	O

We	O
introduce	O
a	O
diagnostic	O
dataset	O
aimed	O
at	O
probing	NLP-focus
LMs	NLP-focus
for	O
factual	O
knowledge	O
LMs	O
changes	O
over	O
time	O
and	O
highlight	O
problems	O
with	O
LMs	O
at	O
either	O
end	O
of	O
the	O
spectrum	O
—	O
those	O
trained	O
on	O
specific	O
slices	O
of	O
temporal	O
data	O
temporal	O
data	O
ose	O
trained	O
on	O
a	O
wide	O
range	O
of	O
temporal	O
data	O
.	O

We	O
present	O
mGENRE	O
a	O
sequence	O
-	O
to	O
-	O
sequence	O
system	O
for	O
the	O
Multilingual	NLP-focus
Entity	NLP-focus
Linking	NLP-focus
(	NLP-focus
MEL	NLP-focus
)	NLP-focus
problem	O
—	O
the	O
task	O
of	O
resolving	O
language	O
-	O
specific	O
mentions	O
to	O
a	O
multilingual	O
Knowledge	O
Base	O
(	O
KB	O
)	O
.	O

While	O
prior	O
MEL	NLP-focus
works	O
use	O
a	O
single	O
representation	O
for	O
each	O
entity	O
we	O
match	O
against	O
entity	O
names	O
of	O
as	O
many	O
languages	O
as	O
possible	O
,	O
which	O
allows	O
exploiting	O
language	O
connections	O
between	O
source	O
input	O
and	O
target	O
name	O
.	O

This	O
leads	O
to	O
over	O
50	O
\\%	O
improvements	O
in	O
average	Classification-metrics
accuracy	Classification-metrics
.	O

Because	O
byte	O
or	O
character	O
sequences	O
are	O
longer	O
than	O
token	O
sequences	O
past	O
work	O
on	O
token	NLP-focus
-	NLP-focus
free	NLP-focus
models	NLP-focus
has	O
often	O
introduced	O
new	O
model	O
architectures	O
designed	O
to	O
amortize	O
the	O
cost	O
of	O
operating	O
directly	O
on	O
raw	O
text	O
.	O

In	O
this	O
paper	O
,	O
we	O
show	O
that	O
a	O
standard	O
Transformer	O
architecture	O
can	O
be	O
used	O
with	O
minimal	O
modifications	O
to	O
process	NLP-focus
byte	NLP-focus
sequences	NLP-focus
.	O

We	O
characterize	O
the	O
trade	O
-	O
offs	O
in	O
terms	O
of	O
parameter	Miscellaneous-metrics
count	Miscellaneous-metrics
training	Miscellaneous-metrics
FLOPs	Miscellaneous-metrics
and	O
inference	Miscellaneous-metrics
speed	Miscellaneous-metrics
and	O
show	O
that	O
byte	O
-	O
level	O
models	O
are	O
competitive	O
with	O
their	O
token	O
-	O
level	O
counterparts	O
.	O

Persuasion	AI/ML/DL-focus
games	AI/ML/DL-focus
are	O
fundamental	O
in	O
economics	O
and	O
AI	O
research	O
and	O
serve	O
as	O
the	O
basis	O
for	O
important	O
applications	O
.	O

We	O
design	O
an	O
automatic	AI/ML/DL-focus
expert	AI/ML/DL-focus
that	O
plays	O
this	O
repeated	O
game	O
,	O
aiming	O
to	O
achieve	O
the	O
maximal	O
payoff	O
.	O

We	O
introduce	O
the	O
Probabilistic	O
Worldbuilding	O
Model	O
(	O
PWM	O
)	O
a	O
new	O
fully	O
symbolic	O
Bayesian	O
model	O
of	O
semantic	NLP-focus
parsing	NLP-focus
and	O
reasoning	NLP-focus
as	O
a	O
first	O
step	O
in	O
a	O
research	O
program	O
toward	O
more	O
domain	O
-	O
and	O
task	O
-	O
general	O
NLU	O
and	O
AI	O
.	O

Text	NLP-focus
augmentation	NLP-focus
is	O
an	O
effective	O
technique	O
in	O
alleviating	O
overfitting	AI/ML/DL-focus
in	O
NLP	O
tasks	O
.	O

In	O
existing	O
methods	O
,	O
text	NLP-focus
augmentation	NLP-focus
and	O
downstream	O
tasks	O
are	O
mostly	O
performed	O
separately	O
.	O

To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
a	O
three	O
-	O
level	O
optimization	O
framework	O
to	O
perform	O
text	NLP-focus
augmentation	NLP-focus
and	O
the	O
downstream	O
task	O
end	O
-	O
to	O
-	O
end	O
.	O

A	O
text	O
summarization	O
model	O
is	O
trained	O
to	O
perform	O
data	NLP-focus
augmentation	NLP-focus
at	O
the	O
first	O
stage	O
.	O

Each	O
summarization	O
example	O
is	O
associated	O
with	O
a	O
weight	O
to	O
account	O
for	O
its	O
domain	O
difference	O
with	O
the	O
text	NLP-focus
classification	NLP-focus
data	O
.	O

At	O
the	O
second	O
stage	O
,	O
we	O
use	O
the	O
model	O
trained	O
at	O
the	O
first	O
stage	O
to	O
perform	O
text	NLP-focus
augmentation	NLP-focus
train	O
ain	O
a	O
text	O
classification	O
model	O
on	O
the	O
augmented	O
texts	O
.	O

We	O
evaluate	O
our	O
method	O
on	O
several	O
text	NLP-focus
classification	NLP-focus
datasets	O
where	O
the	O
results	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O

While	O
many	O
methods	O
purport	O
to	O
explain	AI/ML/DL-focus
predictions	AI/ML/DL-focus
by	O
highlighting	O
salient	O
features	O
,	O
what	O
aims	O
these	O
explanations	O
serve	O
and	O
how	O
they	O
ought	O
to	O
be	O
evaluated	O
often	O
go	O
unstated	O
.	O

Using	O
our	O
framework	O
,	O
we	O
compare	O
numerous	O
attribution	O
methods	O
for	O
text	NLP-focus
classification	NLP-focus
and	O
question	NLP-focus
answering	NLP-focus
and	O
observe	O
quantitative	O
differences	O
that	O
are	O
consistent	O
(	O
to	O
a	O
moderate	O
to	O
high	O
degree	O
)	O
across	O
different	O
student	O
model	O
architectures	O
and	O
learning	O
strategies	O
1	O
.	O

Accurately	O
extracting	NLP-focus
structured	NLP-focus
content	NLP-focus
from	NLP-focus
PDFs	NLP-focus
is	O
a	O
critical	O
first	O
step	O
for	O
NLP	O
over	O
scientific	O
papers	O
.	O

In	O
our	O
I	O
-	O
VILA	O
approach	O
,	O
we	O
show	O
that	O
simply	O
inserting	O
special	O
tokens	O
denoting	O
layout	O
group	O
boundaries	O
into	O
model	O
inputs	O
can	O
lead	O
to	O
a	O
1	O
.	O
9	O
\\%	O
Macro	O
F1	O
improvement	O
Macro	Classification-metrics
F1	Classification-metrics
classification	O
.	O

In	O
the	O
H	O
-	O
VILA	O
approach	O
,	O
we	O
show	O
that	O
hierarchical	AI/ML/DL-focus
encoding	AI/ML/DL-focus
of	O
layout	O
-	O
groups	O
can	O
result	O
in	O
up	O
to	O
47	O
\\%	O
inference	O
time	O
reduction	O
with	O
less	O
than	O
0	O
.	O
8	O
\\%	O
Macro	O
F1	O
loss	O
Macro	Classification-metrics
F1	Classification-metrics
.	O

In	O
the	O
H	O
-	O
VILA	O
approach	O
,	O
we	O
show	O
that	O
hierarchical	AI/ML/DL-focus
encoding	AI/ML/DL-focus
of	O
layout	O
-	O
groups	O
can	O
result	O
in	O
up	O
to	O
47	O
\\%	O
inference	O
time	O
reduction	O
with	O
less	O
than	O
0	O
.	O
8	O
\\%	O
Macro	O
F1	O
loss	O
Macro	Classification-metrics
F1	Classification-metrics
.	O

Experiments	O
are	O
conducted	O
on	O
a	O
newly	O
curated	O
evaluation	O
suite	O
,	O
S2	NLP-metrics
-	NLP-metrics
VLUE	NLP-metrics
that	O
unifies	O
existing	O
automatically	O
labeled	O
datasets	O
and	O
includes	O
a	O
new	O
dataset	O
of	O
manual	O
annotations	O
covering	O
diverse	O
papers	O
from	O
19	O
scientific	O
disciplines	O
.	O

Common	O
designs	O
of	O
model	AI/ML/DL-focus
evaluation	AI/ML/DL-focus
typically	O
focus	O
on	O
monolingual	O
settings	O
where	O
different	O
models	O
are	O
compared	O
according	O
to	O
their	O
performance	O
on	O
a	O
single	O
data	O
set	O
that	O
is	O
assumed	O
to	O
be	O
representative	O
of	O
all	O
possible	O
data	O
for	O
the	O
task	O
at	O
hand	O
.	O

Using	O
morphological	NLP-focus
segmentation	NLP-focus
as	O
the	O
test	O
case	O
,	O
we	O
compare	O
three	O
broad	O
classes	O
of	O
models	O
with	O
different	O
parameterizations	O
taking	O
data	O
from	O
11	O
languages	O
across	O
6	O
language	O
families	O
.	O

We	O
address	O
a	O
challenging	O
and	O
underexplored	O
version	O
of	O
this	O
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
problem	O
,	O
where	O
an	O
algorithm	O
is	O
trained	O
on	O
several	O
source	O
domains	O
,	O
and	O
then	O
applied	O
to	O
examples	O
from	O
unseen	O
domains	O
that	O
are	O
unknown	O
at	O
training	O
time	O
.	O

Given	O
a	O
test	O
example	O
,	O
PADA	O
first	O
generates	O
a	O
unique	O
prompt	O
for	O
it	O
and	O
then	O
,	O
conditioned	O
on	O
this	O
prompt	O
,	O
labels	O
the	O
example	O
with	O
respect	O
to	O
the	O
NLP	NLP-focus
prediction	NLP-focus
task	NLP-focus
.	O

In	O
experiments	O
with	O
3	O
tasks	O
(	O
text	NLP-focus
classification	NLP-focus
and	O
sequence	NLP-focus
tagging	NLP-focus
,	O
for	O
a	O
total	O
of	O
14	O
multi	O
-	O
source	O
adaptation	O
scenarios	O
PADA	O
substantially	O
outperforms	O
strong	O
baselines	O
.	O
1	O
.	O

However	O
,	O
long	NLP-focus
text	NLP-focus
modeling	NLP-focus
modeling	O
many	O
distinct	O
abilities	O
in	O
contrast	O
to	O
short	O
texts	O
,	O
such	O
as	O
the	O
modeling	O
of	O
long	NLP-focus
-	NLP-focus
range	NLP-focus
discourse	NLP-focus
and	O
commonsense	NLP-focus
relations	NLP-focus
and	O
the	O
coherence	O
and	O
controllability	O
of	O
generation	O
.	O

Therefore	O
,	O
we	O
propose	O
a	O
story	O
-	O
centric	O
benchmark	O
named	O
LOT	O
for	O
evaluating	O
Chinese	NLP-focus
long	NLP-focus
text	NLP-focus
modeling	NLP-focus
which	O
aggregates	O
two	O
understanding	O
tasks	O
and	O
two	O
generation	O
tasks	O
.	O

We	O
pretrain	O
LongLM	O
on	O
120G	O
Chinese	O
novels	O
with	O
two	O
generative	O
tasks	O
including	O
text	NLP-focus
infilling	NLP-focus
and	O
conditional	NLP-focus
continuation	NLP-focus
.	O

We	O
introduce	O
a	O
large	O
and	O
diverse	O
Czech	O
corpus	O
annotated	O
for	O
grammatical	NLP-focus
error	NLP-focus
correction	NLP-focus
(	NLP-focus
GEC	NLP-focus
)	NLP-focus
with	O
the	O
aim	O
to	O
contribute	O
to	O
the	O
still	O
scarce	O
data	O
resources	O
in	O
this	O
domain	O
for	O
languages	O
other	O
than	O
English	O
.	O

We	O
compare	O
several	O
Czech	NLP-focus
GEC	NLP-focus
systems	NLP-focus
including	O
several	O
Transformer	O
based	O
ones	O
,	O
setting	O
a	O
strong	O
baseline	O
to	O
future	O
research	O
.	O

Finally	O
,	O
we	O
meta	O
-	O
evaluate	O
common	O
GEC	NLP-focus
metrics	O
against	O
human	O
judgments	O
on	O
our	O
data	O
.	O

In	O
a	O
conversational	NLP-focus
question	NLP-focus
answering	NLP-focus
scenario	O
,	O
a	O
questioner	O
seeks	O
to	O
extract	O
information	O
about	O
a	O
topic	O
through	O
a	O
series	O
of	O
interdependent	O
questions	O
and	O
answers	O
.	O

However	O
,	O
current	O
datasets	O
for	O
conversational	NLP-focus
question	NLP-focus
answering	NLP-focus
are	O
limiting	O
in	O
two	O
ways	O
:	O
1	O
)	O
they	O
do	O
not	O
contain	O
topic	O
switches	O
;	O
and	O
2	O
)	O
they	O
assume	O
the	O
reference	O
text	O
for	O
the	O
conversation	O
is	O
given	O
,	O
that	O
is	O
,	O
the	O
setting	O
is	O
not	O
open	O
-	O
domain	O
.	O

TopiOCQA	O
poses	O
a	O
challenging	O
test	O
-	O
bed	O
for	O
models	O
,	O
where	O
efficient	O
retrieval	AI/ML/DL-focus
is	O
required	O
on	O
multiple	O
turns	O
of	O
the	O
same	O
conversation	O
,	O
in	O
conjunction	O
with	O
constructing	O
valid	O
responses	O
using	O
conversational	O
history	O
.	O

Our	O
best	O
model	O
achieves	O
F1	Classification-metrics
of	O
55	O
.	O
8	O
falling	O
short	O
of	O
human	O
performance	O
by	O
14	O
.	O
2	O
points	O
,	O
indicating	O
the	O
difficulty	O
of	O
our	O
dataset	O
.	O

We	O
propose	O
a	O
novel	O
framework	O
for	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
content	NLP-focus
flagging	NLP-focus
with	O
limited	O
target	O
-	O
language	O
data	O
,	O
which	O
significantly	O
outperforms	O
prior	O
work	O
in	O
terms	O
of	O
predictive	O
performance	O
.	O

Our	O
evaluation	O
results	O
on	O
eight	O
languages	O
from	O
two	O
different	O
datasets	O
for	O
abusive	NLP-focus
language	NLP-focus
detection	NLP-focus
show	O
sizable	O
improvements	O
of	O
up	O
to	O
9	O
.	O
5	O
F1	Classification-metrics
points	O
absolute	O
(	O
for	O
Italian	O
)	O
over	O
strong	O
baselines	O
.	O

Our	O
evaluation	O
results	O
on	O
eight	O
languages	O
from	O
two	O
different	O
datasets	O
for	O
abusive	NLP-focus
language	NLP-focus
detection	NLP-focus
show	O
sizable	O
improvements	O
of	O
up	O
to	O
9	O
.	O
5	O
F1	Classification-metrics
points	O
absolute	O
(	O
for	O
Italian	O
)	O
over	O
strong	O
baselines	O
.	O

On	O
average	O
,	O
we	O
achieve	O
3	O
.	O
6	O
absolute	O
F1	Classification-metrics
points	O
of	O
improvement	O
for	O
the	O
three	O
languages	O
in	O
the	O
Jigsaw	O
Multilingual	O
dataset	O
and	O
2	O
.	O
14	O
points	O
for	O
the	O
WUL	O
dataset	O
.	O

Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
to	O
cross	Miscellaneous-focus
-	Miscellaneous-focus
modal	Miscellaneous-focus
retrieval	Miscellaneous-focus
process	O
text	O
and	O
visual	O
input	O
jointly	O
,	O
relying	O
on	O
Transformer	O
based	O
architectures	O
with	O
cross	O
-	O
attention	O
mechanisms	O
that	O
attend	O
over	O
all	O
words	O
and	O
objects	O
in	O
an	O
image	O
.	O

To	O
address	O
these	O
crucial	O
gaps	O
towards	O
both	O
improved	O
and	O
efficient	O
cross	AI/ML/DL-focus
-	AI/ML/DL-focus
modal	AI/ML/DL-focus
retrieval	AI/ML/DL-focus
we	O
propose	O
a	O
novel	O
fine	O
-	O
tuning	O
framework	O
that	O
turns	O
any	O
pretrained	O
text	O
-	O
image	O
multi	O
-	O
modal	O
model	O
into	O
an	O
efficient	O
retrieval	O
model	O
.	O

Our	O
experiments	O
on	O
a	O
series	O
of	O
standard	O
cross	AI/ML/DL-focus
-	AI/ML/DL-focus
modal	AI/ML/DL-focus
retrieval	AI/ML/DL-focus
benchmarks	O
in	O
monolingual	O
multilingual	O
and	O
zero	O
-	O
shot	O
setups	O
,	O
demonstrate	O
improved	O
accuracy	Classification-metrics
and	O
huge	O
efficiency	O
benefits	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
cross	O
-	O
encoders	O
1	O
.	O

Our	O
experiments	O
on	O
a	O
series	O
of	O
standard	O
cross	AI/ML/DL-focus
-	AI/ML/DL-focus
modal	AI/ML/DL-focus
retrieval	AI/ML/DL-focus
benchmarks	O
in	O
monolingual	O
multilingual	O
and	O
zero	O
-	O
shot	O
setups	O
,	O
demonstrate	O
improved	O
accuracy	Classification-metrics
and	O
huge	O
efficiency	O
benefits	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
cross	O
-	O
encoders	O
1	O
.	O

One	O
of	O
the	O
biggest	O
challenges	O
hindering	O
progress	O
in	O
low	O
-	O
resource	O
and	O
multilingual	NLP-focus
machine	NLP-focus
translation	NLP-focus
is	O
the	O
lack	O
of	O
good	O
evaluation	O
benchmarks	O
.	O

By	O
publicly	O
releasing	O
such	O
a	O
high	O
-	O
quality	O
and	O
high	O
-	O
coverage	O
dataset	O
we	O
hope	O
to	O
foster	O
progress	O
in	O
the	O
machine	NLP-focus
translation	NLP-focus
community	O
and	O
beyond	O
.	O

Multihop	NLP-focus
reasoning	NLP-focus
remains	O
an	O
elusive	O
goal	O
as	O
existing	O
multihop	O
benchmarks	O
are	O
known	O
to	O
be	O
largely	O
solvable	O
via	O
shortcuts	O
.	O

Can	O
we	O
create	O
a	O
question	O
answering	O
(	O
QA	O
)	O
dataset	O
that	O
,	O
by	O
construction	O
,	O
requires	O
proper	O
multihop	NLP-focus
reasoning	NLP-focus
To	O
this	O
end	O
,	O
we	O
introduce	O
a	O
bottom	O
–	O
up	O
approach	O
that	O
systematically	O
selects	O
composable	O
pairs	O
of	O
single	O
-	O
hop	O
questions	O
that	O
are	O
connected	O
,	O
that	O
is	O
,	O
where	O
one	O
reasoning	O
step	O
critically	O
relies	O
on	O
information	O
from	O
another	O
.	O

We	O
represent	O
the	O
graph	O
as	O
a	O
collection	O
of	O
relation	O
triples	O
and	O
retrieve	O
relevant	O
relations	O
for	O
a	O
given	O
context	O
to	O
improve	O
text	NLP-focus
generation	NLP-focus
.	O

Experiments	O
on	O
WikiText	O
-	O
103	O
WMT19	O
and	O
enwik8	O
English	O
datasets	O
demonstrate	O
that	O
our	O
approach	O
produces	O
a	O
better	O
language	O
model	O
in	O
terms	O
of	O
perplexity	NLP-metrics
and	O
bits	O
per	O
character	O
.	O

Existing	O
methods	O
to	O
measure	O
sentence	NLP-focus
similarity	NLP-focus
are	O
faced	O
with	O
two	O
challenges	O
:	O
(	O
1	O
)	O
labeled	O
datasets	O
are	O
usually	O
limited	O
in	O
size	O
,	O
making	O
them	O
insufficient	O
to	O
train	O
supervised	O
neural	O
models	O
and	O
(	O
2	O
)	O
there	O
is	O
a	O
training	O
-	O
test	O
gap	O
for	O
unsupervised	O
language	O
modeling	O
(	O
LM	O
)	O
based	O
models	O
to	O
compute	O
semantic	O
scores	O
between	O
sentences	O
,	O
since	O
sentence	O
-	O
level	O
semantics	O
training	O
xplicitly	O
modeled	O
at	O
training	O
.	O

The	O
task	O
of	O
ultra	NLP-focus
-	NLP-focus
fine	NLP-focus
entity	NLP-focus
typing	NLP-focus
(	NLP-focus
UFET	NLP-focus
)	NLP-focus
seeks	O
to	O
predict	O
diverse	O
and	O
free	O
-	O
form	O
words	O
or	O
phrases	O
that	O
describe	O
the	O
appropriate	O
types	O
of	O
entities	O
mentioned	O
in	O
sentences	O
.	O

Existing	O
systems	O
formulate	O
the	O
task	O
as	O
a	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
way	AI/ML/DL-focus
classification	AI/ML/DL-focus
problem	AI/ML/DL-focus
and	O
train	O
directly	O
or	O
distantly	O
supervised	O
classifiers	O
.	O

This	O
causes	O
two	O
issues	O
:	O
(	O
i	O
)	O
the	O
classifiers	O
do	O
not	O
capture	O
the	O
type	O
semantics	O
because	O
types	O
are	O
often	O
converted	O
into	O
indices	O
;	O
(	O
ii	O
)	O
systems	O
developed	O
in	O
this	O
way	O
are	O
limited	O
to	O
predicting	O
within	O
a	O
pre	O
-	O
defined	O
type	O
set	O
,	O
and	O
often	O
fall	O
short	O
of	O
generalizing	O
to	O
types	O
that	O
are	O
rarely	O
seen	O
or	O
unseen	O
in	O
training	O
This	O
work	O
presents	O
LITE	O
a	O
new	O
approach	O
that	O
formulates	O
entity	NLP-focus
typing	NLP-focus
as	O
a	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
problem	O
,	O
making	O
use	O
of	O
(	O
i	O
)	O
the	O
indirect	O
supervision	O
NLI	O
NLI	O
to	O
infer	O
type	O
information	O
meaningfully	O
represented	O
as	O
textual	O
hypotheses	O
and	O
alleviate	O
the	O
data	O
scarcity	O
issue	O
,	O
as	O
well	O
as	O
(	O
ii	O
)	O
a	O
learning	O
-	O
to	O
-	O
rank	O
objective	O
to	O
avoid	O
the	O
pre	O
-	O
defining	O
of	O
a	O
type	O
set	O
.	O

Experiments	O
show	O
that	O
,	O
with	O
limited	O
training	O
data	O
LITE	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
UFET	NLP-focus
task	O
.	O

In	O
addition	O
,	O
LITE	O
demonstrates	O
its	O
strong	O
generalizability	O
by	O
not	O
only	O
yielding	O
best	O
results	O
on	O
other	O
fine	NLP-focus
-	NLP-focus
grained	NLP-focus
entity	NLP-focus
typing	NLP-focus
benchmarks	O
,	O
more	O
importantly	O
,	O
a	O
pre	O
-	O
trained	O
LITE	O
system	O
works	O
well	O
on	O
new	O
data	O
containing	O
unseen	O
types	O
.	O
1	O
.	O

For	O
query	NLP-focus
-	NLP-focus
focused	NLP-focus
summarization	NLP-focus
(	NLP-focus
QFS	NLP-focus
)	NLP-focus
labeled	O
training	O
data	O
in	O
the	O
form	O
of	O
queries	O
,	O
documents	O
,	O
and	O
summaries	O
is	O
not	O
readily	O
available	O
.	O

We	O
provide	O
a	O
unified	O
modeling	O
framework	O
for	O
any	O
kind	O
of	O
summarization	NLP-focus
under	O
the	O
assumption	O
that	O
all	O
summaries	O
are	O
a	O
response	O
to	O
a	O
query	O
which	O
is	O
observed	O
in	O
the	O
case	O
of	O
QFS	NLP-focus
and	O
latent	O
in	O
the	O
case	O
of	O
generic	NLP-focus
summarization	NLP-focus
.	O

Our	O
framework	O
formulates	O
summarization	NLP-focus
as	O
a	O
generative	O
process	O
and	O
jointly	O
optimizes	O
a	O
latent	O
query	O
model	O
and	O
a	O
conditional	O
language	O
model	O
.	O

Despite	O
learning	O
from	O
generic	NLP-focus
summarization	NLP-focus
data	O
only	O
,	O
our	O
approach	O
outperforms	O
strong	O
comparison	O
systems	O
across	O
benchmarks	O
,	O
query	O
types	O
,	O
document	O
settings	O
,	O
and	O
target	O
domains	O
.	O
1	O
.	O

Mining	O
an	O
argument	O
structure	O
from	O
text	O
is	O
an	O
important	O
step	O
for	O
tasks	O
such	O
as	O
argument	NLP-focus
search	NLP-focus
and	O
summarization	NLP-focus
.	O

While	O
studies	O
on	O
argument	NLP-focus
(	NLP-focus
ation	NLP-focus
)	NLP-focus
mining	NLP-focus
have	O
proposed	O
promising	O
neural	O
network	O
models	O
they	O
usually	O
suffer	O
from	O
a	O
shortage	O
of	O
training	O
data	O
.	O

To	O
address	O
this	O
issue	O
,	O
we	O
expand	O
the	O
training	O
data	O
with	O
various	O
auxiliary	NLP-focus
argument	NLP-focus
mining	NLP-focus
corpora	O
and	O
propose	O
an	O
end	O
-	O
to	O
-	O
end	O
cross	O
-	O
corpus	O
training	O
method	O
called	O
Multi	O
-	O
Task	O
Argument	O
Mining	O
(	O
MT	O
-	O
AM	O
)	O

To	O
evaluate	O
our	O
approach	O
,	O
we	O
conducted	O
experiments	O
for	O
the	O
main	O
argument	NLP-focus
mining	NLP-focus
tasks	O
on	O
several	O
well	O
-	O
established	O
argument	O
mining	O
corpora	O
.	O

The	O
results	O
demonstrate	O
that	O
MT	O
-	O
AM	O
generally	O
outperformed	O
the	O
models	O
trained	O
on	O
a	O
single	O
corpus	AI/ML/DL-focus
.	O

State	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	AI/ML/DL-focus
and	O
regression	AI/ML/DL-focus
models	AI/ML/DL-focus
are	O
often	O
not	O
well	O
calibrated	O
,	O
and	O
cannot	O
reliably	O
provide	O
uncertainty	O
estimates	O
,	O
limiting	O
their	O
utility	O
in	O
safety	O
-	O
critical	O
applications	O
such	O
as	O
clinical	O
decision	O
-	O
making	O
.	O

In	O
this	O
paper	O
,	O
we	O
quantify	O
the	O
calibration	O
of	O
pre	O
-	O
trained	O
language	O
models	O
for	O
text	NLP-focus
regression	NLP-focus
both	O
intrinsically	O
and	O
extrinsically	O
.	O

Our	O
experiments	O
on	O
three	O
regression	O
tasks	O
in	O
both	O
self	O
-	O
training	O
and	O
active	O
-	O
learning	O
settings	O
show	O
that	O
uncertainty	O
estimation	O
can	O
be	O
used	O
to	O
increase	O
overall	O
performance	O
and	O
enhance	O
model	AI/ML/DL-focus
generalization	AI/ML/DL-focus
.	O

We	O
consider	O
the	O
task	O
of	O
data	NLP-focus
-	NLP-focus
to	NLP-focus
-	NLP-focus
text	NLP-focus
generation	NLP-focus
which	O
aims	O
to	O
create	O
textual	O
output	O
from	O
non	O
-	O
linguistic	O
input	O
.	O

We	O
focus	O
on	O
generating	NLP-focus
long	NLP-focus
-	NLP-focus
form	NLP-focus
text	NLP-focus
that	O
is	O
,	O
documents	O
with	O
multiple	O
paragraphs	O
,	O
and	O
propose	O
a	O
neural	O
model	O
enhanced	O
with	O
a	O
planning	O
component	O
responsible	O
for	O
organizing	O
high	O
-	O
level	O
information	O
in	O
a	O
coherent	O
and	O
meaningful	O
way	O
.	O

Prompt	O
based	O
approaches	O
excel	O
at	O
few	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

These	O
results	O
demonstrate	O
that	O
prompt	O
-	O
based	O
learners	O
can	O
successfully	O
be	O
applied	O
in	O
true	O
few	O
-	O
shot	O
settings	O
and	O
underpin	O
our	O
belief	O
that	O
learning	O
from	O
instructions	O
will	O
play	O
an	O
important	O
role	O
on	O
the	O
path	O
towards	O
human	O
-	O
like	O
few	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
learning	AI/ML/DL-focus
capabilities	O
.	O

To	O
this	O
end	O
,	O
this	O
paper	O
develops	O
the	O
heterogeneous	O
supervised	O
topic	O
model	O
(	O
HSTM	O
)	O
a	O
probabilistic	O
approach	O
to	O
text	NLP-focus
analysis	NLP-focus
and	NLP-focus
prediction	NLP-focus
.	O

Automating	O
the	O
fact	NLP-focus
checking	NLP-focus
(	NLP-focus
FC	NLP-focus
)	NLP-focus
process	O
relies	O
on	O
information	O
obtained	O
from	O
external	O
sources	O
.	O

We	O
identify	O
when	O
models	O
consider	O
the	O
remaining	O
evidence	O
(	O
in	O
)	O
sufficient	O
for	O
FC	NLP-focus
based	O
on	O
three	O
trained	O
models	O
with	O
different	O
Transformer	O
FC	NLP-focus
hitectures	O
and	O
three	O
FC	O
datasets	O
.	O

Second	O
,	O
we	O
ask	O
annotators	O
whether	O
the	O
omitted	O
evidence	O
was	O
important	O
for	O
FC	NLP-focus
resulting	O
in	O
a	O
novel	O
diagnostic	O
dataset	O
SufficientFacts1	O
for	O
FC	O
with	O
omitted	O
evidence	O
.	O

We	O
find	O
that	O
models	O
are	O
least	O
successful	O
in	O
detecting	O
missing	O
evidence	O
when	O
adverbial	O
modifiers	O
are	O
omitted	O
(	O
21	O
\\%	O
accuracy	Classification-metrics
,	O
whereas	O
it	O
is	O
easiest	O
for	O
omitted	O
date	O
modifiers	O
(	O
63	O
\\%	O
accuracy	Classification-metrics
.	O

It	O
improves	O
performance	O
for	O
Evidence	NLP-focus
Sufficiency	NLP-focus
Prediction	NLP-focus
by	O
up	O
to	O
17	O
.	O
8	O
F1	Classification-metrics
score	O
,	O
which	O
in	O
turn	O
improves	O
FC	O
performance	O
by	O
up	O
to	O
2	O
.	O
6	O
F1	Classification-metrics
score	O
.	O

It	O
improves	O
performance	O
for	O
Evidence	NLP-focus
Sufficiency	NLP-focus
Prediction	NLP-focus
by	O
up	O
to	O
17	O
.	O
8	O
F1	Classification-metrics
score	O
,	O
which	O
in	O
turn	O
improves	O
FC	O
performance	O
by	O
up	O
to	O
2	O
.	O
6	O
F1	Classification-metrics
score	O
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
novel	O
task	O
termed	O
t	O
ext	NLP-focus
-	NLP-focus
based	NLP-focus
NP	NLP-focus
enrichment	NLP-focus
(	NLP-focus
TNE	NLP-focus
)	NLP-focus
NP	O
which	O
we	O
aim	O
to	O
enrich	O
each	O
NP	O
in	O
a	O
text	O
with	O
all	O
the	O
preposition	O
-	O
mediated	O
relations	O
—	O
either	O
explicit	O
or	O
implicit	O
—	O
that	O
hold	O
between	O
it	O
and	O
other	O
NPs	O
in	O
the	O
text	O
.	O

We	O
train	O
neural	O
networks	O
to	O
optimize	O
a	O
Minimum	AI/ML/DL-focus
Description	AI/ML/DL-focus
Length	AI/ML/DL-focus
score	O
,	O
that	O
is	O
,	O
to	O
balance	O
between	O
the	O
complexity	O
of	O
the	O
network	O
and	O
its	O
accuracy	Classification-metrics
at	O
a	O
task	O
.	O

We	O
train	O
neural	O
networks	O
to	O
optimize	O
a	O
Minimum	AI/ML/DL-focus
Description	AI/ML/DL-focus
Length	AI/ML/DL-focus
score	O
,	O
that	O
is	O
,	O
to	O
balance	O
between	O
the	O
complexity	O
of	O
the	O
network	O
and	O
its	O
accuracy	Classification-metrics
at	O
a	O
task	O
.	O

Moreover	O
,	O
they	O
often	O
do	O
so	O
with	O
100	O
\\%	O
accuracy	Classification-metrics
.	O

We	O
thus	O
provide	O
formal	O
proofs	O
that	O
their	O
perfect	O
accuracy	Classification-metrics
holds	O
not	O
only	O
on	O
a	O
given	O
test	O
set	O
,	O
but	O
for	O
any	O
input	O
sequence	O
.	O

In	O
Neural	NLP-focus
Machine	NLP-focus
Translation	NLP-focus
it	O
is	O
typically	O
assumed	O
that	O
the	O
sentence	O
with	O
the	O
highest	O
estimated	O
probability	O
should	O
also	O
be	O
the	O
translation	O
with	O
the	O
highest	O
quality	O
as	O
measured	O
by	O
humans	O
.	O

Our	O
experiments	O
show	O
that	O
the	O
combination	O
of	O
a	O
neural	O
translation	O
model	O
with	O
a	O
neural	O
reference	O
-	O
based	O
metric	O
Bleurt	NLP-metrics
results	O
in	O
significant	O
improvement	O
in	O
human	O
evaluations	O
.	O

This	O
improvement	O
is	O
obtained	O
with	O
translations	O
different	O
from	O
classical	O
beam	O
-	O
search	O
output	O
:	O
These	O
translations	O
have	O
much	O
lower	O
model	O
likelihood	O
and	O
are	O
less	O
favored	O
by	O
surface	O
metrics	O
like	O
Bleu	NLP-metrics
.	O

We	O
formulate	O
a	O
general	O
framework	O
called	O
“	O
generate	O
,	O
annotate	O
,	O
and	O
learn	O
(	O
GAL	O
)”	O
to	O
take	O
advantage	O
of	O
synthetic	O
text	O
within	O
knowledge	AI/ML/DL-focus
distillation	AI/ML/DL-focus
self	AI/ML/DL-focus
-	AI/ML/DL-focus
training	AI/ML/DL-focus
and	O
few	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
learning	AI/ML/DL-focus
applications	O
.	O

We	O
use	O
the	O
best	O
available	O
classifier	O
to	O
annotate	O
synthetic	O
text	O
with	O
soft	O
pseudo	O
labels	O
for	O
knowledge	AI/ML/DL-focus
distillation	AI/ML/DL-focus
and	O
self	AI/ML/DL-focus
-	AI/ML/DL-focus
training	AI/ML/DL-focus
and	O
use	O
LMs	O
to	O
obtain	O
hard	O
labels	O
for	O
few	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

GAL	O
achieves	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
knowledge	AI/ML/DL-focus
distillation	AI/ML/DL-focus
results	O
for	O
6	O
-	O
layer	O
transformers	O
on	O
the	O
GLUE	O
leaderboard	O
.	O

While	O
improving	O
neural	O
dialogue	O
agents	O
factual	O
accuracy	Classification-metrics
neural	O
dialogue	O
much	O
research	O
,	O
another	O
important	O
aspect	O
of	O
communication	O
,	O
less	O
studied	O
in	O
the	O
setting	O
of	O
neural	O
dialogue	O
,	O
is	O
transparency	O
about	O
ignorance	O
.	O

Interactive	NLP-focus
Fiction	NLP-focus
Games	NLP-focus
(	O
or	O
Text	NLP-focus
Games	NLP-focus
are	O
one	O
such	O
problem	O
type	O
that	O
offer	O
a	O
set	O
of	O
safe	O
,	O
partially	O
observable	O
environments	O
where	O
natural	O
language	O
is	O
required	O
as	O
part	O
of	O
the	O
Reinforcement	O
Learning	O
solution	O
.	O

Therefore	O
,	O
this	O
survey	O
’	O
s	O
aim	O
is	O
to	O
assist	O
in	O
the	O
development	O
of	O
new	O
Text	NLP-focus
Game	NLP-focus
problem	NLP-focus
settings	O
and	O
solutions	O
for	O
Reinforcement	O
Learning	O
informed	O
by	O
natural	O
language	O
.	O

Specifically	O
,	O
this	O
survey	O
:	O
1	O
)	O
introduces	O
the	O
challenges	O
in	O
Text	NLP-focus
Game	NLP-focus
Reinforcement	NLP-focus
Learning	NLP-focus
problems	O
,	O
2	O
)	O
outlines	O
the	O
generation	O
tools	O
for	O
rendering	O
Text	NLP-focus
Games	NLP-focus
and	O
the	O
subsequent	O
environments	O
generated	O
,	O
and	O
3	O
)	O
compares	O
the	O
agent	O
architectures	O
currently	O
applied	O
to	O
provide	O
a	O
systematic	O
review	O
of	O
benchmark	O
methodologies	O
and	O
opportunities	O
for	O
future	O
researchers	O
.	O

Greedy	O
algorithms	O
for	O
NLP	O
such	O
as	O
transition	NLP-focus
-	NLP-focus
based	NLP-focus
parsing	NLP-focus
are	O
prone	O
to	O
error	O
propagation	O
.	O

We	O
present	O
experiments	O
for	O
several	O
tasks	O
in	O
English	O
where	O
the	O
label	O
correctness	O
is	O
not	O
dependent	O
on	O
time	O
and	O
demonstrate	O
the	O
importance	O
of	O
distinguishing	O
between	O
temporal	AI/ML/DL-focus
model	AI/ML/DL-focus
deterioration	AI/ML/DL-focus
and	O
temporal	AI/ML/DL-focus
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
for	O
systems	O
using	O
pre	O
-	O
trained	O
representations	O
.	O

We	O
find	O
that	O
,	O
depending	O
on	O
the	O
task	O
,	O
temporal	AI/ML/DL-focus
model	AI/ML/DL-focus
deterioration	AI/ML/DL-focus
is	O
not	O
necessarily	O
a	O
concern	O
.	O

Temporal	AI/ML/DL-focus
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
however	O
,	O
is	O
beneficial	O
in	O
all	O
cases	O
,	O
with	O
better	O
performance	O
for	O
a	O
given	O
time	O
period	O
possible	O
when	O
the	O
system	O
is	O
trained	O
on	O
temporally	O
more	O
recent	O
data	O
.	O

Self	O
-	O
labeling	O
shows	O
consistent	O
improvement	O
and	O
notably	O
,	O
for	O
named	NLP-focus
entity	NLP-focus
recognition	NLP-focus
leads	O
to	O
better	O
temporal	O
adaptation	O
than	O
even	O
human	O
annotations	O
.	O

Semantic	NLP-focus
parsing	NLP-focus
(	NLP-focus
SP	NLP-focus
)	NLP-focus
allows	O
humans	O
to	O
leverage	O
vast	O
knowledge	O
resources	O
through	O
natural	O
interaction	O
.	O

We	O
introduce	O
such	O
a	O
dataset	O
,	O
which	O
we	O
call	O
Multilingual	O
Compositional	O
Wikidata	O
Questions	O
(	O
MCWQ	O
)	O
and	O
use	O
it	O
to	O
analyze	O
the	O
compositional	NLP-focus
generalization	NLP-focus
of	O
semantic	NLP-focus
parsers	NLP-focus
in	O
Hebrew	O
,	O
Kannada	O
,	O
Chinese	O
,	O
and	O
English	O
.	O

While	O
within	NLP-focus
-	NLP-focus
language	NLP-focus
generalization	NLP-focus
is	O
comparable	O
across	O
languages	O
,	O
experiments	O
on	O
zero	NLP-focus
-	NLP-focus
shot	NLP-focus
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
transfer	NLP-focus
demonstrate	O
that	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
compositional	NLP-focus
generalization	NLP-focus
fails	O
,	O
even	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
pretrained	O
multilingual	O
encoders	O
.	O

Furthermore	O
,	O
our	O
methodology	O
,	O
dataset	O
,	O
and	O
results	O
will	O
facilitate	O
future	O
research	O
on	O
SP	NLP-focus
in	O
more	O
realistic	O
and	O
diverse	O
settings	O
than	O
has	O
been	O
possible	O
with	O
existing	O
resources	O
.	O

We	O
reflect	O
on	O
the	O
question	O
:	O
Have	O
transfer	AI/ML/DL-focus
learning	AI/ML/DL-focus
methods	O
sufficiently	O
addressed	O
the	O
poor	O
performance	O
of	O
benchmark	O
-	O
trained	O
models	O
on	O
the	O
long	O
tail	O
long	O
tail	O
tualize	O
the	O
long	O
tail	O
using	O
macro	O
-	O
level	O
dimensions	O
(	O
underrepresented	O
genres	O
,	O
topics	O
,	O
etc	O
.),	O
and	O
perform	O
a	O
qualitative	O
meta	O
-	O
analysis	O
transfer	AI/ML/DL-focus
learning	AI/ML/DL-focus
ive	O
papers	O
on	O
transfer	O
learning	O
research	O
for	O
NLU	O
.	O

Our	O
analysis	O
asks	O
three	O
questions	O
:	O
(	O
i	O
)	O
Which	O
long	O
tail	O
dimensions	O
do	O
transfer	AI/ML/DL-focus
learning	AI/ML/DL-focus
long	O
tail	O
long	O
tail	O
long	O
tail	O
perties	O
of	O
adaptation	O
methods	O
help	O
improve	O
performance	O
on	O
the	O
long	O
tail	O
?	O
(	O
iii	O
)	O
Which	O
methodological	O
gaps	O
have	O
greatest	O
negative	O
impact	O
on	O
long	O
tail	O
performance	O
?	O
Our	O
answers	O
highlight	O
major	O
avenues	O
for	O
future	O
research	O
in	O
transfer	O
learning	O
for	O
the	O
long	O
tail	O
.	O

Yet	O
the	O
properties	O
elicited	O
by	O
various	O
decoding	O
strategies	O
do	O
not	O
always	O
transfer	O
across	O
natural	NLP-focus
language	NLP-focus
generation	NLP-focus
tasks	O
.	O

For	O
example	O
,	O
while	O
mode	O
-	O
seeking	O
methods	O
like	O
beam	O
search	O
perform	O
remarkably	O
well	O
for	O
machine	NLP-focus
translation	NLP-focus
they	O
have	O
been	O
observed	O
to	O
lead	O
to	O
incoherent	O
and	O
repetitive	O
text	O
in	O
story	NLP-focus
generation	NLP-focus
.	O

This	O
work	O
—	O
in	O
contrast	O
—	O
provides	O
a	O
comprehensive	O
analysis	O
of	O
the	O
interaction	O
between	O
language	NLP-focus
generation	NLP-focus
tasks	O
and	O
decoding	O
strategies	O
.	O

For	O
example	O
,	O
the	O
nature	O
of	O
the	O
diversity	O
–	O
quality	O
trade	O
-	O
off	O
in	O
language	NLP-focus
generation	NLP-focus
is	O
very	O
task	O
-	O
specific	O
;	O
the	O
length	O
bias	O
often	O
attributed	O
to	O
beam	O
search	O
is	O
not	O
constant	O
across	O
tasks	O
.	O

Fact	O
verification	O
systems	O
typically	O
rely	O
on	O
neural	O
network	O
classifiers	O
for	O
veracity	NLP-focus
prediction	NLP-focus
which	O
lack	O
explainability	O
.	O

Claim	NLP-focus
veracity	NLP-focus
is	O
determined	O
solely	O
based	O
on	O
the	O
sequence	O
of	O
these	O
operators	O
.	O

Currently	O
,	O
ProoFVer	O
has	O
the	O
highest	O
label	O
accuracy	Classification-metrics
and	O
the	O
second	O
best	O
score	O
in	O
the	O
FEVER	O
leaderboard	O
.	O

We	O
investigate	O
the	O
extent	O
to	O
which	O
modern	O
neural	O
language	O
models	O
are	O
susceptible	O
to	O
structural	NLP-focus
priming	NLP-focus
the	O
phenomenon	O
whereby	O
the	O
structure	O
of	O
a	O
sentence	O
makes	O
the	O
same	O
structure	O
more	O
probable	O
in	O
a	O
follow	O
-	O
up	O
sentence	O
.	O

We	O
find	O
that	O
Transformer	O
models	O
indeed	O
show	O
evidence	O
of	O
structural	NLP-focus
priming	NLP-focus
but	O
also	O
that	O
the	O
generalizations	O
they	O
learned	O
are	O
to	O
some	O
extent	O
modulated	O
by	O
semantic	O
information	O
.	O

Popular	O
Bayesian	O
non	O
-	O
parametric	O
models	O
for	O
text	NLP-focus
segmentation	NLP-focus
(	O
Goldwater	O
et	O
al	O
.,	O
2006	O
,	O
2009	O
)	O
use	O
a	O
Dirichlet	O
process	O
to	O
jointly	O
segment	O
sentences	O
and	O
build	O
a	O
lexicon	O
of	O
word	O
types	O
.	O

On	O
the	O
Zero	O
Resource	O
Speech	O
Benchmark	O
2017	O
our	O
model	O
sets	O
a	O
new	O
speech	NLP-focus
segmentation	NLP-focus
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
5	O
languages	O
.	O

Thus	O
,	O
we	O
investigate	O
the	O
ability	O
of	O
agents	O
to	O
identify	O
non	O
-	O
cooperative	O
interlocutors	O
while	O
completing	O
a	O
concurrent	O
visual	NLP-focus
-	NLP-focus
dialogue	NLP-focus
task	NLP-focus
.	O

To	O
demonstrate	O
the	O
efficacy	O
of	O
the	O
hybrid	O
framework	O
,	O
we	O
combine	O
existing	O
ILP	O
-	O
based	O
solvers	O
for	O
multi	NLP-focus
-	NLP-focus
hop	NLP-focus
Question	NLP-focus
Answering	NLP-focus
(	NLP-focus
QA	NLP-focus
)	NLP-focus
with	O
Transformer	O
based	O
representations	O
.	O

An	O
extensive	O
empirical	O
evaluation	O
on	O
scientific	O
and	O
commonsense	NLP-focus
QA	NLP-focus
tasks	O
demonstrates	O
that	O
the	O
integration	O
of	O
explicit	O
constraints	O
in	O
a	O
end	O
-	O
to	O
-	O
end	O
differentiable	O
framework	O
can	O
significantly	O
improve	O
the	O
performance	O
of	O
non	O
-	O
differentiable	O
ILP	O
solvers	O
(	O
8	O
.	O
91	O
\\%–	O
13	O
.	O
3	O
\\%	O
.	O

The	O
improved	O
capability	O
over	O
baselines	O
(	O
e	O
.	O
g	O
.,	O
BART	O
is	O
seen	O
via	O
intrinsic	O
and	O
extrinsic	O
methods	O
,	O
where	O
idiom	O
embeddings	O
score	O
0	O
.	O
19	O
points	O
higher	O
in	O
homogeneity	O
score	O
for	O
embedding	O
clustering	O
,	O
and	O
up	O
to	O
25	O
\\%	O
higher	O
sequence	Classification-metrics
accuracy	Classification-metrics
on	O
the	O
idiom	O
processing	O
tasks	O
of	O
IE	NLP-focus
sense	NLP-focus
disambiguation	NLP-focus
an	NLP-focus
span	NLP-focus
detection	NLP-focus
.	O

The	O
improved	O
capability	O
over	O
baselines	O
(	O
e	O
.	O
g	O
.,	O
BART	O
is	O
seen	O
via	O
intrinsic	O
and	O
extrinsic	O
methods	O
,	O
where	O
idiom	O
embeddings	O
score	O
0	O
.	O
19	O
points	O
higher	O
in	O
homogeneity	O
score	O
for	O
embedding	O
clustering	O
,	O
and	O
up	O
to	O
25	O
\\%	O
higher	O
sequence	Classification-metrics
accuracy	Classification-metrics
on	O
the	O
idiom	O
processing	O
tasks	O
of	O
IE	NLP-focus
sense	NLP-focus
disambiguation	NLP-focus
an	NLP-focus
span	NLP-focus
detection	NLP-focus
.	O

This	O
distinction	O
is	O
beginning	O
to	O
fade	O
,	O
with	O
an	O
emerging	O
area	O
of	O
interdisciplinary	O
research	O
at	O
the	O
convergence	O
of	O
causal	Miscellaneous-focus
inference	Miscellaneous-focus
and	O
language	NLP-focus
processing	NLP-focus
.	O

Generalizing	O
dialogue	NLP-focus
state	NLP-focus
tracking	NLP-focus
(	NLP-focus
DST	NLP-focus
)	NLP-focus
to	O
new	O
data	O
is	O
especially	O
challenging	O
due	O
to	O
the	O
strong	O
reliance	O
on	O
abundant	O
and	O
fine	O
-	O
grained	O
supervision	O
during	O
training	O
.	O

We	O
combine	O
the	O
strengths	O
of	O
triple	O
copy	O
strategy	O
DST	NLP-focus
and	O
value	O
matching	O
to	O
benefit	O
from	O
complementary	O
predictions	O
without	O
violating	O
the	O
principle	O
of	O
ontology	O
independence	O
.	O

Multi	NLP-focus
-	NLP-focus
task	NLP-focus
learning	NLP-focus
in	O
which	O
several	O
tasks	O
are	O
jointly	O
learned	O
by	O
a	O
single	O
model	O
,	O
allows	O
NLP	O
models	O
to	O
share	O
information	O
from	O
multiple	O
annotations	O
and	O
may	O
facilitate	O
better	O
predictions	O
when	O
the	O
tasks	O
are	O
inter	O
-	O
related	O
.	O

We	O
explore	O
various	O
multi	O
-	O
task	O
multi	O
-	O
task	O
riteria	O
in	O
three	O
realistic	O
multi	O
-	O
task	O
scenarios	O
,	O
reflecting	O
different	O
relations	O
between	O
the	O
participating	O
tasks	O
,	O
and	O
demonstrate	O
the	O
effectiveness	O
of	O
multi	O
-	O
task	O
compared	O
to	O
single	AI/ML/DL-focus
-	AI/ML/DL-focus
task	AI/ML/DL-focus
selection	AI/ML/DL-focus
.	O

We	O
introduce	O
the	O
task	O
of	O
microblog	NLP-focus
opinion	NLP-focus
summarization	NLP-focus
(	NLP-focus
MOS	NLP-focus
)	NLP-focus
and	O
share	O
a	O
dataset	O
of	O
3100	O
gold	O
-	O
standard	O
opinion	O
summaries	O
to	O
facilitate	O
research	O
in	O
this	O
domain	O
.	O

Instead	O
,	O
we	O
prepare	O
PLMs	O
for	O
data	AI/ML/DL-focus
-	AI/ML/DL-focus
and	AI/ML/DL-focus
parameter	AI/ML/DL-focus
-	AI/ML/DL-focus
efficient	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
PLMs	O
arning	O
to	O
learn	O
the	O
difference	O
between	O
general	O
and	O
adapted	O
PLMs	O
.	O

Experiments	O
on	O
few	NLP-focus
-	NLP-focus
shot	NLP-focus
dialogue	NLP-focus
completion	NLP-focus
low	NLP-focus
-	NLP-focus
resource	NLP-focus
abstractive	NLP-focus
summarization	NLP-focus
and	O
multi	NLP-focus
-	NLP-focus
domain	NLP-focus
language	NLP-focus
modeling	NLP-focus
show	O
improvements	O
in	O
adaptation	O
time	O
and	O
performance	O
over	O
direct	O
finetuning	O
or	O
preparation	O
via	O
domain	O
-	O
adaptive	O
pretraining	O
.	O

Natural	NLP-focus
Language	NLP-focus
Inference	NLP-focus
(	NLP-focus
NLI	NLP-focus
)	NLP-focus
and	O
Semantic	NLP-focus
Textual	NLP-focus
Similarity	NLP-focus
(	NLP-focus
STS	NLP-focus
)	NLP-focus
are	O
widely	O
used	O
benchmark	O
tasks	O
for	O
compositional	O
evaluation	O
of	O
pre	O
-	O
trained	O
language	O
models	O
.	O

Despite	O
growing	O
interest	O
in	O
linguistic	O
universals	O
,	O
most	O
NLI	NLP-focus
STS	NLP-focus
studies	O
have	O
focused	O
almost	O
exclusively	O
on	O
English	O
.	O

In	O
particular	O
,	O
there	O
are	O
no	O
available	O
multilingual	O
NLI	NLP-focus
STS	NLP-focus
datasets	O
in	O
Japanese	O
,	O
which	O
is	O
typologically	O
different	O
from	O
English	O
and	O
can	O
shed	O
light	O
on	O
the	O
currently	O
controversial	O
behavior	O
of	O
language	O
models	O
in	O
matters	O
such	O
as	O
sensitivity	O
to	O
word	O
order	O
and	O
case	O
particles	O
.	O

Against	O
this	O
background	O
,	O
we	O
introduce	O
JSICK	O
a	O
Japanese	O
NLI	NLP-focus
STS	NLP-focus
dataset	O
that	O
was	O
manually	O
translated	O
from	O
the	O
English	O
dataset	O
SICK	O
.	O

In	O
this	O
paper	O
,	O
we	O
survey	O
the	O
work	O
done	O
on	O
neuron	AI/ML/DL-focus
analysis	AI/ML/DL-focus
including	O
:	O
i	O
)	O
methods	O
to	O
discover	O
and	O
understand	O
neurons	O
neuron	AI/ML/DL-focus
analysis	AI/ML/DL-focus
)	O
evaluation	O
methods	O
;	O
iii	O
)	O
major	O
findings	O
including	O
cross	O
architectural	O
comparisons	O
that	O
neuron	O
analysis	O
has	O
unraveled	O
;	O
iv	O
)	O
applications	O
of	O
neuron	AI/ML/DL-focus
probing	AI/ML/DL-focus
such	O
as	O
:	O
controlling	O
the	O
model	O
,	O
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
and	O
so	O
forth	O
;	O
and	O
v	O
)	O
a	O
discussion	O
on	O
open	O
issues	O
and	O
future	O
research	O
directions	O
.	O

Cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
summarization	NLP-focus
is	O
the	O
task	O
of	O
generating	O
a	O
summary	O
in	O
one	O
language	O
(	O
e	O
.	O
g	O
.,	O
English	O
)	O
for	O
the	O
given	O
document	O
(	O
s	O
)	O
in	O
a	O
different	O
language	O
(	O
e	O
.	O
g	O
.,	O
Chinese	O
).	O

This	O
survey	O
is	O
for	O
both	O
beginners	O
and	O
experts	O
in	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
summarization	NLP-focus
and	O
we	O
hope	O
it	O
will	O
serve	O
as	O
a	O
starting	O
point	O
as	O
well	O
as	O
a	O
source	O
of	O
new	O
ideas	O
for	O
researchers	O
and	O
engineers	O
interested	O
in	O
this	O
area	O
.	O

This	O
framework	O
consists	O
of	O
four	O
learning	O
stages	O
,	O
including	O
training	O
machine	O
translation	O
models	O
for	O
sentence	NLP-focus
augmentation	NLP-focus
pretraining	O
a	O
text	O
encoder	O
using	O
contrastive	O
learning	O
finetuning	O
a	O
text	O
classification	O
model	O
and	O
updating	O
weights	O
of	O
translation	O
data	O
by	O
minimizing	O
the	O
validation	O
loss	O
classification	O
model	O
model	O
,	O
which	O
are	O
performed	O
in	O
a	O
unified	O
way	O
.	O

Abstraction	NLP-focus
is	O
a	O
core	O
tenet	O
of	O
human	O
cognition	O
and	O
communication	O
.	O

Yet	O
,	O
interpreting	O
and	O
grounding	O
abstraction	NLP-focus
expressed	O
in	O
NL	O
has	O
not	O
yet	O
been	O
systematically	O
studied	O
in	O
NLP	O
with	O
no	O
accepted	O
benchmarks	O
specifically	O
eliciting	O
abstraction	O
in	O
NL	O
.	O

In	O
this	O
work	O
,	O
we	O
set	O
the	O
foundation	O
for	O
a	O
systematic	O
study	O
of	O
processing	O
and	O
grounding	O
abstraction	NLP-focus
in	O
NLP	O
.	O

First	O
,	O
we	O
deliver	O
a	O
novel	O
abstraction	NLP-focus
elicitation	NLP-focus
method	O
and	O
present	O
Hexagons	O
a	O
2D	O
instruction	O
-	O
following	O
game	O
.	O

Our	O
results	O
show	O
that	O
contemporary	O
models	O
and	O
modeling	O
practices	O
are	O
substantially	O
inferior	O
to	O
human	O
performance	O
,	O
and	O
that	O
model	O
performance	O
is	O
inversely	O
correlated	O
with	O
the	O
level	O
of	O
abstraction	NLP-focus
abstraction	NLP-focus
s	O
satisfying	O
performance	O
on	O
higher	O
levels	O
of	O
abstraction	O
.	O

We	O
investigate	O
how	O
disagreement	O
in	O
natural	NLP-focus
language	NLP-focus
inference	NLP-focus
(	NLP-focus
NLI	NLP-focus
)	NLP-focus
annotation	O
arises	O
.	O

We	O
explore	O
two	O
modeling	O
approaches	O
for	O
detecting	O
items	O
with	O
potential	O
disagreement	O
:	O
a	O
4	O
-	O
way	O
classification	O
with	O
a	O
“	O
Complicated	O
”	O
label	O
in	O
addition	O
to	O
the	O
three	O
standard	O
NLI	O
labels	O
and	O
a	O
multilabel	AI/ML/DL-focus
classification	AI/ML/DL-focus
approach	O
.	O

We	O
found	O
that	O
the	O
multilabel	AI/ML/DL-focus
classification	AI/ML/DL-focus
is	O
more	O
expressive	O
and	O
gives	O
better	O
recall	O
of	O
the	O
possible	O
interpretations	O
in	O
the	O
data	O
.	O

We	O
also	O
measure	O
transitivity	NLP-metrics
which	O
quantifies	O
the	O
importance	O
of	O
word	O
order	O
.	O

Our	O
results	O
indicate	O
that	O
the	O
awareness	O
of	O
object	O
structure	O
yields	O
a	O
more	O
natural	NLP-focus
sentence	NLP-focus
organization	NLP-focus
.	O

Despite	O
extensive	O
research	O
efforts	O
in	O
recent	O
years	O
,	O
computational	NLP-focus
argumentation	NLP-focus
(	NLP-focus
CA	NLP-focus
)	NLP-focus
remains	O
one	O
of	O
the	O
most	O
challenging	O
areas	O
of	O
natural	O
language	O
processing	O
.	O

The	O
integration	O
of	O
knowledge	O
from	O
such	O
a	O
wide	O
range	O
in	O
CA	NLP-focus
requires	O
modeling	O
capabilities	O
far	O
beyond	O
many	O
other	O
natural	O
language	O
understanding	O
tasks	O
.	O

However	O
,	O
a	O
systematic	O
overview	O
of	O
the	O
types	O
of	O
knowledge	O
introduced	O
in	O
existing	O
CA	NLP-focus
models	O
is	O
missing	O
,	O
hindering	O
targeted	O
progress	O
in	O
the	O
field	O
.	O

Adopting	O
the	O
operational	O
definition	O
of	O
knowledge	O
as	O
any	O
task	O
-	O
relevant	O
normative	O
information	O
not	O
provided	O
as	O
input	O
,	O
the	O
survey	O
paper	O
at	O
hand	O
fills	O
this	O
gap	O
by	O
(	O
1	O
)	O
proposing	O
a	O
taxonomy	O
of	O
types	O
of	O
knowledge	O
required	O
in	O
CA	NLP-focus
CA	NLP-focus
CA	NLP-focus
CA	NLP-focus
)	O
systematizing	O
the	O
large	O
body	O
of	O
CA	O
work	O
according	O
to	O
the	O
reliance	O
on	O
and	O
exploitation	O
of	O
these	O
knowledge	O
types	O
for	O
the	O
four	O
main	O
research	O
areas	O
in	O
CA	O
,	O
and	O
(	O
3	O
)	O
outlining	O
and	O
discussing	O
directions	O
for	O
future	O
research	O
efforts	O
in	O
CA	O
.	O

We	O
find	O
that	O
TGs	O
outperform	O
various	O
strong	O
baselines	O
on	O
sentence	NLP-focus
-	NLP-focus
level	NLP-focus
language	NLP-focus
modeling	NLP-focus
perplexity	NLP-metrics
as	O
well	O
as	O
on	O
multiple	O
syntax	O
-	O
sensitive	O
language	O
modeling	O
evaluation	O
metrics	O
.	O

We	O
find	O
that	O
TGs	O
outperform	O
various	O
strong	O
baselines	O
on	O
sentence	NLP-focus
-	NLP-focus
level	NLP-focus
language	NLP-focus
modeling	NLP-focus
perplexity	NLP-metrics
as	O
well	O
as	O
on	O
multiple	O
syntax	O
-	O
sensitive	O
language	O
modeling	O
evaluation	O
metrics	O
.	O

Additionally	O
,	O
we	O
find	O
that	O
the	O
recursive	O
syntactic	O
composition	O
bottleneck	O
which	O
represents	O
each	O
sentence	O
as	O
a	O
single	O
vector	O
harms	O
perplexity	O
on	O
document	NLP-focus
-	NLP-focus
level	NLP-focus
language	NLP-focus
modeling	NLP-focus
providing	O
evidence	O
that	O
a	O
different	O
kind	O
of	O
memory	O
mechanism	O
—	O
one	O
that	O
is	O
independent	O
of	O
composed	O
syntactic	O
representations	O
plays	O
an	O
important	O
role	O
in	O
current	O
successful	O
models	O
of	O
long	O
text	O
.	O

In	O
this	O
work	O
we	O
introduce	O
the	O
concept	O
of	O
policy	NLP-focus
-	NLP-focus
aware	NLP-focus
abuse	NLP-focus
detection	NLP-focus
abandoning	O
the	O
unrealistic	O
expectation	O
that	O
systems	O
can	O
reliably	O
learn	O
which	O
phenomena	O
constitute	O
abuse	O
from	O
inspecting	O
the	O
data	O
alone	O
.	O

We	O
collect	O
and	O
annotate	O
a	O
dataset	O
of	O
3	O
,	O
535	O
English	O
posts	O
with	O
such	O
slots	O
,	O
and	O
show	O
how	O
architectures	O
for	O
intent	NLP-focus
classification	NLP-focus
and	O
slot	NLP-focus
filling	NLP-focus
can	O
be	O
used	O
for	O
abuse	O
detection	O
,	O
while	O
providing	O
a	O
rationale	O
for	O
model	O
decisions	O
.	O
1	O
.	O

Morphological	NLP-focus
tasks	NLP-focus
use	O
large	O
multi	O
-	O
lingual	O
datasets	O
that	O
organize	O
words	O
into	O
inflection	O
tables	O
,	O
which	O
then	O
serve	O
as	O
training	O
and	O
evaluation	O
data	O
for	O
various	O
tasks	O
.	O

To	O
overcome	O
this	O
deficiency	O
,	O
we	O
propose	O
to	O
view	O
morphology	NLP-focus
as	O
a	O
clause	O
-	O
level	O
phenomenon	O
,	O
rather	O
than	O
word	O
-	O
level	O
.	O

We	O
use	O
this	O
dataset	O
to	O
derive	O
3	O
clause	NLP-focus
-	NLP-focus
level	NLP-focus
morphological	NLP-focus
tasks	NLP-focus
inflection	NLP-focus
reinflection	NLP-focus
and	O
analysis	O
.	O

Taken	O
together	O
,	O
this	O
work	O
opens	O
up	O
new	O
horizons	O
in	O
the	O
study	O
of	O
computational	O
morphology	O
,	O
leaving	O
ample	O
space	O
for	O
studying	O
neural	NLP-focus
morphology	NLP-focus
cross	O
-	O
linguistically	O
.	O

However	O
,	O
dialogue	O
systems	O
often	O
produce	O
unsupported	O
utterances	O
,	O
a	O
phenomenon	O
known	O
as	O
hallucination	AI/ML/DL-focus
.	O

We	O
show	O
that	O
FaithDial	O
can	O
serve	O
as	O
training	O
signal	O
for	O
:	O
i	O
)	O
a	O
hallucination	O
critic	O
,	O
which	O
discriminates	O
whether	O
an	O
utterance	O
is	O
faithful	O
or	O
not	O
,	O
and	O
boosts	O
the	O
performance	O
by	O
12	O
.	O
8	O
F1	Classification-metrics
score	O
on	O
the	O
BEGIN	O
benchmark	O
compared	O
to	O
existing	O
datasets	O
for	O
dialogue	O
coherence	O
;	O
ii	O
)	O
high	O
-	O
quality	O
dialogue	O
generation	O
.	O

When	O
building	O
machine	NLP-focus
translation	NLP-focus
systems	O
,	O
one	O
often	O
needs	O
to	O
make	O
the	O
best	O
out	O
of	O
heterogeneous	O
sets	O
of	O
parallel	O
data	O
in	O
training	O
and	O
to	O
robustly	O
handle	O
inputs	O
from	O
unexpected	O
domains	O
in	O
testing	O
.	O

In	O
this	O
study	O
,	O
we	O
revisit	O
multi	NLP-focus
-	NLP-focus
domain	NLP-focus
machine	NLP-focus
translation	NLP-focus
with	O
the	O
aim	O
to	O
formulate	O
the	O
motivations	O
for	O
developing	O
such	O
systems	O
and	O
the	O
associated	O
expectations	O
with	O
respect	O
to	O
performance	O
.	O

Task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialogue	NLP-focus
systems	O
typically	O
rely	O
on	O
large	O
amounts	O
of	O
high	O
-	O
quality	O
training	O
data	O
or	O
require	O
complex	O
handcrafted	O
rules	O
.	O

We	O
propose	O
the	O
Conversation	O
Graph	O
(	O
ConvGraph	O
)	O
a	O
graph	O
-	O
based	O
representation	O
of	O
dialogues	O
that	O
can	O
be	O
exploited	O
for	O
data	NLP-focus
augmentation	NLP-focus
multi	O
-	O
reference	O
training	O
and	O
evaluation	O
of	O
non	O
-	O
deterministic	O
agents	O
.	O

Intrinsic	O
and	O
extrinsic	O
evaluation	O
across	O
three	O
datasets	O
shows	O
that	O
data	NLP-focus
augmentation	NLP-focus
and	O
/	O
or	O
multi	O
-	O
reference	O
training	O
with	O
ConvGraph	O
can	O
improve	O
dialogue	O
success	O
rates	O
by	O
up	O
to	O
6	O
.	O
4	O
\\%	O
.	O

Self	O
-	O
attention	O
has	O
recently	O
been	O
adopted	O
for	O
a	O
wide	O
range	O
of	O
sequence	AI/ML/DL-focus
modeling	AI/ML/DL-focus
problems	O
.	O

We	O
show	O
that	O
our	O
model	O
outperforms	O
comparable	O
sparse	O
attention	O
models	O
on	O
language	O
modeling	O
on	O
Wikitext	O
-	O
103	O
(	O
15	O
.	O
8	O
vs	O
18	O
.	O
3	O
perplexity	O
),	O
as	O
well	O
as	O
on	O
image	AI/ML/DL-focus
generation	AI/ML/DL-focus
on	O
ImageNet	O
-	O
64	O
(	O
3	O
.	O
43	O
vs	O
3	O
.	O
44	O
bits	O
/	O
dim	O
)	O
while	O
using	O
fewer	O
self	O
-	O
attention	O
layers	O
.	O

Additionally	O
,	O
we	O
set	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
newly	O
released	O
PG	O
-	O
19	O
data	O
-	O
set	O
,	O
obtaining	O
a	O
test	O
perplexity	NLP-metrics
of	O
33	O
.	O
2	O
with	O
a	O
22	O
layer	O
Routing	O
Transformer	O
model	O
trained	O
on	O
sequences	O
of	O
length	O
8192	O
.	O

The	O
resulting	O
generative	O
framework	O
jointly	O
models	O
word	NLP-focus
segmentation	NLP-focus
and	O
cognate	NLP-focus
alignment	NLP-focus
informed	O
by	O
phonological	O
constraints	O
.	O

We	O
propose	O
the	O
Recursive	O
Non	O
-	O
autoregressive	O
Graph	O
-	O
to	O
-	O
Graph	O
Transformer	O
architecture	O
(	O
RNGTr	O
)	O
for	O
the	O
iterative	O
refinement	O
of	O
arbitrary	O
graphs	O
through	O
the	O
recursive	O
application	O
of	O
a	O
non	O
-	O
autoregressive	O
Graph	O
-	O
to	O
-	O
Graph	O
Transformer	O
and	O
apply	O
it	O
to	O
syntactic	NLP-focus
dependency	NLP-focus
parsing	NLP-focus
.	O

We	O
use	O
large	O
-	O
scale	O
corpora	O
in	O
six	O
different	O
gendered	O
languages	O
,	O
along	O
with	O
tools	O
from	O
NLP	O
and	O
information	NLP-focus
theory	NLP-focus
to	O
test	O
whether	O
there	O
is	O
a	O
relationship	O
between	O
the	O
grammatical	O
genders	O
of	O
inanimate	O
nouns	O
and	O
the	O
adjectives	O
used	O
to	O
describe	O
those	O
nouns	O
.	O

In	O
this	O
work	O
,	O
we	O
point	O
out	O
the	O
inability	O
to	O
infer	O
behavioral	O
conclusions	O
from	O
probing	AI/ML/DL-focus
results	O
,	O
and	O
offer	O
an	O
alternative	O
method	O
that	O
focuses	O
on	O
how	O
the	O
information	O
is	O
being	O
used	O
,	O
rather	O
than	O
on	O
what	O
information	O
is	O
encoded	O
.	O

Equipped	O
with	O
this	O
new	O
analysis	O
tool	O
,	O
we	O
can	O
ask	O
questions	O
that	O
were	O
not	O
possible	O
before	O
,	O
for	O
example	O
,	O
is	O
part	O
-	O
of	O
-	O
speech	O
information	O
important	O
for	O
word	NLP-focus
prediction	NLP-focus
We	O
perform	O
a	O
series	O
of	O
analyses	O
on	O
BERT	O
to	O
answer	O
these	O
types	O
of	O
questions	O
.	O

Our	O
findings	O
demonstrate	O
that	O
conventional	O
probing	AI/ML/DL-focus
probing	AI/ML/DL-focus
nce	O
is	O
not	O
correlated	O
to	O
task	O
importance	O
,	O
and	O
we	O
call	O
for	O
increased	O
scrutiny	O
of	O
claims	O
that	O
draw	O
behavioral	O
or	O
causal	O
conclusions	O
from	O
probing	O
results	O
.	O
1	O
.	O

Experimental	O
results	O
show	O
that	O
KEPLER	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
on	O
various	O
NLP	O
tasks	O
,	O
and	O
also	O
works	O
remarkably	O
well	O
as	O
an	O
inductive	O
KE	O
model	O
on	O
KG	NLP-focus
link	NLP-focus
prediction	NLP-focus
.	O

Answering	O
questions	O
that	O
involve	O
multi	NLP-focus
-	NLP-focus
step	NLP-focus
reasoning	NLP-focus
requires	O
decomposing	O
them	O
and	O
using	O
the	O
answers	O
of	O
intermediate	O
steps	O
to	O
reach	O
the	O
final	O
answer	O
.	O

However	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
in	O
grounded	O
question	NLP-focus
answering	NLP-focus
often	O
do	O
not	O
explicitly	O
perform	O
decomposition	O
,	O
leading	O
to	O
difficulties	O
in	O
generalization	O
to	O
out	O
-	O
of	O
-	O
distribution	O
examples	O
.	O

We	O
show	O
that	O
this	O
inductive	O
bias	O
towards	O
tree	O
structures	O
dramatically	O
improves	O
systematic	O
generalization	O
to	O
out	O
-	O
of	O
-	O
distribution	O
examples	O
,	O
compared	O
to	O
strong	O
baselines	O
on	O
an	O
arithmetic	O
expressions	O
benchmark	O
as	O
well	O
as	O
on	O
C	O
losure	O
a	O
dataset	O
that	O
focuses	O
on	O
systematic	O
generalization	O
for	O
grounded	O
question	NLP-focus
answering	NLP-focus
.	O

On	O
this	O
challenging	O
dataset	O
,	O
our	O
model	O
reaches	O
an	O
accuracy	Classification-metrics
of	O
96	O
.	O
1	O
\\%	O
significantly	O
higher	O
than	O
prior	O
models	O
that	O
almost	O
perfectly	O
solve	O
the	O
task	O
on	O
a	O
random	O
,	O
in	O
-	O
distribution	O
split	O
.	O

Aspect	NLP-focus
-	NLP-focus
based	NLP-focus
summarization	NLP-focus
is	O
the	O
task	O
of	O
generating	O
focused	O
summaries	O
based	O
on	O
specific	O
points	O
of	O
interest	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
WikiAsp	O
1	O
a	O
large	O
-	O
scale	O
dataset	O
for	O
multi	NLP-focus
-	NLP-focus
domain	NLP-focus
aspect	NLP-focus
-	NLP-focus
based	NLP-focus
summarization	NLP-focus
that	O
attempts	O
to	O
spur	O
research	O
in	O
the	O
direction	O
of	O
open	NLP-focus
-	NLP-focus
domain	NLP-focus
aspect	NLP-focus
-	NLP-focus
based	NLP-focus
summarization	NLP-focus
.	O

Specifically	O
,	O
we	O
build	O
the	O
dataset	O
using	O
Wikipedia	O
articles	O
from	O
20	O
different	O
domains	O
,	O
using	O
the	O
section	O
titles	O
and	O
boundaries	O
of	O
each	O
article	O
as	O
a	O
proxy	O
for	O
aspect	NLP-focus
annotation	NLP-focus
.	O

Rather	O
than	O
give	O
up	O
on	O
rare	O
tags	O
,	O
we	O
investigate	O
constructive	O
models	O
that	O
account	O
for	O
their	O
internal	O
structure	O
,	O
including	O
novel	O
methods	O
for	O
tree	AI/ML/DL-focus
-	AI/ML/DL-focus
structured	AI/ML/DL-focus
prediction	AI/ML/DL-focus
.	O

Our	O
best	O
tagger	O
is	O
capable	O
of	O
recovering	O
a	O
sizeable	O
fraction	O
of	O
the	O
long	O
-	O
tail	O
supertags	O
and	O
even	O
generates	O
CCG	NLP-focus
categories	O
that	O
have	O
never	O
been	O
seen	O
in	O
training	O
while	O
approximating	O
the	O
prior	O
state	O
of	O
the	O
art	O
in	O
overall	O
tag	O
accuracy	Classification-metrics
with	O
fewer	O
parameters	O
.	O

Our	O
best	O
tagger	O
is	O
capable	O
of	O
recovering	O
a	O
sizeable	O
fraction	O
of	O
the	O
long	O
-	O
tail	O
supertags	O
and	O
even	O
generates	O
CCG	NLP-focus
categories	O
that	O
have	O
never	O
been	O
seen	O
in	O
training	O
while	O
approximating	O
the	O
prior	O
state	O
of	O
the	O
art	O
in	O
overall	O
tag	O
accuracy	Classification-metrics
with	O
fewer	O
parameters	O
.	O

Prior	O
studies	O
in	O
multilingual	NLP-focus
language	NLP-focus
modeling	NLP-focus
(	O
e	O
.	O
g	O
.,	O
Cotterell	O
et	O
al	O
.,	O
2018	O
;	O
Mielke	O
et	O
al	O
.,	O
2019	O
)	O
disagree	O
on	O
whether	O
or	O
not	O
inflectional	NLP-focus
morphology	NLP-focus
makes	O
languages	O
harder	O
to	O
model	O
.	O

We	O
also	O
investigate	O
linguistically	O
motivated	O
subword	NLP-focus
segmentation	NLP-focus
strategies	O
like	O
Morfessor	O
and	O
Finite	O
-	O
State	O
Transducers	O
(	O
FSTs	O
)	O
segmentation	NLP-focus
these	O
segmentation	O
strategies	O
yield	O
better	O
performance	O
and	O
reduce	O
the	O
impact	O
of	O
a	O
language	O
’	O
s	O
morphology	O
on	O
language	NLP-focus
modeling	NLP-focus
.	O

We	O
present	O
the	O
Quantized	O
Transformer	O
(	O
QT	O
)	O
an	O
unsupervised	O
system	O
for	O
extractive	NLP-focus
opinion	NLP-focus
summarization	NLP-focus
QT	O

QT	O
is	O
inspired	O
by	O
Vector	O
-	O
Quantized	O
Variational	O
Autoencoders	O
which	O
we	O
repurpose	O
for	O
popularity	O
-	O
driven	O
summarization	NLP-focus
.	O

It	O
uses	O
a	O
clustering	O
interpretation	O
of	O
the	O
quantized	O
space	O
and	O
a	O
novel	O
extraction	O
algorithm	O
to	O
discover	O
popular	O
opinions	O
among	O
hundreds	O
of	O
reviews	O
,	O
a	O
significant	O
step	O
towards	O
opinion	NLP-focus
summarization	NLP-focus
of	O
practical	O
scope	O
.	O

We	O
also	O
make	O
publicly	O
available	O
Space	O
a	O
large	O
-	O
scale	O
evaluation	O
benchmark	O
for	O
opinion	NLP-focus
summarizers	NLP-focus
comprising	O
general	O
and	O
aspect	O
-	O
specific	O
summaries	O
for	O
50	O
hotels	O
.	O

We	O
find	O
that	O
the	O
requirement	O
of	O
model	AI/ML/DL-focus
interpretations	AI/ML/DL-focus
to	O
be	O
faithful	O
is	O
vague	O
and	O
incomplete	O
.	O

We	O
reformulate	O
faithfulness	O
as	O
an	O
accurate	O
attribution	O
of	O
causality	O
to	O
the	O
model	O
,	O
and	O
introduce	O
the	O
concept	O
of	O
aligned	NLP-focus
faithfulness	NLP-focus
faithful	O
causal	O
chains	O
that	O
are	O
aligned	O
with	O
their	O
expected	O
social	O
behavior	O
.	O

We	O
introduce	O
an	O
Edit	O
-	O
Based	O
TransfOrmer	O
with	O
Repositioning	O
(	O
EDITOR	O
)	O
which	O
makes	O
sequence	NLP-focus
generation	NLP-focus
flexible	O
by	O
seamlessly	O
allowing	O
users	O
to	O
specify	O
preferences	O
in	O
output	O
lexical	O
choice	O
.	O

Building	O
on	O
recent	O
models	O
for	O
non	NLP-focus
-	NLP-focus
autoregressive	NLP-focus
sequence	NLP-focus
generation	NLP-focus
(	O
Gu	O
et	O
al	O
.,	O
2019	O
),	O
EDITOR	O
generates	O
new	O
sequences	O
by	O
iteratively	O
editing	O
hypotheses	O
.	O

EDITOR	O
also	O
achieves	O
comparable	O
or	O
better	O
translation	O
quality	O
with	O
faster	O
decoding	O
speed	O
than	O
the	O
Levenshtein	O
Transformer	O
on	O
standard	O
Romanian	O
-	O
English	O
English	O
-	O
German	O
and	O
English	O
-	O
Japanese	O
machine	NLP-focus
translation	NLP-focus
tasks	O
.	O

Building	O
on	O
these	O
insights	O
,	O
we	O
propose	O
a	O
simple	O
neural	O
model	O
that	O
combines	O
the	O
efficiency	O
of	O
dual	O
encoders	O
with	O
some	O
of	O
the	O
expressiveness	O
of	O
more	O
costly	O
attentional	O
architectures	O
,	O
and	O
explore	O
sparse	O
-	O
dense	O
hybrids	O
to	O
capitalize	O
on	O
the	O
precision	O
of	O
sparse	NLP-focus
retrieval	NLP-focus
.	O

A	O
key	O
limitation	O
in	O
current	O
datasets	O
for	O
multi	NLP-focus
-	NLP-focus
hop	NLP-focus
reasoning	NLP-focus
is	O
that	O
the	O
required	O
steps	O
for	O
answering	O
the	O
question	O
are	O
mentioned	O
in	O
it	O
explicitly	O
.	O

In	O
this	O
work	O
,	O
we	O
introduce	O
StrategyQA	O
a	O
question	NLP-focus
answering	NLP-focus
(	NLP-focus
QA	NLP-focus
)	NLP-focus
benchmark	O
where	O
the	O
required	O
reasoning	O
steps	O
are	O
implicit	O
in	O
the	O
question	O
,	O
and	O
should	O
be	O
inferred	O
using	O
a	O
strategy	O
.	O

Task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialog	NLP-focus
(	NLP-focus
TOD	NLP-focus
)	NLP-focus
systems	O
often	O
need	O
to	O
formulate	O
knowledge	O
base	O
(	O
KB	O
)	O
queries	O
corresponding	O
to	O
the	O
user	O
intent	O
and	O
use	O
the	O
query	O
results	O
to	O
generate	O
system	O
responses	O
.	O

For	O
query	NLP-focus
prediction	NLP-focus
we	O
propose	O
a	O
reinforcement	O
learning	O
(	O
RL	O
)	O
baseline	O
,	O
which	O
rewards	O
the	O
generation	O
of	O
those	O
queries	O
whose	O
KB	O
results	O
cover	O
the	O
entities	O
mentioned	O
in	O
subsequent	O
dialog	O
.	O

To	O
train	O
the	O
full	O
TOD	NLP-focus
system	O
for	O
our	O
setting	O
,	O
we	O
propose	O
a	O
pipelined	O
approach	O
:	O
it	O
independently	O
predicts	O
when	O
to	O
make	O
a	O
KB	O
query	O
(	O
query	O
position	O
predictor	O
KB	O
query	O
edicts	O
a	O
KB	O
query	O
at	O
the	O
predicted	O
position	O
(	O
query	O
predictor	O
),	O
and	O
uses	O
the	O
results	O
of	O
predicted	O
query	O
in	O
subsequent	O
dialog	O
(	O
next	O
response	O
predictor	O
).	O

The	O
scarcity	O
of	O
comprehensive	O
up	O
-	O
to	O
-	O
date	O
studies	O
on	O
evaluation	O
metrics	O
for	O
text	NLP-focus
summarization	NLP-focus
and	O
the	O
lack	O
of	O
consensus	O
regarding	O
evaluation	O
protocols	O
continue	O
to	O
inhibit	O
progress	O
.	O

We	O
hope	O
that	O
this	O
work	O
will	O
help	O
promote	O
a	O
more	O
complete	O
evaluation	O
protocol	O
for	O
text	NLP-focus
summarization	NLP-focus
as	O
well	O
as	O
advance	O
research	O
in	O
developing	O
evaluation	O
metrics	O
that	O
better	O
correlate	O
with	O
human	O
judgments	O
.	O

For	O
instance	O
,	O
given	O
training	O
data	O
for	O
named	NLP-focus
entity	NLP-focus
recognition	NLP-focus
(	NLP-focus
NER	NLP-focus
)	NLP-focus
in	O
Vietnamese	O
and	O
for	O
part	NLP-focus
-	NLP-focus
of	NLP-focus
-	NLP-focus
speech	NLP-focus
(	NLP-focus
POS	NLP-focus
)	NLP-focus
tagging	NLP-focus
in	O
Wolof	O
NER	NLP-focus
Wolof	O
can	O
perform	O
accurate	O
predictions	O
for	O
NER	O
in	O
Wolof	O
.	O

The	O
metrics	O
standardly	O
used	O
to	O
evaluate	O
Natural	O
Language	O
Generation	O
(	O
NLG	O
)	O
models	O
such	O
as	O
BLEU	NLP-metrics
or	O
METEOR	NLP-metrics
fail	O
to	O
provide	O
information	O
on	O
which	O
linguistic	O
factors	O
impact	O
performance	O
.	O

Focusing	O
on	O
Surface	NLP-focus
Realization	NLP-focus
(	NLP-focus
SR	NLP-focus
)	NLP-focus
the	O
task	O
of	O
converting	O
an	O
unordered	O
dependency	O
tree	O
into	O
a	O
well	O
-	O
formed	O
sentence	O
,	O
we	O
propose	O
a	O
framework	O
for	O
error	AI/ML/DL-focus
analysis	AI/ML/DL-focus
which	O
permits	O
identifying	O
which	O
features	O
of	O
the	O
input	O
affect	O
the	O
models	O
’	O
results	O
.	O

We	O
demonstrate	O
the	O
advantages	O
of	O
our	O
framework	O
by	O
performing	O
error	AI/ML/DL-focus
analysis	AI/ML/DL-focus
on	O
the	O
results	O
of	O
174	O
system	O
runs	O
submitted	O
to	O
the	O
Multilingual	NLP-focus
SR	NLP-focus
shared	O
tasks	O
;	O
we	O
show	O
that	O
dependency	O
edge	O
accuracy	Classification-metrics
correlate	O
with	O
automatic	O
metrics	O
thereby	O
providing	O
a	O
more	O
interpretable	O
basis	O
for	O
evaluation	O
;	O
and	O
we	O
suggest	O
ways	O
in	O
which	O
our	O
framework	O
could	O
be	O
used	O
to	O
improve	O
models	O
and	O
data	O
.	O

We	O
demonstrate	O
the	O
advantages	O
of	O
our	O
framework	O
by	O
performing	O
error	AI/ML/DL-focus
analysis	AI/ML/DL-focus
on	O
the	O
results	O
of	O
174	O
system	O
runs	O
submitted	O
to	O
the	O
Multilingual	NLP-focus
SR	NLP-focus
shared	O
tasks	O
;	O
we	O
show	O
that	O
dependency	O
edge	O
accuracy	Classification-metrics
correlate	O
with	O
automatic	O
metrics	O
thereby	O
providing	O
a	O
more	O
interpretable	O
basis	O
for	O
evaluation	O
;	O
and	O
we	O
suggest	O
ways	O
in	O
which	O
our	O
framework	O
could	O
be	O
used	O
to	O
improve	O
models	O
and	O
data	O
.	O

The	O
framework	O
is	O
available	O
in	O
the	O
form	O
of	O
a	O
toolkit	O
which	O
can	O
be	O
used	O
both	O
by	O
campaign	O
organizers	O
to	O
provide	O
detailed	O
,	O
linguistically	O
interpretable	O
feedback	O
on	O
the	O
state	O
of	O
the	O
art	O
in	O
multilingual	NLP-focus
SR	NLP-focus
and	O
by	O
individual	O
researchers	O
to	O
improve	O
models	O
and	O
datasets	O
1	O
.	O

Models	O
for	O
question	NLP-focus
answering	NLP-focus
dialogue	NLP-focus
agents	NLP-focus
and	O
summarization	NLP-focus
often	O
interpret	O
the	O
meaning	O
of	O
a	O
sentence	O
in	O
a	O
rich	O
context	O
and	O
use	O
that	O
meaning	O
in	O
a	O
new	O
context	O
.	O

We	O
isolate	O
and	O
define	O
the	O
problem	O
of	O
sentence	NLP-focus
decontextualization	NLP-focus
taking	O
a	O
sentence	O
together	O
with	O
its	O
context	O
and	O
rewriting	O
it	O
to	O
be	O
interpretable	O
out	O
of	O
context	O
,	O
while	O
preserving	O
its	O
meaning	O
.	O

We	O
present	O
preliminary	O
studies	O
that	O
show	O
the	O
value	O
of	O
sentence	NLP-focus
decontextualization	NLP-focus
in	O
a	O
user	O
-	O
facing	O
task	O
,	O
and	O
as	O
preprocessing	O
for	O
systems	O
that	O
perform	O
document	NLP-focus
understanding	NLP-focus
.	O

We	O
argue	O
that	O
decontextualization	NLP-focus
is	O
an	O
important	O
subtask	O
in	O
many	O
downstream	O
applications	O
,	O
and	O
that	O
the	O
definitions	O
and	O
resources	O
provided	O
can	O
benefit	O
tasks	O
that	O
operate	O
on	O
sentences	O
that	O
occur	O
in	O
a	O
richer	O
context	O
.	O

We	O
take	O
an	O
initial	O
step	O
toward	O
machine	NLP-focus
generation	NLP-focus
of	O
slang	O
by	O
developing	O
a	O
framework	O
that	O
models	O
the	O
speaker	O
’	O
s	O
word	O
choice	O
in	O
slang	O
context	O
.	O

Optical	Computer/vision-focus
character	Computer/vision-focus
recognition	Computer/vision-focus
(	Computer/vision-focus
OCR	Computer/vision-focus
)	Computer/vision-focus
OCR	Computer/vision-focus
rucial	O
for	O
a	O
deeper	O
access	O
to	O
historical	O
collections	O
.	O

For	O
digital	O
corpora	O
of	O
historical	O
prints	O
,	O
the	O
errors	O
are	O
further	O
exacerbated	O
due	O
to	O
low	O
scan	O
quality	O
and	O
lack	O
of	O
language	O
standardization	O
.	O
For	O
the	O
task	O
of	O
OCR	NLP-focus
post	NLP-focus
-	NLP-focus
hoc	NLP-focus
correction	NLP-focus
we	O
propose	O
a	O
neural	O
approach	O
based	O
on	O
a	O
combination	O
of	O
recurrent	O
(	O
RNN	O
)	O
and	O
deep	O
convolutional	O
network	O
(	O
ConvNet	O
)	O
to	O
correct	O
OCR	O
transcription	O
errors	O
.	O

Accounting	O
for	O
the	O
input	O
and	O
output	O
similarity	O
,	O
we	O
propose	O
a	O
new	O
loss	O
function	O
that	O
rewards	O
the	O
model	O
’	O
s	O
correcting	O
behavior	O
.	O
Evaluation	O
on	O
a	O
historical	O
book	O
corpus	O
in	O
German	O
language	O
shows	O
that	O
our	O
models	O
are	O
robust	O
in	O
capturing	O
diverse	O
OCR	NLP-focus
transcription	NLP-focus
errors	O
and	O
reduce	O
the	O
word	O
error	O
rate	O
of	O
32	O
.	O
3	O
\\%	O
by	O
more	O
than	O
89	O
\\%.	O

We	O
introduce	O
a	O
novel	O
paraphrastic	NLP-focus
augmentation	NLP-focus
strategy	O
based	O
on	O
sentence	O
-	O
level	O
lexically	O
constrained	O
paraphrasing	O
and	O
discriminative	O
span	O
alignment	O
.	O

Recent	O
approaches	O
to	O
data	NLP-focus
-	NLP-focus
to	NLP-focus
-	NLP-focus
text	NLP-focus
generation	NLP-focus
have	O
adopted	O
the	O
very	O
successful	O
encoder	O
-	O
decoder	O
architecture	O
or	O
variants	O
thereof	O
.	O

Extensive	O
experiments	O
on	O
two	O
data	NLP-focus
-	NLP-focus
to	NLP-focus
-	NLP-focus
text	NLP-focus
benchmarks	O
(	O
RotoWire	O
and	O
MLB	O
show	O
that	O
our	O
approach	O
outperforms	O
competitive	O
baselines	O
in	O
terms	O
of	O
automatic	O
and	O
human	O
evaluation	O
.	O

Phonological	NLP-focus
generalizations	NLP-focus
are	O
finite	O
-	O
state	O
.	O

Tracking	NLP-focus
dialogue	NLP-focus
states	NLP-focus
to	O
better	O
interpret	O
user	O
goals	O
and	O
feed	O
downstream	O
policy	O
learning	O
is	O
a	O
bottleneck	O
in	O
dialogue	O
management	O
.	O

Focusing	O
on	O
zero	Computer/vision-focus
-	Computer/vision-focus
shot	Computer/vision-focus
image	Computer/vision-focus
retrieval	Computer/vision-focus
tasks	O
,	O
we	O
study	O
three	O
important	O
factors	O
that	O
can	O
impact	O
the	O
quality	O
of	O
learned	O
representations	O
pretraining	O
data	O
the	O
attention	O
mechanism	O
and	O
loss	O
functions	O
.	O

We	O
introduce	O
NRB	O
,	O
a	O
new	O
testbed	O
carefully	O
designed	O
to	O
diagnose	O
Name	NLP-focus
Regularity	NLP-focus
Bias	NLP-focus
of	O
NER	O
models	O
.	O

Our	O
results	O
indicate	O
that	O
all	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
we	O
tested	O
show	O
such	O
a	O
bias	O
;	O
BERT	O
fine	O
-	O
tuned	O
models	O
significantly	O
outperforming	O
feature	O
-	O
based	O
(	O
LSTM	O
-	O
CRF	O
ones	O
on	O
NRB	NLP-focus
despite	O
having	O
comparable	O
(	O
sometimes	O
lower	O
)	O
performance	O
on	O
standard	O
benchmarks	O
.	O
To	O
mitigate	O
this	O
bias	O
,	O
we	O
propose	O
a	O
novel	O
model	O
-	O
agnostic	O
training	O
method	O
that	O
adds	O
learnable	O
adversarial	O
noise	O
NRB	NLP-focus
ome	O
entity	O
mentions	O
,	O
thus	O
enforcing	O
models	O
to	O
focus	O
more	O
strongly	O
on	O
the	O
contextual	O
signal	O
,	O
leading	O
to	O
significant	O
gains	O
on	O
NRB	O
.	O

Limerick	NLP-focus
generation	NLP-focus
exemplifies	O
some	O
of	O
the	O
most	O
difficult	O
challenges	O
faced	O
in	O
poetry	O
generation	O
,	O
as	O
the	O
poems	O
must	O
tell	O
a	O
story	O
in	O
only	O
five	O
lines	O
,	O
with	O
constraints	O
on	O
rhyme	O
,	O
stress	O
,	O
and	O
meter	O
.	O

To	O
address	O
these	O
challenges	O
,	O
we	O
introduce	O
LimGen	O
a	O
novel	O
and	O
fully	O
automated	O
system	O
for	O
limerick	NLP-focus
generation	NLP-focus
that	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
LimGen	O
network	O
-	O
based	O
poetry	O
models	O
,	O
as	O
well	O
as	O
prior	O
rule	O
-	O
based	O
poetry	O
models	O
.	O

As	O
a	O
step	O
towards	O
a	O
better	O
understanding	O
of	O
their	O
discourse	NLP-focus
modeling	NLP-focus
capabilities	O
,	O
we	O
propose	O
a	O
sentence	NLP-focus
intrusion	NLP-focus
detection	NLP-focus
task	O
.	O

Lacking	O
a	O
dataset	O
for	O
the	O
task	O
,	O
we	O
introduce	O
INSteD	O
a	O
novel	O
intruder	NLP-focus
sentence	NLP-focus
detection	NLP-focus
dataset	O
,	O
containing	O
170	O
,	O
000	O
+	O
documents	O
constructed	O
from	O
English	O
Wikipedia	O
and	O
CNN	O
news	O
articles	O
.	O

Text	NLP-focus
classification	NLP-focus
is	O
a	O
widely	O
studied	O
problem	O
and	O
has	O
broad	O
applications	O
.	O

In	O
many	O
real	O
-	O
world	O
problems	O
,	O
the	O
number	O
of	O
texts	O
for	O
training	O
classification	O
models	O
is	O
limited	O
,	O
which	O
renders	O
these	O
models	O
prone	O
to	O
overfitting	AI/ML/DL-focus
.	O

In	O
SSL	O
-	O
Reg	O
a	O
supervised	AI/ML/DL-focus
classification	AI/ML/DL-focus
task	O
and	O
an	O
unsupervised	AI/ML/DL-focus
SSL	AI/ML/DL-focus
SSL	AI/ML/DL-focus
are	O
performed	O
simultaneously	O
.	O

Training	O
a	O
model	O
using	O
an	O
SSL	AI/ML/DL-focus
task	O
can	O
prevent	O
the	O
model	O
from	O
being	O
overfitted	O
to	O
a	O
limited	O
number	O
of	O
class	O
labels	O
in	O
the	O
classification	AI/ML/DL-focus
task	AI/ML/DL-focus
.	O

Experiments	O
on	O
17	O
text	NLP-focus
classification	NLP-focus
datasets	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
method	O
.	O

Direct	O
decoding	O
for	O
task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialogue	NLP-focus
is	O
known	O
to	O
suffer	O
from	O
the	O
explaining	O
-	O
away	O
effect	O
,	O
manifested	O
in	O
models	O
that	O
prefer	O
short	O
and	O
generic	O
responses	O
.	O

We	O
explore	O
few	O
-	O
shot	O
learning	O
(	O
FSL	O
)	O
for	O
relation	NLP-focus
classification	NLP-focus
(	NLP-focus
RC	NLP-focus
)	NLP-focus
.	O

To	O
remedy	O
this	O
,	O
we	O
propose	O
a	O
novel	O
methodology	O
for	O
deriving	O
more	O
realistic	O
few	O
-	O
shot	O
test	O
data	O
from	O
available	O
datasets	O
for	O
supervised	NLP-focus
RC	NLP-focus
and	O
apply	O
it	O
to	O
the	O
TACRED	O
dataset	O
.	O

While	O
argument	NLP-focus
mining	NLP-focus
has	O
achieved	O
significant	O
success	O
in	O
classifying	O
argumentative	O
relations	O
between	O
statements	O
(	O
support	O
,	O
attack	O
,	O
and	O
neutral	O
),	O
we	O
have	O
a	O
limited	O
computational	O
understanding	O
of	O
logical	O
mechanisms	O
that	O
constitute	O
those	O
relations	O
.	O

In	O
this	O
paper	O
,	O
we	O
evaluate	O
the	O
translation	NLP-focus
of	O
negation	O
both	O
automatically	O
and	O
manually	O
,	O
in	O
English	NLP-focus
–	NLP-focus
German	NLP-focus
(	NLP-focus
EN	NLP-focus
–	NLP-focus
DE	NLP-focus
)	NLP-focus
and	O
English	NLP-focus
–	NLP-focus
Chinese	NLP-focus
(	NLP-focus
EN	NLP-focus
–	NLP-focus
ZH	NLP-focus
)	NLP-focus
.	O

We	O
show	O
that	O
the	O
ability	O
of	O
neural	NLP-focus
machine	NLP-focus
translation	NLP-focus
(	NLP-focus
NMT	NLP-focus
)	NLP-focus
models	O
to	O
translate	O
negation	O
has	O
improved	O
with	O
deeper	O
and	O
more	O
advanced	O
networks	O
,	O
although	O
the	O
performance	O
varies	O
between	O
language	O
pairs	O
and	O
translation	O
directions	O
.	O

The	O
accuracy	O
of	O
manual	O
evaluation	O
in	O
EN	NLP-focus
→	NLP-focus
DE	NLP-focus
DE	NLP-focus
→	NLP-focus
EN	NLP-focus
EN	NLP-focus
→	NLP-focus
ZH	NLP-focus
and	O
ZH	NLP-focus
→	NLP-focus
EN	NLP-focus
is	O
95	O
.	O
7	O
\\%	O
94	O
.	O
8	O
\\%	O
93	O
.	O
4	O
\\%	O
and	O
91	O
.	O
7	O
\\%	O
respectively	O
.	O

In	O
addition	O
,	O
we	O
show	O
that	O
under	O
-	O
translation	O
is	O
the	O
most	O
significant	O
error	O
type	O
in	O
NMT	NLP-focus
which	O
contrasts	O
with	O
the	O
more	O
diverse	O
error	O
profile	O
previously	O
observed	O
for	O
statistical	NLP-focus
machine	NLP-focus
translation	NLP-focus
.	O

While	O
our	O
information	O
flow	O
analysis	O
does	O
not	O
reveal	O
any	O
deficiencies	O
that	O
could	O
be	O
used	O
to	O
detect	O
or	O
fix	O
the	O
under	NLP-focus
-	NLP-focus
translation	NLP-focus
of	O
negation	O
,	O
we	O
find	O
that	O
negation	O
is	O
often	O
rephrased	O
during	O
training	O
,	O
which	O
could	O
make	O
it	O
more	O
difficult	O
for	O
the	O
model	O
to	O
learn	O
a	O
reliable	O
link	O
between	O
source	O
and	O
target	O
negation	O
.	O

Traditional	O
text	O
overlap	O
based	O
metrics	O
such	O
as	O
ROUGE	NLP-metrics
fail	O
to	O
achieve	O
this	O
because	O
they	O
are	O
limited	O
to	O
matching	O
tokens	O
,	O
either	O
lexically	O
or	O
via	O
embeddings	O
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
metric	O
to	O
evaluate	O
the	O
content	O
quality	O
of	O
a	O
summary	O
using	O
question	NLP-focus
-	NLP-focus
answering	NLP-focus
(	NLP-focus
QA	NLP-focus
)	NLP-focus
QA	NLP-focus
.	O

We	O
demonstrate	O
the	O
experimental	O
benefits	O
of	O
QA	O
-	O
based	O
metrics	O
through	O
an	O
analysis	O
of	O
our	O
proposed	O
metric	O
,	O
QAEval	NLP-metrics
QAEval	NLP-metrics
.	O

Through	O
a	O
careful	O
analysis	O
of	O
each	O
component	O
of	O
QAEval	NLP-metrics
we	O
identify	O
its	O
performance	O
bottlenecks	O
and	O
estimate	O
that	O
its	O
potential	O
upper	O
-	O
bound	O
performance	O
surpasses	O
all	O
other	O
automatic	O
metrics	O
,	O
approaching	O
that	O
of	O
the	O
gold	O
-	O
standard	O
Pyramid	O
Method	O
1	O
.	O

A	O
question	NLP-focus
answering	NLP-focus
system	O
that	O
in	O
addition	O
to	O
providing	O
an	O
answer	O
provides	O
an	O
explanation	O
of	O
the	O
reasoning	O
that	O
leads	O
to	O
that	O
answer	O
has	O
potential	O
advantages	O
in	O
terms	O
of	O
debuggability	O
,	O
extensibility	O
,	O
and	O
trust	O
.	O

To	O
this	O
end	O
,	O
we	O
propose	O
QED	O
a	O
linguistically	O
informed	O
extensible	O
framework	O
for	O
explanations	O
in	O
question	NLP-focus
answering	NLP-focus
QED	O

We	O
describe	O
and	O
publicly	O
release	O
an	O
expert	O
-	O
annotated	O
dataset	O
of	O
QED	O
explanations	O
built	O
upon	O
a	O
subset	O
of	O
the	O
Google	O
Natural	O
Questions	O
dataset	O
,	O
and	O
report	O
baseline	O
models	O
on	O
two	O
tasks	O
—	O
post	O
-	O
hoc	O
explanation	O
generation	O
given	O
an	O
answer	O
,	O
and	O
joint	O
question	NLP-focus
answering	NLP-focus
explanation	NLP-focus
generation	NLP-focus
ion	O
.	O

We	O
parameterize	O
classical	O
modular	O
task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialog	NLP-focus
systems	NLP-focus
using	O
a	O
Transformer	O
-	O
based	O
auto	O
-	O
regressive	O
language	O
model	O
which	O
subsumes	O
different	O
dialog	O
modules	O
into	O
a	O
single	O
neural	O
model	O
.	O

Pre	O
-	O
trained	O
language	O
models	O
(	O
LMs	O
)	O
encode	O
rich	O
information	O
about	O
linguistic	O
structure	O
but	O
their	O
knowledge	O
about	O
lexical	NLP-focus
polysemy	NLP-focus
remains	O
unclear	O
.	O

Machine	NLP-focus
translation	NLP-focus
(	NLP-focus
MT	NLP-focus
)	NLP-focus
technology	O
has	O
facilitated	O
our	O
daily	O
tasks	O
by	O
providing	O
accessible	O
shortcuts	O
for	O
gathering	O
,	O
processing	O
,	O
and	O
communicating	O
information	O
.	O

As	O
a	O
relatively	O
new	O
field	O
of	O
inquiry	O
,	O
studies	O
of	O
gender	O
bias	O
in	O
MT	NLP-focus
still	O
lack	O
cohesion	O
.	O

To	O
this	O
end	O
,	O
we	O
:	O
i	O
)	O
critically	O
review	O
current	O
conceptualizations	O
of	O
bias	O
in	O
light	O
of	O
theoretical	O
insights	O
from	O
related	O
disciplines	O
,	O
ii	O
)	O
summarize	O
previous	O
analyses	O
aimed	O
at	O
assessing	O
gender	O
bias	O
in	O
MT	NLP-focus
iii	O
)	O
discuss	O
the	O
mitigating	O
strategies	O
proposed	O
so	O
far	O
,	O
and	O
iv	O
)	O
point	O
toward	O
potential	O
directions	O
for	O
future	O
work	O
.	O

We	O
present	O
a	O
new	O
conjunctivist	O
framework	O
,	O
neural	O
event	O
semantics	O
(	O
NES	O
)	O
for	O
compositional	NLP-focus
grounded	NLP-focus
language	NLP-focus
understanding	NLP-focus
.	O

We	O
introduce	O
a	O
theoretical	O
framework	O
for	O
understanding	O
and	O
predicting	O
the	O
complexity	O
of	O
sequence	NLP-focus
classification	NLP-focus
tasks	O
,	O
using	O
a	O
novel	O
extension	O
of	O
the	O
theory	O
of	O
Boolean	O
function	O
sensitivity	O
.	O

We	O
then	O
estimate	O
sensitivity	O
on	O
15	O
NLP	O
tasks	O
,	O
finding	O
that	O
sensitivity	O
is	O
higher	O
on	O
challenging	O
tasks	O
collected	O
in	O
GLUE	O
than	O
on	O
simple	O
text	NLP-focus
classification	NLP-focus
tasks	O
,	O
and	O
that	O
sensitivity	O
predicts	O
the	O
performance	O
both	O
of	O
simple	O
lexical	O
classifiers	O
and	O
of	O
vanilla	O
BiLSTMs	O
without	O
pretrained	O
contextualized	O
embeddings	O
.	O

Named	NLP-focus
Entity	NLP-focus
Recognition	NLP-focus
(	NLP-focus
NER	NLP-focus
)	NLP-focus
is	O
a	O
fundamental	O
NLP	O
task	O
,	O
commonly	O
formulated	O
as	O
classification	AI/ML/DL-focus
over	O
a	O
sequence	O
of	O
tokens	O
.	O

To	O
address	O
NER	NLP-focus
in	O
MRLs	O
we	O
then	O
need	O
to	O
answer	O
two	O
fundamental	O
questions	O
,	O
namely	O
,	O
what	O
are	O
the	O
basic	O
units	O
to	O
be	O
labeled	O
,	O
and	O
how	O
can	O
these	O
units	O
be	O
detected	O
and	O
classified	O
in	O
realistic	O
settings	O
(	O
i	O
.	O
e	O
.,	O
where	O
no	O
gold	O
morphology	O
is	O
available	O
).	O

We	O
empirically	O
investigate	O
these	O
questions	O
on	O
a	O
novel	O
NER	NLP-focus
benchmark	O
,	O
with	O
parallel	O
token	O
-	O
level	O
and	O
morpheme	O
-	O
level	O
NER	O
annotations	O
,	O
which	O
we	O
develop	O
for	O
Modern	O
Hebrew	O
,	O
a	O
morphologically	O
rich	O
-	O
and	O
-	O
ambiguous	O
language	O
.	O

Our	O
results	O
show	O
that	O
explicitly	O
modeling	O
morphological	O
boundaries	O
leads	O
to	O
improved	O
NER	NLP-focus
performance	O
,	O
and	O
that	O
a	O
novel	O
hybrid	O
architecture	O
,	O
in	O
which	O
NER	O
precedes	O
and	O
prunes	O
morphological	O
decomposition	O
,	O
greatly	O
outperforms	O
the	O
standard	O
pipeline	O
,	O
where	O
morphological	O
decomposition	O
strictly	O
precedes	O
NER	O
,	O
setting	O
a	O
new	O
performance	O
bar	O
for	O
both	O
Hebrew	O
NER	O
and	O
Hebrew	O
morphological	O
decomposition	O
tasks	O
.	O

Systems	O
for	O
Open	NLP-focus
-	NLP-focus
Domain	NLP-focus
Question	NLP-focus
Answering	NLP-focus
(	NLP-focus
OpenQA	NLP-focus
)	NLP-focus
generally	O
depend	O
on	O
a	O
retriever	O
for	O
finding	O
candidate	O
passages	O
in	O
a	O
large	O
corpus	O
and	O
a	O
reader	O
for	O
extracting	O
answers	O
from	O
those	O
passages	O
.	O

To	O
address	O
this	O
,	O
we	O
define	O
ColBERT	O
-	O
QA	O
which	O
adapts	O
the	O
scalable	O
neural	O
retrieval	O
model	O
ColBERT	O
to	O
OpenQA	NLP-focus
ColBERT	O
.	O

This	O
greatly	O
improves	O
OpenQA	NLP-focus
retrieval	O
on	O
Natural	O
Questions	O
SQuAD	O
and	O
TriviaQA	O
and	O
the	O
resulting	O
system	O
attains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
OpenQA	NLP-focus
ive	O
OpenQA	O
performance	O
on	O
all	O
three	O
datasets	O
.	O

This	O
paper	O
presents	O
a	O
novel	O
unsupervised	NLP-focus
abstractive	NLP-focus
summarization	NLP-focus
method	O
for	O
opinionated	O
texts	O
.	O

We	O
examine	O
three	O
strong	O
generative	O
models	O
T5	O
BART	O
and	O
GPT	O
-	O
2	O
and	O
study	O
whether	O
their	O
probabilities	O
on	O
QA	NLP-focus
tasks	O
are	O
well	O
calibrated	O
,	O
finding	O
the	O
answer	O
is	O
a	O
relatively	O
emphatic	O
no	O
.	O

Common	NLP-focus
grounding	NLP-focus
is	O
the	O
process	O
of	O
creating	O
and	O
maintaining	O
mutual	O
understandings	O
,	O
which	O
is	O
a	O
critical	O
aspect	O
of	O
sophisticated	O
human	O
communication	O
.	O

Recent	O
advancements	O
in	O
open	NLP-focus
-	NLP-focus
domain	NLP-focus
question	NLP-focus
answering	NLP-focus
(	NLP-focus
ODQA	NLP-focus
)	NLP-focus
that	O
is	O
,	O
finding	O
answers	O
from	O
large	O
open	O
-	O
domain	O
corpus	O
like	O
Wikipedia	O
,	O
have	O
led	O
to	O
human	O
-	O
level	O
performance	O
on	O
many	O
datasets	O
.	O

However	O
,	O
progress	O
in	O
QA	NLP-focus
over	O
book	O
stories	O
(	O
Book	NLP-focus
QA	NLP-focus
lags	O
despite	O
its	O
similar	O
task	O
formulation	O
to	O
ODQA	NLP-focus
.	O

This	O
work	O
provides	O
a	O
comprehensive	O
and	O
quantitative	O
analysis	O
about	O
the	O
difficulty	O
of	O
Book	NLP-focus
QA	NLP-focus
(	O
1	O
)	O
We	O
benchmark	O
the	O
research	O
on	O
the	O
NarrativeQA	O
dataset	O
with	O
extensive	O
experiments	O
with	O
cutting	O
-	O
edge	O
ODQA	NLP-focus
techniques	O
.	O

This	O
quantifies	O
the	O
challenges	O
Book	NLP-focus
QA	NLP-focus
poses	O
,	O
as	O
well	O
as	O
advances	O
the	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
with	O
a	O
∼	O
7	O
\\%	O
absolute	O
improvement	O
on	O
ROUGE	O
-	O
L	O
.	O

(	O
2	O
)	O
We	O
further	O
analyze	O
the	O
detailed	O
challenges	O
in	O
Book	NLP-focus
QA	NLP-focus
through	O
human	O
studies	O
.	O
1	O
Our	O
findings	O
indicate	O
that	O
the	O
event	O
-	O
centric	O
questions	O
dominate	O
this	O
task	O
,	O
which	O
exemplifies	O
the	O
inability	O
of	O
existing	O
QA	O
models	O
to	O
handle	O
event	O
-	O
oriented	O
scenarios	O
.	O

We	O
find	O
that	O
assertions	O
enable	O
semantic	O
emulation	O
of	O
languages	O
that	O
satisfy	O
a	O
strong	O
notion	O
of	O
semantic	NLP-focus
transparency	NLP-focus
.	O

Open	NLP-focus
-	NLP-focus
domain	NLP-focus
Question	NLP-focus
Answering	NLP-focus
models	O
that	O
directly	O
leverage	O
question	O
-	O
answer	O
(	O
QA	O
)	O
pairs	O
such	O
as	O
closed	O
-	O
book	O
QA	O
(	O
CBQA	O
)	O
models	O
and	O
QA	O
-	O
pair	O
retrievers	O
show	O
promise	O
in	O
terms	O
of	O
speed	O
and	O
memory	O
compared	O
with	O
conventional	O
models	O
which	O
retrieve	O
and	O
read	O
from	O
text	O
corpora	O
.	O

RePAQ	O
can	O
be	O
configured	O
for	O
size	O
(	O
under	O
500MB	O
)	O
or	O
speed	O
(	O
over	O
1K	O
questions	O
per	O
second	O
)	O
while	O
retaining	O
high	O
accuracy	Classification-metrics
.	O

We	O
take	O
a	O
step	O
towards	O
addressing	O
the	O
under	O
-	O
representation	O
of	O
the	O
African	O
continent	O
in	O
NLP	O
research	O
by	O
bringing	O
together	O
different	O
stakeholders	O
to	O
create	O
the	O
first	O
large	O
,	O
publicly	O
available	O
,	O
high	O
-	O
quality	O
dataset	O
for	O
named	NLP-focus
entity	NLP-focus
recognition	NLP-focus
(	NLP-focus
NER	NLP-focus
)	NLP-focus
in	O
ten	O
African	O
languages	O
.	O

We	O
detail	O
the	O
characteristics	O
of	O
these	O
languages	O
to	O
help	O
researchers	O
and	O
practitioners	O
better	O
understand	O
the	O
challenges	O
they	O
pose	O
for	O
NER	NLP-focus
tasks	O
.	O

The	O
quality	O
of	O
a	O
summarization	NLP-focus
evaluation	NLP-focus
metric	NLP-focus
is	O
quantified	O
by	O
calculating	O
the	O
correlation	O
between	O
its	O
scores	O
and	O
human	O
annotations	O
across	O
a	O
large	O
number	O
of	O
summaries	O
.	O

Further	O
,	O
although	O
many	O
metrics	O
fail	O
to	O
show	O
statistical	O
improvements	O
over	O
ROUGE	NLP-metrics
two	O
recent	O
works	O
,	O
QAEval	NLP-metrics
and	O
BERTScore	NLP-metrics
do	O
so	O
in	O
some	O
evaluation	O
settings	O
.	O
1	O
.	O

We	O
introduce	O
ParsiNLU	O
the	O
first	O
benchmark	O
in	O
Persian	O
language	O
that	O
includes	O
a	O
range	O
of	O
language	O
understanding	O
tasks	O
—	O
reading	NLP-focus
comprehension	NLP-focus
textual	NLP-focus
entailment	NLP-focus
and	O
so	O
on	O
.	O

We	O
hope	O
ParsiNLU	O
fosters	O
further	O
research	O
and	O
advances	O
in	O
Persian	NLP-focus
language	NLP-focus
understanding	NLP-focus
1	O
.	O

The	O
ability	O
to	O
structure	O
a	O
conversational	O
transcript	O
as	O
a	O
sequence	O
of	O
dialog	O
acts	O
dialog	NLP-focus
act	NLP-focus
recognition	NLP-focus
including	O
the	O
segmentation	NLP-focus
is	O
critical	O
for	O
understanding	O
dialog	O
.	O

We	O
apply	O
two	O
pre	O
-	O
trained	O
transformer	O
models	O
XLNet	O
and	O
Longformer	O
to	O
this	O
task	O
in	O
English	O
and	O
achieve	O
strong	O
results	O
on	O
Switchboard	O
Dialog	O
Act	O
and	O
Meeting	O
Recorder	O
Dialog	O
Act	O
corpora	O
with	O
dialog	NLP-metrics
act	NLP-metrics
segmentation	NLP-metrics
error	NLP-metrics
rates	NLP-metrics
(	NLP-metrics
DSER	NLP-metrics
)	NLP-metrics
of	O
8	O
.	O
4	O
\\%	O
and	O
14	O
.	O
2	O
\\%	O
.	O

To	O
understand	O
the	O
key	O
factors	O
affecting	O
dialog	NLP-focus
act	NLP-focus
recognition	NLP-focus
we	O
perform	O
a	O
comparative	O
analysis	O
of	O
models	O
trained	O
under	O
different	O
conditions	O
.	O

Exploration	O
of	O
how	O
meaningful	O
representations	O
of	O
identity	O
-	O
based	O
patterns	O
emerge	O
in	O
CNNs	O
and	O
how	O
the	O
latent	O
space	O
variables	O
outside	O
of	O
the	O
training	O
range	O
correlate	O
with	O
identity	O
-	O
based	O
patterns	O
in	O
the	O
output	O
has	O
general	O
implications	O
for	O
neural	AI/ML/DL-focus
network	AI/ML/DL-focus
interpretability	AI/ML/DL-focus
.	O

We	O
present	O
a	O
memory	O
-	O
based	O
model	O
for	O
context	NLP-focus
-	NLP-focus
dependent	NLP-focus
semantic	NLP-focus
parsing	NLP-focus
.	O

We	O
evaluate	O
our	O
approach	O
on	O
three	O
semantic	NLP-focus
parsing	NLP-focus
benchmarks	O
.	O

We	O
study	O
controllable	NLP-focus
text	NLP-focus
summarization	NLP-focus
which	O
allows	O
users	O
to	O
gain	O
control	O
on	O
a	O
particular	O
attribute	O
(	O
e	O
.	O
g	O
.,	O
length	O
limit	O
)	O
of	O
the	O
generated	O
summaries	O
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
novel	O
training	O
framework	O
based	O
on	O
Constrained	O
Markov	O
Decision	O
Process	O
(	O
CMDP	O
)	O
which	O
conveniently	O
includes	O
a	O
reward	O
function	O
along	O
with	O
a	O
set	O
of	O
constraints	O
,	O
to	O
facilitate	O
better	O
summarization	NLP-focus
control	O
.	O

Our	O
framework	O
can	O
be	O
applied	O
to	O
control	O
important	O
attributes	O
of	O
summarization	NLP-focus
including	O
length	O
,	O
covered	O
entities	O
and	O
abstractiveness	O
,	O
as	O
we	O
devise	O
specific	O
constraints	O
for	O
each	O
of	O
these	O
aspects	O
.	O

Using	O
a	O
variety	O
of	O
synthetic	O
languages	O
and	O
a	O
newly	O
introduced	O
translation	O
challenge	O
set	O
,	O
we	O
find	O
that	O
word	O
order	O
flexibility	O
in	O
the	O
source	O
language	O
only	O
leads	O
to	O
a	O
very	O
small	O
loss	O
of	O
NMT	NLP-focus
quality	O
,	O
even	O
though	O
the	O
core	O
verb	O
arguments	O
become	O
impossible	O
to	O
disambiguate	O
in	O
sentences	O
without	O
semantic	O
cues	O
.	O

However	O
,	O
in	O
medium	O
-	O
and	O
low	O
-	O
resource	O
settings	O
,	O
the	O
overall	O
NMT	NLP-focus
quality	O
of	O
fixed	O
-	O
order	O
languages	O
remains	O
unmatched	O
.	O

Optical	Computer/vision-focus
character	Computer/vision-focus
recognition	Computer/vision-focus
(	Computer/vision-focus
OCR	Computer/vision-focus
)	Computer/vision-focus
OCR	Computer/vision-focus
be	O
used	O
to	O
produce	O
digitized	O
text	O
,	O
and	O
previous	O
work	O
has	O
demonstrated	O
the	O
utility	O
of	O
neural	O
post	O
-	O
correction	O
methods	O
that	O
improve	O
the	O
results	O
of	O
general	O
-	O
purpose	O
OCR	O
systems	O
on	O
recognition	O
of	O
less	O
-	O
well	O
-	O
resourced	O
languages	O
.	O

We	O
study	O
continual	O
learning	O
for	O
natural	NLP-focus
language	NLP-focus
instruction	NLP-focus
generation	NLP-focus
by	O
observing	O
human	O
users	O
’	O
instruction	O
execution	O
.	O

(	O
2021	O
)	O
by	O
+	O
12	O
.	O
7	O
and	O
+	O
2	O
.	O
3	O
F1	Classification-metrics
score	O
in	O
a	O
challenging	O
setting	O
with	O
only	O
1	O
,	O
000	O
biased	O
annotations	O
,	O
averaged	O
across	O
7	O
datasets	O
.	O

We	O
introduce	O
Generative	NLP-focus
Spoken	NLP-focus
Language	NLP-focus
Modeling	NLP-focus
the	O
task	O
of	O
learning	O
the	O
acoustic	O
and	O
linguistic	O
characteristics	O
acoustic	O
uage	O
from	O
raw	O
audio	O
(	O
no	O
text	O
,	O
no	O
labels	O
),	O
and	O
a	O
set	O
of	O
metrics	O
to	O
automatically	O
evaluate	O
the	O
learned	O
representations	O
at	O
acoustic	O
and	O
linguistic	O
levels	O
for	O
both	O
encoding	O
and	O
generation	O
.	O

To	O
understand	O
the	O
connection	O
between	O
model	O
compression	O
and	O
out	O
-	O
of	O
-	O
distribution	O
generalization	O
,	O
we	O
define	O
the	O
task	O
of	O
compressing	O
language	O
representation	O
models	O
such	O
that	O
they	O
perform	O
best	O
in	O
a	O
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
setting	O
.	O

AMoC	O
outperforms	O
strong	O
baselines	O
on	O
dozens	O
of	O
domain	O
pairs	O
across	O
three	O
text	NLP-focus
classification	NLP-focus
and	O
sequence	NLP-focus
tagging	NLP-focus
tasks	O
.	O
1	O
.	O

Progress	O
in	O
cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
modeling	NLP-focus
depends	O
on	O
challenging	O
,	O
realistic	O
,	O
and	O
diverse	O
evaluation	O
sets	O
.	O

We	O
introduce	O
Multilingual	O
Knowledge	O
Questions	O
and	O
Answers	O
(	O
MKQA	O
)	O
an	O
open	NLP-focus
-	NLP-focus
domain	NLP-focus
question	NLP-focus
answering	NLP-focus
evaluation	O
set	O
comprising	O
10k	O
question	O
-	O
answer	O
pairs	O
aligned	O
across	O
26	O
typologically	O
diverse	O
languages	O
(	O
260k	O
question	O
-	O
answer	O
pairs	O
in	O
total	O
).	O

We	O
benchmark	O
a	O
variety	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
and	O
baselines	O
for	O
generative	O
and	O
extractive	NLP-focus
question	NLP-focus
answering	NLP-focus
trained	O
on	O
Natural	O
Questions	O
,	O
in	O
zero	O
shot	O
and	O
translation	O
settings	O
.	O

We	O
refer	O
to	O
this	O
capability	O
as	O
self	AI/ML/DL-focus
-	AI/ML/DL-focus
diagnosis	AI/ML/DL-focus
.	O

Several	O
metrics	O
have	O
been	O
proposed	O
for	O
assessing	O
the	O
similarity	O
of	O
(	NLP-focus
abstract	NLP-focus
)	NLP-focus
meaning	NLP-focus
representations	NLP-focus
(	NLP-focus
AMRs	NLP-focus
)	NLP-focus
but	O
little	O
is	O
known	O
about	O
how	O
they	O
relate	O
to	O
human	O
similarity	O
ratings	O
.	O

e	O
conduct	O
experiments	O
on	O
natural	NLP-focus
language	NLP-focus
inference	NLP-focus
and	O
machine	NLP-focus
translation	NLP-focus
we	O
show	O
that	O
differentiable	O
subset	O
pruning	O
performs	O
comparably	O
or	O
better	O
than	O
previous	O
works	O
while	O
offering	O
precise	O
control	O
of	O
the	O
sparsity	O
level	O
.	O

Human	O
evaluation	O
of	O
modern	O
high	O
-	O
quality	O
machine	NLP-focus
translation	NLP-focus
systems	O
is	O
a	O
difficult	O
problem	O
,	O
and	O
there	O
is	O
increasing	O
evidence	O
that	O
inadequate	O
evaluation	O
procedures	O
can	O
lead	O
to	O
erroneous	O
conclusions	O
.	O

By	O
prompting	O
the	O
decoder	O
with	O
a	O
modified	O
content	O
plan	O
that	O
drops	O
hallucinated	O
entities	O
,	O
we	O
outperform	O
state	AI/ML/DL-focus
-	AI/ML/DL-focus
of	AI/ML/DL-focus
-	AI/ML/DL-focus
the	AI/ML/DL-focus
-	AI/ML/DL-focus
art	AI/ML/DL-focus
approaches	O
for	O
faithfulness	O
when	O
evaluated	O
automatically	O
and	O
by	O
humans	O
.	O

We	O
develop	O
neural	O
models	O
that	O
possess	O
an	O
interpretable	O
inference	O
process	O
for	O
dependency	NLP-focus
parsing	NLP-focus
.	O

We	O
call	O
this	O
problem	O
explanation	NLP-focus
-	NLP-focus
based	NLP-focus
human	NLP-focus
debugging	NLP-focus
(	NLP-focus
EBHD	NLP-focus
)	NLP-focus
.	O

In	O
particular	O
,	O
we	O
categorize	O
and	O
discuss	O
existing	O
work	O
along	O
three	O
dimensions	O
of	O
EBHD	NLP-focus
EBHD	NLP-focus
bug	O
context	O
,	O
the	O
workflow	O
,	O
and	O
the	O
experimental	O
setting	O
),	O
compile	O
findings	O
on	O
how	O
EBHD	O
components	O
affect	O
the	O
feedback	O
providers	O
,	O
and	O
highlight	O
open	O
problems	O
that	O
could	O
be	O
future	O
research	O
directions	O
.	O

We	O
present	O
methods	O
for	O
calculating	O
a	O
measure	O
of	O
phonotactic	NLP-focus
complexity	NLP-focus
bits	O
per	O
phoneme	O
that	O
permits	O
a	O
straightforward	O
cross	O
-	O
linguistic	O
comparison	O
.	O

Abstract	NLP-focus
meaning	NLP-focus
representation	NLP-focus
(	NLP-focus
AMR	NLP-focus
)-	NLP-focus
to	NLP-focus
-	NLP-focus
text	NLP-focus
generation	NLP-focus
is	O
the	O
challenging	O
task	O
of	O
generating	O
natural	O
language	O
texts	O
from	O
AMR	O
graphs	O
where	O
nodes	O
represent	O
concepts	O
and	O
edges	O
denote	O
relations	O
.	O

Our	O
model	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
approach	O
by	O
1	O
.	O
5	O
BLEU	NLP-metrics
points	O
on	O
LDC2015E86	O
and	O
4	O
.	O
8	O
BLEU	NLP-metrics
points	O
on	O
LDC2017T10	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
.	O

Pre	O
-	O
training	O
by	O
language	NLP-focus
modeling	NLP-focus
has	O
become	O
a	O
popular	O
and	O
successful	O
approach	O
to	O
NLP	O
tasks	O
,	O
but	O
we	O
have	O
yet	O
to	O
understand	O
exactly	O
what	O
linguistic	O
capacities	O
these	O
pre	O
-	O
training	O
processes	O
confer	O
upon	O
models	O
.	O

Data	AI/ML/DL-focus
privacy	AI/ML/DL-focus
is	O
an	O
important	O
issue	O
for	O
“	O
machine	O
learning	O
as	O
a	O
service	O
”	O
providers	O
.	O

We	O
focus	O
on	O
the	O
problem	O
of	O
membership	AI/ML/DL-focus
inference	AI/ML/DL-focus
attacks	AI/ML/DL-focus
Given	O
a	O
data	O
sample	O
and	O
black	O
-	O
box	O
access	O
to	O
a	O
model	O
’	O
s	O
API	O
determine	O
whether	O
the	O
sample	O
existed	O
in	O
the	O
model	O
’	O
s	O
training	O
data	O
.	O

Our	O
contribution	O
is	O
an	O
investigation	O
of	O
this	O
problem	O
in	O
the	O
context	O
of	O
sequence	O
-	O
to	O
-	O
sequence	O
models	O
which	O
are	O
important	O
in	O
applications	O
such	O
as	O
machine	NLP-focus
translation	NLP-focus
and	O
video	O
captioning	O
.	O

We	O
define	O
the	O
membership	AI/ML/DL-focus
inference	AI/ML/DL-focus
problem	O
for	O
sequence	AI/ML/DL-focus
generation	AI/ML/DL-focus
provide	O
an	O
open	O
dataset	O
based	O
on	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
machine	O
translation	O
models	O
and	O
report	O
initial	O
results	O
on	O
whether	O
these	O
models	O
leak	O
private	O
information	O
against	O
several	O
kinds	O
of	O
membership	AI/ML/DL-focus
inference	AI/ML/DL-focus
attacks	AI/ML/DL-focus
.	O

SpanBERT	O
BERT	O
stently	O
outperforms	O
BERT	O
and	O
our	O
better	O
-	O
tuned	O
baselines	O
,	O
with	O
substantial	O
gains	O
on	O
span	NLP-focus
selection	NLP-focus
tasks	O
such	O
as	O
question	NLP-focus
answering	NLP-focus
and	O
coreference	NLP-focus
resolution	NLP-focus
.	O

In	O
particular	O
,	O
with	O
the	O
same	O
training	O
data	O
and	O
model	O
size	O
as	O
BERTlarge	O
our	O
single	O
model	O
obtains	O
94	O
.	O
6	O
\\%	O
and	O
88	O
.	O
7	O
\\%	O
F1	Classification-metrics
on	O
SQuAD	O
1	O
.	O
1	O
and	O
2	O
.	O
0	O
respectively	O
.	O

We	O
also	O
achieve	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
the	O
OntoNotes	O
coreference	NLP-focus
resolution	NLP-focus
task	O
(	O
79	O
.	O
6	O
\\%	O
F1	Classification-metrics
,	O
strong	O
performance	O
on	O
the	O
TACRED	O
relation	NLP-focus
extraction	NLP-focus
benchmark	O
,	O
and	O
even	O
gains	O
on	O
GLUE	O
.	O

We	O
also	O
achieve	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
the	O
OntoNotes	O
coreference	NLP-focus
resolution	NLP-focus
task	O
(	O
79	O
.	O
6	O
\\%	O
F1	Classification-metrics
,	O
strong	O
performance	O
on	O
the	O
TACRED	O
relation	NLP-focus
extraction	NLP-focus
benchmark	O
,	O
and	O
even	O
gains	O
on	O
GLUE	O
.	O

Chinese	NLP-focus
word	NLP-focus
segmentation	NLP-focus
and	O
dependency	NLP-focus
parsing	NLP-focus
are	O
two	O
fundamental	O
tasks	O
for	O
Chinese	O
natural	O
language	O
processing	O
.	O

The	O
dependency	NLP-focus
parsing	NLP-focus
is	O
defined	O
at	O
the	O
word	O
-	O
level	O
.	O

Therefore	O
word	O
segmentation	O
is	O
the	O
precondition	O
of	O
dependency	NLP-focus
parsing	NLP-focus
dependency	NLP-focus
parsing	NLP-focus
ency	O
parsing	O
suffer	O
from	O
error	O
propagation	O
and	O
unable	O
to	O
directly	O
make	O
use	O
of	O
character	O
-	O
level	O
pre	O
-	O
trained	O
language	O
models	O
(	O
such	O
as	O
BERT	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
graph	O
-	O
based	O
model	O
to	O
integrate	O
Chinese	NLP-focus
word	NLP-focus
segmentation	NLP-focus
and	O
dependency	NLP-focus
parsing	NLP-focus
.	O

Our	O
graph	O
-	O
based	O
joint	O
model	O
achieves	O
better	O
performance	O
than	O
previous	O
joint	O
models	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
both	O
Chinese	NLP-focus
word	NLP-focus
segmentation	NLP-focus
and	O
dependency	NLP-focus
parsing	NLP-focus
.	O

Additionally	O
,	O
when	O
BERT	O
is	O
combined	O
,	O
our	O
model	O
can	O
substantially	O
reduce	O
the	O
performance	O
gap	O
of	O
dependency	NLP-focus
parsing	NLP-focus
between	O
joint	O
models	O
and	O
gold	O
-	O
segmented	O
word	O
-	O
based	O
models	O
code	O
.	O

Story	NLP-focus
generation	NLP-focus
namely	O
,	O
generating	O
a	O
reasonable	O
story	O
from	O
a	O
leading	O
context	O
is	O
an	O
important	O
but	O
challenging	O
task	O
.	O

In	O
this	O
paper	O
,	O
we	O
devise	O
a	O
knowledge	O
-	O
enhanced	O
pretraining	O
model	O
for	O
commonsense	NLP-focus
story	NLP-focus
generation	NLP-focus
.	O

Cross	NLP-focus
-	NLP-focus
lingual	NLP-focus
entity	NLP-focus
linking	NLP-focus
(	NLP-focus
XEL	NLP-focus
)	NLP-focus
is	O
the	O
task	O
of	O
finding	O
referents	O
in	O
a	O
target	O
-	O
language	O
knowledge	O
base	O
(	O
KB	O
)	O
for	O
mentions	O
extracted	O
from	O
source	O
-	O
language	O
texts	O
.	O

The	O
first	O
step	O
of	O
(	NLP-focus
X	NLP-focus
)	NLP-focus
EL	NLP-focus
is	O
candidate	O
generation	O
,	O
which	O
retrieves	O
a	O
list	O
of	O
plausible	O
candidate	O
entities	O
from	O
the	O
target	O
-	O
language	O
KB	O
for	O
each	O
mention	O
.	O

In	O
this	O
paper	O
,	O
we	O
first	O
assess	O
the	O
problems	O
faced	O
by	O
current	O
entity	NLP-focus
candidate	NLP-focus
generation	NLP-focus
methods	O
for	O
low	NLP-focus
-	NLP-focus
resource	NLP-focus
XEL	NLP-focus
then	O
propose	O
three	O
improvements	O
that	O
(	O
1	O
)	O
reduce	O
the	O
disconnect	O
between	O
entity	O
mentions	O
and	O
KB	O
entries	O
and	O
(	O
2	O
)	O
improve	O
the	O
robustness	O
of	O
the	O
model	O
to	O
low	O
-	O
resource	O
scenarios	O
.	O

The	O
methods	O
are	O
simple	O
,	O
but	O
effective	O
:	O
We	O
experiment	O
with	O
our	O
approach	O
on	O
seven	O
XEL	NLP-focus
datasets	O
and	O
find	O
that	O
they	O
yield	O
an	O
average	O
gain	O
of	O
16	O
.	O
9	O
\\%	O
in	O
Top	O
-	O
30	O
gold	O
candidate	O
recall	Classification-metrics
compared	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
.	O

The	O
methods	O
are	O
simple	O
,	O
but	O
effective	O
:	O
We	O
experiment	O
with	O
our	O
approach	O
on	O
seven	O
XEL	NLP-focus
datasets	O
and	O
find	O
that	O
they	O
yield	O
an	O
average	O
gain	O
of	O
16	O
.	O
9	O
\\%	O
in	O
Top	O
-	O
30	O
gold	O
candidate	O
recall	Classification-metrics
compared	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
.	O

Our	O
improved	O
model	O
also	O
yields	O
an	O
average	O
gain	O
of	O
7	O
.	O
9	O
\\%	O
in	O
in	Classification-metrics
-	Classification-metrics
KB	Classification-metrics
accuracy	Classification-metrics
of	O
end	NLP-focus
-	NLP-focus
to	NLP-focus
-	NLP-focus
end	NLP-focus
XEL	NLP-focus
1	O
.	O

Our	O
improved	O
model	O
also	O
yields	O
an	O
average	O
gain	O
of	O
7	O
.	O
9	O
\\%	O
in	O
in	Classification-metrics
-	Classification-metrics
KB	Classification-metrics
accuracy	Classification-metrics
of	O
end	NLP-focus
-	NLP-focus
to	NLP-focus
-	NLP-focus
end	NLP-focus
XEL	NLP-focus
1	O
.	O

We	O
investigate	O
which	O
architectural	O
factors	O
affect	O
the	O
generalization	O
behavior	O
of	O
neural	O
sequence	O
-	O
to	O
-	O
sequence	O
models	O
trained	O
on	O
two	O
syntactic	O
tasks	O
,	O
English	NLP-focus
question	NLP-focus
formation	NLP-focus
and	O
English	NLP-focus
tense	NLP-focus
reinflection	NLP-focus
.	O

However	O
,	O
the	O
only	O
factor	O
that	O
consistently	O
contributed	O
a	O
hierarchical	O
bias	O
across	O
tasks	O
was	O
the	O
use	O
of	O
a	O
tree	O
-	O
structured	O
model	O
rather	O
than	O
a	O
model	O
with	O
sequential	O
recurrence	O
suggesting	O
that	O
human	O
-	O
like	O
syntactic	NLP-focus
generalization	NLP-focus
requires	O
architectural	O
syntactic	O
structure	O
.	O

Machine	NLP-focus
reading	NLP-focus
comprehension	NLP-focus
tasks	O
require	O
a	O
machine	O
reader	O
to	O
answer	O
questions	O
relevant	O
to	O
the	O
given	O
document	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
the	O
first	O
free	O
-	O
form	O
multiple	NLP-focus
-	NLP-focus
Choice	NLP-focus
Chinese	NLP-focus
machine	NLP-focus
reading	NLP-focus
Comprehension	NLP-focus
dataset	O
(	O
C3	O
,	O
containing	O
13	O
,	O
369	O
documents	O
(	O
dialogues	O
or	O
more	O
formally	O
written	O
mixed	O
-	O
genre	O
texts	O
)	O
and	O
their	O
associated	O
19	O
,	O
577	O
multiple	O
-	O
choice	O
free	O
-	O
form	O
questions	O
collected	O
from	O
Chinese	O
-	O
as	O
-	O
a	O
-	O
second	O
-	O
language	O
examinations	O
.	O

Target	NLP-focus
-	NLP-focus
dependent	NLP-focus
sentiment	NLP-focus
analysis	NLP-focus
(	NLP-focus
TDSA	NLP-focus
)	NLP-focus
aims	O
to	O
classify	O
the	O
sentiment	O
of	O
a	O
text	O
towards	O
a	O
given	O
target	O
.	O

This	O
paper	O
proposes	O
a	O
novel	O
Target	O
-	O
Guided	O
Structured	O
Attention	O
Network	O
(	O
TG	O
-	O
SAN	O
)	O
which	O
captures	O
target	O
-	O
related	O
contexts	O
for	O
TDSA	NLP-focus
in	O
a	O
fine	O
-	O
to	O
-	O
coarse	O
manner	O
.	O

It	O
then	O
fuses	O
the	O
extracted	O
segments	O
based	O
on	O
their	O
relatedness	O
with	O
the	O
target	O
for	O
sentiment	NLP-focus
classification	NLP-focus
.	O

First	O
,	O
TG	O
-	O
SAN	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
up	O
to	O
1	O
.	O
61	O
\\%	O
and	O
3	O
.	O
58	O
\\%	O
in	O
terms	O
of	O
accuracy	O
and	O
Marco	Classification-metrics
-	Classification-metrics
F1	Classification-metrics
respectively	O
.	O

We	O
demonstrate	O
the	O
utility	O
of	O
QDMR	O
by	O
showing	O
that	O
(	O
a	O
)	O
it	O
can	O
be	O
used	O
to	O
improve	O
open	NLP-focus
-	NLP-focus
domain	NLP-focus
question	NLP-focus
answering	NLP-focus
on	O
the	O
HotpotQA	O
dataset	O
,	O
(	O
b	O
)	O
it	O
can	O
be	O
deterministically	O
converted	O
to	O
a	O
pseudo	O
-	O
SQL	O
formal	O
language	O
which	O
can	O
alleviate	O
annotation	O
in	O
semantic	NLP-focus
parsing	NLP-focus
applications	O
.	O

With	O
this	O
data	O
we	O
built	O
classifiers	O
to	O
automatically	O
distinguish	O
trusted	O
from	O
mistrusted	O
speech	O
,	O
achieving	O
an	O
F1	Classification-metrics
of	O
66	O
.	O
1	O
\\%	O
.	O

Our	O
work	O
sheds	O
light	O
on	O
the	O
nature	O
of	O
trusted	O
language	O
and	O
provides	O
insight	O
into	O
the	O
challenging	O
problem	O
of	O
human	NLP-focus
deception	NLP-focus
detection	NLP-focus
.	O

Our	O
results	O
suggest	O
that	O
compositional	O
models	O
and	O
word	O
embedding	O
are	O
able	O
to	O
capture	O
differences	O
in	O
the	O
processing	O
of	O
literal	O
and	O
metaphoric	O
sentences	O
,	O
providing	O
support	O
for	O
the	O
idea	O
that	O
the	O
literal	O
meaning	O
is	O
not	O
fully	O
accessible	O
during	O
familiar	O
metaphor	NLP-focus
comprehension	NLP-focus
.	O

We	O
describe	O
a	O
method	O
for	O
rapidly	O
creating	O
language	NLP-focus
proficiency	NLP-focus
assessments	NLP-focus
and	O
provide	O
experimental	O
evidence	O
that	O
such	O
tests	O
can	O
be	O
valid	O
,	O
reliable	O
,	O
and	O
secure	O
.	O

In	O
this	O
paper	O
,	O
we	O
demonstrate	O
the	O
efficacy	O
of	O
pre	O
-	O
trained	O
checkpoints	O
for	O
Sequence	AI/ML/DL-focus
Generation	AI/ML/DL-focus
.	O

Our	O
models	O
result	O
in	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
Machine	NLP-focus
Translation	NLP-focus
Text	NLP-focus
Summarization	NLP-focus
Sentence	NLP-focus
Splitting	NLP-focus
and	O
Sentence	NLP-focus
Fusion	NLP-focus
.	O

To	O
advance	O
multi	NLP-focus
-	NLP-focus
domain	NLP-focus
(	NLP-focus
cross	NLP-focus
-	NLP-focus
domain	NLP-focus
)	NLP-focus
dialogue	NLP-focus
modeling	NLP-focus
as	O
well	O
as	O
alleviate	O
the	O
shortage	O
of	O
Chinese	O
task	O
-	O
oriented	O
datasets	O
we	O
propose	O
CrossWOZ	O
the	O
first	O
large	O
-	O
scale	O
Chinese	O
Cross	O
-	O
Domain	O
Wizard	O
-	O
of	O
-	O
Oz	O
task	O
-	O
oriented	O
dataset	O
.	O

The	O
large	O
size	O
and	O
rich	O
annotation	O
of	O
CrossWOZ	O
make	O
it	O
suitable	O
to	O
investigate	O
a	O
variety	O
of	O
tasks	O
in	O
cross	NLP-focus
-	NLP-focus
domain	NLP-focus
dialogue	NLP-focus
modeling	NLP-focus
such	O
as	O
dialogue	O
state	O
tracking	O
,	O
policy	O
learning	O
,	O
user	O
simulation	O
,	O
etc	O
.	O

We	O
study	O
the	O
influence	O
of	O
context	O
on	O
sentence	NLP-focus
acceptability	NLP-focus
.	O

In	O
a	O
suite	O
of	O
intrinsic	O
benchmarks	O
,	O
we	O
show	O
that	O
our	O
model	O
outperforms	O
previous	O
approaches	O
on	O
relatedness	O
tasks	O
and	O
on	O
hypernymy	NLP-focus
classification	NLP-focus
and	NLP-focus
detection	NLP-focus
while	O
being	O
competitive	O
on	O
word	NLP-focus
similarity	NLP-focus
tasks	O
.	O

Going	O
beyond	O
such	O
simple	O
constraints	O
,	O
recent	O
work	O
has	O
started	O
exploring	O
the	O
incorporation	O
of	O
complex	O
syntactic	O
-	O
guidance	O
as	O
constraints	O
in	O
the	O
task	O
of	O
controlled	NLP-focus
paraphrase	NLP-focus
generation	NLP-focus
.	O

We	O
address	O
this	O
limitation	O
in	O
the	O
paper	O
and	O
propose	O
Syntax	O
Guided	O
Controlled	O
Paraphraser	O
(	O
SGCP	O
,	O
an	O
end	O
-	O
to	O
-	O
end	O
framework	O
for	O
syntactic	NLP-focus
paraphrase	NLP-focus
generation	NLP-focus
.	O

We	O
generate	O
the	O
data	O
according	O
to	O
linguist	O
-	O
crafted	O
grammar	O
templates	O
,	O
and	O
human	Miscellaneous-metrics
aggregate	Miscellaneous-metrics
agreement	Miscellaneous-metrics
with	O
the	O
labels	O
is	O
96	O
.	O
4	O
\\%	O
.	O

Hyperparameter	AI/ML/DL-focus
selection	AI/ML/DL-focus
is	O
a	O
crucial	O
part	O
of	O
building	O
neural	NLP-focus
machine	NLP-focus
translation	NLP-focus
(	NLP-focus
NMT	NLP-focus
)	NLP-focus
systems	O
across	O
both	O
academia	O
and	O
industry	O
.	O

While	O
recent	O
literature	O
has	O
proposed	O
methods	O
for	O
automatic	O
hyperparameter	AI/ML/DL-focus
optimization	AI/ML/DL-focus
(	AI/ML/DL-focus
HPO	AI/ML/DL-focus
)	AI/ML/DL-focus
there	O
has	O
been	O
limited	O
work	O
on	O
applying	O
these	O
methods	O
to	O
neural	NLP-focus
machine	NLP-focus
translation	NLP-focus
(	NLP-focus
NMT	NLP-focus
)	NLP-focus
due	O
in	O
part	O
to	O
the	O
high	O
costs	O
associated	O
with	O
experiments	O
that	O
train	O
large	O
numbers	O
of	O
model	O
variants	O
.	O

To	O
facilitate	O
research	O
in	O
this	O
space	O
,	O
we	O
introduce	O
a	O
lookup	O
-	O
based	O
approach	O
that	O
uses	O
a	O
library	O
of	O
pre	O
-	O
trained	O
models	O
for	O
fast	O
,	O
low	O
cost	O
HPO	AI/ML/DL-focus
experimentation	O
.	O

Our	O
contributions	O
include	O
(	O
1	O
)	O
the	O
release	O
of	O
a	O
large	O
collection	O
of	O
trained	O
NMT	O
models	O
covering	O
a	O
wide	O
range	O
of	O
hyperparameters	O
(	O
2	O
)	O
the	O
proposal	O
of	O
targeted	O
metrics	O
for	O
evaluating	O
HPO	AI/ML/DL-focus
NMT	NLP-focus
HPO	AI/ML/DL-focus
on	O
NMT	O
,	O
and	O
(	O
3	O
)	O
a	O
reproducible	O
benchmark	O
of	O
several	O
HPO	O
methods	O
against	O
our	O
model	O
library	O
,	O
including	O
novel	O
graph	O
-	O
based	O
and	O
multiobjective	O
methods	O
.	O

Topic	NLP-focus
modeling	NLP-focus
analyzes	O
documents	O
to	O
learn	O
meaningful	O
patterns	O
of	O
words	O
.	O

It	O
outperforms	O
existing	O
document	O
models	O
such	O
as	O
latent	O
Dirichlet	O
allocation	O
in	O
terms	O
of	O
both	O
topic	NLP-metrics
quality	NLP-metrics
and	O
predictive	O
performance	O
.	O

We	O
present	O
TyDi	O
QA	O
a	O
question	NLP-focus
answering	NLP-focus
dataset	O
covering	O
11	O
typologically	O
diverse	O
languages	O
with	O
204K	O
question	O
-	O
answer	O
pairs	O
.	O

The	O
trained	O
model	O
maps	O
words	O
to	O
topic	O
-	O
dependent	O
embeddings	O
which	O
naturally	O
addresses	O
the	O
issue	O
of	O
word	NLP-focus
polysemy	NLP-focus
.	O

Experimental	O
results	O
show	O
that	O
the	O
proposed	O
model	O
outperforms	O
the	O
word	O
-	O
level	O
embedding	O
methods	O
in	O
both	O
word	NLP-focus
similarity	NLP-focus
evaluation	NLP-focus
and	O
word	NLP-focus
sense	NLP-focus
disambiguation	NLP-focus
.	O

Finally	O
,	O
the	O
model	O
can	O
be	O
easily	O
integrated	O
with	O
existing	O
deep	O
contextualized	O
word	O
embedding	O
learning	O
methods	O
to	O
further	O
improve	O
the	O
performance	O
of	O
downstream	O
tasks	O
such	O
as	O
sentiment	NLP-focus
classification	NLP-focus
.	O

We	O
also	O
propose	O
a	O
new	O
bias	O
evaluation	O
metric	O
,	O
Gender	NLP-metrics
-	NLP-metrics
based	NLP-metrics
Illicit	NLP-metrics
Proximity	NLP-metrics
Estimate	NLP-metrics
(	NLP-metrics
GIPE	NLP-metrics
)	NLP-metrics
which	O
measures	O
the	O
extent	O
of	O
undue	O
proximity	O
in	O
word	O
vectors	O
resulting	O
from	O
the	O
presence	O
of	O
gender	O
-	O
based	O
predilections	O
.	O

Experiments	O
based	O
on	O
a	O
suite	O
of	O
evaluation	O
metrics	O
show	O
that	O
RAN	O
-	O
Debias	O
significantly	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
reducing	O
proximity	O
bias	O
(	O
GIPE	NLP-metrics
by	O
at	O
least	O
42	O
.	O
02	O
\\%	O
.	O

It	O
also	O
reduces	O
direct	O
bias	O
adding	O
minimal	O
semantic	O
disturbance	O
,	O
and	O
achieves	O
the	O
best	O
performance	O
in	O
a	O
downstream	O
application	O
task	O
(	O
coreference	NLP-focus
resolution	NLP-focus
.	O

The	O
canonical	O
Smatch	NLP-metrics
metric	O
(	O
Cai	O
and	O
Knight	O
,	O
2013	O
)	O
aligns	O
the	O
variables	O
of	O
two	O
graphs	O
and	O
assesses	O
triple	O
matches	O
.	O

The	O
recent	O
SemBleu	NLP-metrics
metric	O
(	O
Song	O
and	O
Gildea	O
,	O
2019	O
)	O
is	O
based	O
on	O
the	O
machine	NLP-focus
-	NLP-focus
translation	NLP-focus
Bleu	O
c	O
Bleu	O
(	O
Papineni	O
et	O
al	O
.,	O
2002	O
)	O
and	O
increases	O
computational	O
efficiency	O
by	O
ablating	O
the	O
variable	O
-	O
alignment	O
.	O

The	O
recent	O
SemBleu	NLP-metrics
metric	O
(	O
Song	O
and	O
Gildea	O
,	O
2019	O
)	O
is	O
based	O
on	O
the	O
machine	NLP-focus
-	NLP-focus
translation	NLP-focus
Bleu	O
c	O
Bleu	O
(	O
Papineni	O
et	O
al	O
.,	O
2002	O
)	O
and	O
increases	O
computational	O
efficiency	O
by	O
ablating	O
the	O
variable	O
-	O
alignment	O
.	O

In	O
this	O
paper	O
,	O
i	O
)	O
we	O
establish	O
criteria	O
that	O
enable	O
researchers	O
to	O
perform	O
a	O
principled	O
assessment	O
of	O
metrics	O
comparing	O
meaning	O
representations	O
like	O
AMR	NLP-focus
ii	O
)	O
we	O
undertake	O
a	O
thorough	O
analysis	O
of	O
Smatch	NLP-metrics
and	O
SemBleu	NLP-metrics
where	O
we	O
show	O
that	O
the	O
latter	O
exhibits	O
some	O
undesirable	O
properties	O
.	O

In	O
this	O
paper	O
,	O
i	O
)	O
we	O
establish	O
criteria	O
that	O
enable	O
researchers	O
to	O
perform	O
a	O
principled	O
assessment	O
of	O
metrics	O
comparing	O
meaning	O
representations	O
like	O
AMR	NLP-focus
ii	O
)	O
we	O
undertake	O
a	O
thorough	O
analysis	O
of	O
Smatch	NLP-metrics
and	O
SemBleu	NLP-metrics
where	O
we	O
show	O
that	O
the	O
latter	O
exhibits	O
some	O
undesirable	O
properties	O
.	O

For	O
example	O
,	O
it	O
does	O
not	O
conform	O
to	O
the	O
identity	O
of	O
indiscernibles	O
rule	O
and	O
introduces	O
biases	O
that	O
are	O
hard	O
to	O
control	O
;	O
and	O
iii	O
)	O
we	O
propose	O
a	O
novel	O
metric	O
S2match	NLP-metrics
that	O
is	O
more	O
benevolent	O
to	O
only	O
very	O
slight	O
meaning	O
deviations	O
and	O
targets	O
the	O
fulfilment	O
of	O
all	O
established	O
criteria	O
.	O

We	O
assess	O
its	O
suitability	O
and	O
show	O
its	O
advantages	O
over	O
Smatch	NLP-metrics
and	O
SemBleu	NLP-metrics
.	O

Quality	NLP-focus
Estimation	NLP-focus
(	NLP-focus
QE	NLP-focus
)	NLP-focus
is	O
an	O
important	O
component	O
in	O
making	O
Machine	NLP-focus
Translation	NLP-focus
(	NLP-focus
MT	NLP-focus
)	NLP-focus
MT	NLP-focus
ful	O
in	O
real	O
-	O
world	O
applications	O
,	O
as	O
it	O
is	O
aimed	O
to	O
inform	O
the	O
user	O
on	O
the	O
quality	O
of	O
the	O
MT	O
output	O
at	O
test	O
time	O
.	O

As	O
an	O
alternative	O
,	O
we	O
devise	O
an	O
unsupervised	O
approach	O
to	O
QE	NLP-focus
where	O
no	O
training	O
or	O
access	O
to	O
additional	O
resources	O
besides	O
the	O
MT	NLP-focus
system	O
itself	O
is	O
required	O
.	O

Different	O
from	O
most	O
of	O
the	O
current	O
work	O
that	O
treats	O
the	O
MT	NLP-focus
MT	NLP-focus
tem	O
as	O
a	O
black	O
box	O
,	O
we	O
explore	O
useful	O
information	O
that	O
can	O
be	O
extracted	O
from	O
the	O
MT	O
system	O
as	O
a	O
by	O
-	O
product	O
of	O
translation	O
.	O

To	O
evaluate	O
our	O
approach	O
we	O
collect	O
the	O
first	O
dataset	O
that	O
enables	O
work	O
on	O
both	O
black	O
-	O
box	O
and	O
glass	O
-	O
box	O
approaches	O
to	O
QE	NLP-focus
.	O

We	O
describe	O
an	O
approach	O
to	O
task	NLP-focus
-	NLP-focus
oriented	NLP-focus
dialogue	NLP-focus
in	O
which	O
dialogue	O
state	O
is	O
represented	O
as	O
a	O
dataflow	O
graph	O
.	O

Open	NLP-focus
-	NLP-focus
domain	NLP-focus
question	NLP-focus
answering	NLP-focus
(	NLP-focus
QA	NLP-focus
)	NLP-focus
involves	O
many	O
knowledge	O
and	O
reasoning	O
challenges	O
,	O
but	O
are	O
successful	O
QA	O
models	O
actually	O
learning	O
such	O
knowledge	O
when	O
trained	O
on	O
benchmark	O
QA	O
tasks	O
?	O
We	O
investigate	O
this	O
via	O
several	O
new	O
diagnostic	O
tasks	O
probing	O
whether	O
multiple	O
-	O
choice	O
QA	O
models	O
know	O
definitions	O
and	O
taxonomic	O
reasoning	O
—	O
two	O
skills	O
widespread	O
in	O
existing	O
benchmarks	O
and	O
fundamental	O
to	O
more	O
complex	O
reasoning	O
.	O

In	O
our	O
experiments	O
,	O
we	O
demonstrate	O
that	O
our	O
approaches	O
lead	O
to	O
significant	O
improvements	O
on	O
two	O
graph	O
-	O
to	O
-	O
text	O
datasets	O
achieving	O
BLEU	NLP-metrics
scores	O
of	O
18	O
.	O
01	O
on	O
the	O
AGENDA	O
dataset	O
,	O
and	O
63	O
.	O
69	O
on	O
the	O
WebNLG	O
dataset	O
for	O
seen	O
categories	O
,	O
outperforming	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
by	O
3	O
.	O
7	O
and	O
3	O
.	O
1	O
points	O
,	O
respectively	O
.	O
1	O
.	O

Our	O
method	O
has	O
no	O
additional	O
hyperparameters	O
to	O
the	O
conditional	O
random	O
field	O
based	O
model	O
widely	O
used	O
for	O
flat	O
named	NLP-focus
entity	NLP-focus
recognition	NLP-focus
tasks	O
.	O

Experiments	O
demonstrate	O
that	O
our	O
method	O
performs	O
better	O
than	O
or	O
at	O
least	O
as	O
well	O
as	O
existing	O
methods	O
capable	O
of	O
handling	O
nested	O
entities	O
achieving	O
F1	Classification-metrics
scores	O
of	O
85	O
.	O
82	O
\\%	O
84	O
.	O
34	O
\\%	O
and	O
77	O
.	O
36	O
\\%	O
on	O
ACE	O
-	O
2004	O
ACE	O
-	O
2005	O
and	O
GENIA	O
datasets	O
,	O
respectively	O
.	O

Our	O
experiments	O
on	O
natural	NLP-focus
language	NLP-focus
inference	NLP-focus
and	O
paraphrase	O
identification	O
show	O
that	O
MTL	O
with	O
the	O
right	O
auxiliary	O
tasks	O
significantly	O
improves	O
performance	O
on	O
challenging	O
examples	O
without	O
hurting	O
the	O
in	O
-	O
distribution	O
performance	O
.	O

Recent	O
progress	O
in	O
the	O
task	O
of	O
Grammatical	NLP-focus
Error	NLP-focus
Correction	NLP-focus
(	NLP-focus
GEC	NLP-focus
)	NLP-focus
has	O
been	O
driven	O
by	O
addressing	O
data	O
sparsity	O
,	O
both	O
through	O
new	O
methods	O
for	O
generating	O
large	O
and	O
noisy	O
pretraining	O
data	O
and	O
through	O
the	O
publication	O
of	O
small	O
and	O
higher	O
-	O
quality	O
finetuning	O
data	O
in	O
the	O
BEA	O
-	O
2019	O
shared	O
task	O
.	O

Building	O
upon	O
recent	O
work	O
in	O
Neural	NLP-focus
Machine	NLP-focus
Translation	NLP-focus
(	NLP-focus
NMT	NLP-focus
)	NLP-focus
we	O
make	O
use	O
of	O
both	O
kinds	O
of	O
data	O
by	O
deriving	O
example	O
-	O
level	O
scores	O
on	O
our	O
large	O
pretraining	O
data	O
based	O
on	O
a	O
smaller	O
,	O
higher	O
-	O
quality	O
dataset	O
.	O

In	O
this	O
work	O
,	O
we	O
perform	O
an	O
empirical	O
study	O
to	O
discover	O
how	O
to	O
best	O
incorporate	O
delta	O
-	O
log	O
-	O
perplexity	O
,	O
a	O
type	O
of	O
example	O
scoring	O
,	O
into	O
a	O
training	O
schedule	O
for	O
GEC	NLP-focus
.	O

Models	O
trained	O
on	O
scored	O
data	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
common	O
GEC	NLP-focus
test	O
sets	O
.	O

In	O
this	O
paper	O
we	O
demonstrate	O
that	O
context	O
free	O
grammar	O
(	O
CFG	O
)	O
based	O
methods	O
for	O
grammar	NLP-focus
induction	NLP-focus
benefit	O
from	O
modeling	O
lexical	O
dependencies	O
.	O

This	O
contrasts	O
to	O
the	O
most	O
popular	O
current	O
methods	O
for	O
grammar	NLP-focus
induction	NLP-focus
which	O
focus	O
on	O
discovering	O
either	O
constituents	O
or	O
dependencies	O
.	O

Innovations	O
in	O
annotation	AI/ML/DL-focus
methodology	AI/ML/DL-focus
have	O
been	O
a	O
catalyst	O
for	O
Reading	NLP-focus
Comprehension	NLP-focus
(	NLP-focus
RC	NLP-focus
)	NLP-focus
datasets	O
and	O
models	O
.	O

In	O
this	O
work	O
we	O
investigate	O
this	O
annotation	AI/ML/DL-focus
methodology	AI/ML/DL-focus
and	O
apply	O
it	O
in	O
three	O
different	O
settings	O
,	O
collecting	O
a	O
total	O
of	O
36	O
,	O
000	O
samples	O
with	O
progressively	O
stronger	O
models	O
in	O
the	O
annotation	O
loop	O
.	O

We	O
find	O
that	O
training	O
on	O
adversarially	O
collected	O
samples	O
leads	O
to	O
strong	O
generalization	AI/ML/DL-focus
to	O
non	O
-	O
adversarially	O
collected	O
datasets	O
yet	O
with	O
progressive	O
performance	O
deterioration	O
with	O
increasingly	O
stronger	O
models	O
-	O
in	O
-	O
the	O
-	O
loop	O
.	O

When	O
trained	O
on	O
data	O
collected	O
with	O
a	O
BiDAF	O
model	O
in	O
the	O
loop	O
,	O
RoBERTa	O
achieves	O
39	O
.	O
9	O
F1	Classification-metrics
n	O
questions	O
that	O
it	O
cannot	O
answer	O
when	O
trained	O
on	O
SQuAD	O
RoBERTa	O
ginally	O
lower	O
than	O
when	O
trained	O
on	O
data	O
collected	O
using	O
RoBERTa	O
itself	O
(	O
41	O
.	O
0	O
F1	Classification-metrics
.	O

The	O
conventional	O
paradigm	O
in	O
speech	NLP-focus
translation	NLP-focus
starts	O
with	O
a	O
speech	NLP-focus
recognition	NLP-focus
step	O
to	O
generate	O
transcripts	O
,	O
followed	O
by	O
a	O
translation	O
step	O
with	O
the	O
automatic	O
transcripts	O
as	O
input	O
.	O

We	O
introduce	O
a	O
methodology	O
to	O
evaluate	O
consistency	Miscellaneous-metrics
and	O
compare	O
several	O
modeling	O
approaches	O
,	O
including	O
the	O
traditional	O
cascaded	O
approach	O
and	O
end	O
-	O
to	O
-	O
end	O
models	O
.	O

We	O
find	O
that	O
direct	O
models	O
are	O
poorly	O
suited	O
to	O
the	O
joint	NLP-focus
transcription	NLP-focus
/	NLP-focus
translation	NLP-focus
task	NLP-focus
but	O
that	O
end	O
-	O
to	O
-	O
end	O
models	O
that	O
feature	O
a	O
coupled	O
inference	O
procedure	O
are	O
able	O
to	O
achieve	O
strong	O
consistency	Miscellaneous-metrics
.	O

We	O
find	O
that	O
direct	O
models	O
are	O
poorly	O
suited	O
to	O
the	O
joint	NLP-focus
transcription	NLP-focus
/	NLP-focus
translation	NLP-focus
task	NLP-focus
but	O
that	O
end	O
-	O
to	O
-	O
end	O
models	O
that	O
feature	O
a	O
coupled	O
inference	O
procedure	O
are	O
able	O
to	O
achieve	O
strong	O
consistency	Miscellaneous-metrics
.	O

We	O
further	O
introduce	O
simple	O
techniques	O
for	O
directly	O
optimizing	O
for	O
consistency	Miscellaneous-metrics
consistency	Miscellaneous-metrics
the	O
resulting	O
trade	O
-	O
offs	O
between	O
consistency	O
,	O
transcription	Classification-metrics
accuracy	Classification-metrics
and	O
translation	Classification-metrics
accuracy	Classification-metrics
1	O
.	O

Neural	NLP-focus
machine	NLP-focus
translation	NLP-focus
(	NLP-focus
NMT	NLP-focus
)	NLP-focus
systems	O
are	O
usually	O
trained	O
on	O
clean	O
parallel	O
data	O
.	O

Given	O
the	O
lack	O
of	O
parallel	O
data	O
of	O
UGT	O
that	O
can	O
be	O
used	O
to	O
train	O
or	O
adapt	O
NMT	NLP-focus
UGT	O
UGT	O
we	O
synthesize	O
parallel	O
data	O
of	O
UGT	O
,	O
exploiting	O
monolingual	O
data	O
of	O
UGT	O
through	O
crosslingual	O
language	O
model	O
pre	O
-	O
training	O
and	O
zero	NLP-focus
-	NLP-focus
shot	NLP-focus
NMT	NLP-focus
systems	O
.	O

On	O
the	O
MTNT	O
translation	O
tasks	O
,	O
we	O
show	O
that	O
our	O
synthesized	O
parallel	O
data	O
can	O
lead	O
to	O
better	O
NMT	NLP-focus
systems	O
for	O
UGT	O
while	O
making	O
them	O
more	O
robust	O
in	O
translating	O
texts	O
from	O
various	O
domains	O
and	O
styles	O
.	O

This	O
paper	O
demonstrates	O
that	O
multilingual	O
denoising	O
pre	O
-	O
training	O
produces	O
significant	O
performance	O
gains	O
across	O
a	O
wide	O
variety	O
of	O
machine	NLP-focus
translation	NLP-focus
(	NLP-focus
MT	NLP-focus
)	NLP-focus
tasks	O
.	O

Pre	O
-	O
training	O
a	O
complete	O
model	O
allows	O
it	O
to	O
be	O
directly	O
fine	O
-	O
tuned	O
for	O
supervised	O
(	O
both	O
sentence	O
-	O
level	O
and	O
document	O
-	O
level	O
)	O
and	O
unsupervised	NLP-focus
machine	NLP-focus
translation	NLP-focus
with	O
no	O
task	O
-	O
specific	O
modifications	O
.	O

We	O
demonstrate	O
that	O
adding	O
mBART	O
initialization	O
produces	O
performance	O
gains	O
in	O
all	O
but	O
the	O
highest	O
-	O
resource	O
settings	O
,	O
including	O
up	O
to	O
12	O
BLEU	NLP-metrics
points	O
for	O
low	NLP-focus
resource	NLP-focus
MT	NLP-focus
BLEU	NLP-metrics
ver	O
5	O
BLEU	O
points	O
for	O
many	O
document	O
-	O
level	O
and	O
unsupervised	O
models	O
.	O

We	O
demonstrate	O
that	O
adding	O
mBART	O
initialization	O
produces	O
performance	O
gains	O
in	O
all	O
but	O
the	O
highest	O
-	O
resource	O
settings	O
,	O
including	O
up	O
to	O
12	O
BLEU	NLP-metrics
points	O
for	O
low	NLP-focus
resource	NLP-focus
MT	NLP-focus
BLEU	NLP-metrics
ver	O
5	O
BLEU	O
points	O
for	O
many	O
document	O
-	O
level	O
and	O
unsupervised	O
models	O
.	O

However	O
,	O
efforts	O
to	O
understand	O
whether	O
LM	O
representations	O
are	O
useful	O
for	O
symbolic	NLP-focus
reasoning	NLP-focus
tasks	O
have	O
been	O
limited	O
and	O
scattered	O
.	O

For	O
many	O
NLP	O
applications	O
,	O
such	O
as	O
question	NLP-focus
answering	NLP-focus
and	O
summarization	NLP-focus
the	O
goal	O
is	O
to	O
select	O
the	O
best	O
solution	O
from	O
a	O
large	O
space	O
of	O
candidates	O
to	O
meet	O
a	O
particular	O
user	O
’	O
s	O
needs	O
.	O

We	O
apply	O
our	O
method	O
to	O
community	NLP-focus
question	NLP-focus
answering	NLP-focus
(	NLP-focus
cQA	NLP-focus
)	NLP-focus
and	O
extractive	NLP-focus
multidocument	NLP-focus
summarization	NLP-focus
finding	O
that	O
it	O
significantly	O
outperforms	O
existing	O
interactive	O
approaches	O
.	O

We	O
also	O
show	O
that	O
the	O
ranking	O
function	O
learned	O
by	O
our	O
method	O
is	O
an	O
effective	O
reward	O
function	O
for	O
reinforcement	O
learning	O
which	O
improves	O
the	O
state	O
of	O
the	O
art	O
for	O
interactive	NLP-focus
summarization	NLP-focus
.	O

There	O
is	O
an	O
increasing	O
focus	O
on	O
model	O
-	O
based	O
dialog	O
evaluation	O
metrics	O
such	O
as	O
ADEM	NLP-metrics
RUBER	NLP-metrics
and	O
the	O
more	O
recent	O
BERT	O
based	O
metrics	O
.	O

Using	O
this	O
dataset	O
,	O
we	O
first	O
show	O
that	O
even	O
in	O
the	O
presence	O
of	O
multiple	O
correct	O
references	O
,	O
n	NLP-metrics
-	NLP-metrics
gram	NLP-metrics
based	NLP-metrics
metrics	NLP-metrics
and	O
embedding	O
based	O
metrics	O
do	O
not	O
perform	O
well	O
at	O
separating	O
relevant	O
responses	O
from	O
even	O
random	O
negatives	O
.	O

To	O
check	O
if	O
large	O
scale	O
pretraining	O
could	O
help	O
,	O
we	O
propose	O
a	O
new	O
BERT	O
based	O
evaluation	O
metric	O
called	O
DEB	NLP-metrics
which	O
is	O
pretrained	O
on	O
727M	O
Reddit	O
conversations	O
DEB	NLP-metrics
then	O
finetuned	O
on	O
our	O
dataset	O
.	O

DEB	O
significantly	O
outperforms	O
existing	O
models	O
,	O
showing	O
better	O
correlation	O
with	O
human	O
judgments	O
and	O
better	O
performance	O
on	O
random	O
negatives	O
(	O
88	O
.	O
27	O
\\%	O
accuracy	Classification-metrics
.	O

We	O
describe	O
an	O
unsupervised	O
method	O
to	O
create	O
pseudo	O
-	O
parallel	O
corpora	O
for	O
machine	NLP-focus
translation	NLP-focus
(	NLP-focus
MT	NLP-focus
)	NLP-focus
from	O
unaligned	O
text	O
.	O

We	O
validate	O
our	O
technique	O
by	O
extracting	O
parallel	O
sentence	O
pairs	O
on	O
the	O
BUCC	O
2017	O
bitext	NLP-focus
mining	NLP-focus
task	O
and	O
observe	O
up	O
to	O
a	O
24	O
.	O
5	O
point	O
increase	O
(	O
absolute	O
)	O
in	O
F1	Classification-metrics
scores	O
over	O
previous	O
unsupervised	O
methods	O
.	O

We	O
validate	O
our	O
technique	O
by	O
extracting	O
parallel	O
sentence	O
pairs	O
on	O
the	O
BUCC	O
2017	O
bitext	NLP-focus
mining	NLP-focus
task	O
and	O
observe	O
up	O
to	O
a	O
24	O
.	O
5	O
point	O
increase	O
(	O
absolute	O
)	O
in	O
F1	Classification-metrics
scores	O
over	O
previous	O
unsupervised	O
methods	O
.	O

We	O
then	O
improve	O
an	O
XLM	O
-	O
based	O
unsupervised	O
neural	O
MT	O
system	O
pre	O
-	O
trained	O
on	O
Wikipedia	O
by	O
supplementing	O
it	O
with	O
pseudo	O
-	O
parallel	O
text	O
mined	O
from	O
the	O
same	O
corpus	O
,	O
boosting	O
unsupervised	NLP-focus
translation	NLP-focus
performance	O
by	O
up	O
to	O
3	O
.	O
5	O
BLEU	NLP-metrics
on	O
the	O
WMT	O
’	O
14	O
French	O
-	O
English	O
and	O
WMT	O
’	O
16	O
German	O
-	O
English	O
tasks	O
and	O
outperforming	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O

We	O
then	O
improve	O
an	O
XLM	O
-	O
based	O
unsupervised	O
neural	O
MT	O
system	O
pre	O
-	O
trained	O
on	O
Wikipedia	O
by	O
supplementing	O
it	O
with	O
pseudo	O
-	O
parallel	O
text	O
mined	O
from	O
the	O
same	O
corpus	O
,	O
boosting	O
unsupervised	NLP-focus
translation	NLP-focus
performance	O
by	O
up	O
to	O
3	O
.	O
5	O
BLEU	NLP-metrics
on	O
the	O
WMT	O
’	O
14	O
French	O
-	O
English	O
and	O
WMT	O
’	O
16	O
German	O
-	O
English	O
tasks	O
and	O
outperforming	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O

Finally	O
,	O
we	O
enrich	O
the	O
IWSLT	O
’	O
15	O
English	O
-	O
Vietnamese	O
corpus	O
with	O
pseudo	O
-	O
parallel	O
Wikipedia	O
sentence	O
pairs	O
yielding	O
a	O
1	O
.	O
2	O
BLEU	NLP-metrics
improvement	O
on	O
the	O
low	NLP-focus
-	NLP-focus
resource	NLP-focus
MT	NLP-focus
task	O
.	O

Finally	O
,	O
we	O
enrich	O
the	O
IWSLT	O
’	O
15	O
English	O
-	O
Vietnamese	O
corpus	O
with	O
pseudo	O
-	O
parallel	O
Wikipedia	O
sentence	O
pairs	O
yielding	O
a	O
1	O
.	O
2	O
BLEU	NLP-metrics
improvement	O
on	O
the	O
low	NLP-focus
-	NLP-focus
resource	NLP-focus
MT	NLP-focus
task	O
.	O

We	O
demonstrate	O
that	O
unsupervised	O
bitext	O
mining	O
is	O
an	O
effective	O
way	O
of	O
augmenting	O
MT	NLP-focus
datasets	O
and	O
complements	O
existing	O
techniques	O
like	O
initializing	O
with	O
pre	O
-	O
trained	O
contextual	O
embeddings	O
.	O

We	O
review	O
the	O
current	O
state	O
of	O
knowledge	O
about	O
how	O
BERT	O
works	O
,	O
what	O
kind	O
of	O
information	O
it	O
learns	O
and	O
how	O
it	O
is	O
represented	O
,	O
common	O
modifications	O
to	O
its	O
training	O
objectives	O
and	O
architecture	O
,	O
the	O
overparameterization	AI/ML/DL-focus
issue	O
,	O
and	O
approaches	O
to	O
compression	O
.	O

Until	O
now	O
,	O
most	O
of	O
the	O
research	O
in	O
grammar	NLP-focus
error	NLP-focus
correction	NLP-focus
focused	O
on	O
English	O
,	O
and	O
the	O
problem	O
has	O
hardly	O
been	O
explored	O
for	O
other	O
languages	O
.	O

Although	O
impressive	O
results	O
have	O
recently	O
been	O
achieved	O
for	O
grammar	NLP-focus
error	NLP-focus
correction	NLP-focus
of	O
non	O
-	O
native	O
English	O
writing	O
,	O
these	O
results	O
are	O
limited	O
to	O
domains	O
where	O
plentiful	O
training	O
data	O
are	O
available	O
.	O

It	O
is	O
intuitive	O
that	O
semantic	O
representations	O
can	O
be	O
useful	O
for	O
machine	NLP-focus
translation	NLP-focus
mainly	O
because	O
they	O
can	O
help	O
in	O
enforcing	O
meaning	O
preservation	O
and	O
handling	O
data	O
sparsity	O
(	O
many	O
sentences	O
correspond	O
to	O
one	O
meaning	O
)	O
of	O
machine	O
translation	O
models	O
.	O

On	O
the	O
other	O
hand	O
,	O
little	O
work	O
has	O
been	O
done	O
on	O
leveraging	O
semantics	O
for	O
neural	NLP-focus
machine	NLP-focus
translation	NLP-focus
(	NLP-focus
NMT	NLP-focus
)	NLP-focus
.	O

In	O
this	O
work	O
,	O
we	O
study	O
the	O
usefulness	O
of	O
AMR	O
(	O
abstract	O
meaning	O
representation	O
)	O
on	O
NMT	NLP-focus
.	O

Experiments	O
on	O
a	O
standard	O
English	NLP-focus
-	NLP-focus
to	NLP-focus
-	NLP-focus
German	NLP-focus
dataset	O
show	O
that	O
incorporating	O
AMR	O
as	O
additional	O
knowledge	O
can	O
significantly	O
improve	O
a	O
strong	O
attention	O
-	O
based	O
sequence	O
-	O
to	O
-	O
sequence	O
neural	O
translation	O
model	O
.	O

However	O
,	O
most	O
of	O
the	O
existing	O
methods	O
usually	O
use	O
all	O
data	O
for	O
consensus	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
whereas	O
ignoring	O
the	O
side	O
effects	O
caused	O
by	O
some	O
unreliable	O
or	O
difficult	O
data	O
.	O

To	O
address	O
this	O
issue	O
,	O
in	O
this	O
article	O
,	O
we	O
propose	O
a	O
novel	O
self	O
-	O
paced	O
consensus	O
clustering	O
method	O
with	O
adaptive	O
bipartite	O
graph	O
learning	O
to	O
gradually	O
involve	O
data	O
from	O
more	O
reliable	O
to	O
less	O
reliable	O
ones	O
in	O
consensus	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
.	O

Traffic	Data/Mining/Information/Retrieval-focus
flow	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
has	O
always	O
been	O
the	O
focus	O
of	O
research	O
in	O
the	O
field	O
of	O
Intelligent	Data/Mining/Information/Retrieval-focus
Transportation	Data/Mining/Information/Retrieval-focus
Systems	Data/Mining/Information/Retrieval-focus
which	O
is	O
conducive	O
to	O
the	O
more	O
reasonable	O
allocation	O
of	O
basic	O
transportation	O
resources	O
and	O
formulation	O
of	O
transportation	O
policies	O
.	O

This	O
article	O
proposes	O
a	O
deep	O
-	O
space	O
time	O
traffic	Data/Mining/Information/Retrieval-focus
flow	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
model	O
based	O
on	O
discrete	O
wavelet	O
transform	O
(	O
DSTM	O
-	O
DWT	O
to	O
overcome	O
the	O
highly	O
discrete	O
and	O
irregular	O
nature	O
of	O
the	O
new	O
crown	O
epidemic	O
.	O

Finally	O
,	O
use	O
DWT	O
to	O
segment	O
the	O
predicted	O
traffic	O
data	O
,	O
and	O
then	O
perform	O
the	O
inverse	O
discrete	O
wavelet	O
transform	O
between	O
the	O
newly	O
segmented	O
traffic	O
trend	O
and	O
discrete	O
baseline	O
and	O
the	O
discrete	O
model	O
predicted	O
by	O
GMN	O
to	O
obtain	O
the	O
final	O
traffic	Data/Mining/Information/Retrieval-focus
flow	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
result	O
.	O

Crowdsourcing	Data/Mining/Information/Retrieval-focus
truth	Data/Mining/Information/Retrieval-focus
inference	Data/Mining/Information/Retrieval-focus
aims	O
to	O
assign	O
a	O
correct	O
answer	O
to	O
each	O
task	O
from	O
candidate	O
answers	O
that	O
are	O
provided	O
by	O
crowdsourced	O
workers	O
.	O

From	O
the	O
perspective	O
of	O
multiple	O
crowdsourced	O
relationships	O
a	O
multi	O
-	O
view	O
graph	O
embedding	O
framework	O
is	O
proposed	O
for	O
reliability	Data/Mining/Information/Retrieval-focus
information	Data/Mining/Information/Retrieval-focus
interaction	Data/Mining/Information/Retrieval-focus
on	O
a	O
task	O
-	O
worker	O
graph	O
which	O
encodes	O
latent	O
crowdsourced	O
relationships	O
into	O
vectors	O
of	O
workers	O
and	O
tasks	O
for	O
reliability	Data/Mining/Information/Retrieval-focus
update	Data/Mining/Information/Retrieval-focus
and	O
truth	Data/Mining/Information/Retrieval-focus
inference	Data/Mining/Information/Retrieval-focus
.	O

Experimental	O
results	O
show	O
that	O
D	O
-	O
Tucker	O
achieves	O
up	O
to	O
38	O
.	O
4	O
\	O
texttimes	O
{}	O
faster	O
running	O
times	O
and	O
requires	O
up	O
to	O
17	O
.	O
2	O
\	O
texttimes	O
{}	O
less	O
space	O
than	O
existing	O
methods	O
while	O
having	O
similar	O
accuracy	Classification-metrics
.	O

Hidden	O
community	O
is	O
a	O
useful	O
concept	O
proposed	O
recently	O
for	O
social	Data/Mining/Information/Retrieval-focus
network	Data/Mining/Information/Retrieval-focus
analysis	Data/Mining/Information/Retrieval-focus
.	O

Extensive	O
experiments	O
show	O
that	O
our	O
method	O
could	O
significantly	O
outperform	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
designed	O
for	O
either	O
global	Data/Mining/Information/Retrieval-focus
hidden	Data/Mining/Information/Retrieval-focus
community	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
or	O
multiple	Data/Mining/Information/Retrieval-focus
local	Data/Mining/Information/Retrieval-focus
community	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
.	O

While	O
many	O
efforts	O
have	O
been	O
made	O
for	O
statically	O
measuring	O
and	O
evaluating	O
urban	O
vibrancy	O
urban	O
vibrancy	O
studies	O
on	O
the	O
evolutionary	O
process	O
of	O
urban	O
vibrancy	O
,	O
yet	O
we	O
know	O
little	O
about	O
the	O
relationship	O
between	O
urban	Data/Mining/Information/Retrieval-focus
vibrancy	Data/Mining/Information/Retrieval-focus
evolution	Data/Mining/Information/Retrieval-focus
and	O
sophisticated	O
spatiotemporal	O
dynamics	O
.	O

In	O
this	O
article	O
,	O
we	O
make	O
use	O
of	O
multi	O
-	O
sourced	O
urban	O
data	O
to	O
develop	O
a	O
data	O
-	O
driven	O
framework	O
U	O
-	O
Evolve	O
to	O
investigate	O
urban	Data/Mining/Information/Retrieval-focus
vibrancy	Data/Mining/Information/Retrieval-focus
evolution	Data/Mining/Information/Retrieval-focus
.	O

Our	O
analysis	O
validates	O
the	O
informativeness	O
of	O
multi	O
-	O
view	O
time	O
-	O
dependent	O
graphs	O
for	O
characterizing	O
and	O
informing	O
future	O
urban	Data/Mining/Information/Retrieval-focus
vibrancy	Data/Mining/Information/Retrieval-focus
evolution	Data/Mining/Information/Retrieval-focus
.	O

After	O
that	O
,	O
we	O
construct	O
a	O
feature	O
based	O
model	O
to	O
forecast	O
future	O
urban	Data/Mining/Information/Retrieval-focus
vibrancy	Data/Mining/Information/Retrieval-focus
evolution	Data/Mining/Information/Retrieval-focus
and	O
quantify	O
each	O
feature	O
’	O
s	O
importance	O
.	O

Graph	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
based	Data/Mining/Information/Retrieval-focus
Multi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
View	Data/Mining/Information/Retrieval-focus
Clustering	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
GMVC	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
has	O
received	O
extensive	O
attention	O
due	O
to	O
its	O
ability	O
to	O
capture	O
the	O
neighborhood	O
relationship	O
among	O
data	O
points	O
from	O
diverse	O
views	O
.	O

In	O
this	O
work	O
,	O
we	O
design	O
a	O
novel	O
GMVC	Data/Mining/Information/Retrieval-focus
framework	O
via	O
cOmmoNality	O
and	O
Individuality	O
discOvering	O
in	O
lateNt	O
subspace	O
(	O
ONION	O
)	O
seeking	O
for	O
a	O
robust	O
and	O
discriminative	O
subspace	O
representation	O
GMVC	Data/Mining/Information/Retrieval-focus
tible	O
across	O
multiple	O
features	O
for	O
GMVC	O
.	O

However	O
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
unsupervised	O
deep	O
learning	O
models	O
for	O
MTS	Data/Mining/Information/Retrieval-focus
anomaly	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
are	O
vulnerable	O
to	O
noise	O
and	O
have	O
poor	O
performance	O
on	O
the	O
training	O
data	O
containing	O
anomalies	O
.	O

The	O
STAD	O
-	O
GAN	O
model	O
consists	O
of	O
a	O
generator	O
-	O
discriminator	O
structure	O
for	O
adversarial	O
learning	O
and	O
a	O
neural	O
network	O
classifier	O
for	O
anomaly	Data/Mining/Information/Retrieval-focus
classification	Data/Mining/Information/Retrieval-focus
.	O

Ensemble	O
methods	O
have	O
been	O
used	O
for	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
label	AI/ML/DL-focus
classification	AI/ML/DL-focus
but	O
few	O
methods	O
consider	O
both	O
the	O
accuracy	Classification-metrics
and	O
diversity	Miscellaneous-metrics
of	O
base	O
classifiers	O
.	O

Ensemble	O
methods	O
have	O
been	O
used	O
for	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
label	AI/ML/DL-focus
classification	AI/ML/DL-focus
but	O
few	O
methods	O
consider	O
both	O
the	O
accuracy	Classification-metrics
and	O
diversity	Miscellaneous-metrics
of	O
base	O
classifiers	O
.	O

When	O
the	O
difference	O
value	O
between	O
the	O
number	O
of	O
current	O
instances	O
and	O
the	O
number	O
of	O
warning	O
instances	O
reaches	O
the	O
passive	O
warning	O
value	O
,	O
the	O
algorithm	O
selects	O
the	O
optimal	O
base	O
classifiers	O
from	O
AEC	O
and	O
PEC	O
according	O
to	O
the	O
subset	Classification-metrics
accuracy	Classification-metrics
and	O
hamming	Classification-metrics
score	Classification-metrics
and	O
puts	O
them	O
into	O
the	O
predictive	O
ensemble	O
classifiers	O
.	O

In	O
this	O
study	O
,	O
sentiment	NLP-focus
classification	NLP-focus
and	O
emotion	NLP-focus
distribution	NLP-focus
learning	NLP-focus
across	O
domains	O
are	O
both	O
formulated	O
as	O
a	O
semi	O
-	O
supervised	O
domain	O
adaptation	O
problem	O
which	O
utilizes	O
a	O
small	O
amount	O
of	O
labeled	O
documents	O
in	O
the	O
target	O
domain	O
for	O
model	O
training	O
.	O

By	O
introducing	O
a	O
shared	O
matrix	O
that	O
captures	O
the	O
stable	O
association	O
between	O
document	O
clusters	O
and	O
word	O
clusters	O
,	O
non	O
-	O
negative	O
matrix	O
tri	O
-	O
factorization	O
(	O
NMTF	O
)	O
is	O
robust	O
to	O
the	O
labeled	O
target	O
domain	O
data	O
and	O
has	O
shown	O
remarkable	O
performance	O
in	O
cross	NLP-focus
-	NLP-focus
domain	NLP-focus
text	NLP-focus
classification	NLP-focus
.	O

To	O
address	O
these	O
issues	O
,	O
we	O
propose	O
a	O
semi	O
-	O
supervised	O
NMTF	O
framework	O
for	O
sentiment	NLP-focus
classification	NLP-focus
and	O
emotion	NLP-focus
distribution	NLP-focus
learning	O
across	O
domains	O
.	O

As	O
the	O
scope	O
of	O
receptive	O
field	O
and	O
the	O
depth	O
of	O
Graph	O
Neural	O
Networks	O
(	O
GNNs	O
)	O
are	O
two	O
completely	O
orthogonal	O
aspects	O
for	O
graph	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
GNNs	O
ting	O
GNNs	O
often	O
have	O
shallow	O
layers	O
with	O
truncated	O
-	O
receptive	O
field	O
and	O
far	O
from	O
achieving	O
satisfactory	O
performance	O
.	O

Experimental	O
results	O
show	O
that	O
SAGCN	O
enjoys	O
high	O
accuracy	Classification-metrics
scalability	O
and	O
efficiency	O
on	O
various	O
open	O
benchmarks	O
and	O
is	O
competitive	O
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
competitors	O
.	O

Truth	Data/Mining/Information/Retrieval-focus
inference	Data/Mining/Information/Retrieval-focus
can	O
help	O
solve	O
some	O
difficult	O
problems	O
of	O
data	Data/Mining/Information/Retrieval-focus
integration	Data/Mining/Information/Retrieval-focus
in	O
crowdsourcing	O
.	O

This	O
article	O
proposes	O
a	O
novel	O
algorithm	O
called	O
truth	O
inference	O
based	O
on	O
label	O
confidence	O
clustering	O
(	O
TILCC	O
)	O
to	O
improve	O
the	O
quality	O
of	O
integrated	O
labels	O
for	O
the	O
single	AI/ML/DL-focus
-	AI/ML/DL-focus
choice	AI/ML/DL-focus
classification	AI/ML/DL-focus
problem	O
in	O
crowdsourcing	Data/Mining/Information/Retrieval-focus
labeling	Data/Mining/Information/Retrieval-focus
tasks	O
.	O

Compared	O
with	O
the	O
performances	O
of	O
six	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
MV	O
ZenCrowd	O
PM	O
CATD	O
GLAD	O
and	O
GTIC	O
on	O
12	O
randomly	O
selected	O
real	O
-	O
world	O
datasets	O
the	O
performance	O
of	O
our	O
algorithm	O
showed	O
many	O
advantages	O
:	O
no	O
need	O
to	O
set	O
complex	O
parameters	O
faster	O
running	O
speed	O
,	O
and	O
significantly	O
higher	O
accuracy	Classification-metrics
.	O

Analyzing	O
the	O
spread	O
of	O
information	O
(	O
aka	O
diffusion	Data/Mining/Information/Retrieval-focus
has	O
brought	O
forth	O
multiple	O
research	O
areas	O
such	O
as	O
modelling	O
user	O
engagement	O
determining	O
emerging	O
topics	O
forecasting	O
the	O
virality	O
of	O
online	O
posts	O
and	O
predicting	O
information	O
cascades	O
.	O

Along	O
with	O
performing	O
an	O
exhaustive	O
feature	O
comparison	O
and	O
system	O
evaluation	O
of	O
DiVA	O
against	O
publicly	O
-	O
available	O
web	O
interfaces	O
for	O
information	Data/Mining/Information/Retrieval-focus
diffusion	Data/Mining/Information/Retrieval-focus
DiVA	O
onducted	O
a	O
user	O
study	O
to	O
understand	O
the	O
strengths	O
and	O
limitations	O
of	O
DiVA	O
.	O

We	O
noticed	O
that	O
evaluators	O
had	O
a	O
seamless	O
user	O
experience	O
,	O
especially	O
when	O
analyzing	O
diffusion	Data/Mining/Information/Retrieval-focus
on	O
large	O
networks	O
.	O

While	O
urban	O
rail	O
transit	O
systems	O
are	O
playing	O
an	O
increasingly	O
important	O
role	O
in	O
meeting	O
the	O
transportation	O
demands	O
of	O
people	O
,	O
precise	O
awareness	O
of	O
how	O
the	O
human	O
crowd	O
is	O
distributed	O
within	O
such	O
a	O
system	O
is	O
highly	O
necessary	O
,	O
which	O
serves	O
a	O
range	O
of	O
important	O
applications	O
including	O
emergency	O
response	O
,	O
transit	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
and	O
commercial	O
valuation	O
.	O

What	O
is	O
the	O
best	O
way	O
to	O
match	O
the	O
nodes	O
of	O
two	O
graphs	O
?	O
This	O
graph	Data/Mining/Information/Retrieval-focus
alignment	Data/Mining/Information/Retrieval-focus
problem	O
generalizes	O
graph	O
isomorphism	O
and	O
arises	O
in	O
applications	O
from	O
social	Data/Mining/Information/Retrieval-focus
network	Data/Mining/Information/Retrieval-focus
analysis	Data/Mining/Information/Retrieval-focus
to	O
bioinformatics	O
.	O

In	O
this	O
article	O
,	O
we	O
transfer	O
the	O
shape	O
-	O
analysis	O
concept	O
of	O
functional	O
maps	O
from	O
the	O
continuous	O
to	O
the	O
discrete	O
case	O
,	O
and	O
treat	O
the	O
graph	Data/Mining/Information/Retrieval-focus
alignment	Data/Mining/Information/Retrieval-focus
problem	O
as	O
a	O
special	O
case	O
of	O
the	O
problem	O
of	O
finding	O
a	O
mapping	O
between	O
functions	O
on	O
graphs	O
.	O

Our	O
experimental	O
study	O
,	O
featuring	O
noise	O
levels	O
higher	O
than	O
anything	O
used	O
in	O
previous	O
studies	O
,	O
shows	O
that	O
the	O
enhanced	O
form	O
of	O
GRASP	O
outperforms	O
scalable	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
for	O
graph	Data/Mining/Information/Retrieval-focus
alignment	Data/Mining/Information/Retrieval-focus
across	O
noise	O
levels	O
and	O
graph	O
types	O
,	O
and	O
performs	O
competitively	O
with	O
respect	O
to	O
the	O
best	O
non	O
-	O
scalable	O
ones	O
.	O

We	O
include	O
in	O
our	O
study	O
another	O
modular	O
graph	Data/Mining/Information/Retrieval-focus
alignment	Data/Mining/Information/Retrieval-focus
algorithm	O
,	O
CONE	O
which	O
is	O
also	O
adaptable	O
thanks	O
to	O
its	O
modular	O
nature	O
,	O
and	O
show	O
it	O
can	O
manage	O
graphs	O
with	O
skewed	O
power	O
-	O
law	O
degree	O
distributions	O
.	O

Analysis	O
of	O
social	Data/Mining/Information/Retrieval-focus
networks	Data/Mining/Information/Retrieval-focus
with	O
limited	O
data	O
access	O
is	O
challenging	O
for	O
third	O
parties	O
.	O

To	O
address	O
this	O
challenge	O
,	O
a	O
number	O
of	O
studies	O
have	O
developed	O
algorithms	O
that	O
estimate	O
properties	O
of	O
social	Data/Mining/Information/Retrieval-focus
networks	Data/Mining/Information/Retrieval-focus
via	O
a	O
simple	O
random	O
walk	O
.	O

However	O
,	O
most	O
existing	O
algorithms	O
do	O
not	O
assume	O
private	O
nodes	O
that	O
do	O
not	O
publish	O
their	O
neighbors	O
’	O
data	O
when	O
they	O
are	O
queried	O
in	O
empirical	O
social	Data/Mining/Information/Retrieval-focus
networks	Data/Mining/Information/Retrieval-focus
.	O

Here	O
we	O
propose	O
a	O
practical	O
framework	O
for	O
estimating	O
properties	O
via	O
random	O
walk	O
-	O
based	O
sampling	O
in	O
social	Data/Mining/Information/Retrieval-focus
networks	Data/Mining/Information/Retrieval-focus
involving	O
private	O
nodes	O
.	O

First	O
,	O
we	O
develop	O
a	O
sampling	O
algorithm	O
by	O
extending	O
a	O
simple	O
random	O
walk	O
to	O
the	O
case	O
of	O
social	Data/Mining/Information/Retrieval-focus
networks	Data/Mining/Information/Retrieval-focus
involving	O
private	O
nodes	O
.	O

Our	O
results	O
show	O
that	O
the	O
proposed	O
estimators	O
reduce	O
biases	O
induced	O
by	O
private	O
nodes	O
in	O
the	O
existing	O
estimators	O
by	O
up	O
to	O
92	O
.	O
6	O
%	O
on	O
social	Data/Mining/Information/Retrieval-focus
network	Data/Mining/Information/Retrieval-focus
datasets	O
private	O
nodes	O
ate	O
nodes	O
.	O

In	O
this	O
article	O
,	O
we	O
formulate	O
lifelong	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
as	O
an	O
online	O
transfer	O
learning	O
procedure	O
over	O
consecutive	O
tasks	O
,	O
where	O
learning	O
a	O
given	O
task	O
depends	O
on	O
the	O
accumulated	O
knowledge	O
.	O

Accurate	O
citywide	O
traffic	O
inference	O
is	O
critical	O
for	O
improving	O
intelligent	Miscellaneous-focus
transportation	Miscellaneous-focus
systems	Miscellaneous-focus
with	O
smart	O
city	O
applications	O
.	O

A	O
more	O
practical	O
scenario	O
to	O
study	O
the	O
citywide	Data/Mining/Information/Retrieval-focus
traffic	Data/Mining/Information/Retrieval-focus
inference	Data/Mining/Information/Retrieval-focus
is	O
effectively	O
modeling	O
the	O
spatial	O
and	O
temporal	O
traffic	O
patterns	O
with	O
limited	O
historical	O
traffic	O
observations	O
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
a	O
dynamic	O
multi	O
-	O
view	O
graph	O
neural	O
network	O
for	O
citywide	Data/Mining/Information/Retrieval-focus
traffic	Data/Mining/Information/Retrieval-focus
inference	Data/Mining/Information/Retrieval-focus
with	O
the	O
method	O
CTVI	O
+	O
.	O

Transportation	Miscellaneous-focus
demand	Miscellaneous-focus
forecasting	Miscellaneous-focus
is	O
a	O
critical	O
precondition	O
of	O
optimal	Miscellaneous-focus
online	Miscellaneous-focus
transportation	Miscellaneous-focus
dispatch	Miscellaneous-focus
which	O
will	O
greatly	O
reduce	O
drivers	O
’	O
wasted	O
mileage	O
and	O
customers	O
’	O
waiting	O
time	O
,	O
contributing	O
to	O
economic	O
and	O
environmental	O
sustainability	O
.	O

Our	O
framework	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
by	O
reducing	O
6	O
.	O
58	O
%	O
4	O
.	O
57	O
%	O
and	O
4	O
.	O
20	O
%	O
of	O
WMAPE	Statistical/Mathematical-metrics
in	O
experiments	O
on	O
three	O
real	O
-	O
world	O
datasets	O
respectively	O
.	O

Existing	O
research	O
on	O
relation	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
has	O
primarily	O
focused	O
on	O
explicit	O
connections	O
and	O
ignored	O
underlying	O
information	O
,	O
e	O
.	O
g	O
.,	O
the	O
latent	O
entity	O
relations	O
.	O

We	O
empirically	O
evaluate	O
MIRROR	O
on	O
four	O
different	O
genres	O
of	O
networks	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
for	O
target	Data/Mining/Information/Retrieval-focus
relations	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
.	O

Predicting	Data/Mining/Information/Retrieval-focus
traffic	Data/Mining/Information/Retrieval-focus
accidents	Data/Mining/Information/Retrieval-focus
can	O
help	O
traffic	O
management	O
departments	O
respond	O
to	O
sudden	O
traffic	O
situations	O
promptly	O
,	O
improve	O
drivers	O
’	O
vigilance	O
,	O
and	O
reduce	O
losses	O
caused	O
by	O
traffic	O
accidents	O
.	O

Most	O
existing	O
traffic	Data/Mining/Information/Retrieval-focus
accident	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
methods	O
do	O
not	O
consider	O
the	O
dynamic	O
spatio	O
-	O
temporal	O
correlation	O
of	O
traffic	O
data	O
,	O
which	O
leads	O
to	O
unsatisfactory	O
prediction	O
accuracy	O
.	O

To	O
address	O
this	O
issue	O
,	O
we	O
propose	O
a	O
multi	O
-	O
task	O
learning	O
framework	O
(	O
TAP	O
)	O
based	O
on	O
the	O
Spatio	O
-	O
temporal	O
Variational	O
Graph	O
Auto	O
-	O
Encoders	O
(	O
ST	O
-	O
VGAE	O
)	O
for	O
traffic	Data/Mining/Information/Retrieval-focus
accident	Data/Mining/Information/Retrieval-focus
profiling	Data/Mining/Information/Retrieval-focus
.	O

Then	O
,	O
we	O
use	O
a	O
multi	O
-	O
task	O
learning	O
scheme	O
to	O
combine	O
external	O
factors	O
to	O
generate	O
the	O
traffic	Data/Mining/Information/Retrieval-focus
accident	Data/Mining/Information/Retrieval-focus
profiling	Data/Mining/Information/Retrieval-focus
.	O

Furthermore	O
,	O
we	O
propose	O
a	O
traffic	Data/Mining/Information/Retrieval-focus
accident	Data/Mining/Information/Retrieval-focus
profiling	Data/Mining/Information/Retrieval-focus
application	O
framework	O
based	O
on	O
edge	O
computing	O
.	O

This	O
method	O
increases	O
the	O
speed	O
of	O
calculation	O
by	O
offloading	O
the	O
calculation	O
of	O
traffic	Data/Mining/Information/Retrieval-focus
accident	Data/Mining/Information/Retrieval-focus
profiling	Data/Mining/Information/Retrieval-focus
to	O
edge	O
nodes	O
.	O

Most	O
of	O
the	O
existing	O
trip	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
methods	O
mainly	O
consider	O
POI	O
POI	O
POI	O
ty	O
and	O
user	O
preferences	O
,	O
and	O
focus	O
on	O
the	O
last	O
visited	O
POI	O
when	O
choosing	O
the	O
next	O
POI	O
.	O

Finally	O
,	O
after	O
formulating	O
the	O
personalized	O
trip	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
as	O
a	O
Markov	O
Decision	O
Process	O
(	O
MDP	O
)	O
we	O
utilize	O
a	O
reinforcement	O
learning	O
algorithm	O
for	O
generating	O
a	O
personalized	O
trip	O
with	O
maximal	O
user	O
travel	O
experience	O
.	O

Extensive	O
experiments	O
are	O
performed	O
on	O
the	O
public	O
datasets	O
and	O
the	O
results	O
demonstrate	O
the	O
superiority	O
of	O
GRM	O
-	O
RTrip	O
compared	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
trip	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
methods	O
.	O

The	O
results	O
indicate	O
that	O
our	O
approach	O
outperforms	O
several	O
competing	O
methods	O
in	O
terms	O
of	O
Hit	Statistical/Mathematical-metrics
Ratio	Statistical/Mathematical-metrics
(	Statistical/Mathematical-metrics
HR	Statistical/Mathematical-metrics
)	Statistical/Mathematical-metrics
and	O
Normalized	Statistical/Mathematical-metrics
Discounted	Statistical/Mathematical-metrics
Cumulative	Statistical/Mathematical-metrics
Gain	Statistical/Mathematical-metrics
(	Statistical/Mathematical-metrics
NDCG	Statistical/Mathematical-metrics
)	Statistical/Mathematical-metrics
.	O

However	O
,	O
the	O
demand	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
and	O
charger	Data/Mining/Information/Retrieval-focus
planning	Data/Mining/Information/Retrieval-focus
depend	O
on	O
each	O
other	O
,	O
and	O
it	O
is	O
required	O
to	O
re	O
-	O
train	O
the	O
prediction	O
model	O
to	O
eliminate	O
the	O
negative	O
transfer	O
between	O
cities	O
for	O
each	O
varied	O
charger	O
plan	O
,	O
leading	O
to	O
the	O
unacceptable	O
time	Miscellaneous-metrics
complexity	Miscellaneous-metrics
.	O

However	O
,	O
the	O
demand	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
and	O
charger	Data/Mining/Information/Retrieval-focus
planning	Data/Mining/Information/Retrieval-focus
depend	O
on	O
each	O
other	O
,	O
and	O
it	O
is	O
required	O
to	O
re	O
-	O
train	O
the	O
prediction	O
model	O
to	O
eliminate	O
the	O
negative	O
transfer	O
between	O
cities	O
for	O
each	O
varied	O
charger	O
plan	O
,	O
leading	O
to	O
the	O
unacceptable	O
time	Miscellaneous-metrics
complexity	Miscellaneous-metrics
.	O

To	O
this	O
end	O
,	O
we	O
design	O
an	O
effective	O
solution	O
of	O
Simultaneous	O
Demand	O
Prediction	O
And	O
Planning	O
(	O
SPAP	O
)	O
discriminative	O
features	O
are	O
extracted	O
from	O
multi	O
-	O
source	O
data	O
,	O
and	O
fed	O
into	O
an	O
Attention	O
-	O
based	O
Spatial	O
-	O
Temporal	O
City	O
Domain	O
Adaptation	O
Network	O
(	O
AST	O
-	O
CDAN	O
)	O
for	O
cross	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
city	Data/Mining/Information/Retrieval-focus
demand	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
a	O
novel	O
Transfer	O
Iterative	O
Optimization	O
(	O
TIO	O
)	O
algorithm	O
is	O
designed	O
for	O
charger	Data/Mining/Information/Retrieval-focus
planning	Data/Mining/Information/Retrieval-focus
AST	O
-	O
CDAN	O
ively	O
utilizing	O
AST	O
-	O
CDAN	O
and	O
a	O
charger	O
plan	O
fine	O
-	O
tuning	O
algorithm	O
.	O

Attributed	Data/Mining/Information/Retrieval-focus
graph	Data/Mining/Information/Retrieval-focus
clustering	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
AGC	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
is	O
an	O
important	O
problem	O
in	O
graph	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
as	O
more	O
and	O
more	O
complex	O
data	O
in	O
real	O
-	O
world	O
have	O
been	O
represented	O
in	O
graphs	O
with	O
attributed	O
nodes	O
.	O

While	O
it	O
is	O
a	O
common	O
practice	O
to	O
leverage	O
both	O
attribute	O
and	O
structure	O
information	O
for	O
improved	O
clustering	AI/ML/DL-focus
performance	O
,	O
most	O
existing	O
AGC	Data/Mining/Information/Retrieval-focus
algorithms	O
AGC	Data/Mining/Information/Retrieval-focus
ider	O
only	O
a	O
specific	O
type	O
of	O
relations	O
,	O
which	O
hinders	O
their	O
applicability	O
to	O
integrate	O
various	O
complex	O
relations	O
into	O
node	O
attributes	O
for	O
AGC	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
GRACE	O
an	O
extended	O
graph	O
convolution	O
framework	O
for	O
AGC	Data/Mining/Information/Retrieval-focus
tasks	O
.	O

The	O
experimental	O
results	O
show	O
that	O
GRACE	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
AGC	Data/Mining/Information/Retrieval-focus
methods	O
on	O
the	O
different	O
graph	O
types	O
in	O
terms	O
of	O
clustering	AI/ML/DL-focus
quality	O
,	O
time	O
,	O
and	O
memory	O
usage	O
.	O

Such	O
a	O
mixed	O
routing	O
problem	O
can	O
be	O
abstracted	O
and	O
formulated	O
as	O
Vehicle	Data/Mining/Information/Retrieval-focus
Routing	Data/Mining/Information/Retrieval-focus
Problem	Data/Mining/Information/Retrieval-focus
with	Data/Mining/Information/Retrieval-focus
Mixed	Data/Mining/Information/Retrieval-focus
Delivery	Data/Mining/Information/Retrieval-focus
and	Data/Mining/Information/Retrieval-focus
Pickup	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
VRPMDP	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
which	O
is	O
an	O
NP	Miscellaneous-focus
-	Miscellaneous-focus
hard	Miscellaneous-focus
combinatorial	Miscellaneous-focus
optimization	Miscellaneous-focus
problem	Miscellaneous-focus
.	O

To	O
solve	O
VRPMDP	Data/Mining/Information/Retrieval-focus
there	O
are	O
three	O
major	O
challenges	O
as	O
below	O
.	O

To	O
solve	O
the	O
challenges	O
above	O
,	O
we	O
design	O
an	O
encoder	O
decoder	O
based	O
framework	O
to	O
generate	O
high	O
-	O
quality	O
and	O
robust	O
VRPMDP	Data/Mining/Information/Retrieval-focus
solutions	O
.	O

First	O
,	O
we	O
consider	O
a	O
VRPMDP	Data/Mining/Information/Retrieval-focus
instance	O
as	O
a	O
graph	O
and	O
utilize	O
a	O
GNN	O
encoder	O
to	O
extract	O
the	O
feature	O
of	O
the	O
instance	O
effectively	O
.	O

It	O
is	O
based	O
on	O
the	O
combination	O
of	O
clustering	AI/ML/DL-focus
and	O
multiple	O
linear	O
regression	O
methods	O
.	O

Negative	Data/Mining/Information/Retrieval-focus
sequential	Data/Mining/Information/Retrieval-focus
pattern	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
SPM	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
SPM	Data/Mining/Information/Retrieval-focus
n	O
important	O
SPM	O
research	O
topic	O
.	O

Unlike	O
positive	Data/Mining/Information/Retrieval-focus
SPM	Data/Mining/Information/Retrieval-focus
negative	Data/Mining/Information/Retrieval-focus
SPM	Data/Mining/Information/Retrieval-focus
can	O
discover	O
events	O
that	O
should	O
have	O
occurred	O
but	O
have	O
not	O
occurred	O
,	O
and	O
it	O
can	O
be	O
used	O
for	O
financial	O
risk	O
management	O
and	O
fraud	O
detection	O
.	O

Centrality	Data/Mining/Information/Retrieval-focus
is	O
a	O
relevant	O
topic	O
in	O
the	O
field	O
of	O
network	Data/Mining/Information/Retrieval-focus
research	Data/Mining/Information/Retrieval-focus
due	O
to	O
its	O
various	O
theoretical	O
and	O
practical	O
implications	O
.	O

In	O
general	O
,	O
all	O
centrality	O
metrics	O
aim	O
at	O
measuring	O
the	O
importance	O
of	O
nodes	O
(	O
according	O
to	O
some	O
definition	O
of	O
importance	O
),	O
and	O
such	O
importance	O
scores	O
are	O
used	O
to	O
rank	O
the	O
nodes	O
in	O
the	O
network	O
,	O
therefore	O
the	O
rank	Data/Mining/Information/Retrieval-focus
improvement	Data/Mining/Information/Retrieval-focus
is	O
a	O
strictly	O
related	O
topic	O
.	O

In	O
a	O
given	O
network	O
,	O
the	O
rank	Data/Mining/Information/Retrieval-focus
improvement	Data/Mining/Information/Retrieval-focus
is	O
achieved	O
by	O
establishing	O
new	O
links	O
,	O
therefore	O
the	O
question	O
shifts	O
to	O
which	O
and	O
how	O
many	O
links	O
should	O
be	O
collected	O
to	O
get	O
a	O
desired	O
rank	O
.	O

This	O
problem	O
,	O
also	O
known	O
as	O
link	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
building	Data/Mining/Information/Retrieval-focus
has	O
been	O
shown	O
to	O
be	O
NP	O
-	O
hard	O
,	O
and	O
most	O
heuristics	O
developed	O
failed	O
in	O
obtaining	O
good	O
performance	O
with	O
acceptable	O
computational	O
complexity	O
.	O

In	O
this	O
article	O
,	O
we	O
present	O
LB	O
–	O
GDM	O
a	O
novel	O
approach	O
that	O
leverages	O
Geometric	O
Deep	O
Learning	O
to	O
tackle	O
the	O
link	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
building	Data/Mining/Information/Retrieval-focus
problem	O
.	O

Map	Data/Mining/Information/Retrieval-focus
matching	Data/Mining/Information/Retrieval-focus
is	O
a	O
fundamental	O
research	O
topic	O
with	O
the	O
objective	O
of	O
aligning	O
GPS	O
trajectories	O
to	O
paths	O
on	O
the	O
road	O
network	O
.	O

Recommender	AI/ML/DL-focus
systems	AI/ML/DL-focus
nowadays	O
are	O
commonly	O
deployed	O
in	O
e	O
-	O
commerce	O
platforms	O
to	O
help	O
customers	O
making	O
purchase	O
decisions	O
.	O

With	O
real	O
-	O
world	O
social	O
media	O
and	O
e	O
-	O
commerce	O
data	O
,	O
we	O
show	O
that	O
the	O
integration	O
can	O
improve	O
accuracy	Classification-metrics
by	O
up	O
to	O
14	O
%	O
while	O
using	O
the	O
same	O
data	O
.	O

Despite	O
substantial	O
interest	O
in	O
applications	O
of	O
neural	O
networks	O
to	O
information	O
retrieval	O
neural	O
ranking	O
models	O
have	O
mostly	O
been	O
applied	O
to	O
conventional	O
ad	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
hoc	Data/Mining/Information/Retrieval-focus
retrieval	Data/Mining/Information/Retrieval-focus
tasks	Data/Mining/Information/Retrieval-focus
over	O
web	O
pages	O
and	O
newswire	O
articles	O
.	O

This	O
article	O
proposes	O
a	O
concept	O
-	O
enhanced	O
pre	O
-	O
training	O
model	O
for	O
microblog	Data/Mining/Information/Retrieval-focus
retrieval	Data/Mining/Information/Retrieval-focus
task	Data/Mining/Information/Retrieval-focus
leveraging	O
Semantic	O
Matching	O
Model	O
(	O
SMM	O
)	O
objective	O
and	O
Concept	O
Correlation	O
Model	O
(	O
CCM	O
)	O
objective	O
.	O

With	O
the	O
wide	O
use	O
of	O
Location	O
-	O
Based	O
Social	O
Networks	O
(	O
LBSNs	O
)	O
predicting	Data/Mining/Information/Retrieval-focus
user	Data/Mining/Information/Retrieval-focus
friendship	Data/Mining/Information/Retrieval-focus
from	O
online	O
social	O
relations	O
and	O
offline	O
trajectory	O
data	O
is	O
of	O
great	O
value	O
to	O
improve	O
the	O
platform	O
service	O
quality	O
and	O
user	O
satisfaction	O
.	O

Existing	O
methods	O
mainly	O
focus	O
on	O
some	O
hand	O
-	O
crafted	O
features	O
or	O
graph	O
embedding	O
models	O
based	O
on	O
the	O
user	O
-	O
location	O
bipartite	O
graph	O
,	O
which	O
cannot	O
precisely	O
capture	O
the	O
latent	O
mobility	O
similarity	O
for	O
the	O
majority	O
of	O
users	O
who	O
have	O
no	O
explicit	O
co	O
-	O
visit	O
behaviors	O
and	O
also	O
fail	O
to	O
balance	O
the	O
tradeoff	O
between	O
social	O
features	O
and	O
mobility	O
features	O
for	O
friendship	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
.	O

Temporal	Data/Mining/Information/Retrieval-focus
link	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
TLP	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
is	O
among	O
the	O
most	O
important	O
graph	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
tasks	O
,	O
capable	O
of	O
predicting	O
dynamic	O
,	O
time	O
-	O
varying	O
links	O
within	O
networks	O
.	O

The	O
key	O
problem	O
of	O
TLP	Data/Mining/Information/Retrieval-focus
is	O
how	O
to	O
explore	O
potential	O
link	O
-	O
evolving	O
tendency	O
from	O
the	O
increasing	O
number	O
of	O
links	O
over	O
time	O
.	O

The	O
experimental	O
results	O
demonstrate	O
that	O
our	O
model	O
outperforms	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
TLP	Data/Mining/Information/Retrieval-focus
methods	O
such	O
as	O
Transformer	O
TGAT	O
and	O
EvolveGCN	O
.	O

It	O
achieves	O
the	O
three	O
highest	O
AUC	Classification-metrics
and	O
four	O
highest	O
precision	Classification-metrics
scores	O
in	O
five	O
different	O
representative	O
dynamic	Data/Mining/Information/Retrieval-focus
networks	Data/Mining/Information/Retrieval-focus
problems	O
.	O

It	O
achieves	O
the	O
three	O
highest	O
AUC	Classification-metrics
and	O
four	O
highest	O
precision	Classification-metrics
scores	O
in	O
five	O
different	O
representative	O
dynamic	Data/Mining/Information/Retrieval-focus
networks	Data/Mining/Information/Retrieval-focus
problems	O
.	O

Time	AI/ML/DL-focus
series	AI/ML/DL-focus
classification	AI/ML/DL-focus
has	O
become	O
an	O
interesting	O
field	O
of	O
research	O
,	O
thanks	O
to	O
the	O
extensive	O
studies	O
conducted	O
in	O
the	O
past	O
two	O
decades	O
.	O

Multiple	Data/Mining/Information/Retrieval-focus
imputation	Data/Mining/Information/Retrieval-focus
is	O
a	O
data	O
recovery	O
method	O
where	O
it	O
produced	O
multiple	O
imputed	O
data	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
two	O
multiple	Data/Mining/Information/Retrieval-focus
imputation	Data/Mining/Information/Retrieval-focus
approaches	O
for	O
time	O
series	O
.	O

The	O
first	O
is	O
a	O
multiple	Data/Mining/Information/Retrieval-focus
imputation	Data/Mining/Information/Retrieval-focus
method	O
based	O
on	O
interpolation	O
.	O

The	O
second	O
is	O
a	O
multiple	Data/Mining/Information/Retrieval-focus
imputation	Data/Mining/Information/Retrieval-focus
and	O
ensemble	O
method	O
.	O

First	O
,	O
we	O
simulate	O
missing	O
consecutive	O
sub	O
-	O
sequences	O
under	O
a	O
Missing	O
Completely	O
at	O
Random	O
mechanism	O
;	O
then	O
,	O
we	O
use	O
single	O
/	O
multiple	Data/Mining/Information/Retrieval-focus
imputation	Data/Mining/Information/Retrieval-focus
methods	O
.	O

Our	O
findings	O
show	O
that	O
the	O
combination	O
of	O
multiple	Data/Mining/Information/Retrieval-focus
imputation	Data/Mining/Information/Retrieval-focus
and	O
ensemble	O
improves	O
the	O
performance	O
of	O
the	O
majority	O
of	O
classifiers	O
tested	O
in	O
this	O
study	O
,	O
often	O
above	O
the	O
performance	O
obtained	O
from	O
the	O
complete	O
data	O
,	O
even	O
under	O
increasing	O
missing	O
data	O
scenarios	O
.	O

This	O
may	O
be	O
because	O
the	O
diversity	O
injected	O
by	O
multiple	Data/Mining/Information/Retrieval-focus
imputation	Data/Mining/Information/Retrieval-focus
has	O
a	O
very	O
favourable	O
and	O
stabilising	O
effect	O
on	O
the	O
classifier	O
performance	O
,	O
which	O
is	O
a	O
very	O
important	O
finding	O
.	O

We	O
introduce	O
CODEtect	O
the	O
first	O
approach	O
that	O
addresses	O
the	O
anomaly	AI/ML/DL-focus
detection	AI/ML/DL-focus
task	O
for	O
graph	O
databases	O
with	O
such	O
complex	O
nature	O
.	O

The	O
anchor	O
graph	O
structure	O
has	O
been	O
widely	O
used	O
to	O
speed	O
up	O
large	O
-	O
scale	O
multi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
view	Data/Mining/Information/Retrieval-focus
clustering	Data/Mining/Information/Retrieval-focus
and	O
exhibited	O
promising	O
performance	O
.	O

To	O
overcome	O
these	O
drawbacks	O
,	O
we	O
propose	O
a	O
novel	O
structural	O
fusion	O
framework	O
to	O
integrate	O
the	O
multi	O
-	O
view	O
anchor	O
graphs	O
for	O
clustering	AI/ML/DL-focus
.	O

Different	O
from	O
traditional	O
integration	O
strategies	O
,	O
we	O
merge	O
the	O
anchors	O
and	O
edges	O
of	O
all	O
the	O
view	O
-	O
specific	O
anchor	O
graphs	O
into	O
a	O
single	O
graph	O
for	O
the	O
structural	O
optimal	Data/Mining/Information/Retrieval-focus
graph	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
.	O

By	O
leveraging	O
the	O
potential	O
structural	O
consistency	O
among	O
each	O
anchor	O
graph	O
a	O
connectivity	O
constraint	O
is	O
imposed	O
on	O
the	O
target	O
graph	O
to	O
indicate	O
clusters	O
directly	O
without	O
any	O
post	O
-	O
processing	O
such	O
as	O
k	O
-	O
means	O
in	O
classical	O
spectral	Data/Mining/Information/Retrieval-focus
clustering	Data/Mining/Information/Retrieval-focus
.	O

To	O
solve	O
this	O
task	O
,	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
label	AI/ML/DL-focus
learning	AI/ML/DL-focus
methods	O
emerged	O
in	O
recent	O
years	O
.	O

Graph	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
based	Data/Mining/Information/Retrieval-focus
multi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
view	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
has	O
attracted	O
much	O
attention	O
due	O
to	O
the	O
efficacy	O
of	O
fusing	O
the	O
information	O
from	O
different	O
views	O
.	O

Specifically	O
,	O
different	O
from	O
existing	O
anchor	O
-	O
based	O
methods	O
where	O
anchors	O
are	O
obtained	O
from	O
key	O
samples	O
by	O
clustering	AI/ML/DL-focus
or	O
weighted	O
averaging	O
strategies	O
in	O
this	O
article	O
,	O
the	O
anchors	O
are	O
learned	O
in	O
a	O
principled	O
fashion	O
which	O
aims	O
at	O
constructing	O
a	O
distance	O
-	O
preserving	O
embedding	O
for	O
each	O
view	O
from	O
samples	O
to	O
their	O
representations	O
,	O
whose	O
elements	O
are	O
the	O
weights	O
of	O
the	O
edges	O
linking	O
corresponding	O
samples	O
and	O
anchors	O
.	O

In	O
most	O
domains	O
,	O
anomaly	AI/ML/DL-focus
detection	AI/ML/DL-focus
is	O
typically	O
cast	O
as	O
an	O
unsupervised	O
learning	O
problem	O
because	O
of	O
the	O
infeasibility	O
of	O
labeling	O
large	O
datasets	O
.	O

In	O
this	O
setup	O
,	O
the	O
evaluation	O
and	O
comparison	O
of	O
different	O
anomaly	AI/ML/DL-focus
detection	AI/ML/DL-focus
algorithms	O
is	O
difficult	O
.	O

Therefore	O
,	O
in	O
this	O
article	O
,	O
we	O
propose	O
an	O
equivalence	O
criterion	O
for	O
anomaly	AI/ML/DL-focus
detection	AI/ML/DL-focus
anomaly	AI/ML/DL-focus
detection	AI/ML/DL-focus
asures	O
to	O
what	O
degree	O
two	O
anomaly	O
detection	O
algorithms	O
detect	O
the	O
same	O
kind	O
of	O
anomalies	O
.	O

For	O
the	O
real	O
-	O
world	O
dataset	O
,	O
we	O
show	O
how	O
GEC	O
can	O
provide	O
insight	O
about	O
the	O
anomaly	AI/ML/DL-focus
detection	AI/ML/DL-focus
algorithms	O
as	O
well	O
as	O
the	O
dataset	O
.	O

Traditional	O
embedding	O
methodologies	O
,	O
also	O
known	O
as	O
dimensionality	AI/ML/DL-focus
reduction	AI/ML/DL-focus
techniques	O
,	O
assume	O
the	O
availability	O
of	O
exact	O
pairwise	O
distances	O
between	O
the	O
high	O
-	O
dimensional	O
objects	O
that	O
will	O
be	O
embedded	O
in	O
a	O
lower	O
dimensionality	O
.	O

Structured	NLP-focus
text	NLP-focus
classification	NLP-focus
is	O
attracting	O
more	O
attention	O
in	O
natural	O
language	O
processing	O
due	O
to	O
the	O
increasing	O
complexity	O
of	O
application	O
scenarios	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
HGMETA	O
a	O
novel	O
meta	O
-	O
information	O
embedding	O
frame	O
network	O
for	O
structured	Data/Mining/Information/Retrieval-focus
text	Data/Mining/Information/Retrieval-focus
classification	Data/Mining/Information/Retrieval-focus
to	O
obtain	O
the	O
fusion	O
embedding	O
of	O
hierarchical	O
semantics	O
dependency	O
and	O
graph	O
structure	O
structured	O
text	O
text	O
,	O
and	O
to	O
distill	O
the	O
meta	O
-	O
information	O
from	O
fusion	O
characteristics	O
.	O

Finally	O
,	O
the	O
fusion	O
embedding	O
and	O
the	O
meta	O
-	O
information	O
can	O
be	O
straightforwardly	O
incorporated	O
for	O
structured	NLP-focus
text	NLP-focus
classification	NLP-focus
.	O

Potential	Data/Mining/Information/Retrieval-focus
transmission	Data/Mining/Information/Retrieval-focus
cluster	Data/Mining/Information/Retrieval-focus
discovery	Data/Mining/Information/Retrieval-focus
is	O
to	O
find	O
all	O
suspected	O
users	O
with	O
infections	O
,	O
which	O
is	O
greatly	O
needed	O
to	O
fast	O
discover	O
virus	O
transmission	O
chains	O
so	O
as	O
to	O
prevent	O
an	O
outbreak	O
of	O
COVID	O
-	O
19	O
as	O
early	O
as	O
possible	O
.	O

In	O
this	O
article	O
,	O
we	O
study	O
the	O
problem	O
of	O
potential	Data/Mining/Information/Retrieval-focus
transmission	Data/Mining/Information/Retrieval-focus
cluster	Data/Mining/Information/Retrieval-focus
discovery	Data/Mining/Information/Retrieval-focus
based	O
on	O
the	O
spatio	O
-	O
temporal	O
logs	O
.	O

Leveraging	O
two	O
well	O
-	O
designed	O
techniques	O
of	O
spatio	O
-	O
temporal	O
compression	O
and	O
graph	O
partition	O
on	O
bipartite	O
contact	O
graphs	O
our	O
BCG	O
-	O
index	O
approach	O
achieves	O
a	O
good	O
balance	O
of	O
index	Data/Mining/Information/Retrieval-focus
construction	Data/Mining/Information/Retrieval-focus
and	O
online	Data/Mining/Information/Retrieval-focus
query	Data/Mining/Information/Retrieval-focus
processing	Data/Mining/Information/Retrieval-focus
to	O
fast	O
discover	O
potential	O
transmission	O
cluster	O
.	O

A	O
battery	O
of	O
eye	O
-	O
tracking	O
video	O
stimuli	O
was	O
used	O
in	O
the	O
study	O
,	O
including	O
Activity	Data/Mining/Information/Retrieval-focus
Monitoring	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
AM	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
Social	Data/Mining/Information/Retrieval-focus
Referencing	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
SR	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
Theory	Data/Mining/Information/Retrieval-focus
of	Data/Mining/Information/Retrieval-focus
Mind	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
ToM	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
and	O
Dyadic	Data/Mining/Information/Retrieval-focus
Bid	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
DB	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
tasks	O
.	O

Spatio	O
-	O
Temporal	O
scan	O
-	O
paths	O
that	O
incorporate	O
velocity	O
of	O
eye	O
movement	O
in	O
their	O
images	O
of	O
eye	O
-	O
gaze	O
are	O
shown	O
to	O
outperform	O
other	O
feature	O
representation	O
methods	O
achieving	O
classification	AI/ML/DL-focus
accuracy	Classification-metrics
of	O
80	O
.	O
25	O
%	O
Conclusion	O
:	O
The	O
results	O
indicate	O
the	O
feasibility	O
of	O
scan	O
-	O
path	O
images	O
to	O
stratify	O
ASD	O
and	O
TD	O
diagnosis	O
in	O
children	O
of	O
varying	O
ages	O
and	O
gender	O
.	O

Spatio	O
-	O
Temporal	O
scan	O
-	O
paths	O
that	O
incorporate	O
velocity	O
of	O
eye	O
movement	O
in	O
their	O
images	O
of	O
eye	O
-	O
gaze	O
are	O
shown	O
to	O
outperform	O
other	O
feature	O
representation	O
methods	O
achieving	O
classification	AI/ML/DL-focus
accuracy	Classification-metrics
of	O
80	O
.	O
25	O
%	O
Conclusion	O
:	O
The	O
results	O
indicate	O
the	O
feasibility	O
of	O
scan	O
-	O
path	O
images	O
to	O
stratify	O
ASD	O
and	O
TD	O
diagnosis	O
in	O
children	O
of	O
varying	O
ages	O
and	O
gender	O
.	O

Infusion	O
of	O
temporal	O
information	O
and	O
velocity	O
data	O
improves	O
the	O
classification	AI/ML/DL-focus
performance	O
of	O
our	O
deep	O
learning	O
models	O
.	O

Effective	O
time	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
series	Data/Mining/Information/Retrieval-focus
forecasting	Data/Mining/Information/Retrieval-focus
methods	O
are	O
of	O
significant	O
importance	O
to	O
solve	O
a	O
broad	O
spectrum	O
of	O
research	O
problems	O
.	O

In	O
particular	O
,	O
a	O
relational	O
global	O
model	O
learns	O
complex	O
non	O
-	O
linear	O
time	O
-	O
series	O
patterns	O
globally	O
using	O
the	O
structure	O
of	O
the	O
graph	O
to	O
improve	O
both	O
forecasting	O
accuracy	Classification-metrics
and	O
computational	O
efficiency	O
.	O

The	O
experiments	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
deep	O
hybrid	O
graph	O
-	O
based	O
forecasting	O
model	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
its	O
forecasting	O
accuracy	Classification-metrics
runtime	O
and	O
scalability	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
an	O
online	O
incremental	O
learning	O
framework	O
for	O
probabilistic	Data/Mining/Information/Retrieval-focus
forecasting	Data/Mining/Information/Retrieval-focus
.	O

The	O
framework	O
is	O
theoretically	O
proven	O
to	O
have	O
lower	O
time	O
and	O
space	Miscellaneous-metrics
complexity	Miscellaneous-metrics
.	O

Recent	O
advancements	O
in	O
deep	O
learning	O
techniques	O
have	O
transformed	O
the	O
area	O
of	O
semantic	NLP-focus
text	NLP-focus
matching	NLP-focus
(	NLP-focus
STM	NLP-focus
)	NLP-focus
.	O

Besides	O
outperforming	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
the	O
document	NLP-focus
matching	NLP-focus
task	O
,	O
CoLDE	O
is	O
also	O
robust	O
to	O
changes	O
in	O
document	O
length	O
and	O
text	O
perturbations	O
and	O
provides	O
interpretable	O
results	O
.	O

Crowdsourcing	Data/Mining/Information/Retrieval-focus
techniques	Data/Mining/Information/Retrieval-focus
have	O
been	O
extensively	O
explored	O
in	O
the	O
past	O
decade	O
,	O
including	O
task	Data/Mining/Information/Retrieval-focus
allocation	Data/Mining/Information/Retrieval-focus
quality	Data/Mining/Information/Retrieval-focus
assessment	Data/Mining/Information/Retrieval-focus
and	O
so	O
on	O
.	O

In	O
this	O
article	O
,	O
we	O
study	O
the	O
problem	O
of	O
pricing	Data/Mining/Information/Retrieval-focus
crowdsourcing	Data/Mining/Information/Retrieval-focus
tasks	Data/Mining/Information/Retrieval-focus
with	O
optional	O
bonuses	O
.	O

Next	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
item	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
involves	O
predicting	O
the	O
next	O
item	O
of	O
interest	O
of	O
a	O
given	O
user	O
from	O
their	O
past	O
behavior	O
.	O

Most	O
existing	O
next	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
item	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
methods	O
aim	O
at	O
extracting	O
the	O
main	O
point	O
of	O
interest	O
in	O
each	O
browsing	O
session	O
and	O
encapsulate	O
it	O
in	O
a	O
single	O
representation	O
.	O

In	O
experiments	O
,	O
the	O
proposed	O
method	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
session	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
based	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
systems	Data/Mining/Information/Retrieval-focus
on	O
three	O
real	O
-	O
world	O
datasets	O
,	O
achieving	O
4	O
%	O
improvement	O
of	O
Recall	Classification-metrics
over	O
the	O
SOTAs	O
on	O
Jdata	O
dataset	O
.	O

In	O
experiments	O
,	O
the	O
proposed	O
method	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
session	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
based	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
systems	Data/Mining/Information/Retrieval-focus
on	O
three	O
real	O
-	O
world	O
datasets	O
,	O
achieving	O
4	O
%	O
improvement	O
of	O
Recall	Classification-metrics
over	O
the	O
SOTAs	O
on	O
Jdata	O
dataset	O
.	O

Textual	O
reviews	O
contain	O
rich	O
semantic	O
information	O
that	O
is	O
useful	O
for	O
making	O
better	O
recommendation	Data/Mining/Information/Retrieval-focus
semantic	O
information	O
ormation	O
may	O
indicate	O
more	O
fine	O
-	O
grained	O
preferences	O
of	O
users	O
.	O

Recent	O
efforts	O
make	O
considerable	O
improvement	O
on	O
recommendation	Data/Mining/Information/Retrieval-focus
by	O
integrating	O
textual	O
reviews	O
in	O
rating	O
-	O
based	O
recommendations	O
.	O

However	O
,	O
there	O
still	O
exist	O
major	O
challenges	O
on	O
integrating	O
textual	O
reviews	O
for	O
recommendation	Data/Mining/Information/Retrieval-focus
.	O

Multi	AI/ML/DL-focus
-	AI/ML/DL-focus
label	AI/ML/DL-focus
learning	AI/ML/DL-focus
deals	O
with	O
the	O
problem	O
where	O
an	O
instance	O
is	O
associated	O
with	O
multiple	O
labels	O
simultaneously	O
.	O

As	O
an	O
important	O
machine	O
learning	O
task	O
,	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
label	AI/ML/DL-focus
feature	AI/ML/DL-focus
selection	AI/ML/DL-focus
has	O
received	O
considerable	O
attention	O
in	O
recent	O
years	O
due	O
to	O
its	O
promising	O
performance	O
in	O
dealing	O
with	O
high	O
-	O
dimensional	O
multi	O
-	O
label	O
data	O
.	O

Specifically	O
,	O
GLFS	O
employs	O
linear	O
regression	O
and	O
ℓ2	O
,	O
1	O
-	O
norm	O
on	O
the	O
regression	O
parameters	O
to	O
achieve	O
simultaneous	O
global	O
and	O
local	AI/ML/DL-focus
feature	AI/ML/DL-focus
selection	AI/ML/DL-focus
.	O

Moreover	O
,	O
the	O
proposed	O
algorithm	O
has	O
an	O
effective	O
mechanism	O
for	O
utilizing	O
label	O
correlations	O
to	O
improve	O
the	O
feature	AI/ML/DL-focus
selection	AI/ML/DL-focus
.	O

Through	O
extensive	O
tests	O
,	O
we	O
demonstrate	O
that	O
the	O
new	O
method	O
significantly	O
outperforms	O
ABBA	O
with	O
a	O
considerable	O
reduction	O
in	O
runtime	O
while	O
also	O
outperforming	O
the	O
popular	O
SAX	O
and	O
1d	O
-	O
SAX	O
representations	O
in	O
terms	O
of	O
reconstruction	Classification-metrics
accuracy	Classification-metrics
.	O

Graph	Data/Mining/Information/Retrieval-focus
pattern	Data/Mining/Information/Retrieval-focus
matching	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
GPM	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
is	O
widely	O
used	O
in	O
social	O
network	O
analysis	O
such	O
as	O
expert	O
finding	O
social	O
group	O
query	O
and	O
social	O
position	O
detection	O
.	O

Technically	O
,	O
GPM	Data/Mining/Information/Retrieval-focus
is	O
to	O
find	O
matched	O
subgraphs	O
that	O
meet	O
the	O
requirements	O
of	O
pattern	O
graphs	O
in	O
big	O
social	O
networks	O
.	O

However	O
,	O
the	O
existing	O
GPM	Data/Mining/Information/Retrieval-focus
methods	O
focus	O
on	O
shortening	O
the	O
matching	O
time	O
and	O
without	O
considering	O
the	O
preference	O
of	O
the	O
decision	O
maker	O
(	O
DM	O
)	O
DM	O
ich	O
makes	O
it	O
difficult	O
for	O
the	O
DM	O
to	O
find	O
ideal	O
teams	O
from	O
numerous	O
matches	O
to	O
complete	O
the	O
assigned	O
task	O
.	O

In	O
this	O
article	O
,	O
as	O
for	O
the	O
process	O
of	O
graph	Data/Mining/Information/Retrieval-focus
pattern	Data/Mining/Information/Retrieval-focus
matching	Data/Mining/Information/Retrieval-focus
and	O
rematching	Data/Mining/Information/Retrieval-focus
with	O
a	O
preferred	O
expert	O
set	O
,	O
i	O
.	O
e	O
.,	O
the	O
DM	O
hopes	O
that	O
one	O
or	O
more	O
experts	O
in	O
this	O
set	O
will	O
appear	O
in	O
matched	O
subgraphs	O
,	O
we	O
propose	O
a	O
Dual	O
Simulation	O
-	O
based	O
Edge	O
Sequencing	O
-	O
oriented	O
Semi	O
-	O
Supervised	O
GPM	O
method	O
(	O
DsEs	O
-	O
ssGPM	O
)	O
.	O

Especially	O
,	O
as	O
for	O
the	O
rematching	O
process	O
,	O
when	O
the	O
preferred	O
and	O
/	O
or	O
the	O
dispreferred	O
expert	O
sets	O
change	O
continuously	O
,	O
to	O
process	O
the	O
GPM	Data/Mining/Information/Retrieval-focus
again	O
is	O
unnecessary	O
and	O
it	O
is	O
possible	O
to	O
revise	O
the	O
previous	O
matched	O
results	O
partially	O
with	O
DsEs	O
-	O
ssGPM	O
methods	O
.	O

Multi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
view	Data/Mining/Information/Retrieval-focus
clustering	Data/Mining/Information/Retrieval-focus
clustering	AI/ML/DL-focus
at	O
boosting	O
the	O
clustering	O
performance	O
by	O
leveraging	O
the	O
individual	O
information	O
and	O
the	O
common	O
information	O
of	O
multi	O
-	O
view	O
data	O
has	O
gained	O
extensive	O
consideration	O
in	O
recent	O
years	O
.	O

However	O
,	O
most	O
existing	O
multi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
view	Data/Mining/Information/Retrieval-focus
clustering	Data/Mining/Information/Retrieval-focus
algorithms	O
either	O
focus	O
on	O
extracting	O
the	O
multi	O
-	O
view	O
individuality	O
or	O
emphasize	O
on	O
exploring	O
the	O
multi	O
-	O
view	O
commonality	O
neither	O
of	O
which	O
can	O
fully	O
utilize	O
the	O
comprehensive	O
information	O
from	O
multiple	O
views	O
.	O

To	O
this	O
end	O
,	O
we	O
propose	O
a	O
novel	O
algorithm	O
named	O
View	O
-	O
specific	O
and	O
Consensus	O
Graph	O
Alignment	O
(	O
VCGA	O
)	O
for	O
multi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
view	Data/Mining/Information/Retrieval-focus
clustering	Data/Mining/Information/Retrieval-focus
which	O
simultaneously	O
formulates	O
the	O
multi	O
-	O
view	O
individuality	O
and	O
the	O
multi	O
-	O
view	O
commonality	O
into	O
a	O
unified	O
framework	O
to	O
effectively	O
partition	O
data	O
points	O
.	O

Furthermore	O
,	O
the	O
view	O
-	O
specific	O
graphs	O
of	O
different	O
views	O
and	O
the	O
consensus	O
graph	O
are	O
aligned	O
into	O
an	O
informative	O
target	O
graph	O
,	O
which	O
is	O
employed	O
as	O
a	O
crucial	O
input	O
to	O
the	O
standard	O
spectral	O
clustering	O
clustering	AI/ML/DL-focus
clustering	O
.	O

Extensive	O
experimental	O
results	O
on	O
six	O
benchmark	O
datasets	O
demonstrate	O
the	O
superiority	O
of	O
our	O
method	O
against	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
clustering	AI/ML/DL-focus
algorithms	O
.	O

Signed	Data/Mining/Information/Retrieval-focus
link	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
in	O
graphs	O
is	O
an	O
important	O
problem	O
that	O
has	O
applications	O
in	O
diverse	O
domains	O
.	O

It	O
is	O
a	O
binary	AI/ML/DL-focus
classification	AI/ML/DL-focus
problem	O
that	O
predicts	O
whether	O
an	O
edge	O
between	O
a	O
pair	O
of	O
nodes	O
is	O
positive	O
or	O
negative	O
.	O

Existing	O
approaches	O
for	O
link	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
in	O
unsigned	O
networks	O
cannot	O
be	O
directly	O
applied	O
for	O
signed	O
link	O
prediction	O
due	O
to	O
their	O
inherent	O
differences	O
.	O

Furthermore	O
,	O
signed	Data/Mining/Information/Retrieval-focus
link	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
must	O
consider	O
the	O
inherent	O
characteristics	O
of	O
signed	O
networks	O
,	O
such	O
as	O
structural	O
balance	O
theory	O
.	O

Recent	O
signed	Data/Mining/Information/Retrieval-focus
link	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
approaches	O
generate	O
node	O
representations	O
using	O
either	O
generative	O
models	O
or	O
discriminative	O
models	O
.	O

Traffic	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
is	O
the	O
cornerstone	O
of	O
intelligent	O
transportation	O
system	O
.	O

To	O
address	O
the	O
above	O
challenges	O
,	O
in	O
this	O
article	O
,	O
we	O
propose	O
a	O
novel	O
traffic	Data/Mining/Information/Retrieval-focus
prediction	Data/Mining/Information/Retrieval-focus
framework	O
,	O
named	O
Dynamic	O
Graph	O
Convolutional	O
Recurrent	O
Network	O
(	O
DGCRN	O
)	O
.	O

Utility	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
driven	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
is	O
an	O
important	O
task	O
in	O
data	O
science	O
and	O
has	O
many	O
applications	O
in	O
real	O
life	O
.	O

High	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
utility	Data/Mining/Information/Retrieval-focus
sequential	Data/Mining/Information/Retrieval-focus
pattern	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
HUSPM	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
is	O
one	O
kind	O
of	O
utility	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
driven	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
.	O

However	O
,	O
the	O
existing	O
algorithms	O
of	O
HUSPM	Data/Mining/Information/Retrieval-focus
can	O
not	O
provide	O
a	O
relatively	O
accurate	O
probability	O
to	O
deal	O
with	O
some	O
scenarios	O
for	O
prediction	O
or	O
recommendation	O
.	O

Knowledge	Data/Mining/Information/Retrieval-focus
Graph	Data/Mining/Information/Retrieval-focus
Completion	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
KGC	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
aims	O
at	O
inferring	O
missing	O
entities	O
or	O
relations	O
by	O
embedding	O
them	O
in	O
a	O
low	O
-	O
dimensional	O
space	O
.	O

However	O
,	O
most	O
existing	O
KGC	Data/Mining/Information/Retrieval-focus
methods	O
generally	O
fail	O
to	O
handle	O
the	O
complex	O
concepts	O
hidden	O
in	O
triplets	O
,	O
so	O
the	O
learned	O
embeddings	O
of	O
entities	O
or	O
relations	O
may	O
deviate	O
from	O
the	O
true	O
situation	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
a	O
novel	O
Multi	O
-	O
concept	O
Representation	O
Learning	O
(	O
McRL	O
)	O
method	O
for	O
the	O
KGC	Data/Mining/Information/Retrieval-focus
task	O
,	O
which	O
mainly	O
consists	O
of	O
a	O
multi	O
-	O
concept	O
representation	O
module	O
a	O
deep	O
residual	O
attention	O
module	O
and	O
an	O
interaction	O
embedding	O
module	O
.	O

We	O
conduct	O
the	O
link	O
prediction	O
experiment	O
to	O
evaluate	O
the	O
proposed	O
method	O
on	O
several	O
standard	O
datasets	O
,	O
and	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
outperforms	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
KGC	Data/Mining/Information/Retrieval-focus
methods	O
.	O

Entity	NLP-focus
resolution	NLP-focus
(	NLP-focus
ER	NLP-focus
)	NLP-focus
is	O
the	O
process	O
of	O
linking	O
records	O
that	O
refer	O
to	O
the	O
same	O
entity	O
.	O

Text	NLP-focus
augmentation	NLP-focus
is	O
a	O
strategy	O
for	O
increasing	O
the	O
diversity	O
of	O
training	O
examples	O
without	O
explicitly	O
collecting	O
new	O
data	O
.	O

Owing	O
to	O
the	O
efficiency	O
and	O
effectiveness	O
of	O
text	NLP-focus
augmentation	NLP-focus
numerous	O
augmentation	O
methodologies	O
have	O
been	O
proposed	O
.	O

That	O
is	O
,	O
even	O
if	O
a	O
word	O
that	O
has	O
a	O
critical	O
effect	O
on	O
the	O
classification	AI/ML/DL-focus
result	O
is	O
manipulated	O
,	O
it	O
is	O
not	O
considered	O
significant	O
in	O
labeling	O
the	O
augmented	O
data	O
.	O

Therefore	O
,	O
in	O
this	O
study	O
,	O
we	O
propose	O
an	O
effective	O
text	NLP-focus
augmentation	NLP-focus
technique	O
that	O
explicitly	O
derives	O
the	O
importance	O
of	O
manipulated	O
words	O
and	O
reflects	O
this	O
importance	O
in	O
the	O
labeling	O
of	O
augmented	O
data	O
.	O

In	O
recommendation	O
systems	O
,	O
the	O
existence	O
of	O
the	O
missing	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
not	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
at	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
random	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
MNAR	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
problem	O
results	O
in	O
the	O
selection	O
bias	O
issue	O
,	O
degrading	O
the	O
recommendation	O
performance	O
ultimately	O
.	O

A	O
common	O
practice	O
to	O
address	O
MNAR	Data/Mining/Information/Retrieval-focus
is	O
to	O
treat	O
missing	O
entries	O
from	O
the	O
so	O
-	O
called	O
“	O
exposure	O
”	O
perspective	O
,	O
i	O
.	O
e	O
.,	O
modeling	O
how	O
an	O
item	O
is	O
exposed	O
(	O
provided	O
)	O
to	O
a	O
user	O
.	O

In	O
general	O
,	O
DENC	O
provides	O
a	O
causal	O
analysis	O
on	O
MNAR	Data/Mining/Information/Retrieval-focus
from	O
both	O
the	O
inherent	O
factors	O
(	O
e	O
.	O
g	O
.,	O
latent	O
user	O
or	O
item	O
factors	O
)	O
and	O
auxiliary	O
network	O
’	O
s	O
perspective	O
.	O

Nearest	AI/ML/DL-focus
neighbor	AI/ML/DL-focus
search	AI/ML/DL-focus
aims	O
at	O
obtaining	O
the	O
samples	O
in	O
the	O
database	O
with	O
the	O
smallest	O
distances	O
from	O
them	O
to	O
the	O
queries	O
,	O
which	O
is	O
a	O
basic	O
task	O
in	O
a	O
range	O
of	O
fields	O
,	O
including	O
computer	O
vision	O
and	O
data	O
mining	O
.	O

Moreover	O
,	O
deep	O
unsupervised	O
hashing	O
is	O
categorized	O
into	O
similarity	O
reconstruction	O
-	O
based	O
methods	O
pseudo	O
-	O
label	O
-	O
based	O
methods	O
and	O
prediction	O
-	O
free	O
self	O
-	O
supervised	O
learning	O
-	O
based	O
methods	O
based	O
on	O
their	O
semantic	AI/ML/DL-focus
learning	AI/ML/DL-focus
manners	O
.	O

Based	O
on	O
the	O
analysis	O
of	O
conditions	O
for	O
a	O
good	O
distance	Data/Mining/Information/Retrieval-focus
function	Data/Mining/Information/Retrieval-focus
we	O
found	O
four	O
rules	O
that	O
should	O
be	O
fulfilled	O
.	O

Then	O
,	O
we	O
introduce	O
two	O
new	O
distance	Data/Mining/Information/Retrieval-focus
functions	Data/Mining/Information/Retrieval-focus
a	O
metric	O
and	O
a	O
pseudometric	O
one	O
.	O

We	O
rank	O
distance	Data/Mining/Information/Retrieval-focus
functions	Data/Mining/Information/Retrieval-focus
according	O
to	O
several	O
criteria	O
and	O
tests	O
.	O

We	O
have	O
found	O
that	O
the	O
new	O
distance	Data/Mining/Information/Retrieval-focus
functions	Data/Mining/Information/Retrieval-focus
distance	Data/Mining/Information/Retrieval-focus
functions	Data/Mining/Information/Retrieval-focus
mong	O
the	O
four	O
or	O
five	O
best	O
out	O
of	O
23	O
distance	O
functions	O
.	O

Our	O
results	O
show	O
that	O
a	O
suitable	O
distance	Data/Mining/Information/Retrieval-focus
function	Data/Mining/Information/Retrieval-focus
can	O
improve	O
behavior	O
of	O
distance	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
based	Data/Mining/Information/Retrieval-focus
classification	Data/Mining/Information/Retrieval-focus
rules	O
.	O

After	O
training	O
the	O
accuracy	Classification-metrics
of	O
the	O
prediction	O
model	O
can	O
reach	O
up	O
to	O
82	O
%	O
.	O

The	O
result	O
has	O
proven	O
not	O
only	O
the	O
outperformance	O
of	O
our	O
proposed	O
rainfall	O
prediction	O
method	O
in	O
terms	O
of	O
cost	O
and	O
prediction	O
time	O
,	O
but	O
also	O
its	O
accuracy	Classification-metrics
and	O
feasibility	O
compared	O
with	O
general	O
prediction	O
methods	O
.	O

This	O
branch	O
of	O
continual	AI/ML/DL-focus
learning	AI/ML/DL-focus
is	O
also	O
referred	O
to	O
as	O
lifelong	AI/ML/DL-focus
learning	AI/ML/DL-focus
(	AI/ML/DL-focus
LL	AI/ML/DL-focus
)	AI/ML/DL-focus
where	O
a	O
major	O
challenge	O
is	O
to	O
minimize	O
catastrophic	AI/ML/DL-focus
forgetting	AI/ML/DL-focus
or	O
forgetting	O
previously	O
learned	O
tasks	O
.	O

While	O
previous	O
work	O
on	O
catastrophic	AI/ML/DL-focus
forgetting	AI/ML/DL-focus
has	O
been	O
focused	O
on	O
vision	O
problems	O
;	O
this	O
work	O
targets	O
time	O
-	O
series	O
data	O
.	O

We	O
present	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
objective	AI/ML/DL-focus
learning	AI/ML/DL-focus
with	O
three	O
loss	O
functions	O
to	O
minimize	O
catastrophic	AI/ML/DL-focus
forgetting	AI/ML/DL-focus
prediction	O
error	O
,	O
and	O
errors	O
in	O
generalizing	O
across	O
label	O
shifts	O
,	O
simultaneously	O
.	O

The	O
task	O
of	O
next	Data/Mining/Information/Retrieval-focus
Point	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
of	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
Interest	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
POI	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
aims	O
at	O
recommending	O
a	O
list	O
of	O
POIs	O
for	O
a	O
user	O
to	O
visit	O
at	O
the	O
next	O
timestamp	O
based	O
on	O
his	O
/	O
her	O
previous	O
interactions	O
,	O
which	O
is	O
valuable	O
for	O
both	O
location	O
-	O
based	O
service	O
providers	O
and	O
users	O
.	O

Additionally	O
,	O
we	O
propose	O
a	O
novel	O
Graph	O
-	O
enhanced	O
Spatial	O
-	O
Temporal	O
network	O
(	O
GSTN	O
)	O
which	O
incorporates	O
user	O
spatial	O
and	O
temporal	O
dependencies	O
for	O
next	Data/Mining/Information/Retrieval-focus
POI	Data/Mining/Information/Retrieval-focus
recommendation	Data/Mining/Information/Retrieval-focus
.	O

Outlier	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
is	O
an	O
important	O
task	O
in	O
data	O
mining	O
and	O
many	O
technologies	O
for	O
it	O
have	O
been	O
explored	O
in	O
various	O
applications	O
.	O

However	O
,	O
owing	O
to	O
the	O
default	O
assumption	O
that	O
outliers	O
are	O
not	O
concentrated	O
,	O
unsupervised	Data/Mining/Information/Retrieval-focus
outlier	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
may	O
not	O
correctly	O
identify	O
group	O
anomalies	O
with	O
higher	O
levels	O
of	O
density	O
.	O

Although	O
high	O
detection	O
rates	O
and	O
optimal	O
parameters	O
can	O
usually	O
be	O
achieved	O
by	O
using	O
supervised	Data/Mining/Information/Retrieval-focus
outlier	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
obtaining	O
a	O
sufficient	O
number	O
of	O
correct	O
labels	O
is	O
a	O
time	O
-	O
consuming	O
task	O
.	O

To	O
solve	O
these	O
problems	O
,	O
we	O
focus	O
on	O
semi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
supervised	Data/Mining/Information/Retrieval-focus
outlier	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
with	O
few	O
identified	O
anomalies	O
and	O
a	O
large	O
amount	O
of	O
unlabeled	O
data	O
.	O

The	O
task	O
of	O
semi	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
supervised	Data/Mining/Information/Retrieval-focus
outlier	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
is	O
first	O
decomposed	O
into	O
the	O
detection	O
of	O
discrete	O
anomalies	O
and	O
that	O
of	O
partially	O
identified	O
group	O
anomalies	O
and	O
a	O
distribution	O
construction	O
sub	O
-	O
module	O
and	O
a	O
data	O
augmentation	O
sub	O
-	O
module	O
are	O
then	O
proposed	O
to	O
identify	O
them	O
,	O
respectively	O
.	O

Extensive	O
experiments	O
on	O
synthetic	O
and	O
real	O
-	O
world	O
data	O
show	O
that	O
the	O
proposed	O
Dual	O
-	O
MGAN	O
can	O
significantly	O
improve	O
the	O
accuracy	O
of	O
outlier	Data/Mining/Information/Retrieval-focus
detection	Data/Mining/Information/Retrieval-focus
and	O
the	O
proposed	O
evaluation	O
indicators	O
can	O
reflect	O
the	O
training	O
status	O
of	O
the	O
sub	O
-	O
GANs	O
.	O

With	O
the	O
rapid	O
development	O
of	O
text	Data/Mining/Information/Retrieval-focus
mining	Data/Mining/Information/Retrieval-focus
many	O
studies	O
observe	O
that	O
text	O
generally	O
contains	O
a	O
variety	O
of	O
implicit	O
information	O
,	O
and	O
it	O
is	O
important	O
to	O
develop	O
techniques	O
for	O
extracting	O
such	O
information	O
.	O

Named	NLP-focus
Entity	NLP-focus
Recognition	NLP-focus
(	NLP-focus
NER	NLP-focus
)	NLP-focus
the	O
first	O
step	O
of	O
information	NLP-focus
extraction	NLP-focus
mainly	O
identifies	O
names	O
of	O
persons	O
,	O
locations	O
,	O
and	O
organizations	O
in	O
text	O
.	O

Recently	O
,	O
diverse	O
studies	O
focus	O
on	O
the	O
nested	NLP-focus
NER	NLP-focus
problem	NLP-focus
and	O
yield	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O

This	O
survey	O
attempts	O
to	O
provide	O
a	O
comprehensive	O
review	O
on	O
existing	O
approaches	O
for	O
nested	NLP-focus
NER	NLP-focus
from	O
the	O
perspectives	O
of	O
the	O
model	O
architecture	O
and	O
the	O
model	O
property	O
,	O
which	O
may	O
help	O
readers	O
have	O
a	O
better	O
understanding	O
of	O
the	O
current	O
research	O
status	O
and	O
ideas	O
.	O

In	O
this	O
survey	O
,	O
we	O
first	O
introduce	O
the	O
background	O
of	O
nested	NLP-focus
NER	NLP-focus
nested	NLP-focus
NER	NLP-focus
NER	NLP-focus
differences	O
between	O
nested	O
NER	O
and	O
traditional	O
(	O
i	O
.	O
e	O
.,	O
flat	O
)	O
NER	O
.	O

We	O
then	O
review	O
the	O
existing	O
nested	NLP-focus
NER	NLP-focus
approaches	O
from	O
2002	O
to	O
2020	O
and	O
mainly	O
classify	O
them	O
into	O
five	O
categories	O
according	O
to	O
the	O
model	O
architecture	O
including	O
early	O
rule	O
-	O
based	O
layered	O
-	O
based	O
region	O
-	O
based	O
hypergraph	O
-	O
based	O
and	O
transition	O
-	O
based	O
approaches	O
.	O

We	O
also	O
explore	O
in	O
greater	O
depth	O
the	O
impact	O
of	O
key	O
properties	O
unique	O
to	O
nested	NLP-focus
NER	NLP-focus
approaches	O
from	O
the	O
model	O
property	O
perspective	O
,	O
namely	NLP-focus
entity	NLP-focus
dependency	NLP-focus
stage	O
framework	O
error	O
propagation	O
and	O
tag	O
scheme	O
.	O

This	O
survey	O
would	O
be	O
useful	O
for	O
three	O
kinds	O
of	O
readers	O
:	O
(	O
i	O
)	O
Newcomers	O
in	O
the	O
field	O
who	O
want	O
to	O
learn	O
about	O
NER	NLP-focus
especially	O
for	O
nested	NLP-focus
NER	NLP-focus
.	O

(	O
ii	O
)	O
Researchers	O
who	O
want	O
to	O
clarify	O
the	O
relationship	O
and	O
advantages	O
between	O
flat	O
NER	NLP-focus
and	O
nested	NLP-focus
NER	NLP-focus
.	O

(	O
iii	O
)	O
Practitioners	O
who	O
just	O
need	O
to	O
determine	O
which	O
NER	NLP-focus
technique	O
(	O
i	O
.	O
e	O
.,	O
nested	O
or	O
not	O
)	O
works	O
best	O
in	O
their	O
applications	O
.	O

Experimentally	O
,	O
we	O
show	O
that	O
the	O
proposed	O
framework	O
is	O
more	O
efficient	O
and	O
effective	O
than	O
existing	O
ADMM	O
based	O
solutions	O
on	O
both	O
synthetic	O
and	O
real	O
-	O
world	O
datasets	O
due	O
to	O
its	O
faster	O
convergence	O
rate	O
and	O
higher	O
accuracy	Classification-metrics
.	O

Experimental	O
results	O
show	O
that	O
ARIS	O
effectively	O
weakens	O
the	O
impact	O
of	O
noise	O
and	O
reduces	O
the	O
amount	O
of	O
data	O
and	O
significantly	O
improves	O
the	O
accuracy	Classification-metrics
of	O
data	O
analysis	O
within	O
a	O
reasonable	O
time	O
cost	O
range	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
the	O
first	O
HIN	O
-	O
assisted	O
contextual	O
bandit	O
framework	O
HIN	O
ch	O
utilizes	O
a	O
given	O
HIN	O
to	O
assist	O
contextual	Data/Mining/Information/Retrieval-focus
bandit	Data/Mining/Information/Retrieval-focus
learning	Data/Mining/Information/Retrieval-focus
.	O

The	O
main	O
challenge	O
is	O
how	O
to	O
leverage	O
these	O
relations	O
,	O
since	O
users	O
’	O
preference	O
over	O
items	O
,	O
the	O
target	O
of	O
our	O
online	AI/ML/DL-focus
learning	AI/ML/DL-focus
are	O
closely	O
related	O
to	O
users	O
’	O
preference	O
over	O
meta	O
-	O
paths	O
.	O

A	O
bandit	O
master	O
is	O
then	O
employed	O
to	O
learn	O
users	O
’	O
preference	O
over	O
meta	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
paths	Data/Mining/Information/Retrieval-focus
to	O
dynamically	O
combine	O
base	O
bandit	O
algorithms	O
with	O
a	O
balance	O
of	O
exploration	O
vs	O
.	O

We	O
introduce	O
the	O
tasks	O
of	O
diagram	Computer/vision-focus
classification	Computer/vision-focus
(	Computer/vision-focus
DC	Computer/vision-focus
)	Computer/vision-focus
and	O
diagram	Computer/vision-focus
question	Computer/vision-focus
answering	Computer/vision-focus
(	Computer/vision-focus
DQA	Computer/vision-focus
)	Computer/vision-focus
based	O
on	O
the	O
new	O
dataset	O
,	O
and	O
propose	O
the	O
Diagram	O
Paring	O
Net	O
(	O
DPN	O
)	O
that	O
focuses	O
on	O
analyzing	O
the	O
topological	O
structure	O
and	O
text	O
information	O
of	O
diagrams	O
.	O

We	O
use	O
DPN	O
based	O
models	O
to	O
solve	O
DC	Computer/vision-focus
and	O
DQA	Computer/vision-focus
tasks	O
,	O
and	O
compare	O
the	O
performances	O
to	O
well	O
-	O
known	O
natural	O
images	O
classification	O
models	O
and	O
visual	O
question	O
answering	O
models	O
.	O

Our	O
experiments	O
show	O
the	O
effectiveness	O
of	O
the	O
proposed	O
DPN	O
based	O
models	O
on	O
diagram	Computer/vision-focus
understanding	Computer/vision-focus
tasks	O
,	O
also	O
indicate	O
that	O
our	O
dataset	O
is	O
more	O
complex	O
compared	O
to	O
previous	O
natural	Computer/vision-focus
image	Computer/vision-focus
understanding	Computer/vision-focus
datasets	O
.	O

The	O
presented	O
dataset	O
opens	O
new	O
challenges	O
for	O
research	O
in	O
diagram	Computer/vision-focus
understanding	Computer/vision-focus
and	O
the	O
DPN	O
method	O
provides	O
a	O
novel	O
perspective	O
for	O
studying	O
such	O
data	O
.	O

What	O
are	O
the	O
key	O
structures	O
existing	O
in	O
a	O
large	O
real	O
-	O
world	O
MMORPG	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
Massively	Data/Mining/Information/Retrieval-focus
Multiplayer	Data/Mining/Information/Retrieval-focus
Online	Data/Mining/Information/Retrieval-focus
Role	Data/Mining/Information/Retrieval-focus
-	Data/Mining/Information/Retrieval-focus
Playing	Data/Mining/Information/Retrieval-focus
Game	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
graph	Data/Mining/Information/Retrieval-focus
How	O
can	O
we	O
compactly	O
summarize	O
an	O
MMORPG	Data/Mining/Information/Retrieval-focus
graph	Data/Mining/Information/Retrieval-focus
with	O
hierarchical	O
node	O
labels	O
considering	O
substructures	O
at	O
different	O
levels	O
of	O
hierarchy	O
?	O
Recent	O
MMORPGs	Data/Mining/Information/Retrieval-focus
generate	O
complex	O
interactions	O
between	O
entities	O
inducing	O
a	O
heterogeneous	O
graph	O
where	O
each	O
entity	O
has	O
hierarchical	O
labels	O
.	O

Succinctly	O
summarizing	O
a	O
heterogeneous	O
MMORPG	Data/Mining/Information/Retrieval-focus
graph	Data/Mining/Information/Retrieval-focus
is	O
crucial	O
to	O
better	O
understand	O
its	O
structure	O
;	O
however	O
it	O
is	O
a	O
challenging	O
task	O
since	O
it	O
needs	O
to	O
handle	O
complex	O
interactions	O
and	O
hierarchical	O
labels	O
efficiently	O
.	O

Experiments	O
on	O
a	O
large	O
real	O
-	O
world	O
MMORPG	Data/Mining/Information/Retrieval-focus
graph	Data/Mining/Information/Retrieval-focus
with	O
multi	O
-	O
million	O
edges	O
show	O
that	O
GSHL	O
is	O
a	O
useful	O
and	O
scalable	O
tool	O
for	O
summarizing	O
the	O
graph	O
,	O
finding	O
important	O
structures	O
in	O
the	O
graph	O
,	O
and	O
finding	O
similar	O
users	O
.	O

Regularization	AI/ML/DL-focus
that	O
incorporates	O
the	O
linear	O
combination	O
of	O
empirical	O
loss	O
and	O
explicit	O
regularization	O
terms	O
as	O
the	O
loss	O
function	O
has	O
been	O
frequently	O
used	O
for	O
many	O
machine	O
learning	O
tasks	O
.	O

While	O
regularized	O
learning	O
often	O
boost	O
the	O
performance	O
with	O
higher	O
accuracy	Classification-metrics
and	O
faster	O
convergence	O
,	O
the	O
regularization	O
would	O
sometimes	O
hurt	O
the	O
empirical	O
loss	O
minimization	O
and	O
lead	O
to	O
poor	O
performance	O
.	O

We	O
propose	O
a	O
framework	O
for	O
building	O
data	O
generation	O
models	O
and	O
evaluating	O
their	O
effectiveness	O
regarding	O
those	O
accuracy	Classification-metrics
and	O
privacy	O
measures	O
.	O

We	O
present	O
a	O
novel	O
and	O
practical	O
deep	O
fully	O
convolutional	O
neural	O
network	O
architecture	O
for	O
semantic	Computer/vision-focus
pixel	Computer/vision-focus
-	Computer/vision-focus
wise	Computer/vision-focus
segmentation	Computer/vision-focus
termed	O
SegNet	O
.	O

The	O
role	O
of	O
the	O
decoder	O
network	O
is	O
to	O
map	O
the	O
low	O
resolution	O
encoder	O
feature	O
maps	O
to	O
full	O
input	O
resolution	O
feature	O
maps	O
for	O
pixel	Computer/vision-focus
-	Computer/vision-focus
wise	Computer/vision-focus
classification	Computer/vision-focus
.	O

This	O
comparison	O
reveals	O
the	O
memory	O
versus	O
accuracy	Classification-metrics
trade	O
-	O
off	O
involved	O
in	O
achieving	O
good	O
segmentation	O
performance	O
.	O

We	O
also	O
performed	O
a	O
controlled	O
benchmark	O
of	O
SegNet	O
and	O
other	O
architectures	O
on	O
both	O
road	O
scenes	O
and	O
SUN	O
RGB	O
-	O
D	O
indoor	Computer/vision-focus
scene	Computer/vision-focus
segmentation	Computer/vision-focus
tasks	O
.	O

Image	Computer/vision-focus
segmentation	Computer/vision-focus
is	O
a	O
key	O
task	O
in	O
computer	O
vision	O
and	O
image	O
processing	O
with	O
important	O
applications	O
such	O
as	O
scene	Computer/vision-focus
understanding	Computer/vision-focus
medical	Computer/vision-focus
image	Computer/vision-focus
analysis	Computer/vision-focus
robotic	O
perception	O
video	O
surveillance	O
augmented	Computer/vision-focus
reality	Computer/vision-focus
and	O
image	Computer/vision-focus
compression	Computer/vision-focus
segmentation	Computer/vision-focus
,	O
and	O
numerous	O
segmentation	O
algorithms	O
are	O
found	O
in	O
the	O
literature	O
.	O

Against	O
this	O
backdrop	O
,	O
the	O
broad	O
success	O
of	O
deep	O
learning	O
(	O
DL	O
)	O
has	O
prompted	O
the	O
development	O
of	O
new	O
image	Computer/vision-focus
segmentation	Computer/vision-focus
approaches	O
leveraging	O
DL	O
models	O
.	O

The	O
field	O
of	O
meta	AI/ML/DL-focus
-	AI/ML/DL-focus
learning	AI/ML/DL-focus
or	O
learning	O
-	O
to	O
-	O
learn	O
,	O
has	O
seen	O
a	O
dramatic	O
rise	O
in	O
interest	O
in	O
recent	O
years	O
.	O

Contrary	O
to	O
conventional	O
approaches	O
to	O
AI	O
where	O
tasks	O
are	O
solved	O
from	O
scratch	O
using	O
a	O
fixed	O
learning	O
algorithm	O
meta	AI/ML/DL-focus
-	AI/ML/DL-focus
learning	AI/ML/DL-focus
learning	O
algorithm	O
learning	O
algorithm	O
itself	O
,	O
given	O
the	O
experience	O
of	O
multiple	O
learning	O
episodes	O
.	O

This	O
survey	O
describes	O
the	O
contemporary	O
meta	AI/ML/DL-focus
-	AI/ML/DL-focus
learning	AI/ML/DL-focus
landscape	O
.	O

We	O
first	O
discuss	O
definitions	O
of	O
meta	AI/ML/DL-focus
-	AI/ML/DL-focus
learning	AI/ML/DL-focus
and	O
position	O
it	O
with	O
respect	O
to	O
related	O
fields	O
,	O
such	O
as	O
transfer	AI/ML/DL-focus
learning	AI/ML/DL-focus
and	O
hyperparameter	AI/ML/DL-focus
optimization	AI/ML/DL-focus
.	O

We	O
then	O
propose	O
a	O
new	O
taxonomy	O
that	O
provides	O
a	O
more	O
comprehensive	O
breakdown	O
of	O
the	O
space	O
of	O
meta	AI/ML/DL-focus
-	AI/ML/DL-focus
learning	AI/ML/DL-focus
methods	O
today	O
.	O

We	O
survey	O
promising	O
applications	O
and	O
successes	O
of	O
meta	AI/ML/DL-focus
-	AI/ML/DL-focus
learning	AI/ML/DL-focus
such	O
as	O
few	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
learning	AI/ML/DL-focus
and	O
reinforcement	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

We	O
present	O
SR3	O
an	O
approach	O
to	O
image	Computer/vision-focus
Super	Computer/vision-focus
-	Computer/vision-focus
Resolution	Computer/vision-focus
via	Computer/vision-focus
Repeated	Computer/vision-focus
Refinement	Computer/vision-focus
.	O

2015	O
)	O
to	O
image	Computer/vision-focus
-	Computer/vision-focus
to	Computer/vision-focus
-	Computer/vision-focus
image	Computer/vision-focus
translation	Computer/vision-focus
and	O
performs	O
super	O
-	O
resolution	O
through	O
a	O
stochastic	O
iterative	O
denoising	O
process	O
.	O

SR3	O
exhibits	O
strong	O
performance	O
on	O
super	Computer/vision-focus
-	Computer/vision-focus
resolution	Computer/vision-focus
tasks	Computer/vision-focus
at	O
different	O
magnification	O
factors	O
,	O
on	O
faces	O
and	O
natural	O
images	O
.	O

We	O
conduct	O
human	O
evaluation	O
on	O
a	O
standard	O
8	Computer/vision-focus
×	Computer/vision-focus
face	Computer/vision-focus
super	Computer/vision-focus
-	Computer/vision-focus
resolution	Computer/vision-focus
task	Computer/vision-focus
on	O
CelebA	O
-	O
HQ	O
for	O
which	O
SR3	O
achieves	O
a	O
fool	O
rate	O
close	O
to	O
50	O
%,	O
suggesting	O
photo	O
-	O
realistic	O
outputs	O
,	O
while	O
GAN	O
baselines	O
do	O
not	O
exceed	O
a	O
fool	O
rate	O
of	O
34	O
%	O
.	O

We	O
evaluate	O
SR3	O
on	O
a	O
4	Computer/vision-focus
×	Computer/vision-focus
super	Computer/vision-focus
-	Computer/vision-focus
resolution	Computer/vision-focus
task	Computer/vision-focus
on	O
ImageNet	O
SR3	O
re	O
SR3	O
outperforms	O
baselines	O
in	O
human	O
evaluation	O
and	O
classification	Classification-metrics
accuracy	Classification-metrics
of	O
a	O
ResNet	O
-	O
50	O
classifier	O
trained	O
on	O
high	O
-	O
resolution	O
images	O
.	O

We	O
evaluate	O
SR3	O
on	O
a	O
4	Computer/vision-focus
×	Computer/vision-focus
super	Computer/vision-focus
-	Computer/vision-focus
resolution	Computer/vision-focus
task	Computer/vision-focus
on	O
ImageNet	O
SR3	O
re	O
SR3	O
outperforms	O
baselines	O
in	O
human	O
evaluation	O
and	O
classification	Classification-metrics
accuracy	Classification-metrics
of	O
a	O
ResNet	O
-	O
50	O
classifier	O
trained	O
on	O
high	O
-	O
resolution	O
images	O
.	O

We	O
further	O
show	O
the	O
effectiveness	O
of	O
SR3	O
in	O
cascaded	Computer/vision-focus
image	Computer/vision-focus
generation	Computer/vision-focus
where	O
a	O
generative	O
model	O
is	O
chained	O
with	O
super	O
-	O
resolution	O
models	O
to	O
synthesize	O
high	O
-	O
resolution	O
images	O
with	O
competitive	O
FID	Statistical/Mathematical-metrics
scores	O
on	O
the	O
class	O
-	O
conditional	O
256	O
×	O
256	O
ImageNet	O
generation	O
challenge	O
.	O

We	O
further	O
show	O
the	O
effectiveness	O
of	O
SR3	O
in	O
cascaded	Computer/vision-focus
image	Computer/vision-focus
generation	Computer/vision-focus
where	O
a	O
generative	O
model	O
is	O
chained	O
with	O
super	O
-	O
resolution	O
models	O
to	O
synthesize	O
high	O
-	O
resolution	O
images	O
with	O
competitive	O
FID	Statistical/Mathematical-metrics
scores	O
on	O
the	O
class	O
-	O
conditional	O
256	O
×	O
256	O
ImageNet	O
generation	O
challenge	O
.	O

Dimensionality	AI/ML/DL-focus
reduction	AI/ML/DL-focus
revealed	O
that	O
the	O
raw	O
pLM	O
-	O
embeddings	O
from	O
unlabeled	O
data	O
captured	O
some	O
biophysical	O
features	O
of	O
protein	O
sequences	O
.	O

We	O
validated	O
the	O
advantage	O
of	O
using	O
the	O
embeddings	O
as	O
exclusive	O
input	O
for	O
several	O
subsequent	O
tasks	O
:	O
(	O
1	O
)	O
a	O
per	O
-	O
residue	O
(	O
per	O
-	O
token	O
)	O
prediction	O
of	O
protein	O
secondary	O
structure	O
(	O
3	Classification-metrics
-	Classification-metrics
state	Classification-metrics
accuracy	Classification-metrics
Q3	O
=	O
81	O
%-	O
87	O
%	O
;	O
(	O
2	O
)	O
per	O
-	O
protein	O
(	O
pooling	O
)	O
predictions	O
of	O
protein	O
sub	O
-	O
cellular	O
location	O
(	O
ten	Classification-metrics
-	Classification-metrics
state	Classification-metrics
accuracy	Classification-metrics
81	O
%	O
=	O
81	O
%)	O
and	O
membrane	O
versus	O
water	O
-	O
soluble	O
(	O
2	Classification-metrics
-	Classification-metrics
state	Classification-metrics
accuracy	Classification-metrics
Q2	O
=	O
91	O
%	O
.	O

For	O
the	O
very	O
deep	O
VGG	O
-	O
16	O
model	O
[	O
3	O
],	O
our	O
detection	O
system	O
has	O
a	O
frame	O
rate	O
of	O
5	O
fps	O
(	O
including	O
all	O
steps	O
)	O
on	O
a	O
GPU	O
,	O
while	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	Computer/vision-focus
detection	Computer/vision-focus
accuracy	Classification-metrics
on	O
PASCAL	O
VOC	O
2007	O
,	O
2012	O
and	O
MS	O
COCO	O
datasets	O
with	O
only	O
300	O
proposals	O
per	O
image	O
.	O

For	O
the	O
very	O
deep	O
VGG	O
-	O
16	O
model	O
[	O
3	O
],	O
our	O
detection	O
system	O
has	O
a	O
frame	O
rate	O
of	O
5	O
fps	O
(	O
including	O
all	O
steps	O
)	O
on	O
a	O
GPU	O
,	O
while	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	Computer/vision-focus
detection	Computer/vision-focus
accuracy	Classification-metrics
on	O
PASCAL	O
VOC	O
2007	O
,	O
2012	O
and	O
MS	O
COCO	O
datasets	O
with	O
only	O
300	O
proposals	O
per	O
image	O
.	O

Face	O
anti	O
-	O
spoofing	O
(	O
FAS	O
)	O
has	O
lately	O
attracted	O
increasing	O
attention	O
due	O
to	O
its	O
vital	O
role	O
in	O
securing	O
face	Computer/vision-focus
recognition	Computer/vision-focus
systems	Computer/vision-focus
from	O
presentation	Computer/vision-focus
attacks	Computer/vision-focus
(	Computer/vision-focus
PAs	Computer/vision-focus
)	Computer/vision-focus
.	O

As	O
more	O
and	O
more	O
realistic	O
PAs	Computer/vision-focus
with	O
novel	O
types	O
spring	O
up	O
,	O
early	O
-	O
stage	O
FAS	Computer/vision-focus
methods	O
based	O
on	O
handcrafted	O
features	O
become	O
unreliable	O
due	O
to	O
their	O
limited	O
representation	O
capacity	O
.	O

It	O
covers	O
several	O
novel	O
and	O
insightful	O
components	O
:	O
1	O
)	O
besides	O
supervision	O
with	O
binary	O
label	O
(	O
e	O
.	O
g	O
.,	O
‘	O
0	O
’	O
for	O
bonafide	O
versus	O
‘	O
1	O
’	O
for	O
PAs	Computer/vision-focus
,	O
we	O
also	O
investigate	O
recent	O
methods	O
with	O
pixel	O
-	O
wise	O
supervision	O
(	O
e	O
.	O
g	O
.,	O
pseudo	O
depth	O
map	O
;	O
2	O
)	O
in	O
addition	O
to	O
traditional	O
intra	O
-	O
dataset	O
evaluation	O
,	O
we	O
collect	O
and	O
analyze	O
the	O
latest	O
methods	O
specially	O
designed	O
for	O
domain	O
generalization	O
and	O
open	O
-	O
set	O
FAS	O
;	O
and	O
3	O
)	O
besides	O
commercial	O
RGB	O
camera	O
,	O
we	O
summarize	O
the	O
deep	O
learning	O
applications	O
under	O
multi	O
-	O
modal	O
(	O
e	O
.	O
g	O
.,	O
depth	O
and	O
infrared	O
)	O
or	O
specialized	O
(	O
e	O
.	O
g	O
.,	O
light	O
field	O
and	O
flash	O
)	O
sensors	O
.	O

Denoising	O
diffusion	O
models	O
represent	O
a	O
recent	O
emerging	O
topic	O
in	O
computer	O
vision	O
demonstrating	O
remarkable	O
results	O
in	O
the	O
area	O
of	O
generative	AI/ML/DL-focus
modeling	AI/ML/DL-focus
.	O

First	O
,	O
we	O
identify	O
and	O
present	O
three	O
generic	O
diffusion	Computer/vision-focus
modeling	Computer/vision-focus
frameworks	O
,	O
which	O
are	O
based	O
on	O
denoising	O
diffusion	O
probabilistic	O
models	O
noise	O
conditioned	O
score	O
networks	O
,	O
and	O
stochastic	O
differential	O
equations	O
.	O

In	O
recent	O
years	O
,	O
advancements	O
in	O
machine	O
learning	O
(	O
ML	O
)	O
techniques	O
,	O
in	O
particular	O
,	O
deep	O
learning	O
(	O
DL	O
)	O
methods	O
have	O
gained	O
a	O
lot	O
of	O
momentum	O
in	O
solving	O
inverse	Computer/vision-focus
imaging	Computer/vision-focus
problems	O
,	O
often	O
surpassing	O
the	O
performance	O
provided	O
by	O
hand	O
-	O
crafted	O
approaches	O
.	O

Traditionally	O
,	O
analytical	O
methods	O
have	O
been	O
used	O
to	O
solve	O
inverse	Computer/vision-focus
imaging	Computer/vision-focus
problems	O
such	O
as	O
image	O
restoration	O
inpainting	O
and	O
superresolution	O
.	O

Accurate	O
and	O
robust	Computer/vision-focus
visual	Computer/vision-focus
object	Computer/vision-focus
tracking	Computer/vision-focus
is	O
one	O
of	O
the	O
most	O
challenging	O
and	O
fundamental	O
computer	O
vision	O
problems	O
.	O

Discriminative	O
Correlation	O
Filters	O
(	O
DCFs	O
)	O
and	O
deep	AI/ML/DL-focus
Siamese	AI/ML/DL-focus
Networks	AI/ML/DL-focus
(	AI/ML/DL-focus
SNs	AI/ML/DL-focus
)	AI/ML/DL-focus
have	O
emerged	O
as	O
dominating	O
tracking	O
paradigms	O
,	O
which	O
have	O
led	O
to	O
significant	O
progress	O
.	O

Following	O
the	O
rapid	O
evolution	O
of	O
visual	Computer/vision-focus
object	Computer/vision-focus
tracking	Computer/vision-focus
in	O
the	O
last	O
decade	O
,	O
this	O
survey	O
presents	O
a	O
systematic	O
and	O
thorough	O
review	O
of	O
more	O
than	O
90	O
DCFs	O
and	O
Siamese	O
trackers	O
based	O
on	O
results	O
in	O
nine	O
tracking	O
benchmarks	O
.	O

Furthermore	O
,	O
we	O
thoroughly	O
analyze	O
the	O
performance	O
of	O
DCF	O
and	O
Siamese	O
trackers	O
on	O
nine	O
benchmarks	O
,	O
covering	O
different	O
experimental	O
aspects	O
of	O
visual	Computer/vision-focus
tracking	Computer/vision-focus
datasets	O
evaluation	O
metrics	O
,	O
performance	O
,	O
and	O
speed	O
comparisons	O
.	O

The	O
inappropriate	O
deformations	O
originate	O
from	O
a	O
proximity	O
-	O
based	O
deformation	O
constraint	O
called	O
motion	Computer/vision-focus
coherence	Computer/vision-focus
.	O

From	O
meteorology	O
to	O
medical	O
imaging	O
and	O
cell	O
mechanics	O
many	O
scientific	O
domains	O
use	O
inverse	Computer/vision-focus
problems	Computer/vision-focus
(	Computer/vision-focus
IPs	Computer/vision-focus
)	Computer/vision-focus
to	O
extract	O
physical	O
measurements	O
from	O
image	O
movement	O
.	O

To	O
this	O
end	O
,	O
motion	O
estimation	O
methods	O
such	O
as	O
optical	O
flow	O
(	O
OF	O
)	O
pre	O
-	O
process	O
images	O
into	O
motion	O
data	O
to	O
feed	O
the	O
IP	Computer/vision-focus
which	O
then	O
inverts	O
for	O
the	O
measurements	O
through	O
a	O
physical	O
model	O
.	O

Event	Computer/vision-focus
cameras	Computer/vision-focus
are	O
bio	O
-	O
inspired	O
sensors	O
that	O
differ	O
from	O
conventional	O
frame	O
cameras	O
:	O
Instead	O
of	O
capturing	O
images	O
at	O
a	O
fixed	O
rate	O
,	O
they	O
asynchronously	O
measure	O
per	O
-	O
pixel	O
brightness	O
changes	O
,	O
and	O
output	O
a	O
stream	O
of	O
events	O
that	O
encode	O
the	O
time	O
,	O
location	O
and	O
sign	O
of	O
the	O
brightness	O
changes	O
.	O

Event	Computer/vision-focus
cameras	Computer/vision-focus
offer	O
attractive	O
properties	O
compared	O
to	O
traditional	O
cameras	O
:	O
high	O
temporal	O
resolution	O
(	O
in	O
the	O
order	O
of	O
$\	O
mu	O
$	O
μs	O
),	O
very	O
high	O
dynamic	O
range	O
(	O
140	O
dB	O
versus	O
60	O
dB	O
),	O
low	O
power	O
consumption	O
,	O
and	O
high	O
pixel	O
bandwidth	O
(	O
on	O
the	O
order	O
of	O
kHz	O
)	O
resulting	O
in	O
reduced	O
motion	O
blur	O
.	O

This	O
paper	O
provides	O
a	O
comprehensive	O
overview	O
of	O
the	O
emerging	O
field	O
of	O
event	Computer/vision-focus
-	Computer/vision-focus
based	Computer/vision-focus
vision	Computer/vision-focus
with	O
a	O
focus	O
on	O
the	O
applications	O
and	O
the	O
algorithms	O
developed	O
to	O
unlock	O
the	O
outstanding	O
properties	O
of	O
event	O
cameras	O
.	O

In	O
stark	O
contrast	O
,	O
Deep	O
Networks	O
forget	O
catastrophically	O
and	O
,	O
for	O
this	O
reason	O
,	O
the	O
sub	O
-	O
field	O
of	O
Class	AI/ML/DL-focus
-	AI/ML/DL-focus
Incremental	AI/ML/DL-focus
Continual	AI/ML/DL-focus
Learning	AI/ML/DL-focus
fosters	O
methods	O
that	O
learn	O
a	O
sequence	O
of	O
tasks	O
incrementally	O
,	O
blending	O
sequentially	O
-	O
gained	O
knowledge	O
into	O
a	O
comprehensive	O
prediction	O
.	O

Finally	O
,	O
the	O
experiments	O
are	O
conducted	O
on	O
Origin	O
Pilot	O
and	O
it	O
demonstrates	O
that	O
the	O
PHL	O
algorithm	O
can	O
deal	O
with	O
the	O
image	Computer/vision-focus
segmentation	Computer/vision-focus
problem	O
and	O
provide	O
a	O
segmentation	O
solution	O
accurately	O
.	O

Most	O
value	AI/ML/DL-focus
function	AI/ML/DL-focus
learning	AI/ML/DL-focus
algorithms	O
in	O
reinforcement	O
learning	O
are	O
based	O
on	O
the	O
mean	O
squared	O
(	O
projected	O
)	O
Bellman	O
error	O
.	O

In	O
this	O
work	O
,	O
we	O
build	O
on	O
recent	O
insights	O
reformulating	O
squared	O
Bellman	O
errors	O
as	O
a	O
saddlepoint	AI/ML/DL-focus
optimization	AI/ML/DL-focus
problem	O
and	O
propose	O
a	O
saddlepoint	O
reformulation	O
for	O
a	O
Huber	O
Bellman	O
error	O
and	O
Absolute	O
Bellman	O
error	O
.	O

Point	AI/ML/DL-focus
cloud	AI/ML/DL-focus
learning	AI/ML/DL-focus
has	O
lately	O
attracted	O
increasing	O
attention	O
due	O
to	O
its	O
wide	O
applications	O
in	O
many	O
areas	O
,	O
such	O
as	O
computer	O
vision	O
autonomous	O
driving	O
and	O
robotics	O
.	O

It	O
covers	O
three	O
major	O
tasks	O
,	O
including	O
3D	Computer/vision-focus
shape	Computer/vision-focus
classification	Computer/vision-focus
3D	Computer/vision-focus
object	Computer/vision-focus
detection	Computer/vision-focus
and	Computer/vision-focus
tracking	Computer/vision-focus
and	O
3D	Computer/vision-focus
point	Computer/vision-focus
cloud	Computer/vision-focus
segmentation	Computer/vision-focus
.	O

Our	O
proposed	O
“	O
DeepLab	O
”	O
system	O
sets	O
the	O
new	O
state	O
-	O
of	O
-	O
art	O
at	O
the	O
PASCAL	O
VOC	O
-	O
2012	O
semantic	Computer/vision-focus
image	Computer/vision-focus
segmentation	Computer/vision-focus
task	O
,	O
reaching	O
79	O
.	O
7	O
percent	O
mIOU	Statistical/Mathematical-metrics
in	O
the	O
test	O
set	O
,	O
and	O
advances	O
the	O
results	O
on	O
three	O
other	O
datasets	O
PASCAL	O
-	O
Context	O
PASCAL	O
-	O
Person	O
-	O
Part	O
and	O
Cityscapes	O
.	O

Our	O
proposed	O
“	O
DeepLab	O
”	O
system	O
sets	O
the	O
new	O
state	O
-	O
of	O
-	O
art	O
at	O
the	O
PASCAL	O
VOC	O
-	O
2012	O
semantic	Computer/vision-focus
image	Computer/vision-focus
segmentation	Computer/vision-focus
task	O
,	O
reaching	O
79	O
.	O
7	O
percent	O
mIOU	Statistical/Mathematical-metrics
in	O
the	O
test	O
set	O
,	O
and	O
advances	O
the	O
results	O
on	O
three	O
other	O
datasets	O
PASCAL	O
-	O
Context	O
PASCAL	O
-	O
Person	O
-	O
Part	O
and	O
Cityscapes	O
.	O

Generalized	AI/ML/DL-focus
zero	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
learning	AI/ML/DL-focus
(	AI/ML/DL-focus
GZSL	AI/ML/DL-focus
)	AI/ML/DL-focus
aims	O
to	O
train	O
a	O
model	O
for	O
classifying	O
data	O
samples	O
under	O
the	O
condition	O
that	O
some	O
output	O
classes	O
are	O
unknown	O
during	O
supervised	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

To	O
address	O
this	O
challenging	O
task	O
,	O
GZSL	AI/ML/DL-focus
leverages	O
semantic	O
information	O
of	O
the	O
seen	O
(	O
source	O
)	O
and	O
unseen	O
(	O
target	O
)	O
classes	O
to	O
bridge	O
the	O
gap	O
between	O
both	O
seen	O
and	O
unseen	O
classes	O
.	O

Since	O
its	O
introduction	O
,	O
many	O
GZSL	AI/ML/DL-focus
models	O
have	O
been	O
formulated	O
.	O

In	O
this	O
review	O
paper	O
,	O
we	O
present	O
a	O
comprehensive	O
review	O
on	O
GZSL	AI/ML/DL-focus
.	O

First	O
,	O
we	O
provide	O
an	O
overview	O
of	O
GZSL	AI/ML/DL-focus
including	O
the	O
problems	O
and	O
challenges	O
.	O

Then	O
,	O
we	O
introduce	O
a	O
hierarchical	O
categorization	O
for	O
the	O
GZSL	AI/ML/DL-focus
methods	O
and	O
discuss	O
the	O
representative	O
methods	O
in	O
each	O
category	O
.	O

In	O
addition	O
,	O
we	O
discuss	O
the	O
available	O
benchmark	O
data	O
sets	O
and	O
applications	O
of	O
GZSL	AI/ML/DL-focus
along	O
with	O
a	O
discussion	O
on	O
the	O
research	O
gaps	O
and	O
directions	O
for	O
future	O
investigations	O
.	O

Multimodal	Computer/vision-focus
machine	Computer/vision-focus
learning	Computer/vision-focus
aims	O
to	O
build	O
models	O
that	O
can	O
process	O
and	O
relate	O
information	O
from	O
multiple	O
modalities	O
.	O

We	O
go	O
beyond	O
the	O
typical	O
early	O
and	O
late	O
fusion	O
categorization	O
and	O
identify	O
broader	O
challenges	O
that	O
are	O
faced	O
by	O
multimodal	O
machine	O
learning	O
namely	O
:	O
representation	Computer/vision-focus
translation	Computer/vision-focus
alignment	Computer/vision-focus
fusion	AI/ML/DL-focus
,	O
and	O
co	Computer/vision-focus
-	Computer/vision-focus
learning	Computer/vision-focus
.	O

This	O
motivates	O
longer	O
term	O
unanswered	O
questions	O
about	O
the	O
appropriate	O
objectives	O
for	O
learning	O
good	O
representations	O
,	O
for	O
computing	O
representations	O
(	O
i	O
.	O
e	O
.,	O
inference	O
),	O
and	O
the	O
geometrical	O
connections	O
between	O
representation	AI/ML/DL-focus
learning	AI/ML/DL-focus
density	AI/ML/DL-focus
estimation	AI/ML/DL-focus
and	O
manifold	Computer/vision-focus
learning	Computer/vision-focus
.	O

Domain	AI/ML/DL-focus
generalization	AI/ML/DL-focus
(	AI/ML/DL-focus
DG	AI/ML/DL-focus
)	AI/ML/DL-focus
aims	O
to	O
achieve	O
OOD	O
generalization	O
by	O
using	O
only	O
source	O
data	O
for	O
model	O
learning	O
.	O

Over	O
the	O
last	O
ten	O
years	O
,	O
research	O
in	O
DG	AI/ML/DL-focus
DG	AI/ML/DL-focus
made	O
great	O
progress	O
,	O
leading	O
to	O
a	O
broad	O
spectrum	O
of	O
methodologies	O
,	O
e	O
.	O
g	O
.,	O
those	O
based	O
on	O
domain	O
alignment	O
,	O
meta	O
-	O
learning	O
,	O
data	O
augmentation	O
,	O
or	O
ensemble	O
learning	O
,	O
to	O
name	O
a	O
few	O
;	O
DG	O
has	O
also	O
been	O
studied	O
in	O
various	O
application	O
areas	O
including	O
computer	O
vision	O
speech	O
recognition	O
natural	O
language	O
processing	O
medical	O
imaging	O
and	O
reinforcement	O
learning	O
.	O

In	O
this	O
paper	O
,	O
for	O
the	O
first	O
time	O
a	O
comprehensive	O
literature	O
review	O
in	O
DG	AI/ML/DL-focus
is	O
provided	O
to	O
summarize	O
the	O
developments	O
over	O
the	O
past	O
decade	O
.	O

Specifically	O
,	O
we	O
first	O
cover	O
the	O
background	O
by	O
formally	O
defining	O
DG	AI/ML/DL-focus
and	O
relating	O
it	O
to	O
other	O
relevant	O
fields	O
like	O
domain	O
adaptation	O
and	O
transfer	O
learning	O
.	O

Human	Computer/vision-focus
Action	Computer/vision-focus
Recognition	Computer/vision-focus
(	Computer/vision-focus
HAR	Computer/vision-focus
)	Computer/vision-focus
aims	O
to	O
understand	O
human	O
behavior	O
and	O
assign	O
a	O
label	O
to	O
each	O
action	O
.	O

Consequently	O
,	O
lots	O
of	O
existing	O
works	O
have	O
attempted	O
to	O
investigate	O
different	O
types	O
of	O
approaches	O
for	O
HAR	Computer/vision-focus
using	O
various	O
modalities	O
.	O

In	O
this	O
article	O
,	O
we	O
present	O
a	O
comprehensive	O
survey	O
of	O
recent	O
progress	O
in	O
deep	O
learning	O
methods	O
for	O
HAR	Computer/vision-focus
based	O
on	O
the	O
type	O
of	O
input	O
data	O
modality	O
.	O

We	O
also	O
present	O
comparative	O
results	O
on	O
several	O
benchmark	O
datasets	O
for	O
HAR	Computer/vision-focus
together	O
with	O
insightful	O
observations	O
and	O
inspiring	O
future	O
research	O
directions	O
.	O

With	O
these	O
advantages	O
,	O
SPP	O
-	O
net	O
should	O
in	O
general	O
improve	O
all	O
CNN	O
based	O
image	Computer/vision-focus
classification	Computer/vision-focus
methods	O
.	O

On	O
the	O
Pascal	O
VOC	O
2007	O
and	O
Caltech101	O
datasets	O
,	O
SPP	O
-	O
net	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	AI/ML/DL-focus
results	O
using	O
a	O
single	O
full	O
-	O
image	O
representation	O
and	O
no	O
fine	O
-	O
tuning	O
.	O

The	O
power	O
of	O
SPP	O
-	O
net	O
is	O
also	O
significant	O
in	O
object	Computer/vision-focus
detection	Computer/vision-focus
.	O

In	O
ImageNet	O
Large	O
Scale	O
Visual	O
Recognition	O
Challenge	O
(	O
ILSVRC	O
)	O
2014	O
,	O
our	O
methods	O
rank	O
#	O
2	O
in	O
object	Computer/vision-focus
detection	Computer/vision-focus
and	O
#	O
3	O
in	O
image	Computer/vision-focus
classification	Computer/vision-focus
among	O
all	O
38	O
teams	O
.	O

Image	Computer/vision-focus
Super	Computer/vision-focus
-	Computer/vision-focus
Resolution	Computer/vision-focus
(	Computer/vision-focus
SR	Computer/vision-focus
)	Computer/vision-focus
is	O
an	O
important	O
class	O
of	O
image	O
processing	O
techniqueso	O
enhance	O
the	O
resolution	O
of	O
images	O
and	O
videos	O
in	O
computer	O
vision	O
.	O

Recent	O
years	O
have	O
witnessed	O
remarkable	O
progress	O
of	O
image	Computer/vision-focus
super	Computer/vision-focus
-	Computer/vision-focus
resolution	Computer/vision-focus
using	O
deep	O
learning	O
techniques	O
.	O

This	O
article	O
aims	O
to	O
provide	O
a	O
comprehensive	O
survey	O
on	O
recent	O
advances	O
of	O
image	Computer/vision-focus
super	Computer/vision-focus
-	Computer/vision-focus
resolution	Computer/vision-focus
using	O
deep	O
learning	O
approaches	O
.	O

In	O
general	O
,	O
we	O
can	O
roughly	O
group	O
the	O
existing	O
studies	O
of	O
SR	Computer/vision-focus
techniques	O
into	O
three	O
major	O
categories	O
:	O
supervised	Computer/vision-focus
SR	Computer/vision-focus
unsupervised	Computer/vision-focus
SR	Computer/vision-focus
and	O
domain	Computer/vision-focus
-	Computer/vision-focus
specific	Computer/vision-focus
SR	Computer/vision-focus
.	O

For	O
egocentric	Computer/vision-focus
vision	Computer/vision-focus
tasks	O
such	O
as	O
action	Computer/vision-focus
recognition	Computer/vision-focus
there	O
is	O
a	O
relative	O
scarcity	O
of	O
labeled	O
data	O
.	O

In	O
this	O
paper	O
,	O
we	O
address	O
this	O
issue	O
by	O
introducing	O
a	O
multitask	AI/ML/DL-focus
learning	AI/ML/DL-focus
scheme	O
that	O
employs	O
related	O
tasks	O
as	O
well	O
as	O
related	O
datasets	O
in	O
the	O
training	O
process	O
.	O

Our	O
experiments	O
on	O
egocentric	Computer/vision-focus
action	Computer/vision-focus
recognition	Computer/vision-focus
in	O
the	O
EPIC	O
-	O
Kitchens	O
EGTEA	O
Gaze	O
+	O
ADL	O
and	O
Charades	O
-	O
EGO	O
datasets	O
demonstrate	O
the	O
improvements	O
of	O
our	O
approach	O
over	O
single	O
-	O
dataset	O
baselines	O
.	O

Direct	O
Sparse	O
Odometry	O
(	O
DSO	O
)	O
is	O
a	O
visual	Computer/vision-focus
odometry	Computer/vision-focus
method	O
based	O
on	O
a	O
novel	O
,	O
highly	O
accurate	O
sparse	O
and	O
direct	O
structure	O
and	O
motion	O
formulation	O
.	O

The	O
experiments	O
show	O
that	O
the	O
presented	O
approach	O
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
direct	O
and	O
indirect	O
methods	O
in	O
a	O
variety	O
of	O
real	O
-	O
world	O
settings	O
,	O
both	O
in	O
terms	O
of	O
tracking	O
accuracy	Classification-metrics
and	O
robustness	O
.	O

We	O
show	O
that	O
convolutional	O
networks	O
by	O
themselves	O
,	O
trained	O
end	O
-	O
to	O
-	O
end	O
,	O
pixels	O
-	O
to	O
-	O
pixels	O
,	O
improve	O
on	O
the	O
previous	O
best	O
result	O
in	O
semantic	Computer/vision-focus
segmentation	Computer/vision-focus
.	O

We	O
define	O
and	O
detail	O
the	O
space	O
of	O
fully	O
convolutional	O
networks	O
explain	O
their	O
application	O
to	O
spatially	Computer/vision-focus
dense	Computer/vision-focus
prediction	Computer/vision-focus
tasks	O
,	O
and	O
draw	O
connections	O
to	O
prior	O
models	O
.	O

We	O
adapt	O
contemporary	O
classification	O
networks	O
(	O
AlexNet	O
the	O
VGG	O
net	O
and	O
GoogLeNet	O
into	O
fully	O
convolutional	O
networks	O
and	O
transfer	O
their	O
learned	O
representations	O
by	O
fine	O
-	O
tuning	O
to	O
the	O
segmentation	Computer/vision-focus
task	O
.	O

Artificial	O
neural	O
networks	O
thrive	O
in	O
solving	O
the	O
classification	AI/ML/DL-focus
problem	O
for	O
a	O
particular	O
rigid	O
task	O
,	O
acquiring	O
knowledge	O
through	O
generalized	O
learning	O
behaviour	O
from	O
a	O
distinct	O
training	O
phase	O
.	O

Continual	AI/ML/DL-focus
learning	AI/ML/DL-focus
shifts	O
this	O
paradigm	O
towards	O
networks	O
that	O
can	O
continually	O
accumulate	O
knowledge	O
over	O
different	O
tasks	O
without	O
the	O
need	O
to	O
retrain	O
from	O
scratch	O
.	O

We	O
focus	O
on	O
task	AI/ML/DL-focus
incremental	AI/ML/DL-focus
classification	AI/ML/DL-focus
where	O
tasks	O
arrive	O
sequentially	O
and	O
are	O
delineated	O
by	O
clear	O
boundaries	O
.	O

We	O
empirically	O
scrutinize	O
method	O
strengths	O
and	O
weaknesses	O
on	O
three	O
benchmarks	O
,	O
considering	O
Tiny	O
Imagenet	O
and	O
large	O
-	O
scale	O
unbalanced	O
iNaturalist	O
and	O
a	O
sequence	O
of	O
recognition	Computer/vision-focus
datasets	O
.	O

Radial	Computer/vision-focus
lens	Computer/vision-focus
distortion	Computer/vision-focus
is	O
modeled	O
.	O

It	O
advances	O
3D	Computer/vision-focus
computer	Computer/vision-focus
vision	Computer/vision-focus
one	O
more	O
step	O
from	O
laboratory	O
environments	O
to	O
real	O
world	O
use	O
.	O

However	O
,	O
there	O
is	O
neither	O
a	O
unified	O
treatment	O
of	O
GNN	AI/ML/DL-focus
explainability	AI/ML/DL-focus
methods	O
,	O
nor	O
a	O
standard	O
benchmark	O
and	O
testbed	O
for	O
evaluations	O
.	O

In	O
this	O
survey	O
,	O
we	O
provide	O
a	O
unified	O
and	O
taxonomic	O
view	O
of	O
current	O
GNN	AI/ML/DL-focus
explainability	AI/ML/DL-focus
methods	O
.	O

To	O
facilitate	O
evaluations	O
,	O
we	O
provide	O
a	O
testbed	O
for	O
GNN	AI/ML/DL-focus
explainability	AI/ML/DL-focus
including	O
datasets	O
common	O
algorithms	O
and	O
evaluation	O
metrics	O
.	O

Altogether	O
,	O
this	O
work	O
provides	O
a	O
unified	O
methodological	O
treatment	O
of	O
GNN	AI/ML/DL-focus
explainability	AI/ML/DL-focus
and	O
a	O
standardized	O
testbed	O
for	O
evaluations	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
tackle	O
egocentric	Computer/vision-focus
action	Computer/vision-focus
recognition	Computer/vision-focus
by	O
suppressing	O
background	O
distractors	O
and	O
enhancing	O
action	O
-	O
relevant	O
interactions	O
.	O

Second	O
,	O
we	O
propose	O
a	O
symbiotic	O
attention	O
mechanism	O
to	O
encourage	O
the	O
mutual	O
interaction	O
between	O
the	O
two	O
branches	O
and	O
select	O
the	O
most	O
action	O
-	O
relevant	O
candidates	O
for	O
classification	AI/ML/DL-focus
.	O

In	O
an	O
effort	O
to	O
understand	O
the	O
benefits	O
and	O
drawbacks	O
of	O
existing	O
methods	O
,	O
we	O
empirically	O
compare	O
five	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
superpixel	O
algorithms	O
for	O
their	O
ability	O
to	O
adhere	O
to	O
image	O
boundaries	O
,	O
speed	O
,	O
memory	O
efficiency	O
,	O
and	O
their	O
impact	O
on	O
segmentation	Computer/vision-focus
performance	O
.	O

At	O
the	O
same	O
time	O
,	O
it	O
is	O
faster	O
and	O
more	O
memory	O
efficient	O
,	O
improves	O
segmentation	Computer/vision-focus
performance	O
,	O
and	O
is	O
straightforward	O
to	O
extend	O
to	O
supervoxel	Computer/vision-focus
generation	Computer/vision-focus
.	O

Large	O
-	O
scale	O
labeled	O
data	O
are	O
generally	O
required	O
to	O
train	O
deep	O
neural	O
networks	O
in	O
order	O
to	O
obtain	O
better	O
performance	O
in	O
visual	Computer/vision-focus
feature	Computer/vision-focus
learning	Computer/vision-focus
from	O
images	O
or	O
videos	O
for	O
computer	O
vision	O
applications	O
.	O

Next	O
,	O
the	O
schema	O
and	O
evaluation	O
metrics	O
of	O
self	O
-	O
supervised	O
learning	O
methods	O
are	O
reviewed	O
followed	O
by	O
the	O
commonly	O
used	O
datasets	O
for	O
images	O
,	O
videos	O
,	O
audios	O
,	O
and	O
3D	O
data	O
,	O
as	O
well	O
as	O
the	O
existing	O
self	Computer/vision-focus
-	Computer/vision-focus
supervised	Computer/vision-focus
visual	Computer/vision-focus
feature	Computer/vision-focus
learning	Computer/vision-focus
methods	O
.	O

At	O
last	O
,	O
this	O
paper	O
is	O
concluded	O
and	O
lists	O
a	O
set	O
of	O
promising	O
future	O
directions	O
for	O
self	Computer/vision-focus
-	Computer/vision-focus
supervised	Computer/vision-focus
visual	Computer/vision-focus
feature	Computer/vision-focus
learning	Computer/vision-focus
.	O

Hence	O
,	O
different	O
fusion	Computer/vision-focus
tasks	O
are	O
unified	O
in	O
the	O
same	O
framework	O
.	O

Based	O
on	O
the	O
adaptive	O
degrees	O
,	O
a	O
network	O
is	O
trained	O
to	O
preserve	O
the	O
adaptive	O
similarity	O
between	O
the	O
fusion	Computer/vision-focus
result	O
and	O
source	O
images	O
.	O

Therefore	O
,	O
the	O
stumbling	O
blocks	O
in	O
applying	O
deep	O
learning	O
for	O
image	Computer/vision-focus
fusion	Computer/vision-focus
e	O
.	O
g	O
.,	O
the	O
requirement	O
of	O
ground	O
-	O
truth	O
and	O
specifically	O
designed	O
metrics	O
,	O
are	O
greatly	O
mitigated	O
.	O

By	O
avoiding	O
the	O
loss	O
of	O
previous	O
fusion	Computer/vision-focus
capabilities	O
when	O
training	O
a	O
single	O
model	O
for	O
different	O
tasks	O
sequentially	O
,	O
we	O
obtain	O
a	O
unified	O
model	O
that	O
is	O
applicable	O
to	O
multiple	Computer/vision-focus
fusion	Computer/vision-focus
tasks	O
.	O

Qualitative	O
and	O
quantitative	O
experimental	O
results	O
on	O
three	O
typical	O
image	Computer/vision-focus
fusion	Computer/vision-focus
tasks	O
validate	O
the	O
effectiveness	O
and	O
universality	O
of	O
U2Fusion	O
.	O

Realtime	Computer/vision-focus
multi	Computer/vision-focus
-	Computer/vision-focus
person	Computer/vision-focus
2D	Computer/vision-focus
pose	Computer/vision-focus
estimation	Computer/vision-focus
is	O
a	O
key	O
component	O
in	O
enabling	O
machines	O
to	O
have	O
an	O
understanding	O
of	O
people	O
in	O
images	O
and	O
videos	O
.	O

This	O
bottom	O
-	O
up	O
system	O
achieves	O
high	O
accuracy	Classification-metrics
and	O
realtime	O
performance	O
,	O
regardless	O
of	O
the	O
number	O
of	O
people	O
in	O
the	O
image	O
.	O

We	O
demonstrate	O
that	O
a	O
PAF	O
PAF	O
refinement	O
rather	O
than	O
both	O
PAF	O
and	O
body	O
part	O
location	O
refinement	O
results	O
in	O
a	O
substantial	O
increase	O
in	O
both	O
runtime	O
performance	O
and	O
accuracy	Classification-metrics
.	O

We	O
show	O
that	O
the	O
combined	O
detector	O
not	O
only	O
reduces	O
the	O
inference	O
time	O
compared	O
to	O
running	O
them	O
sequentially	O
,	O
but	O
also	O
maintains	O
the	O
accuracy	Classification-metrics
of	O
each	O
component	O
individually	O
.	O

This	O
work	O
has	O
culminated	O
in	O
the	O
release	O
of	O
OpenPose	O
the	O
first	O
open	O
-	O
source	O
realtime	O
system	O
for	O
multi	Computer/vision-focus
-	Computer/vision-focus
person	Computer/vision-focus
2D	Computer/vision-focus
pose	Computer/vision-focus
detection	Computer/vision-focus
including	O
body	O
,	O
foot	O
,	O
hand	O
,	O
and	O
facial	O
keypoints	O
.	O

The	O
highest	O
accuracy	Classification-metrics
object	O
detectors	O
to	O
date	O
are	O
based	O
on	O
a	O
two	O
-	O
stage	O
approach	O
popularized	O
by	O
R	O
-	O
CNN	O
where	O
a	O
classifier	O
is	O
applied	O
to	O
a	O
sparse	O
set	O
of	O
candidate	O
object	O
locations	O
.	O

Our	O
results	O
show	O
that	O
when	O
trained	O
with	O
the	O
focal	O
loss	O
,	O
RetinaNet	O
is	O
able	O
to	O
match	O
the	O
speed	O
of	O
previous	O
one	O
-	O
stage	O
detectors	O
while	O
surpassing	O
the	O
accuracy	Classification-metrics
of	O
all	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
two	O
-	O
stage	O
detectors	O
.	O

Feature	Computer/vision-focus
selection	Computer/vision-focus
is	O
an	O
important	O
problem	O
for	O
pattern	Computer/vision-focus
classification	Computer/vision-focus
systems	O
.	O

Because	O
of	O
the	O
difficulty	O
in	O
directly	O
implementing	O
the	O
maximal	O
dependency	O
condition	O
,	O
we	O
first	O
derive	O
an	O
equivalent	O
form	O
,	O
called	O
minimal	O
-	O
redundancy	O
-	O
maximal	O
-	O
relevance	O
criterion	O
(	O
mRMR	O
)	O
for	O
first	Computer/vision-focus
-	Computer/vision-focus
order	Computer/vision-focus
incremental	Computer/vision-focus
feature	Computer/vision-focus
selection	Computer/vision-focus
.	O

Then	O
,	O
we	O
present	O
a	O
two	O
-	O
stage	O
feature	Computer/vision-focus
selection	Computer/vision-focus
algorithm	O
by	O
combining	O
mRMR	O
and	O
other	O
more	O
sophisticated	O
feature	O
selectors	O
(	O
e	O
.	O
g	O
.,	O
wrappers	O
).	O

The	O
results	O
confirm	O
that	O
mRMR	O
leads	O
to	O
promising	O
improvement	O
on	O
feature	Computer/vision-focus
selection	Computer/vision-focus
and	O
classification	AI/ML/DL-focus
accuracy	Classification-metrics
.	O

The	O
results	O
confirm	O
that	O
mRMR	O
leads	O
to	O
promising	O
improvement	O
on	O
feature	Computer/vision-focus
selection	Computer/vision-focus
and	O
classification	AI/ML/DL-focus
accuracy	Classification-metrics
.	O

However	O
,	O
the	O
breakthrough	O
in	O
neural	O
networks	O
accuracy	Classification-metrics
is	O
always	O
accompanied	O
by	O
explosive	O
growth	O
of	O
computation	O
and	O
parameters	O
,	O
which	O
leads	O
to	O
a	O
severe	O
limitation	O
of	O
model	O
deployment	O
.	O

On	O
average	O
,	O
3	O
.	O
49	O
and	O
2	O
.	O
32	O
percent	O
accuracy	Classification-metrics
boost	O
are	O
observed	O
on	O
CIFAR100	O
and	O
ImageNet	O
.	O

Person	Computer/vision-focus
re	Computer/vision-focus
-	Computer/vision-focus
identification	Computer/vision-focus
(	Computer/vision-focus
Re	Computer/vision-focus
-	Computer/vision-focus
ID	Computer/vision-focus
)	Computer/vision-focus
aims	O
at	O
retrieving	O
a	O
person	O
of	O
interest	O
across	O
multiple	O
non	O
-	O
overlapping	O
cameras	O
.	O

By	O
dissecting	O
the	O
involved	O
components	O
in	O
developing	O
a	O
person	Computer/vision-focus
Re	Computer/vision-focus
-	Computer/vision-focus
ID	Computer/vision-focus
system	O
,	O
we	O
categorize	O
it	O
into	O
the	O
closed	O
-	O
world	O
and	O
open	O
-	O
world	O
settings	O
.	O

We	O
first	O
conduct	O
a	O
comprehensive	O
overview	O
with	O
in	O
-	O
depth	O
analysis	O
for	O
closed	O
-	O
world	O
person	Computer/vision-focus
Re	Computer/vision-focus
-	Computer/vision-focus
ID	Computer/vision-focus
from	O
three	O
different	O
perspectives	O
,	O
including	O
deep	O
feature	O
representation	O
learning	O
deep	O
metric	O
learning	O
and	O
ranking	O
optimization	O
.	O

With	O
the	O
performance	O
saturation	O
under	O
closed	O
-	O
world	O
setting	O
,	O
the	O
research	O
focus	O
for	O
person	Computer/vision-focus
Re	Computer/vision-focus
-	Computer/vision-focus
ID	Computer/vision-focus
has	O
recently	O
shifted	O
to	O
the	O
open	O
-	O
world	O
setting	O
,	O
facing	O
more	O
challenging	O
issues	O
.	O

By	O
analyzing	O
the	O
advantages	O
of	O
existing	O
methods	O
,	O
we	O
design	O
a	O
powerful	O
AGW	O
baseline	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
or	O
at	O
least	O
comparable	O
performance	O
on	O
twelve	O
datasets	O
for	O
four	O
different	O
Re	Computer/vision-focus
-	Computer/vision-focus
ID	Computer/vision-focus
tasks	O
.	O

Meanwhile	O
,	O
we	O
introduce	O
a	O
new	O
evaluation	O
metric	O
(	O
mINP	O
)	O
for	O
person	Computer/vision-focus
Re	Computer/vision-focus
-	Computer/vision-focus
ID	Computer/vision-focus
Re	Computer/vision-focus
-	Computer/vision-focus
ID	Computer/vision-focus
ating	O
the	O
cost	O
for	O
finding	O
all	O
the	O
correct	O
matches	O
,	O
which	O
provides	O
an	O
additional	O
criteria	O
to	O
evaluate	O
the	O
Re	O
-	O
ID	O
system	O
for	O
real	O
applications	O
.	O

Connecting	O
Vision	O
and	O
Language	O
plays	O
an	O
essential	O
role	O
in	O
Generative	AI/ML/DL-focus
Intelligence	AI/ML/DL-focus
.	O

Starting	O
from	O
2015	O
the	O
task	O
has	O
generally	O
been	O
addressed	O
with	O
pipelines	O
composed	O
of	O
a	O
visual	O
encoder	O
and	O
a	O
language	O
model	O
for	O
text	NLP-focus
generation	NLP-focus
.	O

High	O
-	O
resolution	O
representations	O
are	O
essential	O
for	O
position	O
-	O
sensitive	O
vision	O
problems	O
,	O
such	O
as	O
human	Computer/vision-focus
pose	Computer/vision-focus
estimation	Computer/vision-focus
semantic	Computer/vision-focus
segmentation	Computer/vision-focus
and	O
object	Computer/vision-focus
detection	Computer/vision-focus
.	O

We	O
show	O
the	O
superiority	O
of	O
the	O
proposed	O
HRNet	O
in	O
a	O
wide	O
range	O
of	O
applications	O
,	O
including	O
human	Computer/vision-focus
pose	Computer/vision-focus
estimation	Computer/vision-focus
semantic	Computer/vision-focus
segmentation	Computer/vision-focus
and	O
object	Computer/vision-focus
detection	Computer/vision-focus
HRNet	O
sting	O
that	O
the	O
HRNet	O
is	O
a	O
stronger	O
backbone	O
for	O
computer	O
vision	O
problems	O
.	O

This	O
paper	O
describes	O
a	O
computational	O
approach	O
to	O
edge	Computer/vision-focus
detection	Computer/vision-focus
.	O

We	O
extend	O
this	O
simple	O
detector	O
using	O
operators	O
of	O
several	O
widths	O
to	O
cope	O
with	O
different	O
signal	Miscellaneous-metrics
-	Miscellaneous-metrics
to	Miscellaneous-metrics
-	Miscellaneous-metrics
noise	Miscellaneous-metrics
ratios	Miscellaneous-metrics
in	O
the	O
image	O
.	O

Though	O
network	O
pruning	O
receives	O
popularity	O
in	O
reducing	O
the	O
complexity	O
of	O
convolutional	O
neural	O
networks	O
(	O
CNNs	O
)	O
it	O
remains	O
an	O
open	O
issue	O
to	O
concurrently	O
maintain	O
model	O
accuracy	Classification-metrics
as	O
well	O
as	O
achieve	O
significant	O
speedups	O
on	O
general	O
CPUs	O
.	O

We	O
also	O
provide	O
a	O
workflow	O
of	O
filter	O
rearrangement	O
that	O
first	O
rearranges	O
the	O
weight	O
matrix	O
in	O
the	O
output	O
channel	O
dimension	O
to	O
derive	O
more	O
influential	O
blocks	O
for	O
accuracy	Classification-metrics
improvements	O
and	O
then	O
applies	O
similar	O
rearrangement	O
to	O
the	O
next	O
-	O
layer	O
weights	O
in	O
the	O
input	O
channel	O
dimension	O
to	O
ensure	O
correct	O
convolutional	O
operations	O
.	O

For	O
example	O
,	O
given	O
the	O
pruning	O
rate	O
of	O
50	O
%	O
and	O
N	O
=	O
4	O
,	O
our	O
pattern	O
obtains	O
about	O
3	O
.	O
0	O
%	O
improvements	O
over	O
filter	O
pruning	O
in	O
the	O
top	Classification-metrics
-	Classification-metrics
1	Classification-metrics
accuracy	Classification-metrics
of	O
MobileNet	O
-	O
V2	O
.	O

Our	O
method	O
is	O
trained	O
in	O
a	O
weakly	O
supervised	O
manner	O
based	O
on	O
multi	AI/ML/DL-focus
-	AI/ML/DL-focus
view	AI/ML/DL-focus
supervision	AI/ML/DL-focus
completely	O
removing	O
the	O
need	O
for	O
training	O
data	O
with	O
3D	O
ground	O
truth	O
annotations	O
.	O

Thanks	O
to	O
the	O
numerical	O
stability	O
of	O
deterministic	O
training	O
,	O
our	O
method	O
also	O
improves	O
prediction	O
accuracy	Classification-metrics
.	O

Hyperparameter	AI/ML/DL-focus
optimization	AI/ML/DL-focus
(	AI/ML/DL-focus
HPO	AI/ML/DL-focus
)	AI/ML/DL-focus
characterized	O
by	O
hyperparameter	O
tuning	O
is	O
not	O
only	O
a	O
critical	O
step	O
for	O
effective	O
modeling	O
but	O
also	O
is	O
the	O
most	O
time	O
-	O
consuming	O
process	O
in	O
machine	O
learning	O
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
the	O
HPO	AI/ML/DL-focus
problem	O
via	O
meta	O
-	O
learning	O
(	O
MtL	O
)	O
approach	O
under	O
the	O
low	O
-	O
rank	O
tensor	O
completion	O
(	O
LRTC	O
)	O
framework	O
.	O

When	O
some	O
partial	O
evaluations	O
are	O
available	O
for	O
a	O
new	O
problem	O
,	O
the	O
task	O
of	O
estimating	O
the	O
performance	O
of	O
the	O
unevaluated	O
hyperparameters	O
can	O
be	O
formulated	O
as	O
a	O
tensor	AI/ML/DL-focus
completion	AI/ML/DL-focus
(	AI/ML/DL-focus
TC	AI/ML/DL-focus
)	AI/ML/DL-focus
problem	O
.	O

Labeling	O
data	O
is	O
often	O
expensive	O
and	O
time	O
-	O
consuming	O
,	O
especially	O
for	O
tasks	O
such	O
as	O
object	Computer/vision-focus
detection	Computer/vision-focus
and	O
instance	Computer/vision-focus
segmentation	Computer/vision-focus
which	O
require	O
dense	O
labeling	O
of	O
the	O
image	O
.	O

While	O
few	Computer/vision-focus
-	Computer/vision-focus
shot	Computer/vision-focus
object	Computer/vision-focus
detection	Computer/vision-focus
is	O
about	O
training	O
a	O
model	O
on	O
novel	O
(	O
unseen	O
)	O
object	O
classes	O
with	O
little	O
data	O
,	O
it	O
still	O
requires	O
prior	O
training	O
on	O
many	O
labeled	O
examples	O
of	O
base	O
(	O
seen	O
)	O
classes	O
.	O

On	O
the	O
other	O
hand	O
,	O
self	O
-	O
supervised	O
methods	O
aim	O
at	O
learning	O
representations	O
from	O
unlabeled	O
data	O
which	O
transfer	O
well	O
to	O
downstream	O
tasks	O
such	O
as	O
object	Computer/vision-focus
detection	Computer/vision-focus
.	O

Combining	O
few	O
-	O
shot	O
and	O
self	Computer/vision-focus
-	Computer/vision-focus
supervised	Computer/vision-focus
object	Computer/vision-focus
detection	Computer/vision-focus
is	O
a	O
promising	O
research	O
direction	O
.	O

In	O
this	O
survey	O
,	O
we	O
review	O
and	O
characterize	O
the	O
most	O
recent	O
approaches	O
on	O
few	O
-	O
shot	O
and	O
self	Computer/vision-focus
-	Computer/vision-focus
supervised	Computer/vision-focus
object	Computer/vision-focus
detection	Computer/vision-focus
.	O

Rank	Data/Mining/Information/Retrieval-focus
aggregation	Data/Mining/Information/Retrieval-focus
with	O
pairwise	O
comparisons	O
has	O
shown	O
promising	O
results	O
in	O
elections	O
sports	O
competitions	O
recommendations	O
and	O
information	O
retrieval	O
.	O

Meanwhile	O
,	O
the	O
intrinsic	O
vulnerability	O
of	O
the	O
rank	Data/Mining/Information/Retrieval-focus
aggregation	Data/Mining/Information/Retrieval-focus
methods	O
is	O
not	O
well	O
studied	O
in	O
the	O
literature	O
.	O

The	O
unprecedented	O
success	O
of	O
deep	O
convolutional	O
neural	O
networks	O
(	O
CNN	O
)	O
on	O
the	O
task	O
of	O
video	Computer/vision-focus
-	Computer/vision-focus
based	Computer/vision-focus
human	Computer/vision-focus
action	Computer/vision-focus
recognition	Computer/vision-focus
assumes	O
the	O
availability	O
of	O
good	O
resolution	O
videos	O
and	O
resources	O
to	O
develop	O
and	O
deploy	O
complex	O
models	O
.	O

Furthermore	O
,	O
we	O
propose	O
a	O
novel	O
knowledge	O
distillation	O
framework	O
to	O
jointly	O
train	O
the	O
encoder	O
and	O
the	O
action	O
recognition	O
model	O
action	Computer/vision-focus
recognition	Computer/vision-focus
roposed	O
training	O
approach	O
improves	O
the	O
action	O
recognition	O
accuracy	Classification-metrics
by	O
an	O
absolute	O
margin	O
of	O
6	O
.	O
2	O
%	O
2	O
.	O
9	O
%	O
and	O
7	O
.	O
9	O
%	O
on	O
Something	O
$^{	O
2	O
}$	O
2	O
-	O
v2	O
Kinetics	O
-	O
400	O
and	O
UCF	O
-	O
101	O
datasets	O
respectively	O
,	O
in	O
comparison	O
to	O
our	O
previous	O
approach	O
.	O

Furthermore	O
,	O
we	O
propose	O
a	O
novel	O
knowledge	O
distillation	O
framework	O
to	O
jointly	O
train	O
the	O
encoder	O
and	O
the	O
action	O
recognition	O
model	O
action	Computer/vision-focus
recognition	Computer/vision-focus
roposed	O
training	O
approach	O
improves	O
the	O
action	O
recognition	O
accuracy	Classification-metrics
by	O
an	O
absolute	O
margin	O
of	O
6	O
.	O
2	O
%	O
2	O
.	O
9	O
%	O
and	O
7	O
.	O
9	O
%	O
on	O
Something	O
$^{	O
2	O
}$	O
2	O
-	O
v2	O
Kinetics	O
-	O
400	O
and	O
UCF	O
-	O
101	O
datasets	O
respectively	O
,	O
in	O
comparison	O
to	O
our	O
previous	O
approach	O
.	O

This	O
article	O
proposes	O
a	O
unified	O
framework	O
dubbed	O
Multi	O
-	O
view	O
and	O
Temporal	O
Fusing	O
Transformer	O
(	O
MTF	O
-	O
Transformer	O
)	O
to	O
adaptively	O
handle	O
varying	O
view	O
numbers	O
and	O
video	O
length	O
without	O
camera	O
calibration	O
in	O
3D	Computer/vision-focus
Human	Computer/vision-focus
Pose	Computer/vision-focus
Estimation	Computer/vision-focus
(	Computer/vision-focus
HPE	Computer/vision-focus
)	Computer/vision-focus
.	O

Weakly	Computer/vision-focus
-	Computer/vision-focus
supervised	Computer/vision-focus
temporal	Computer/vision-focus
action	Computer/vision-focus
localization	Computer/vision-focus
(	Computer/vision-focus
W	Computer/vision-focus
-	Computer/vision-focus
TAL	Computer/vision-focus
)	Computer/vision-focus
aims	O
to	O
classify	O
and	O
localize	O
all	O
action	O
instances	O
in	O
untrimmed	O
videos	O
under	O
only	O
video	O
-	O
level	O
supervision	O
.	O

Without	O
frame	O
-	O
level	O
annotations	O
,	O
it	O
is	O
challenging	O
for	O
W	Computer/vision-focus
-	Computer/vision-focus
TAL	Computer/vision-focus
methods	O
to	O
clearly	O
distinguish	O
actions	O
and	O
background	O
,	O
which	O
severely	O
degrades	O
the	O
action	O
boundary	O
localization	O
and	O
action	O
proposal	O
scoring	O
.	O

We	O
further	O
demonstrate	O
that	O
commonly	O
-	O
used	O
defense	O
approaches	O
for	O
classification	AI/ML/DL-focus
tasks	O
have	O
limited	O
effectiveness	O
in	O
one	AI/ML/DL-focus
-	AI/ML/DL-focus
class	AI/ML/DL-focus
novelty	AI/ML/DL-focus
detection	AI/ML/DL-focus
.	O

Hence	O
,	O
we	O
need	O
a	O
defense	O
specifically	O
designed	O
for	O
novelty	AI/ML/DL-focus
detection	AI/ML/DL-focus
.	O

Photon	Computer/vision-focus
-	Computer/vision-focus
efficient	Computer/vision-focus
imaging	Computer/vision-focus
which	O
captures	O
3D	O
images	O
with	O
single	O
-	O
photon	O
sensors	O
,	O
has	O
enabled	O
a	O
wide	O
range	O
of	O
applications	O
.	O

However	O
,	O
two	O
major	O
challenges	O
limit	O
the	O
reconstruction	O
performance	O
,	O
i	O
.	O
e	O
.,	O
the	O
low	O
photon	O
counts	O
accompanied	O
by	O
low	O
signal	Miscellaneous-metrics
-	Miscellaneous-metrics
to	Miscellaneous-metrics
-	Miscellaneous-metrics
background	Miscellaneous-metrics
ratio	Miscellaneous-metrics
(	Miscellaneous-metrics
SBR	Miscellaneous-metrics
)	Miscellaneous-metrics
and	O
the	O
multiple	O
returns	O
.	O

The	O
proposed	O
network	O
achieves	O
decent	O
reconstruction	O
fidelity	O
even	O
under	O
extremely	O
low	O
photon	O
counts	O
/	O
SBR	Miscellaneous-metrics
and	O
heavy	O
blur	O
caused	O
by	O
the	O
multiple	O
-	O
return	O
effect	O
,	O
which	O
significantly	O
surpasses	O
the	O
existing	O
methods	O
.	O

Moreover	O
,	O
our	O
network	O
trained	O
on	O
simulated	O
data	O
generalizes	O
well	O
to	O
real	O
-	O
world	O
imaging	O
systems	O
,	O
which	O
greatly	O
extends	O
the	O
application	O
scope	O
of	O
photon	Computer/vision-focus
-	Computer/vision-focus
efficient	Computer/vision-focus
imaging	Computer/vision-focus
in	O
challenging	O
scenarios	O
with	O
a	O
strict	O
limit	O
on	O
optical	O
flux	O
.	O

As	O
a	O
fundamental	O
manner	O
for	O
learning	O
and	O
cognition	O
,	O
transfer	AI/ML/DL-focus
learning	AI/ML/DL-focus
has	O
attracted	O
widespread	O
attention	O
in	O
recent	O
years	O
.	O

Typical	O
transfer	O
learning	O
tasks	O
include	O
unsupervised	AI/ML/DL-focus
domain	AI/ML/DL-focus
adaptation	AI/ML/DL-focus
(	AI/ML/DL-focus
UDA	AI/ML/DL-focus
)	AI/ML/DL-focus
and	O
few	AI/ML/DL-focus
-	AI/ML/DL-focus
shot	AI/ML/DL-focus
learning	AI/ML/DL-focus
(	AI/ML/DL-focus
FSL	AI/ML/DL-focus
)	AI/ML/DL-focus
which	O
both	O
attempt	O
to	O
sufficiently	O
transfer	O
discriminative	O
knowledge	O
from	O
the	O
training	O
environment	O
to	O
the	O
test	O
environment	O
to	O
improve	O
the	O
model	O
'	O
s	O
generalization	O
performance	O
.	O

CKB	O
provides	O
a	O
statistical	O
and	O
interpretable	O
approach	O
,	O
under	O
the	O
optimal	AI/ML/DL-focus
transportation	AI/ML/DL-focus
framework	O
,	O
to	O
understand	O
the	O
knowledge	O
transfer	O
mechanism	O
.	O

CKB	O
can	O
be	O
used	O
as	O
a	O
plug	O
-	O
and	O
-	O
play	O
module	O
and	O
placed	O
onto	O
the	O
loss	O
layer	O
in	O
deep	O
networks	O
thus	O
,	O
it	O
plays	O
the	O
bottleneck	O
role	O
in	O
representation	AI/ML/DL-focus
learning	AI/ML/DL-focus
.	O

From	O
this	O
perspective	O
,	O
the	O
new	O
method	O
with	O
network	O
architecture	O
is	O
abbreviated	O
as	O
BuresNet	O
and	O
it	O
can	O
be	O
used	O
extract	O
conditional	O
invariant	O
features	O
for	O
both	O
UDA	AI/ML/DL-focus
and	O
FSL	AI/ML/DL-focus
tasks	O
.	O

Open	AI/ML/DL-focus
set	AI/ML/DL-focus
recognition	AI/ML/DL-focus
enables	O
deep	O
neural	O
networks	O
(	O
DNNs	O
)	O
to	O
identify	O
samples	O
of	O
unknown	O
classes	O
,	O
while	O
maintaining	O
high	O
classification	AI/ML/DL-focus
accuracy	Classification-metrics
on	O
samples	O
of	O
known	O
classes	O
.	O

Open	AI/ML/DL-focus
set	AI/ML/DL-focus
recognition	AI/ML/DL-focus
enables	O
deep	O
neural	O
networks	O
(	O
DNNs	O
)	O
to	O
identify	O
samples	O
of	O
unknown	O
classes	O
,	O
while	O
maintaining	O
high	O
classification	AI/ML/DL-focus
accuracy	Classification-metrics
on	O
samples	O
of	O
known	O
classes	O
.	O

The	O
results	O
of	O
experiments	O
conducted	O
on	O
multiple	O
datasets	O
show	O
that	O
the	O
proposed	O
method	O
achieves	O
outstanding	O
performance	O
in	O
both	O
close	O
and	O
open	AI/ML/DL-focus
set	AI/ML/DL-focus
recognition	AI/ML/DL-focus
and	O
is	O
sufficiently	O
simple	O
and	O
flexible	O
to	O
incorporate	O
into	O
existing	O
frameworks	O
.	O

However	O
,	O
its	O
performance	O
undergoes	O
a	O
severe	O
deterioration	O
under	O
class	AI/ML/DL-focus
distribution	AI/ML/DL-focus
mismatch	AI/ML/DL-focus
class	O
distribution	O
led	O
data	O
contain	O
numerous	O
instances	O
out	O
of	O
the	O
class	O
distribution	O
of	O
labeled	O
data	O
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
ConAL	O
AL	O
the	O
first	O
AL	O
work	O
for	O
class	AI/ML/DL-focus
distribution	AI/ML/DL-focus
mismatch	AI/ML/DL-focus
.	O

Scene	Computer/vision-focus
graph	Computer/vision-focus
generation	Computer/vision-focus
(	Computer/vision-focus
SGG	Computer/vision-focus
)	Computer/vision-focus
is	O
one	O
of	O
the	O
hottest	O
topics	O
in	O
computer	O
vision	O
and	O
has	O
attracted	O
many	O
interests	O
since	O
it	O
provides	O
rich	O
semantic	O
information	O
between	O
objects	O
.	O

In	O
practice	O
,	O
the	O
SGG	Computer/vision-focus
datasets	O
are	O
often	O
dual	O
imbalanced	O
presented	O
as	O
a	O
large	O
number	O
of	O
backgrounds	O
and	O
rarely	O
few	O
foregrounds	O
,	O
and	O
highly	O
skewed	O
foreground	O
relationships	O
categories	O
(	O
i	O
.	O
e	O
.,	O
the	O
long	O
-	O
tailed	O
distribution	O
.	O

Existing	O
methods	O
only	O
consider	O
the	O
long	O
-	O
tailed	O
distribution	O
of	O
foregrounds	O
classes	O
and	O
ignore	O
the	O
background	O
-	O
foreground	O
imbalance	O
in	O
SGG	Computer/vision-focus
which	O
results	O
in	O
a	O
biased	O
model	O
and	O
prevents	O
it	O
from	O
being	O
applied	O
in	O
the	O
downstream	O
tasks	O
widely	O
.	O

To	O
reduce	O
its	O
side	O
effect	O
and	O
make	O
the	O
contributions	O
of	O
different	O
categories	O
equally	O
,	O
we	O
propose	O
a	O
novel	O
debiased	O
SGG	Computer/vision-focus
method	O
(	O
named	O
DSDI	O
)	O
by	O
incorporating	O
biased	O
resistance	O
loss	O
and	O
causal	O
intervention	O
tree	O
.	O

We	O
first	O
deeply	O
analyze	O
the	O
potential	O
causes	O
of	O
dual	O
imbalanced	O
problem	O
in	O
SGG	Computer/vision-focus
.	O

Despite	O
the	O
progress	O
of	O
action	Computer/vision-focus
recognition	Computer/vision-focus
algorithms	O
in	O
trimmed	O
videos	O
the	O
majority	O
of	O
real	O
-	O
world	O
videos	O
are	O
lengthy	O
and	O
untrimmed	O
with	O
sparse	O
segments	O
of	O
interest	O
.	O

The	O
task	O
of	O
temporal	O
activity	Computer/vision-focus
detection	Computer/vision-focus
in	O
untrimmed	O
videos	O
aims	O
to	O
localize	O
the	O
temporal	O
boundary	O
of	O
actions	O
and	O
classify	O
the	O
action	O
categories	O
.	O

Temporal	Computer/vision-focus
activity	Computer/vision-focus
detection	Computer/vision-focus
task	O
has	O
been	O
investigated	O
in	O
full	O
and	O
limited	O
supervision	O
settings	O
depending	O
on	O
the	O
availability	O
of	O
action	O
annotations	O
.	O

This	O
article	O
provides	O
an	O
extensive	O
overview	O
of	O
deep	O
learning	O
based	O
algorithms	O
to	O
tackle	O
temporal	Computer/vision-focus
action	Computer/vision-focus
detection	Computer/vision-focus
in	O
untrimmed	O
videos	O
with	O
different	O
supervision	O
levels	O
including	O
fully	O
-	O
supervised	O
weakly	O
-	O
supervised	O
unsupervised	O
self	O
-	O
supervised	O
and	O
semi	O
-	O
supervised	O
.	O

In	O
addition	O
,	O
this	O
article	O
reviews	O
advances	O
in	O
spatio	AI/ML/DL-focus
-	AI/ML/DL-focus
temporal	AI/ML/DL-focus
action	AI/ML/DL-focus
detection	AI/ML/DL-focus
temporal	O
ions	O
are	O
localized	O
in	O
both	O
temporal	O
and	O
spatial	O
dimensions	O
.	O

Action	Computer/vision-focus
detection	Computer/vision-focus
in	O
online	O
setting	O
is	O
also	O
reviewed	O
where	O
the	O
goal	O
is	O
to	O
detect	O
actions	O
in	O
each	O
frame	O
without	O
considering	O
any	O
future	O
context	O
in	O
a	O
live	O
video	O
stream	O
.	O

Finally	O
,	O
real	O
-	O
world	O
applications	O
of	O
temporal	Computer/vision-focus
action	Computer/vision-focus
detection	Computer/vision-focus
in	O
untrimmed	O
videos	O
and	O
a	O
set	O
of	O
future	O
directions	O
are	O
discussed	O
.	O

Neural	AI/ML/DL-focus
-	AI/ML/DL-focus
symbolic	AI/ML/DL-focus
learning	AI/ML/DL-focus
aiming	O
to	O
combine	O
the	O
perceiving	O
power	O
of	O
neural	O
perception	O
and	O
the	O
reasoning	O
power	O
of	O
symbolic	O
logic	O
together	O
,	O
has	O
drawn	O
increasing	O
research	O
attention	O
.	O

We	O
argue	O
that	O
such	O
a	O
mechanism	O
has	O
fundamental	O
limitations	O
in	O
building	O
an	O
effective	O
regression	O
loss	O
for	O
rotation	O
detection	O
,	O
especially	O
for	O
high	O
-	O
precision	O
detection	O
with	O
high	O
IoU	Statistical/Mathematical-metrics
(	O
e	O
.	O
g	O
.,	O
0	O
.	O
75	O
.	O

Existing	O
solutions	O
to	O
instance	Computer/vision-focus
-	Computer/vision-focus
level	Computer/vision-focus
visual	Computer/vision-focus
identification	Computer/vision-focus
usually	O
aim	O
to	O
learn	O
faithful	O
and	O
discriminative	O
feature	O
extractors	O
from	O
offline	O
training	O
data	O
and	O
directly	O
use	O
them	O
for	O
the	O
unseen	O
online	O
testing	O
data	O
.	O

Unlike	O
existing	O
online	O
visual	Computer/vision-focus
identification	Computer/vision-focus
methods	O
,	O
our	O
model	O
simultaneously	O
takes	O
both	O
the	O
sample	O
-	O
specific	O
discriminant	O
and	O
the	O
set	O
-	O
based	O
visual	O
similarity	O
among	O
testing	O
samples	O
into	O
consideration	O
.	O

Our	O
method	O
is	O
generally	O
suitable	O
to	O
any	O
off	O
-	O
the	O
-	O
shelf	O
offline	O
learned	O
visual	Computer/vision-focus
identification	Computer/vision-focus
baselines	O
for	O
online	O
performance	O
improvement	O
which	O
can	O
be	O
verified	O
by	O
extensive	O
experiments	O
on	O
several	O
widely	O
-	O
used	O
visual	O
identification	O
benchmarks	O
.	O

Additionally	O
,	O
$\	O
text	O
{	O
L	O
}{	O
A	O
}\	O
text	O
{	O
C	O
}{\	O
scriptsize	O
\	O
text	O
{	O
AS	O
}}\	O
text	O
{	O
T	O
}$	O
LACAST	O
achieved	O
an	O
F1	Classification-metrics
score	O
of	O
.	O
495	O
for	O
annotating	O
mathematical	O
expressions	O
with	O
relevant	O
textual	O
descriptions	O
,	O
which	O
is	O
a	O
significant	O
step	O
towards	O
advancing	O
searchability	O
,	O
readability	O
,	O
and	O
accessibility	O
of	O
mathematical	O
formulae	O
in	O
Wikipedia	O
.	O

Camera	O
-	O
based	O
3D	Computer/vision-focus
object	Computer/vision-focus
detectors	Computer/vision-focus
are	O
welcome	O
due	O
to	O
their	O
wider	O
deployment	O
and	O
lower	O
price	O
than	O
LiDAR	O
sensors	O
.	O

We	O
first	O
revisit	O
the	O
prior	O
stereo	Computer/vision-focus
detector	Computer/vision-focus
DSGN	O
for	O
its	O
stereo	O
volume	O
construction	O
ways	O
for	O
representing	O
both	O
3D	O
geometry	O
and	O
semantics	O
.	O

Typically	O
,	O
we	O
achieves	O
2	O
-	O
4	O
×	O
computation	O
reduction	O
and	O
up	O
to	O
61	O
.	O
5	O
%	O
real	O
-	O
world	O
acceleration	O
on	O
MobileNet	O
ResNet	O
-	O
50	O
and	O
Vision	O
Transformer	O
with	O
minimal	O
accuracy	Classification-metrics
drops	O
on	O
ImageNet	O
.	O

In	O
this	O
article	O
,	O
we	O
propose	O
a	O
unified	O
framework	O
to	O
solve	O
the	O
following	O
two	O
challenging	O
problems	O
in	O
incomplete	O
multi	Computer/vision-focus
-	Computer/vision-focus
view	Computer/vision-focus
representation	Computer/vision-focus
learning	Computer/vision-focus
i	O
)	O
how	O
to	O
learn	O
a	O
consistent	O
representation	O
unifying	O
different	O
views	O
,	O
and	O
ii	O
)	O
how	O
to	O
recover	O
the	O
missing	O
views	O
.	O

Extensive	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
remarkably	O
outperforms	O
20	O
competitive	O
multi	O
-	O
view	O
learning	O
methods	O
on	O
six	O
datasets	O
in	O
terms	O
of	O
clustering	AI/ML/DL-focus
classification	AI/ML/DL-focus
and	O
human	Computer/vision-focus
action	Computer/vision-focus
recognition	Computer/vision-focus
.	O

Image	Computer/vision-focus
forensics	Computer/vision-focus
is	O
a	O
rising	O
topic	O
as	O
the	O
trustworthy	O
multimedia	O
content	O
is	O
critical	O
for	O
modern	O
society	O
.	O

For	O
this	O
gap	O
,	O
we	O
attempt	O
to	O
investigate	O
the	O
forensic	Computer/vision-focus
-	Computer/vision-focus
oriented	Computer/vision-focus
image	Computer/vision-focus
representation	Computer/vision-focus
as	O
a	O
distinct	O
problem	O
,	O
from	O
the	O
perspectives	O
of	O
theory	O
,	O
implementation	O
,	O
and	O
application	O
.	O

We	O
demonstrate	O
the	O
above	O
arguments	O
on	O
the	O
dense	Computer/vision-focus
-	Computer/vision-focus
domain	Computer/vision-focus
pattern	Computer/vision-focus
detection	Computer/vision-focus
and	O
matching	O
experiments	O
,	O
providing	O
comparison	O
results	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
descriptors	O
.	O

In	O
this	O
article	O
,	O
we	O
study	O
the	O
symmetric	Data/Mining/Information/Retrieval-focus
nonnegative	Data/Mining/Information/Retrieval-focus
matrix	Data/Mining/Information/Retrieval-focus
factorization	Data/Mining/Information/Retrieval-focus
(	Data/Mining/Information/Retrieval-focus
SNMF	Data/Mining/Information/Retrieval-focus
)	Data/Mining/Information/Retrieval-focus
which	O
is	O
a	O
powerful	O
tool	O
in	O
data	O
mining	O
for	O
dimension	Data/Mining/Information/Retrieval-focus
reduction	Data/Mining/Information/Retrieval-focus
and	O
clustering	Data/Mining/Information/Retrieval-focus
.	O

The	O
main	O
contributions	O
of	O
the	O
present	O
work	O
include	O
:	O
(	O
i	O
)	O
a	O
new	O
descent	O
direction	O
for	O
the	O
rank	O
-	O
one	O
SNMF	O
is	O
derived	O
and	O
a	O
strategy	O
for	O
choosing	O
the	O
step	O
size	O
along	O
this	O
descent	O
direction	O
is	O
established	O
;	O
(	O
ii	O
)	O
a	O
progressive	O
hierarchical	O
alternating	O
least	O
squares	O
(	O
PHALS	O
)	O
SNMF	Data/Mining/Information/Retrieval-focus
d	O
for	O
SNMF	O
is	O
developed	O
,	O
which	O
is	O
parameter	O
-	O
free	O
and	O
updates	O
the	O
variables	O
column	O
by	O
column	O
.	O

Our	O
PHALS	O
provides	O
better	O
performance	O
in	O
terms	O
of	O
the	O
computational	O
accuracy	Classification-metrics
the	O
optimality	O
gap	O
,	O
and	O
the	O
CPU	O
time	O
,	O
compared	O
with	O
a	O
number	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SNMF	Data/Mining/Information/Retrieval-focus
methods	O
.	O

Our	O
PHALS	O
provides	O
better	O
performance	O
in	O
terms	O
of	O
the	O
computational	O
accuracy	Classification-metrics
the	O
optimality	O
gap	O
,	O
and	O
the	O
CPU	O
time	O
,	O
compared	O
with	O
a	O
number	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SNMF	Data/Mining/Information/Retrieval-focus
methods	O
.	O

